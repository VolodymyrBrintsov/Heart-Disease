{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import recall_score, make_scorer, roc_auc_score, accuracy_score, plot_roc_curve, f1_score, precision_score, confusion_matrix\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Paired\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "age           int64\n",
      "sex           int64\n",
      "cp            int64\n",
      "trestbps      int64\n",
      "chol          int64\n",
      "fbs           int64\n",
      "restecg       int64\n",
      "thalach       int64\n",
      "exang         int64\n",
      "oldpeak     float64\n",
      "slope         int64\n",
      "ca            int64\n",
      "thal          int64\n",
      "target        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#open data set\n",
    "df = pd.read_csv('../data/heart.csv')\n",
    "#sum nan values\n",
    "print(df.isna().sum())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladimir/.local/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show target count\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.countplot('target', data=df)\n",
    "plt.xticks(ticks = [0, 1],labels=('No problem with heart', 'Problem with heart'))\n",
    "plt.ylabel('Count')\n",
    "plt.title('Target parameter count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exang'] = df['exang'].apply(lambda x: 'yes' if x == 1 else 'no')\n",
    "df['cp'] = df['cp'].apply(lambda x: 'typical_angina' if x == 1 else\n",
    "                          'atypical_angina' if x == 2 else\n",
    "                          'non_anginal_pain' if x == 3 else\n",
    "                          'asymptomatic')\n",
    "df['fbs'] = df['fbs'].apply(lambda x: 'lower_than_120mg/ml' if x == 0 else 'higher_than_120mg/ml')\n",
    "df['restecg'] = df['restecg'].apply(lambda x: 'normal' if x == 0 else\n",
    "                                    'st_t_wave abnormality' if x == 1 else\n",
    "                                    'left_ventricular_hypertrophy')\n",
    "df['sex'] = df['sex'].apply(lambda x: 'male' if x == 1 else 'female')\n",
    "df['slope'] = df['slope'].apply(lambda x: 'upsloping' if x == 0 else 'flat' if x == 1 else 'downsloping')\n",
    "df['thal'] = df['thal'].apply(lambda x: 'normal' if x == 1 else 'fixed_defect' if x == 2 else 'reversable_defect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "x = pd.get_dummies(x)\n",
    "ct = ColumnTransformer([('scaled', StandardScaler(), x.columns)],\n",
    "                       remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show dataset\n",
    "pca = PCA(n_components=2)\n",
    "x_pca = pca.fit_transform(ct.fit_transform(x))\n",
    "df_pca = pd.DataFrame(data=x_pca, columns=['1 component', '2 component'])\n",
    "df_pca['target'] = y\n",
    "df_pca_heart_problem = df_pca[df_pca['target'] == 1]\n",
    "df_pca_no_heart_problem = df_pca[df_pca['target'] == 0]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(df_pca_no_heart_problem.iloc[:, 0], df_pca_no_heart_problem.iloc[:, 1], label='No heart problem')\n",
    "plt.scatter(df_pca_heart_problem.iloc[:, 0], df_pca_heart_problem.iloc[:, 1], label='Heart problem')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "x_train_scaled = ct.fit_transform(x_train)\n",
    "x_test_scaled = ct.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model(lr, neurons):\n",
    "    model=Sequential()\n",
    "    model.add(InputLayer(input_shape=(x.shape[1],)))\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=keras_model, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.8073 - acc: 0.3990 - val_loss: 0.8169 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8073 - acc: 0.3990 - val_loss: 0.8168 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8072 - acc: 0.3990 - val_loss: 0.8168 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8072 - acc: 0.3990 - val_loss: 0.8167 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8071 - acc: 0.3990 - val_loss: 0.8167 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8071 - acc: 0.3990 - val_loss: 0.8166 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8070 - acc: 0.3990 - val_loss: 0.8166 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8070 - acc: 0.3990 - val_loss: 0.8165 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8070 - acc: 0.3990 - val_loss: 0.8165 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8069 - acc: 0.3990 - val_loss: 0.8165 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8069 - acc: 0.3990 - val_loss: 0.8164 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8069 - acc: 0.3990 - val_loss: 0.8164 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8068 - acc: 0.3990 - val_loss: 0.8163 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8068 - acc: 0.3990 - val_loss: 0.8163 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8067 - acc: 0.3990 - val_loss: 0.8162 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8067 - acc: 0.3990 - val_loss: 0.8162 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8067 - acc: 0.4041 - val_loss: 0.8162 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8066 - acc: 0.4041 - val_loss: 0.8161 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8066 - acc: 0.4041 - val_loss: 0.8161 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8065 - acc: 0.4041 - val_loss: 0.8160 - val_acc: 0.4098\n",
      "WARNING:tensorflow:From /home/vladimir/.local/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1161 - acc: 0.3264 - val_loss: 1.0878 - val_acc: 0.2951\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1159 - acc: 0.3264 - val_loss: 1.0877 - val_acc: 0.2951\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1158 - acc: 0.3264 - val_loss: 1.0876 - val_acc: 0.2951\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1157 - acc: 0.3264 - val_loss: 1.0875 - val_acc: 0.2951\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1156 - acc: 0.3264 - val_loss: 1.0874 - val_acc: 0.2951\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1155 - acc: 0.3264 - val_loss: 1.0872 - val_acc: 0.2951\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1154 - acc: 0.3264 - val_loss: 1.0871 - val_acc: 0.2951\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1153 - acc: 0.3264 - val_loss: 1.0870 - val_acc: 0.2951\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1152 - acc: 0.3264 - val_loss: 1.0869 - val_acc: 0.2951\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1151 - acc: 0.3264 - val_loss: 1.0868 - val_acc: 0.2951\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1149 - acc: 0.3264 - val_loss: 1.0867 - val_acc: 0.2951\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1148 - acc: 0.3264 - val_loss: 1.0866 - val_acc: 0.2951\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1147 - acc: 0.3264 - val_loss: 1.0865 - val_acc: 0.2951\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1146 - acc: 0.3264 - val_loss: 1.0864 - val_acc: 0.2951\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1145 - acc: 0.3264 - val_loss: 1.0863 - val_acc: 0.2951\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1144 - acc: 0.3264 - val_loss: 1.0862 - val_acc: 0.2951\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1143 - acc: 0.3264 - val_loss: 1.0861 - val_acc: 0.2951\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1142 - acc: 0.3264 - val_loss: 1.0860 - val_acc: 0.2951\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1141 - acc: 0.3264 - val_loss: 1.0858 - val_acc: 0.2951\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1140 - acc: 0.3264 - val_loss: 1.0857 - val_acc: 0.2951\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8017 - acc: 0.4948 - val_loss: 0.8215 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8017 - acc: 0.4948 - val_loss: 0.8214 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8016 - acc: 0.4948 - val_loss: 0.8213 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8015 - acc: 0.4948 - val_loss: 0.8213 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8015 - acc: 0.4948 - val_loss: 0.8212 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8014 - acc: 0.4948 - val_loss: 0.8211 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8014 - acc: 0.4948 - val_loss: 0.8210 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8013 - acc: 0.4948 - val_loss: 0.8210 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8013 - acc: 0.4948 - val_loss: 0.8209 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8012 - acc: 0.4948 - val_loss: 0.8208 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8011 - acc: 0.4948 - val_loss: 0.8207 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8011 - acc: 0.4948 - val_loss: 0.8207 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8010 - acc: 0.4948 - val_loss: 0.8206 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8010 - acc: 0.4948 - val_loss: 0.8205 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8009 - acc: 0.4948 - val_loss: 0.8205 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8009 - acc: 0.4948 - val_loss: 0.8204 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8008 - acc: 0.4948 - val_loss: 0.8203 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8007 - acc: 0.4948 - val_loss: 0.8202 - val_acc: 0.4426\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8007 - acc: 0.4948 - val_loss: 0.8202 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8006 - acc: 0.4948 - val_loss: 0.8201 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7889 - acc: 0.4536 - val_loss: 0.6727 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7888 - acc: 0.4485 - val_loss: 0.6726 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7887 - acc: 0.4485 - val_loss: 0.6726 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7887 - acc: 0.4485 - val_loss: 0.6725 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7886 - acc: 0.4485 - val_loss: 0.6725 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7886 - acc: 0.4485 - val_loss: 0.6724 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7885 - acc: 0.4485 - val_loss: 0.6724 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7884 - acc: 0.4485 - val_loss: 0.6723 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7884 - acc: 0.4485 - val_loss: 0.6723 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7883 - acc: 0.4485 - val_loss: 0.6722 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7883 - acc: 0.4485 - val_loss: 0.6722 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7882 - acc: 0.4485 - val_loss: 0.6721 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7882 - acc: 0.4485 - val_loss: 0.6721 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7881 - acc: 0.4485 - val_loss: 0.6720 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7880 - acc: 0.4485 - val_loss: 0.6719 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7880 - acc: 0.4485 - val_loss: 0.6719 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7879 - acc: 0.4485 - val_loss: 0.6718 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7879 - acc: 0.4485 - val_loss: 0.6718 - val_acc: 0.6066\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7878 - acc: 0.4485 - val_loss: 0.6717 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7877 - acc: 0.4485 - val_loss: 0.6717 - val_acc: 0.6066\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9032 - acc: 0.4588 - val_loss: 0.7865 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9031 - acc: 0.4588 - val_loss: 0.7864 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9031 - acc: 0.4588 - val_loss: 0.7864 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9030 - acc: 0.4588 - val_loss: 0.7863 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9029 - acc: 0.4588 - val_loss: 0.7862 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9028 - acc: 0.4588 - val_loss: 0.7861 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9027 - acc: 0.4588 - val_loss: 0.7860 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9026 - acc: 0.4588 - val_loss: 0.7859 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9026 - acc: 0.4588 - val_loss: 0.7858 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9025 - acc: 0.4588 - val_loss: 0.7857 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9024 - acc: 0.4588 - val_loss: 0.7856 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9023 - acc: 0.4588 - val_loss: 0.7856 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9022 - acc: 0.4588 - val_loss: 0.7855 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9021 - acc: 0.4588 - val_loss: 0.7854 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9021 - acc: 0.4588 - val_loss: 0.7853 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9020 - acc: 0.4588 - val_loss: 0.7852 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9019 - acc: 0.4588 - val_loss: 0.7851 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9018 - acc: 0.4588 - val_loss: 0.7850 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9017 - acc: 0.4588 - val_loss: 0.7849 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9016 - acc: 0.4588 - val_loss: 0.7848 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7859 - acc: 0.4456 - val_loss: 0.8575 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7859 - acc: 0.4456 - val_loss: 0.8574 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7858 - acc: 0.4456 - val_loss: 0.8573 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7857 - acc: 0.4456 - val_loss: 0.8572 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7857 - acc: 0.4456 - val_loss: 0.8571 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7856 - acc: 0.4456 - val_loss: 0.8570 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7855 - acc: 0.4456 - val_loss: 0.8569 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7855 - acc: 0.4456 - val_loss: 0.8569 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7854 - acc: 0.4456 - val_loss: 0.8568 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7853 - acc: 0.4456 - val_loss: 0.8567 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7853 - acc: 0.4456 - val_loss: 0.8566 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7852 - acc: 0.4456 - val_loss: 0.8565 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7851 - acc: 0.4456 - val_loss: 0.8564 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7851 - acc: 0.4456 - val_loss: 0.8563 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7850 - acc: 0.4456 - val_loss: 0.8562 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7850 - acc: 0.4456 - val_loss: 0.8562 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7849 - acc: 0.4456 - val_loss: 0.8561 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7848 - acc: 0.4456 - val_loss: 0.8560 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7848 - acc: 0.4456 - val_loss: 0.8559 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7847 - acc: 0.4456 - val_loss: 0.8559 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7558 - acc: 0.5596 - val_loss: 0.8041 - val_acc: 0.5082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7557 - acc: 0.5596 - val_loss: 0.8040 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7556 - acc: 0.5596 - val_loss: 0.8039 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7556 - acc: 0.5596 - val_loss: 0.8039 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7555 - acc: 0.5596 - val_loss: 0.8038 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7554 - acc: 0.5596 - val_loss: 0.8037 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7554 - acc: 0.5596 - val_loss: 0.8037 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7553 - acc: 0.5596 - val_loss: 0.8036 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7553 - acc: 0.5596 - val_loss: 0.8036 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7552 - acc: 0.5596 - val_loss: 0.8035 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7552 - acc: 0.5596 - val_loss: 0.8034 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7551 - acc: 0.5596 - val_loss: 0.8034 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7550 - acc: 0.5596 - val_loss: 0.8033 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7550 - acc: 0.5596 - val_loss: 0.8033 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7549 - acc: 0.5596 - val_loss: 0.8032 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7549 - acc: 0.5596 - val_loss: 0.8031 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7548 - acc: 0.5596 - val_loss: 0.8031 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7548 - acc: 0.5596 - val_loss: 0.8030 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7547 - acc: 0.5596 - val_loss: 0.8029 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7546 - acc: 0.5596 - val_loss: 0.8029 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7095 - acc: 0.5979 - val_loss: 0.7653 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7094 - acc: 0.5979 - val_loss: 0.7652 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7093 - acc: 0.5979 - val_loss: 0.7651 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7092 - acc: 0.5979 - val_loss: 0.7650 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7091 - acc: 0.5979 - val_loss: 0.7649 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7090 - acc: 0.5979 - val_loss: 0.7648 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7089 - acc: 0.5979 - val_loss: 0.7647 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7088 - acc: 0.5979 - val_loss: 0.7646 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7088 - acc: 0.5979 - val_loss: 0.7645 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7087 - acc: 0.5979 - val_loss: 0.7644 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7086 - acc: 0.5979 - val_loss: 0.7643 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7085 - acc: 0.5979 - val_loss: 0.7642 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7084 - acc: 0.5979 - val_loss: 0.7641 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7083 - acc: 0.5979 - val_loss: 0.7640 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7082 - acc: 0.5979 - val_loss: 0.7639 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7081 - acc: 0.5979 - val_loss: 0.7639 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7080 - acc: 0.5979 - val_loss: 0.7638 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7080 - acc: 0.5979 - val_loss: 0.7637 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7079 - acc: 0.5979 - val_loss: 0.7636 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7078 - acc: 0.5979 - val_loss: 0.7635 - val_acc: 0.4590\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7874 - acc: 0.5206 - val_loss: 0.8314 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7873 - acc: 0.5206 - val_loss: 0.8313 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7872 - acc: 0.5206 - val_loss: 0.8312 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7872 - acc: 0.5206 - val_loss: 0.8311 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7871 - acc: 0.5206 - val_loss: 0.8310 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7870 - acc: 0.5206 - val_loss: 0.8309 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7869 - acc: 0.5206 - val_loss: 0.8308 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7868 - acc: 0.5206 - val_loss: 0.8307 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7867 - acc: 0.5206 - val_loss: 0.8306 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7866 - acc: 0.5206 - val_loss: 0.8305 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7865 - acc: 0.5206 - val_loss: 0.8304 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7865 - acc: 0.5206 - val_loss: 0.8303 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7864 - acc: 0.5206 - val_loss: 0.8302 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7863 - acc: 0.5206 - val_loss: 0.8301 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7862 - acc: 0.5206 - val_loss: 0.8300 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7861 - acc: 0.5206 - val_loss: 0.8299 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7860 - acc: 0.5206 - val_loss: 0.8298 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7860 - acc: 0.5206 - val_loss: 0.8297 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7859 - acc: 0.5206 - val_loss: 0.8296 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7858 - acc: 0.5206 - val_loss: 0.8295 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8453 - acc: 0.4278 - val_loss: 0.9037 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8452 - acc: 0.4278 - val_loss: 0.9036 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8451 - acc: 0.4278 - val_loss: 0.9035 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8450 - acc: 0.4278 - val_loss: 0.9034 - val_acc: 0.3770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8449 - acc: 0.4278 - val_loss: 0.9033 - val_acc: 0.3770\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8448 - acc: 0.4278 - val_loss: 0.9031 - val_acc: 0.3770\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8447 - acc: 0.4278 - val_loss: 0.9030 - val_acc: 0.3770\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8446 - acc: 0.4278 - val_loss: 0.9029 - val_acc: 0.3770\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8445 - acc: 0.4278 - val_loss: 0.9028 - val_acc: 0.3770\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8444 - acc: 0.4278 - val_loss: 0.9027 - val_acc: 0.3770\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8443 - acc: 0.4278 - val_loss: 0.9026 - val_acc: 0.3770\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8442 - acc: 0.4278 - val_loss: 0.9024 - val_acc: 0.3770\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8441 - acc: 0.4278 - val_loss: 0.9023 - val_acc: 0.3770\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8440 - acc: 0.4278 - val_loss: 0.9022 - val_acc: 0.3770\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8439 - acc: 0.4278 - val_loss: 0.9021 - val_acc: 0.3770\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8438 - acc: 0.4278 - val_loss: 0.9020 - val_acc: 0.3770\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8437 - acc: 0.4278 - val_loss: 0.9019 - val_acc: 0.3770\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8436 - acc: 0.4278 - val_loss: 0.9018 - val_acc: 0.3770\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8435 - acc: 0.4278 - val_loss: 0.9016 - val_acc: 0.3770\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8434 - acc: 0.4278 - val_loss: 0.9015 - val_acc: 0.3770\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5956 - acc: 0.7098 - val_loss: 0.6083 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5955 - acc: 0.7098 - val_loss: 0.6083 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5955 - acc: 0.7098 - val_loss: 0.6082 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5954 - acc: 0.7098 - val_loss: 0.6081 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5953 - acc: 0.7098 - val_loss: 0.6080 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5952 - acc: 0.7098 - val_loss: 0.6080 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5952 - acc: 0.7098 - val_loss: 0.6079 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5951 - acc: 0.7098 - val_loss: 0.6078 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5950 - acc: 0.7098 - val_loss: 0.6077 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5949 - acc: 0.7098 - val_loss: 0.6077 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5949 - acc: 0.7098 - val_loss: 0.6076 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5948 - acc: 0.7098 - val_loss: 0.6075 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5947 - acc: 0.7098 - val_loss: 0.6075 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5947 - acc: 0.7098 - val_loss: 0.6074 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5946 - acc: 0.7098 - val_loss: 0.6073 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5945 - acc: 0.7098 - val_loss: 0.6073 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5945 - acc: 0.7098 - val_loss: 0.6072 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5944 - acc: 0.7098 - val_loss: 0.6071 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5943 - acc: 0.7098 - val_loss: 0.6070 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5942 - acc: 0.7098 - val_loss: 0.6070 - val_acc: 0.6721\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7405 - acc: 0.5440 - val_loss: 0.6997 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7403 - acc: 0.5440 - val_loss: 0.6996 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7402 - acc: 0.5440 - val_loss: 0.6995 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7401 - acc: 0.5440 - val_loss: 0.6994 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7400 - acc: 0.5440 - val_loss: 0.6993 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7399 - acc: 0.5440 - val_loss: 0.6992 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7398 - acc: 0.5440 - val_loss: 0.6991 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7397 - acc: 0.5440 - val_loss: 0.6990 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7395 - acc: 0.5440 - val_loss: 0.6989 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7394 - acc: 0.5440 - val_loss: 0.6988 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7393 - acc: 0.5440 - val_loss: 0.6987 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7392 - acc: 0.5440 - val_loss: 0.6986 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7391 - acc: 0.5440 - val_loss: 0.6986 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7390 - acc: 0.5440 - val_loss: 0.6985 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7389 - acc: 0.5440 - val_loss: 0.6984 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7388 - acc: 0.5440 - val_loss: 0.6983 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7386 - acc: 0.5440 - val_loss: 0.6982 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7385 - acc: 0.5440 - val_loss: 0.6981 - val_acc: 0.6066\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7384 - acc: 0.5440 - val_loss: 0.6980 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7383 - acc: 0.5440 - val_loss: 0.6979 - val_acc: 0.6066\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7806 - acc: 0.4845 - val_loss: 0.8543 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7805 - acc: 0.4845 - val_loss: 0.8542 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7804 - acc: 0.4845 - val_loss: 0.8540 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7802 - acc: 0.4845 - val_loss: 0.8539 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7801 - acc: 0.4845 - val_loss: 0.8538 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7800 - acc: 0.4845 - val_loss: 0.8536 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7799 - acc: 0.4845 - val_loss: 0.8535 - val_acc: 0.3934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7797 - acc: 0.4845 - val_loss: 0.8534 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7796 - acc: 0.4845 - val_loss: 0.8533 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7795 - acc: 0.4845 - val_loss: 0.8531 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7794 - acc: 0.4845 - val_loss: 0.8530 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7793 - acc: 0.4845 - val_loss: 0.8529 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7792 - acc: 0.4845 - val_loss: 0.8527 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7790 - acc: 0.4845 - val_loss: 0.8526 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7789 - acc: 0.4845 - val_loss: 0.8525 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7788 - acc: 0.4845 - val_loss: 0.8524 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7787 - acc: 0.4845 - val_loss: 0.8523 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7786 - acc: 0.4845 - val_loss: 0.8521 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7785 - acc: 0.4845 - val_loss: 0.8520 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7784 - acc: 0.4845 - val_loss: 0.8519 - val_acc: 0.3934\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7878 - acc: 0.4948 - val_loss: 0.8296 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7877 - acc: 0.4948 - val_loss: 0.8295 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7876 - acc: 0.4948 - val_loss: 0.8294 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7874 - acc: 0.4948 - val_loss: 0.8293 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7873 - acc: 0.4948 - val_loss: 0.8291 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7872 - acc: 0.4948 - val_loss: 0.8290 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7871 - acc: 0.4948 - val_loss: 0.8289 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7870 - acc: 0.4948 - val_loss: 0.8288 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7869 - acc: 0.4948 - val_loss: 0.8287 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7868 - acc: 0.4948 - val_loss: 0.8285 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7867 - acc: 0.4948 - val_loss: 0.8284 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7866 - acc: 0.4948 - val_loss: 0.8283 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7865 - acc: 0.4948 - val_loss: 0.8282 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7864 - acc: 0.4948 - val_loss: 0.8280 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7863 - acc: 0.4948 - val_loss: 0.8279 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7862 - acc: 0.4948 - val_loss: 0.8278 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7860 - acc: 0.4948 - val_loss: 0.8277 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7859 - acc: 0.4948 - val_loss: 0.8276 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7858 - acc: 0.4948 - val_loss: 0.8274 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7857 - acc: 0.4948 - val_loss: 0.8273 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8298 - acc: 0.4691 - val_loss: 0.7913 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8297 - acc: 0.4691 - val_loss: 0.7912 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8296 - acc: 0.4691 - val_loss: 0.7911 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8294 - acc: 0.4691 - val_loss: 0.7910 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8293 - acc: 0.4691 - val_loss: 0.7909 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8292 - acc: 0.4691 - val_loss: 0.7908 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8291 - acc: 0.4691 - val_loss: 0.7907 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8290 - acc: 0.4691 - val_loss: 0.7905 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8289 - acc: 0.4691 - val_loss: 0.7904 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8287 - acc: 0.4691 - val_loss: 0.7903 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8286 - acc: 0.4691 - val_loss: 0.7902 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8285 - acc: 0.4691 - val_loss: 0.7901 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8284 - acc: 0.4691 - val_loss: 0.7900 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8283 - acc: 0.4691 - val_loss: 0.7899 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8282 - acc: 0.4691 - val_loss: 0.7898 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8280 - acc: 0.4691 - val_loss: 0.7897 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8279 - acc: 0.4691 - val_loss: 0.7895 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8278 - acc: 0.4691 - val_loss: 0.7894 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8277 - acc: 0.4691 - val_loss: 0.7893 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8276 - acc: 0.4691 - val_loss: 0.7892 - val_acc: 0.4590\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8748 - acc: 0.3161 - val_loss: 0.9158 - val_acc: 0.2459\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8746 - acc: 0.3161 - val_loss: 0.9156 - val_acc: 0.2459\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8744 - acc: 0.3161 - val_loss: 0.9154 - val_acc: 0.2459\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8742 - acc: 0.3161 - val_loss: 0.9152 - val_acc: 0.2459\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8740 - acc: 0.3161 - val_loss: 0.9150 - val_acc: 0.2459\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8738 - acc: 0.3161 - val_loss: 0.9147 - val_acc: 0.2459\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8736 - acc: 0.3161 - val_loss: 0.9145 - val_acc: 0.2459\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8734 - acc: 0.3161 - val_loss: 0.9143 - val_acc: 0.2459\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8732 - acc: 0.3161 - val_loss: 0.9141 - val_acc: 0.2459\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8730 - acc: 0.3161 - val_loss: 0.9139 - val_acc: 0.2459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8728 - acc: 0.3161 - val_loss: 0.9137 - val_acc: 0.2459\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8726 - acc: 0.3161 - val_loss: 0.9135 - val_acc: 0.2459\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8724 - acc: 0.3161 - val_loss: 0.9133 - val_acc: 0.2459\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8722 - acc: 0.3161 - val_loss: 0.9131 - val_acc: 0.2459\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8721 - acc: 0.3161 - val_loss: 0.9129 - val_acc: 0.2459\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8719 - acc: 0.3161 - val_loss: 0.9127 - val_acc: 0.2459\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8717 - acc: 0.3161 - val_loss: 0.9125 - val_acc: 0.2459\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8715 - acc: 0.3109 - val_loss: 0.9124 - val_acc: 0.2459\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8713 - acc: 0.3161 - val_loss: 0.9122 - val_acc: 0.2459\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8711 - acc: 0.3161 - val_loss: 0.9120 - val_acc: 0.2459\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7195 - acc: 0.5855 - val_loss: 0.6787 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7193 - acc: 0.5855 - val_loss: 0.6785 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7191 - acc: 0.5855 - val_loss: 0.6784 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7190 - acc: 0.5855 - val_loss: 0.6782 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7188 - acc: 0.5855 - val_loss: 0.6780 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7187 - acc: 0.5855 - val_loss: 0.6779 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7186 - acc: 0.5855 - val_loss: 0.6777 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7184 - acc: 0.5855 - val_loss: 0.6776 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7183 - acc: 0.5855 - val_loss: 0.6774 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7182 - acc: 0.5855 - val_loss: 0.6773 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7180 - acc: 0.5855 - val_loss: 0.6771 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7179 - acc: 0.5855 - val_loss: 0.6770 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7178 - acc: 0.5855 - val_loss: 0.6769 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7177 - acc: 0.5855 - val_loss: 0.6767 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7175 - acc: 0.5855 - val_loss: 0.6766 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7174 - acc: 0.5855 - val_loss: 0.6765 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7173 - acc: 0.5855 - val_loss: 0.6763 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7172 - acc: 0.5855 - val_loss: 0.6762 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7170 - acc: 0.5855 - val_loss: 0.6760 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7169 - acc: 0.5855 - val_loss: 0.6759 - val_acc: 0.6066\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7466 - acc: 0.4742 - val_loss: 0.7556 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7464 - acc: 0.4742 - val_loss: 0.7554 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7462 - acc: 0.4742 - val_loss: 0.7552 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7460 - acc: 0.4742 - val_loss: 0.7550 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7458 - acc: 0.4794 - val_loss: 0.7548 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7456 - acc: 0.4794 - val_loss: 0.7545 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7454 - acc: 0.4794 - val_loss: 0.7543 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7453 - acc: 0.4794 - val_loss: 0.7541 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7451 - acc: 0.4794 - val_loss: 0.7539 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7449 - acc: 0.4794 - val_loss: 0.7537 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7447 - acc: 0.4794 - val_loss: 0.7535 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7445 - acc: 0.4794 - val_loss: 0.7533 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7443 - acc: 0.4794 - val_loss: 0.7531 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7441 - acc: 0.4794 - val_loss: 0.7529 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7439 - acc: 0.4794 - val_loss: 0.7527 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7437 - acc: 0.4794 - val_loss: 0.7525 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7435 - acc: 0.4794 - val_loss: 0.7523 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7434 - acc: 0.4845 - val_loss: 0.7520 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7432 - acc: 0.4845 - val_loss: 0.7518 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7430 - acc: 0.4845 - val_loss: 0.7516 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7116 - acc: 0.5567 - val_loss: 0.7875 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7114 - acc: 0.5567 - val_loss: 0.7873 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7113 - acc: 0.5567 - val_loss: 0.7871 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7111 - acc: 0.5567 - val_loss: 0.7869 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7110 - acc: 0.5567 - val_loss: 0.7867 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7108 - acc: 0.5567 - val_loss: 0.7865 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7107 - acc: 0.5567 - val_loss: 0.7863 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7105 - acc: 0.5567 - val_loss: 0.7861 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7103 - acc: 0.5567 - val_loss: 0.7859 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7102 - acc: 0.5567 - val_loss: 0.7857 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7100 - acc: 0.5567 - val_loss: 0.7855 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7099 - acc: 0.5567 - val_loss: 0.7853 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7097 - acc: 0.5567 - val_loss: 0.7850 - val_acc: 0.4426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7096 - acc: 0.5567 - val_loss: 0.7848 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7094 - acc: 0.5567 - val_loss: 0.7846 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7093 - acc: 0.5567 - val_loss: 0.7844 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7091 - acc: 0.5567 - val_loss: 0.7842 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7090 - acc: 0.5567 - val_loss: 0.7840 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7088 - acc: 0.5567 - val_loss: 0.7838 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7087 - acc: 0.5567 - val_loss: 0.7836 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6165 - acc: 0.6701 - val_loss: 0.5899 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6163 - acc: 0.6701 - val_loss: 0.5897 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6162 - acc: 0.6701 - val_loss: 0.5896 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6161 - acc: 0.6701 - val_loss: 0.5895 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6160 - acc: 0.6701 - val_loss: 0.5894 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6158 - acc: 0.6701 - val_loss: 0.5892 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6157 - acc: 0.6701 - val_loss: 0.5891 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6156 - acc: 0.6701 - val_loss: 0.5890 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6155 - acc: 0.6753 - val_loss: 0.5889 - val_acc: 0.7049\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6154 - acc: 0.6753 - val_loss: 0.5888 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6152 - acc: 0.6753 - val_loss: 0.5886 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6151 - acc: 0.6753 - val_loss: 0.5885 - val_acc: 0.7049\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6150 - acc: 0.6753 - val_loss: 0.5884 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6149 - acc: 0.6753 - val_loss: 0.5883 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6147 - acc: 0.6753 - val_loss: 0.5881 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6146 - acc: 0.6753 - val_loss: 0.5880 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6145 - acc: 0.6753 - val_loss: 0.5879 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6144 - acc: 0.6753 - val_loss: 0.5878 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6143 - acc: 0.6753 - val_loss: 0.5877 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6141 - acc: 0.6753 - val_loss: 0.5875 - val_acc: 0.7049\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8074 - acc: 0.3368 - val_loss: 0.8120 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8071 - acc: 0.3368 - val_loss: 0.8117 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8068 - acc: 0.3368 - val_loss: 0.8114 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8065 - acc: 0.3368 - val_loss: 0.8110 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8062 - acc: 0.3368 - val_loss: 0.8107 - val_acc: 0.3770\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8060 - acc: 0.3368 - val_loss: 0.8104 - val_acc: 0.3770\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8057 - acc: 0.3368 - val_loss: 0.8101 - val_acc: 0.3770\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8054 - acc: 0.3368 - val_loss: 0.8098 - val_acc: 0.3770\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8052 - acc: 0.3368 - val_loss: 0.8095 - val_acc: 0.3770\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8049 - acc: 0.3368 - val_loss: 0.8092 - val_acc: 0.3770\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8046 - acc: 0.3368 - val_loss: 0.8089 - val_acc: 0.3770\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8044 - acc: 0.3368 - val_loss: 0.8086 - val_acc: 0.3770\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8041 - acc: 0.3368 - val_loss: 0.8083 - val_acc: 0.3770\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8039 - acc: 0.3368 - val_loss: 0.8081 - val_acc: 0.3770\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8036 - acc: 0.3368 - val_loss: 0.8078 - val_acc: 0.3770\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8033 - acc: 0.3368 - val_loss: 0.8074 - val_acc: 0.3770\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8031 - acc: 0.3368 - val_loss: 0.8071 - val_acc: 0.3770\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8028 - acc: 0.3368 - val_loss: 0.8068 - val_acc: 0.3770\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8025 - acc: 0.3368 - val_loss: 0.8065 - val_acc: 0.3770\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8022 - acc: 0.3368 - val_loss: 0.8062 - val_acc: 0.3770\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6495 - acc: 0.6425 - val_loss: 0.6386 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6493 - acc: 0.6425 - val_loss: 0.6384 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6491 - acc: 0.6425 - val_loss: 0.6382 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6489 - acc: 0.6425 - val_loss: 0.6380 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6487 - acc: 0.6425 - val_loss: 0.6378 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6486 - acc: 0.6425 - val_loss: 0.6376 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6484 - acc: 0.6425 - val_loss: 0.6374 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6482 - acc: 0.6425 - val_loss: 0.6372 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6480 - acc: 0.6477 - val_loss: 0.6370 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6478 - acc: 0.6477 - val_loss: 0.6368 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6477 - acc: 0.6477 - val_loss: 0.6366 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6475 - acc: 0.6477 - val_loss: 0.6364 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6473 - acc: 0.6477 - val_loss: 0.6362 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6471 - acc: 0.6477 - val_loss: 0.6360 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6469 - acc: 0.6477 - val_loss: 0.6358 - val_acc: 0.6885\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6468 - acc: 0.6477 - val_loss: 0.6356 - val_acc: 0.6885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6466 - acc: 0.6477 - val_loss: 0.6354 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6464 - acc: 0.6477 - val_loss: 0.6353 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6463 - acc: 0.6477 - val_loss: 0.6351 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6461 - acc: 0.6477 - val_loss: 0.6349 - val_acc: 0.6885\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7565 - acc: 0.3969 - val_loss: 0.7515 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7562 - acc: 0.3969 - val_loss: 0.7512 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7560 - acc: 0.3918 - val_loss: 0.7509 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7557 - acc: 0.3918 - val_loss: 0.7506 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7554 - acc: 0.3918 - val_loss: 0.7503 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7551 - acc: 0.3918 - val_loss: 0.7500 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7548 - acc: 0.3918 - val_loss: 0.7497 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7546 - acc: 0.3918 - val_loss: 0.7494 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7543 - acc: 0.3918 - val_loss: 0.7491 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7540 - acc: 0.3918 - val_loss: 0.7488 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7537 - acc: 0.3918 - val_loss: 0.7485 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7534 - acc: 0.3918 - val_loss: 0.7482 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7531 - acc: 0.3969 - val_loss: 0.7479 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7529 - acc: 0.3969 - val_loss: 0.7476 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7526 - acc: 0.4021 - val_loss: 0.7473 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7523 - acc: 0.4072 - val_loss: 0.7470 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7520 - acc: 0.4072 - val_loss: 0.7467 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7517 - acc: 0.4072 - val_loss: 0.7464 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7515 - acc: 0.4072 - val_loss: 0.7461 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7512 - acc: 0.4072 - val_loss: 0.7458 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7840 - acc: 0.4278 - val_loss: 0.7586 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7837 - acc: 0.4278 - val_loss: 0.7584 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7834 - acc: 0.4278 - val_loss: 0.7581 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7831 - acc: 0.4278 - val_loss: 0.7578 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7828 - acc: 0.4278 - val_loss: 0.7576 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7826 - acc: 0.4278 - val_loss: 0.7573 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7823 - acc: 0.4278 - val_loss: 0.7570 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7820 - acc: 0.4278 - val_loss: 0.7567 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7818 - acc: 0.4278 - val_loss: 0.7565 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7815 - acc: 0.4278 - val_loss: 0.7562 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7813 - acc: 0.4278 - val_loss: 0.7560 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7810 - acc: 0.4278 - val_loss: 0.7557 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7807 - acc: 0.4278 - val_loss: 0.7554 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7804 - acc: 0.4278 - val_loss: 0.7552 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7802 - acc: 0.4278 - val_loss: 0.7549 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7799 - acc: 0.4278 - val_loss: 0.7546 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7797 - acc: 0.4278 - val_loss: 0.7544 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7794 - acc: 0.4278 - val_loss: 0.7541 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7791 - acc: 0.4278 - val_loss: 0.7538 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7789 - acc: 0.4330 - val_loss: 0.7536 - val_acc: 0.4590\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6849 - acc: 0.5670 - val_loss: 0.7283 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6847 - acc: 0.5670 - val_loss: 0.7280 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6844 - acc: 0.5670 - val_loss: 0.7277 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6842 - acc: 0.5722 - val_loss: 0.7275 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6840 - acc: 0.5722 - val_loss: 0.7272 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6838 - acc: 0.5722 - val_loss: 0.7270 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6836 - acc: 0.5722 - val_loss: 0.7267 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6833 - acc: 0.5722 - val_loss: 0.7264 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6831 - acc: 0.5722 - val_loss: 0.7262 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6829 - acc: 0.5722 - val_loss: 0.7259 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6827 - acc: 0.5722 - val_loss: 0.7256 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6824 - acc: 0.5722 - val_loss: 0.7254 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6822 - acc: 0.5722 - val_loss: 0.7251 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6820 - acc: 0.5722 - val_loss: 0.7249 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6818 - acc: 0.5722 - val_loss: 0.7246 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6816 - acc: 0.5722 - val_loss: 0.7243 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6813 - acc: 0.5722 - val_loss: 0.7240 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6811 - acc: 0.5722 - val_loss: 0.7237 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6809 - acc: 0.5722 - val_loss: 0.7235 - val_acc: 0.4426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6807 - acc: 0.5722 - val_loss: 0.7233 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7169 - acc: 0.4663 - val_loss: 0.7013 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7165 - acc: 0.4663 - val_loss: 0.7009 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7162 - acc: 0.4663 - val_loss: 0.7006 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7158 - acc: 0.4663 - val_loss: 0.7002 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7155 - acc: 0.4663 - val_loss: 0.6998 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7152 - acc: 0.4663 - val_loss: 0.6995 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7149 - acc: 0.4663 - val_loss: 0.6992 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7146 - acc: 0.4663 - val_loss: 0.6988 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7142 - acc: 0.4663 - val_loss: 0.6984 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7139 - acc: 0.4663 - val_loss: 0.6981 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7136 - acc: 0.4663 - val_loss: 0.6978 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7133 - acc: 0.4663 - val_loss: 0.6975 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7130 - acc: 0.4767 - val_loss: 0.6971 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7127 - acc: 0.4767 - val_loss: 0.6968 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7124 - acc: 0.4767 - val_loss: 0.6964 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7121 - acc: 0.4767 - val_loss: 0.6961 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7117 - acc: 0.4767 - val_loss: 0.6957 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7114 - acc: 0.4767 - val_loss: 0.6954 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7111 - acc: 0.4767 - val_loss: 0.6950 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7108 - acc: 0.4767 - val_loss: 0.6946 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7198 - acc: 0.4560 - val_loss: 0.6878 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7195 - acc: 0.4560 - val_loss: 0.6875 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7191 - acc: 0.4560 - val_loss: 0.6871 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7188 - acc: 0.4560 - val_loss: 0.6868 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7185 - acc: 0.4560 - val_loss: 0.6865 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7182 - acc: 0.4560 - val_loss: 0.6862 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7179 - acc: 0.4611 - val_loss: 0.6858 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7176 - acc: 0.4611 - val_loss: 0.6855 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7173 - acc: 0.4611 - val_loss: 0.6852 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7170 - acc: 0.4611 - val_loss: 0.6849 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7167 - acc: 0.4611 - val_loss: 0.6846 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7164 - acc: 0.4611 - val_loss: 0.6843 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7161 - acc: 0.4611 - val_loss: 0.6840 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7158 - acc: 0.4611 - val_loss: 0.6837 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7155 - acc: 0.4611 - val_loss: 0.6834 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7152 - acc: 0.4611 - val_loss: 0.6830 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7149 - acc: 0.4611 - val_loss: 0.6827 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7146 - acc: 0.4611 - val_loss: 0.6824 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7143 - acc: 0.4611 - val_loss: 0.6821 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7140 - acc: 0.4611 - val_loss: 0.6817 - val_acc: 0.5902\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6633 - acc: 0.6392 - val_loss: 0.6334 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6629 - acc: 0.6443 - val_loss: 0.6330 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6626 - acc: 0.6443 - val_loss: 0.6326 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6622 - acc: 0.6443 - val_loss: 0.6322 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6619 - acc: 0.6443 - val_loss: 0.6318 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6615 - acc: 0.6392 - val_loss: 0.6315 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6612 - acc: 0.6443 - val_loss: 0.6310 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6608 - acc: 0.6443 - val_loss: 0.6307 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6605 - acc: 0.6443 - val_loss: 0.6303 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6601 - acc: 0.6443 - val_loss: 0.6299 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6598 - acc: 0.6443 - val_loss: 0.6295 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6594 - acc: 0.6443 - val_loss: 0.6291 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6591 - acc: 0.6443 - val_loss: 0.6287 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6587 - acc: 0.6443 - val_loss: 0.6283 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6584 - acc: 0.6443 - val_loss: 0.6279 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6580 - acc: 0.6443 - val_loss: 0.6275 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6577 - acc: 0.6495 - val_loss: 0.6272 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6574 - acc: 0.6495 - val_loss: 0.6268 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6571 - acc: 0.6495 - val_loss: 0.6265 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6567 - acc: 0.6495 - val_loss: 0.6261 - val_acc: 0.6721\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7147 - acc: 0.5103 - val_loss: 0.7160 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7143 - acc: 0.5103 - val_loss: 0.7156 - val_acc: 0.4098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7139 - acc: 0.5103 - val_loss: 0.7153 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7136 - acc: 0.5103 - val_loss: 0.7149 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7132 - acc: 0.5103 - val_loss: 0.7145 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7128 - acc: 0.5103 - val_loss: 0.7141 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7125 - acc: 0.5103 - val_loss: 0.7137 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7121 - acc: 0.5155 - val_loss: 0.7133 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7118 - acc: 0.5155 - val_loss: 0.7129 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7114 - acc: 0.5155 - val_loss: 0.7125 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7111 - acc: 0.5155 - val_loss: 0.7122 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7107 - acc: 0.5155 - val_loss: 0.7118 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7103 - acc: 0.5155 - val_loss: 0.7114 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7100 - acc: 0.5155 - val_loss: 0.7110 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7096 - acc: 0.5155 - val_loss: 0.7107 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7093 - acc: 0.5206 - val_loss: 0.7103 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7089 - acc: 0.5206 - val_loss: 0.7099 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7086 - acc: 0.5206 - val_loss: 0.7096 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7082 - acc: 0.5206 - val_loss: 0.7092 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7079 - acc: 0.5206 - val_loss: 0.7088 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6590 - acc: 0.6392 - val_loss: 0.6374 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6587 - acc: 0.6392 - val_loss: 0.6371 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6584 - acc: 0.6392 - val_loss: 0.6368 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6581 - acc: 0.6392 - val_loss: 0.6366 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6579 - acc: 0.6392 - val_loss: 0.6363 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6576 - acc: 0.6392 - val_loss: 0.6360 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6573 - acc: 0.6392 - val_loss: 0.6357 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6571 - acc: 0.6392 - val_loss: 0.6355 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6568 - acc: 0.6392 - val_loss: 0.6352 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6565 - acc: 0.6392 - val_loss: 0.6350 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6563 - acc: 0.6392 - val_loss: 0.6347 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6560 - acc: 0.6392 - val_loss: 0.6345 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6558 - acc: 0.6392 - val_loss: 0.6342 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6555 - acc: 0.6392 - val_loss: 0.6339 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6552 - acc: 0.6443 - val_loss: 0.6337 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6550 - acc: 0.6443 - val_loss: 0.6334 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6547 - acc: 0.6443 - val_loss: 0.6331 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6544 - acc: 0.6443 - val_loss: 0.6329 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6542 - acc: 0.6443 - val_loss: 0.6326 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6539 - acc: 0.6443 - val_loss: 0.6324 - val_acc: 0.6885\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7552 - acc: 0.3109 - val_loss: 0.7651 - val_acc: 0.2131\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7546 - acc: 0.3109 - val_loss: 0.7645 - val_acc: 0.2131\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7541 - acc: 0.3109 - val_loss: 0.7639 - val_acc: 0.2131\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7535 - acc: 0.3161 - val_loss: 0.7633 - val_acc: 0.2131\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7530 - acc: 0.3161 - val_loss: 0.7627 - val_acc: 0.2131\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7524 - acc: 0.3161 - val_loss: 0.7622 - val_acc: 0.2131\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7519 - acc: 0.3161 - val_loss: 0.7616 - val_acc: 0.2131\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7514 - acc: 0.3161 - val_loss: 0.7611 - val_acc: 0.2131\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7509 - acc: 0.3161 - val_loss: 0.7605 - val_acc: 0.2295\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7503 - acc: 0.3161 - val_loss: 0.7599 - val_acc: 0.2295\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7498 - acc: 0.3161 - val_loss: 0.7594 - val_acc: 0.2295\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7493 - acc: 0.3161 - val_loss: 0.7588 - val_acc: 0.2295\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7489 - acc: 0.3161 - val_loss: 0.7583 - val_acc: 0.2459\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7484 - acc: 0.3161 - val_loss: 0.7578 - val_acc: 0.2459\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7478 - acc: 0.3161 - val_loss: 0.7573 - val_acc: 0.2459\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7473 - acc: 0.3161 - val_loss: 0.7568 - val_acc: 0.2459\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7468 - acc: 0.3212 - val_loss: 0.7562 - val_acc: 0.2459\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7463 - acc: 0.3212 - val_loss: 0.7556 - val_acc: 0.2459\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7458 - acc: 0.3212 - val_loss: 0.7551 - val_acc: 0.2459\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7453 - acc: 0.3212 - val_loss: 0.7546 - val_acc: 0.2459\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7127 - acc: 0.4249 - val_loss: 0.7367 - val_acc: 0.2787\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7122 - acc: 0.4249 - val_loss: 0.7362 - val_acc: 0.2787\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7117 - acc: 0.4249 - val_loss: 0.7357 - val_acc: 0.2787\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7113 - acc: 0.4352 - val_loss: 0.7352 - val_acc: 0.2951\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7109 - acc: 0.4456 - val_loss: 0.7347 - val_acc: 0.2951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7104 - acc: 0.4456 - val_loss: 0.7342 - val_acc: 0.2951\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7100 - acc: 0.4456 - val_loss: 0.7338 - val_acc: 0.3115\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7096 - acc: 0.4456 - val_loss: 0.7333 - val_acc: 0.3279\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7091 - acc: 0.4456 - val_loss: 0.7328 - val_acc: 0.3279\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7086 - acc: 0.4456 - val_loss: 0.7323 - val_acc: 0.3279\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7082 - acc: 0.4508 - val_loss: 0.7318 - val_acc: 0.3279\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7078 - acc: 0.4508 - val_loss: 0.7313 - val_acc: 0.3443\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7073 - acc: 0.4508 - val_loss: 0.7308 - val_acc: 0.3443\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7069 - acc: 0.4508 - val_loss: 0.7303 - val_acc: 0.3443\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7065 - acc: 0.4508 - val_loss: 0.7298 - val_acc: 0.3443\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7060 - acc: 0.4508 - val_loss: 0.7293 - val_acc: 0.3443\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7056 - acc: 0.4560 - val_loss: 0.7288 - val_acc: 0.3443\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7051 - acc: 0.4560 - val_loss: 0.7284 - val_acc: 0.3443\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7047 - acc: 0.4611 - val_loss: 0.7279 - val_acc: 0.3607\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7043 - acc: 0.4560 - val_loss: 0.7274 - val_acc: 0.3607\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7736 - acc: 0.2474 - val_loss: 0.8009 - val_acc: 0.2459\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7729 - acc: 0.2526 - val_loss: 0.8002 - val_acc: 0.2459\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7723 - acc: 0.2526 - val_loss: 0.7995 - val_acc: 0.2459\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7717 - acc: 0.2526 - val_loss: 0.7989 - val_acc: 0.2459\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7712 - acc: 0.2526 - val_loss: 0.7982 - val_acc: 0.2459\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7706 - acc: 0.2526 - val_loss: 0.7975 - val_acc: 0.2459\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7700 - acc: 0.2526 - val_loss: 0.7968 - val_acc: 0.2459\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7694 - acc: 0.2526 - val_loss: 0.7961 - val_acc: 0.2459\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7688 - acc: 0.2526 - val_loss: 0.7955 - val_acc: 0.2459\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7682 - acc: 0.2577 - val_loss: 0.7949 - val_acc: 0.2459\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7677 - acc: 0.2526 - val_loss: 0.7942 - val_acc: 0.2459\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7671 - acc: 0.2526 - val_loss: 0.7935 - val_acc: 0.2459\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7665 - acc: 0.2577 - val_loss: 0.7929 - val_acc: 0.2459\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7660 - acc: 0.2577 - val_loss: 0.7924 - val_acc: 0.2459\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7654 - acc: 0.2577 - val_loss: 0.7918 - val_acc: 0.2459\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7649 - acc: 0.2577 - val_loss: 0.7911 - val_acc: 0.2459\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7644 - acc: 0.2577 - val_loss: 0.7905 - val_acc: 0.2459\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7638 - acc: 0.2526 - val_loss: 0.7899 - val_acc: 0.2459\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7632 - acc: 0.2526 - val_loss: 0.7892 - val_acc: 0.2459\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7627 - acc: 0.2577 - val_loss: 0.7886 - val_acc: 0.2459\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7037 - acc: 0.4742 - val_loss: 0.6902 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7032 - acc: 0.4742 - val_loss: 0.6897 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7027 - acc: 0.4845 - val_loss: 0.6892 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7022 - acc: 0.4845 - val_loss: 0.6887 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7017 - acc: 0.4897 - val_loss: 0.6882 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7013 - acc: 0.4897 - val_loss: 0.6878 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7008 - acc: 0.4897 - val_loss: 0.6873 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7004 - acc: 0.4897 - val_loss: 0.6868 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6999 - acc: 0.4897 - val_loss: 0.6863 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6995 - acc: 0.4897 - val_loss: 0.6859 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6990 - acc: 0.4897 - val_loss: 0.6854 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6985 - acc: 0.4948 - val_loss: 0.6849 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6981 - acc: 0.4948 - val_loss: 0.6844 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6976 - acc: 0.4948 - val_loss: 0.6839 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6972 - acc: 0.5000 - val_loss: 0.6834 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6967 - acc: 0.5052 - val_loss: 0.6829 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6963 - acc: 0.5052 - val_loss: 0.6825 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6959 - acc: 0.5103 - val_loss: 0.6820 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6954 - acc: 0.5155 - val_loss: 0.6815 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6950 - acc: 0.5155 - val_loss: 0.6811 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6948 - acc: 0.5619 - val_loss: 0.7116 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6943 - acc: 0.5619 - val_loss: 0.7110 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6938 - acc: 0.5619 - val_loss: 0.7104 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6933 - acc: 0.5619 - val_loss: 0.7098 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6928 - acc: 0.5670 - val_loss: 0.7092 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6923 - acc: 0.5670 - val_loss: 0.7086 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6918 - acc: 0.5670 - val_loss: 0.7081 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6913 - acc: 0.5670 - val_loss: 0.7076 - val_acc: 0.5082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6909 - acc: 0.5670 - val_loss: 0.7070 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6904 - acc: 0.5670 - val_loss: 0.7064 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6899 - acc: 0.5722 - val_loss: 0.7059 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6895 - acc: 0.5722 - val_loss: 0.7054 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6890 - acc: 0.5722 - val_loss: 0.7048 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6885 - acc: 0.5722 - val_loss: 0.7043 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6881 - acc: 0.5722 - val_loss: 0.7037 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6876 - acc: 0.5722 - val_loss: 0.7032 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6871 - acc: 0.5722 - val_loss: 0.7026 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6867 - acc: 0.5722 - val_loss: 0.7021 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6863 - acc: 0.5722 - val_loss: 0.7016 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6858 - acc: 0.5722 - val_loss: 0.7010 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.8331 - acc: 0.3420 - val_loss: 0.8135 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8330 - acc: 0.3420 - val_loss: 0.8134 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8330 - acc: 0.3420 - val_loss: 0.8134 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8329 - acc: 0.3420 - val_loss: 0.8133 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8329 - acc: 0.3420 - val_loss: 0.8133 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8328 - acc: 0.3420 - val_loss: 0.8132 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8328 - acc: 0.3420 - val_loss: 0.8132 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8327 - acc: 0.3420 - val_loss: 0.8131 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8327 - acc: 0.3420 - val_loss: 0.8131 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8326 - acc: 0.3420 - val_loss: 0.8130 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8326 - acc: 0.3420 - val_loss: 0.8130 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8325 - acc: 0.3420 - val_loss: 0.8129 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8325 - acc: 0.3420 - val_loss: 0.8129 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8324 - acc: 0.3420 - val_loss: 0.8128 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8324 - acc: 0.3420 - val_loss: 0.8128 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8323 - acc: 0.3420 - val_loss: 0.8127 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8323 - acc: 0.3420 - val_loss: 0.8127 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8322 - acc: 0.3420 - val_loss: 0.8126 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8322 - acc: 0.3420 - val_loss: 0.8126 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8322 - acc: 0.3420 - val_loss: 0.8125 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1442 - acc: 0.2746 - val_loss: 1.1208 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1441 - acc: 0.2746 - val_loss: 1.1207 - val_acc: 0.3115\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1439 - acc: 0.2746 - val_loss: 1.1206 - val_acc: 0.3115\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1438 - acc: 0.2746 - val_loss: 1.1205 - val_acc: 0.3115\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1437 - acc: 0.2746 - val_loss: 1.1204 - val_acc: 0.3115\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1436 - acc: 0.2746 - val_loss: 1.1202 - val_acc: 0.3115\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1435 - acc: 0.2746 - val_loss: 1.1201 - val_acc: 0.3115\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1434 - acc: 0.2746 - val_loss: 1.1200 - val_acc: 0.3115\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1433 - acc: 0.2746 - val_loss: 1.1199 - val_acc: 0.3115\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1432 - acc: 0.2746 - val_loss: 1.1198 - val_acc: 0.3115\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1431 - acc: 0.2746 - val_loss: 1.1197 - val_acc: 0.3115\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1430 - acc: 0.2746 - val_loss: 1.1195 - val_acc: 0.3115\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1429 - acc: 0.2746 - val_loss: 1.1194 - val_acc: 0.3115\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1428 - acc: 0.2746 - val_loss: 1.1193 - val_acc: 0.3115\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1427 - acc: 0.2746 - val_loss: 1.1192 - val_acc: 0.3115\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1426 - acc: 0.2746 - val_loss: 1.1191 - val_acc: 0.3115\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1425 - acc: 0.2746 - val_loss: 1.1190 - val_acc: 0.3115\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1424 - acc: 0.2746 - val_loss: 1.1189 - val_acc: 0.3115\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1423 - acc: 0.2746 - val_loss: 1.1187 - val_acc: 0.3279\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1422 - acc: 0.2746 - val_loss: 1.1186 - val_acc: 0.3279\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7568 - acc: 0.5619 - val_loss: 0.6992 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7568 - acc: 0.5619 - val_loss: 0.6991 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7567 - acc: 0.5619 - val_loss: 0.6990 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7567 - acc: 0.5619 - val_loss: 0.6990 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7566 - acc: 0.5619 - val_loss: 0.6989 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7566 - acc: 0.5619 - val_loss: 0.6989 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7565 - acc: 0.5619 - val_loss: 0.6988 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7565 - acc: 0.5619 - val_loss: 0.6988 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7564 - acc: 0.5619 - val_loss: 0.6987 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7564 - acc: 0.5619 - val_loss: 0.6987 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7563 - acc: 0.5619 - val_loss: 0.6986 - val_acc: 0.5738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7563 - acc: 0.5619 - val_loss: 0.6985 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7562 - acc: 0.5619 - val_loss: 0.6985 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7562 - acc: 0.5619 - val_loss: 0.6984 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7561 - acc: 0.5619 - val_loss: 0.6984 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7561 - acc: 0.5619 - val_loss: 0.6983 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7560 - acc: 0.5619 - val_loss: 0.6983 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7560 - acc: 0.5619 - val_loss: 0.6982 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7559 - acc: 0.5619 - val_loss: 0.6981 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7559 - acc: 0.5619 - val_loss: 0.6981 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6555 - acc: 0.6495 - val_loss: 0.5858 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6554 - acc: 0.6495 - val_loss: 0.5857 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6554 - acc: 0.6495 - val_loss: 0.5857 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6553 - acc: 0.6495 - val_loss: 0.5857 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6553 - acc: 0.6495 - val_loss: 0.5856 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6553 - acc: 0.6495 - val_loss: 0.5856 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6552 - acc: 0.6495 - val_loss: 0.5856 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6552 - acc: 0.6495 - val_loss: 0.5855 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6552 - acc: 0.6495 - val_loss: 0.5855 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6551 - acc: 0.6495 - val_loss: 0.5855 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6551 - acc: 0.6495 - val_loss: 0.5854 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6550 - acc: 0.6495 - val_loss: 0.5854 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6550 - acc: 0.6495 - val_loss: 0.5854 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6550 - acc: 0.6495 - val_loss: 0.5853 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6549 - acc: 0.6495 - val_loss: 0.5853 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6549 - acc: 0.6495 - val_loss: 0.5852 - val_acc: 0.6557\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6549 - acc: 0.6495 - val_loss: 0.5852 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6548 - acc: 0.6495 - val_loss: 0.5852 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6548 - acc: 0.6495 - val_loss: 0.5852 - val_acc: 0.6557\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6548 - acc: 0.6495 - val_loss: 0.5851 - val_acc: 0.6557\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8290 - acc: 0.4691 - val_loss: 0.8085 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8289 - acc: 0.4691 - val_loss: 0.8084 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8289 - acc: 0.4691 - val_loss: 0.8084 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8288 - acc: 0.4691 - val_loss: 0.8083 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8288 - acc: 0.4691 - val_loss: 0.8083 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8287 - acc: 0.4691 - val_loss: 0.8082 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8287 - acc: 0.4691 - val_loss: 0.8082 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8286 - acc: 0.4691 - val_loss: 0.8081 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8285 - acc: 0.4691 - val_loss: 0.8081 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8285 - acc: 0.4691 - val_loss: 0.8080 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8284 - acc: 0.4691 - val_loss: 0.8079 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8284 - acc: 0.4691 - val_loss: 0.8079 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8283 - acc: 0.4691 - val_loss: 0.8078 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8283 - acc: 0.4691 - val_loss: 0.8078 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8282 - acc: 0.4691 - val_loss: 0.8077 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8281 - acc: 0.4691 - val_loss: 0.8077 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8281 - acc: 0.4691 - val_loss: 0.8076 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8280 - acc: 0.4691 - val_loss: 0.8076 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8280 - acc: 0.4691 - val_loss: 0.8075 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8279 - acc: 0.4691 - val_loss: 0.8075 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6913 - acc: 0.5959 - val_loss: 0.6209 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6913 - acc: 0.5959 - val_loss: 0.6208 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6912 - acc: 0.5959 - val_loss: 0.6208 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6911 - acc: 0.5959 - val_loss: 0.6207 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6911 - acc: 0.5959 - val_loss: 0.6206 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6910 - acc: 0.5959 - val_loss: 0.6206 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6910 - acc: 0.6010 - val_loss: 0.6205 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6909 - acc: 0.6010 - val_loss: 0.6205 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6909 - acc: 0.6010 - val_loss: 0.6204 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6908 - acc: 0.6010 - val_loss: 0.6204 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6908 - acc: 0.6010 - val_loss: 0.6203 - val_acc: 0.7213\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6907 - acc: 0.6010 - val_loss: 0.6203 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6907 - acc: 0.6010 - val_loss: 0.6202 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6906 - acc: 0.6010 - val_loss: 0.6202 - val_acc: 0.7213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6905 - acc: 0.6010 - val_loss: 0.6201 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6905 - acc: 0.6010 - val_loss: 0.6200 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6904 - acc: 0.6010 - val_loss: 0.6200 - val_acc: 0.7213\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6904 - acc: 0.6010 - val_loss: 0.6199 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6903 - acc: 0.6010 - val_loss: 0.6199 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6902 - acc: 0.6010 - val_loss: 0.6198 - val_acc: 0.7213\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7880 - acc: 0.4093 - val_loss: 0.7702 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7879 - acc: 0.4093 - val_loss: 0.7701 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7878 - acc: 0.4093 - val_loss: 0.7701 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7877 - acc: 0.4093 - val_loss: 0.7700 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7877 - acc: 0.4093 - val_loss: 0.7699 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7876 - acc: 0.4093 - val_loss: 0.7698 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7875 - acc: 0.4093 - val_loss: 0.7697 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7874 - acc: 0.4093 - val_loss: 0.7697 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7874 - acc: 0.4093 - val_loss: 0.7696 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7873 - acc: 0.4093 - val_loss: 0.7695 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7872 - acc: 0.4093 - val_loss: 0.7694 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7872 - acc: 0.4093 - val_loss: 0.7693 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7871 - acc: 0.4093 - val_loss: 0.7693 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7870 - acc: 0.4093 - val_loss: 0.7692 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7869 - acc: 0.4093 - val_loss: 0.7691 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7869 - acc: 0.4093 - val_loss: 0.7690 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7868 - acc: 0.4093 - val_loss: 0.7689 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7867 - acc: 0.4093 - val_loss: 0.7688 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7867 - acc: 0.4093 - val_loss: 0.7688 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7866 - acc: 0.4093 - val_loss: 0.7687 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0438 - acc: 0.4330 - val_loss: 0.9652 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0437 - acc: 0.4330 - val_loss: 0.9651 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.0435 - acc: 0.4330 - val_loss: 0.9650 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0434 - acc: 0.4330 - val_loss: 0.9649 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0433 - acc: 0.4330 - val_loss: 0.9648 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0432 - acc: 0.4330 - val_loss: 0.9647 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0430 - acc: 0.4330 - val_loss: 0.9646 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0429 - acc: 0.4330 - val_loss: 0.9644 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0428 - acc: 0.4330 - val_loss: 0.9643 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0426 - acc: 0.4330 - val_loss: 0.9642 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.0425 - acc: 0.4330 - val_loss: 0.9641 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0424 - acc: 0.4330 - val_loss: 0.9640 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0422 - acc: 0.4330 - val_loss: 0.9639 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0421 - acc: 0.4330 - val_loss: 0.9638 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0420 - acc: 0.4330 - val_loss: 0.9637 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0419 - acc: 0.4330 - val_loss: 0.9636 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0417 - acc: 0.4330 - val_loss: 0.9635 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0416 - acc: 0.4330 - val_loss: 0.9634 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0415 - acc: 0.4330 - val_loss: 0.9633 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.0414 - acc: 0.4330 - val_loss: 0.9631 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7330 - acc: 0.5567 - val_loss: 0.7469 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7329 - acc: 0.5567 - val_loss: 0.7468 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7328 - acc: 0.5567 - val_loss: 0.7467 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7328 - acc: 0.5567 - val_loss: 0.7466 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7327 - acc: 0.5567 - val_loss: 0.7466 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7326 - acc: 0.5567 - val_loss: 0.7465 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7326 - acc: 0.5567 - val_loss: 0.7464 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7325 - acc: 0.5567 - val_loss: 0.7463 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7325 - acc: 0.5567 - val_loss: 0.7462 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7324 - acc: 0.5567 - val_loss: 0.7461 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7323 - acc: 0.5567 - val_loss: 0.7461 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7323 - acc: 0.5567 - val_loss: 0.7460 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7322 - acc: 0.5567 - val_loss: 0.7459 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7321 - acc: 0.5567 - val_loss: 0.7458 - val_acc: 0.6885\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7321 - acc: 0.5567 - val_loss: 0.7457 - val_acc: 0.6885\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7320 - acc: 0.5567 - val_loss: 0.7456 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7319 - acc: 0.5567 - val_loss: 0.7455 - val_acc: 0.6885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7319 - acc: 0.5567 - val_loss: 0.7455 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7318 - acc: 0.5567 - val_loss: 0.7454 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.8641 - acc: 0.500 - 0s 1ms/step - loss: 0.7317 - acc: 0.5567 - val_loss: 0.7453 - val_acc: 0.6885\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.7391 - acc: 0.4794 - val_loss: 0.7881 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7391 - acc: 0.4794 - val_loss: 0.7880 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7390 - acc: 0.4794 - val_loss: 0.7880 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7389 - acc: 0.4794 - val_loss: 0.7879 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7389 - acc: 0.4794 - val_loss: 0.7878 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7388 - acc: 0.4794 - val_loss: 0.7878 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7387 - acc: 0.4794 - val_loss: 0.7877 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7387 - acc: 0.4794 - val_loss: 0.7876 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7386 - acc: 0.4794 - val_loss: 0.7876 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7385 - acc: 0.4794 - val_loss: 0.7875 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7385 - acc: 0.4794 - val_loss: 0.7874 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7384 - acc: 0.4794 - val_loss: 0.7874 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7383 - acc: 0.4845 - val_loss: 0.7873 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7383 - acc: 0.4845 - val_loss: 0.7872 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7382 - acc: 0.4845 - val_loss: 0.7872 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7381 - acc: 0.4845 - val_loss: 0.7871 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7381 - acc: 0.4845 - val_loss: 0.7870 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7380 - acc: 0.4845 - val_loss: 0.7870 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7379 - acc: 0.4845 - val_loss: 0.7869 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7379 - acc: 0.4845 - val_loss: 0.7868 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7868 - acc: 0.4611 - val_loss: 0.8509 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7867 - acc: 0.4611 - val_loss: 0.8508 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7866 - acc: 0.4611 - val_loss: 0.8506 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7864 - acc: 0.4611 - val_loss: 0.8505 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7863 - acc: 0.4611 - val_loss: 0.8504 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7862 - acc: 0.4611 - val_loss: 0.8502 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7861 - acc: 0.4611 - val_loss: 0.8501 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7860 - acc: 0.4611 - val_loss: 0.8500 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7859 - acc: 0.4611 - val_loss: 0.8499 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7857 - acc: 0.4611 - val_loss: 0.8497 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7856 - acc: 0.4611 - val_loss: 0.8496 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7855 - acc: 0.4611 - val_loss: 0.8495 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7854 - acc: 0.4611 - val_loss: 0.8494 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7853 - acc: 0.4611 - val_loss: 0.8492 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7852 - acc: 0.4611 - val_loss: 0.8491 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7850 - acc: 0.4611 - val_loss: 0.8490 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7849 - acc: 0.4611 - val_loss: 0.8489 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7848 - acc: 0.4611 - val_loss: 0.8487 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7847 - acc: 0.4611 - val_loss: 0.8486 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7846 - acc: 0.4611 - val_loss: 0.8485 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8567 - acc: 0.3990 - val_loss: 0.9377 - val_acc: 0.3443\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8566 - acc: 0.3990 - val_loss: 0.9375 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8564 - acc: 0.3990 - val_loss: 0.9373 - val_acc: 0.3443\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8563 - acc: 0.3990 - val_loss: 0.9371 - val_acc: 0.3443\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8561 - acc: 0.3990 - val_loss: 0.9369 - val_acc: 0.3443\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8560 - acc: 0.3990 - val_loss: 0.9367 - val_acc: 0.3443\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8558 - acc: 0.3938 - val_loss: 0.9365 - val_acc: 0.3443\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8557 - acc: 0.3990 - val_loss: 0.9363 - val_acc: 0.3443\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8556 - acc: 0.4041 - val_loss: 0.9362 - val_acc: 0.3443\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8554 - acc: 0.4041 - val_loss: 0.9360 - val_acc: 0.3443\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8553 - acc: 0.4041 - val_loss: 0.9358 - val_acc: 0.3443\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8552 - acc: 0.4041 - val_loss: 0.9356 - val_acc: 0.3443\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8550 - acc: 0.4041 - val_loss: 0.9354 - val_acc: 0.3443\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8549 - acc: 0.4041 - val_loss: 0.9353 - val_acc: 0.3443\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8547 - acc: 0.4041 - val_loss: 0.9351 - val_acc: 0.3443\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8546 - acc: 0.4041 - val_loss: 0.9349 - val_acc: 0.3443\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8545 - acc: 0.4041 - val_loss: 0.9347 - val_acc: 0.3443\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8543 - acc: 0.4041 - val_loss: 0.9345 - val_acc: 0.3443\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8542 - acc: 0.4041 - val_loss: 0.9344 - val_acc: 0.3443\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8541 - acc: 0.4041 - val_loss: 0.9342 - val_acc: 0.3443\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9960 - acc: 0.3608 - val_loss: 1.1466 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9958 - acc: 0.3608 - val_loss: 1.1463 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9956 - acc: 0.3608 - val_loss: 1.1461 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9954 - acc: 0.3608 - val_loss: 1.1458 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9952 - acc: 0.3608 - val_loss: 1.1456 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9950 - acc: 0.3608 - val_loss: 1.1453 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9948 - acc: 0.3660 - val_loss: 1.1451 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9946 - acc: 0.3660 - val_loss: 1.1448 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9944 - acc: 0.3660 - val_loss: 1.1446 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9942 - acc: 0.3660 - val_loss: 1.1443 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9940 - acc: 0.3660 - val_loss: 1.1441 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9938 - acc: 0.3660 - val_loss: 1.1439 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9936 - acc: 0.3660 - val_loss: 1.1436 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9935 - acc: 0.3660 - val_loss: 1.1434 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9932 - acc: 0.3660 - val_loss: 1.1431 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9930 - acc: 0.3660 - val_loss: 1.1428 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9928 - acc: 0.3660 - val_loss: 1.1426 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9926 - acc: 0.3660 - val_loss: 1.1423 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9924 - acc: 0.3660 - val_loss: 1.1421 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9922 - acc: 0.3660 - val_loss: 1.1418 - val_acc: 0.3934\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0891 - acc: 0.4175 - val_loss: 1.1156 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0889 - acc: 0.4175 - val_loss: 1.1154 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0887 - acc: 0.4175 - val_loss: 1.1151 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0885 - acc: 0.4175 - val_loss: 1.1149 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.0883 - acc: 0.4175 - val_loss: 1.1147 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0881 - acc: 0.4175 - val_loss: 1.1145 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0879 - acc: 0.4175 - val_loss: 1.1142 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0878 - acc: 0.4175 - val_loss: 1.1140 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0876 - acc: 0.4175 - val_loss: 1.1138 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0874 - acc: 0.4175 - val_loss: 1.1136 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0872 - acc: 0.4175 - val_loss: 1.1133 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0870 - acc: 0.4175 - val_loss: 1.1131 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0868 - acc: 0.4175 - val_loss: 1.1129 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0867 - acc: 0.4175 - val_loss: 1.1127 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0865 - acc: 0.4175 - val_loss: 1.1124 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0863 - acc: 0.4175 - val_loss: 1.1122 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0861 - acc: 0.4175 - val_loss: 1.1120 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0859 - acc: 0.4175 - val_loss: 1.1118 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0857 - acc: 0.4175 - val_loss: 1.1115 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0855 - acc: 0.4175 - val_loss: 1.1113 - val_acc: 0.4590\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8251 - acc: 0.3608 - val_loss: 0.8260 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8249 - acc: 0.3608 - val_loss: 0.8258 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8248 - acc: 0.3608 - val_loss: 0.8256 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8246 - acc: 0.3608 - val_loss: 0.8255 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8245 - acc: 0.3608 - val_loss: 0.8253 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8243 - acc: 0.3608 - val_loss: 0.8251 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8242 - acc: 0.3608 - val_loss: 0.8249 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8240 - acc: 0.3608 - val_loss: 0.8247 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8239 - acc: 0.3608 - val_loss: 0.8246 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8237 - acc: 0.3608 - val_loss: 0.8244 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8236 - acc: 0.3608 - val_loss: 0.8242 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8235 - acc: 0.3608 - val_loss: 0.8240 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8233 - acc: 0.3608 - val_loss: 0.8239 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8232 - acc: 0.3608 - val_loss: 0.8237 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8231 - acc: 0.3608 - val_loss: 0.8235 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8229 - acc: 0.3608 - val_loss: 0.8233 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8228 - acc: 0.3608 - val_loss: 0.8232 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8226 - acc: 0.3608 - val_loss: 0.8230 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8225 - acc: 0.3608 - val_loss: 0.8228 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8224 - acc: 0.3608 - val_loss: 0.8226 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8052 - acc: 0.4870 - val_loss: 0.7507 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8050 - acc: 0.4870 - val_loss: 0.7505 - val_acc: 0.4918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8049 - acc: 0.4870 - val_loss: 0.7503 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8047 - acc: 0.4870 - val_loss: 0.7501 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8045 - acc: 0.4870 - val_loss: 0.7500 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8043 - acc: 0.4870 - val_loss: 0.7498 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8041 - acc: 0.4870 - val_loss: 0.7496 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8040 - acc: 0.4870 - val_loss: 0.7495 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8038 - acc: 0.4870 - val_loss: 0.7493 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8037 - acc: 0.4870 - val_loss: 0.7492 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8035 - acc: 0.4870 - val_loss: 0.7490 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8033 - acc: 0.4870 - val_loss: 0.7489 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8032 - acc: 0.4870 - val_loss: 0.7487 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8030 - acc: 0.4870 - val_loss: 0.7486 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8029 - acc: 0.4870 - val_loss: 0.7484 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8027 - acc: 0.4870 - val_loss: 0.7483 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8026 - acc: 0.4870 - val_loss: 0.7481 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8024 - acc: 0.4870 - val_loss: 0.7479 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8022 - acc: 0.4870 - val_loss: 0.7478 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8021 - acc: 0.4870 - val_loss: 0.7476 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7517 - acc: 0.4974 - val_loss: 0.8064 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7515 - acc: 0.4974 - val_loss: 0.8062 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7513 - acc: 0.4974 - val_loss: 0.8060 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7512 - acc: 0.4974 - val_loss: 0.8058 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7510 - acc: 0.4974 - val_loss: 0.8057 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7509 - acc: 0.4974 - val_loss: 0.8055 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7508 - acc: 0.4974 - val_loss: 0.8053 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7506 - acc: 0.4974 - val_loss: 0.8052 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7505 - acc: 0.4974 - val_loss: 0.8050 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7504 - acc: 0.4974 - val_loss: 0.8048 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7502 - acc: 0.4974 - val_loss: 0.8046 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7501 - acc: 0.4974 - val_loss: 0.8045 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7499 - acc: 0.4974 - val_loss: 0.8043 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7498 - acc: 0.4974 - val_loss: 0.8041 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7497 - acc: 0.4974 - val_loss: 0.8039 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7495 - acc: 0.4974 - val_loss: 0.8037 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7494 - acc: 0.4974 - val_loss: 0.8035 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7492 - acc: 0.4974 - val_loss: 0.8033 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7491 - acc: 0.4974 - val_loss: 0.8032 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7489 - acc: 0.4974 - val_loss: 0.8030 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7347 - acc: 0.4948 - val_loss: 0.7475 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7345 - acc: 0.4948 - val_loss: 0.7473 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7344 - acc: 0.4948 - val_loss: 0.7471 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7342 - acc: 0.4948 - val_loss: 0.7470 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7340 - acc: 0.4948 - val_loss: 0.7468 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7338 - acc: 0.4948 - val_loss: 0.7466 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7336 - acc: 0.4948 - val_loss: 0.7464 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7334 - acc: 0.4948 - val_loss: 0.7462 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7333 - acc: 0.4948 - val_loss: 0.7461 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7331 - acc: 0.4948 - val_loss: 0.7459 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7329 - acc: 0.5000 - val_loss: 0.7457 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7328 - acc: 0.5000 - val_loss: 0.7456 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7326 - acc: 0.5000 - val_loss: 0.7454 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7324 - acc: 0.5000 - val_loss: 0.7452 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7322 - acc: 0.5000 - val_loss: 0.7450 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7321 - acc: 0.5000 - val_loss: 0.7449 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7319 - acc: 0.5000 - val_loss: 0.7447 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7317 - acc: 0.5000 - val_loss: 0.7445 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7315 - acc: 0.5000 - val_loss: 0.7443 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7314 - acc: 0.5000 - val_loss: 0.7442 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7524 - acc: 0.4227 - val_loss: 0.7572 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7523 - acc: 0.4227 - val_loss: 0.7571 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7521 - acc: 0.4227 - val_loss: 0.7569 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7519 - acc: 0.4227 - val_loss: 0.7567 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7517 - acc: 0.4227 - val_loss: 0.7565 - val_acc: 0.4262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7516 - acc: 0.4227 - val_loss: 0.7563 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7514 - acc: 0.4227 - val_loss: 0.7561 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7512 - acc: 0.4227 - val_loss: 0.7559 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7511 - acc: 0.4227 - val_loss: 0.7557 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7509 - acc: 0.4227 - val_loss: 0.7556 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7507 - acc: 0.4227 - val_loss: 0.7554 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7506 - acc: 0.4227 - val_loss: 0.7552 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7504 - acc: 0.4227 - val_loss: 0.7550 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7502 - acc: 0.4227 - val_loss: 0.7548 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7501 - acc: 0.4227 - val_loss: 0.7547 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7499 - acc: 0.4227 - val_loss: 0.7545 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7498 - acc: 0.4227 - val_loss: 0.7543 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7496 - acc: 0.4227 - val_loss: 0.7541 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7494 - acc: 0.4227 - val_loss: 0.7539 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7493 - acc: 0.4227 - val_loss: 0.7538 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7405 - acc: 0.4588 - val_loss: 0.8391 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7403 - acc: 0.4588 - val_loss: 0.8389 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7401 - acc: 0.4588 - val_loss: 0.8387 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7400 - acc: 0.4588 - val_loss: 0.8385 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7398 - acc: 0.4588 - val_loss: 0.8383 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7396 - acc: 0.4588 - val_loss: 0.8381 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7395 - acc: 0.4588 - val_loss: 0.8379 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7393 - acc: 0.4588 - val_loss: 0.8377 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7392 - acc: 0.4588 - val_loss: 0.8375 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7390 - acc: 0.4588 - val_loss: 0.8374 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7388 - acc: 0.4588 - val_loss: 0.8372 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7387 - acc: 0.4588 - val_loss: 0.8370 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7385 - acc: 0.4588 - val_loss: 0.8368 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7384 - acc: 0.4588 - val_loss: 0.8366 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7382 - acc: 0.4588 - val_loss: 0.8364 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7381 - acc: 0.4588 - val_loss: 0.8362 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7379 - acc: 0.4588 - val_loss: 0.8360 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7377 - acc: 0.4588 - val_loss: 0.8358 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7376 - acc: 0.4588 - val_loss: 0.8356 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7375 - acc: 0.4588 - val_loss: 0.8355 - val_acc: 0.3934\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5882 - acc: 0.7358 - val_loss: 0.5081 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5880 - acc: 0.7358 - val_loss: 0.5079 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5879 - acc: 0.7358 - val_loss: 0.5078 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5877 - acc: 0.7358 - val_loss: 0.5077 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5876 - acc: 0.7358 - val_loss: 0.5076 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5874 - acc: 0.7358 - val_loss: 0.5074 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5873 - acc: 0.7358 - val_loss: 0.5073 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5871 - acc: 0.7358 - val_loss: 0.5072 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5870 - acc: 0.7358 - val_loss: 0.5071 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5869 - acc: 0.7358 - val_loss: 0.5069 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5867 - acc: 0.7358 - val_loss: 0.5068 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5866 - acc: 0.7358 - val_loss: 0.5067 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5865 - acc: 0.7358 - val_loss: 0.5066 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5863 - acc: 0.7358 - val_loss: 0.5065 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5862 - acc: 0.7358 - val_loss: 0.5063 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5860 - acc: 0.7358 - val_loss: 0.5062 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5859 - acc: 0.7358 - val_loss: 0.5061 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5857 - acc: 0.7358 - val_loss: 0.5060 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5856 - acc: 0.7358 - val_loss: 0.5059 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5855 - acc: 0.7358 - val_loss: 0.5057 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8130 - acc: 0.4041 - val_loss: 0.8252 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8127 - acc: 0.4041 - val_loss: 0.8249 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8124 - acc: 0.4041 - val_loss: 0.8246 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8121 - acc: 0.4041 - val_loss: 0.8244 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8118 - acc: 0.4041 - val_loss: 0.8241 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8116 - acc: 0.4041 - val_loss: 0.8238 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8113 - acc: 0.4041 - val_loss: 0.8235 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8110 - acc: 0.4041 - val_loss: 0.8232 - val_acc: 0.3934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8107 - acc: 0.4041 - val_loss: 0.8230 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8104 - acc: 0.4041 - val_loss: 0.8227 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8102 - acc: 0.4041 - val_loss: 0.8224 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8099 - acc: 0.4041 - val_loss: 0.8221 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8096 - acc: 0.4041 - val_loss: 0.8219 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8094 - acc: 0.4041 - val_loss: 0.8216 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8091 - acc: 0.4041 - val_loss: 0.8214 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8089 - acc: 0.4041 - val_loss: 0.8211 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8086 - acc: 0.4041 - val_loss: 0.8208 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8083 - acc: 0.4041 - val_loss: 0.8206 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8081 - acc: 0.4041 - val_loss: 0.8203 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8078 - acc: 0.4041 - val_loss: 0.8201 - val_acc: 0.3934\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6584 - acc: 0.6598 - val_loss: 0.6667 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6582 - acc: 0.6598 - val_loss: 0.6664 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6580 - acc: 0.6598 - val_loss: 0.6662 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6578 - acc: 0.6598 - val_loss: 0.6659 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6576 - acc: 0.6598 - val_loss: 0.6657 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6573 - acc: 0.6598 - val_loss: 0.6654 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6571 - acc: 0.6598 - val_loss: 0.6652 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6570 - acc: 0.6598 - val_loss: 0.6650 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6567 - acc: 0.6598 - val_loss: 0.6647 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6565 - acc: 0.6649 - val_loss: 0.6645 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6563 - acc: 0.6649 - val_loss: 0.6643 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6561 - acc: 0.6649 - val_loss: 0.6640 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6559 - acc: 0.6649 - val_loss: 0.6638 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6557 - acc: 0.6649 - val_loss: 0.6636 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6555 - acc: 0.6649 - val_loss: 0.6633 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6553 - acc: 0.6649 - val_loss: 0.6631 - val_acc: 0.6557\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6551 - acc: 0.6649 - val_loss: 0.6629 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6549 - acc: 0.6649 - val_loss: 0.6626 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6547 - acc: 0.6649 - val_loss: 0.6624 - val_acc: 0.6557\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6545 - acc: 0.6649 - val_loss: 0.6622 - val_acc: 0.6557\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6622 - acc: 0.5876 - val_loss: 0.6639 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6620 - acc: 0.5876 - val_loss: 0.6637 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6618 - acc: 0.5928 - val_loss: 0.6636 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6616 - acc: 0.5928 - val_loss: 0.6634 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6614 - acc: 0.5928 - val_loss: 0.6632 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6612 - acc: 0.5928 - val_loss: 0.6630 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6611 - acc: 0.5928 - val_loss: 0.6628 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6609 - acc: 0.5928 - val_loss: 0.6626 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6607 - acc: 0.5928 - val_loss: 0.6624 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6605 - acc: 0.5928 - val_loss: 0.6623 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6603 - acc: 0.5928 - val_loss: 0.6621 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6601 - acc: 0.5928 - val_loss: 0.6619 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6600 - acc: 0.5928 - val_loss: 0.6617 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6598 - acc: 0.5928 - val_loss: 0.6615 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6596 - acc: 0.5928 - val_loss: 0.6614 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6594 - acc: 0.5928 - val_loss: 0.6612 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6592 - acc: 0.5928 - val_loss: 0.6610 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6590 - acc: 0.5928 - val_loss: 0.6608 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6589 - acc: 0.5928 - val_loss: 0.6606 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6587 - acc: 0.5928 - val_loss: 0.6605 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5999 - acc: 0.7577 - val_loss: 0.6177 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5997 - acc: 0.7577 - val_loss: 0.6175 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5995 - acc: 0.7577 - val_loss: 0.6173 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5994 - acc: 0.7577 - val_loss: 0.6172 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5992 - acc: 0.7577 - val_loss: 0.6170 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5990 - acc: 0.7577 - val_loss: 0.6168 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5988 - acc: 0.7577 - val_loss: 0.6166 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5987 - acc: 0.7577 - val_loss: 0.6165 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5985 - acc: 0.7577 - val_loss: 0.6163 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5984 - acc: 0.7577 - val_loss: 0.6161 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5982 - acc: 0.7577 - val_loss: 0.6159 - val_acc: 0.6557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5980 - acc: 0.7577 - val_loss: 0.6158 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5979 - acc: 0.7577 - val_loss: 0.6156 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5977 - acc: 0.7577 - val_loss: 0.6154 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5975 - acc: 0.7577 - val_loss: 0.6152 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5974 - acc: 0.7577 - val_loss: 0.6151 - val_acc: 0.6557\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5972 - acc: 0.7577 - val_loss: 0.6149 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5970 - acc: 0.7577 - val_loss: 0.6147 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5969 - acc: 0.7577 - val_loss: 0.6146 - val_acc: 0.6557\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5967 - acc: 0.7577 - val_loss: 0.6144 - val_acc: 0.6557\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7768 - acc: 0.3782 - val_loss: 0.7821 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7764 - acc: 0.3782 - val_loss: 0.7817 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7760 - acc: 0.3782 - val_loss: 0.7813 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7757 - acc: 0.3782 - val_loss: 0.7810 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7754 - acc: 0.3782 - val_loss: 0.7806 - val_acc: 0.3770\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7750 - acc: 0.3782 - val_loss: 0.7802 - val_acc: 0.3770\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7747 - acc: 0.3782 - val_loss: 0.7798 - val_acc: 0.3770\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7743 - acc: 0.3782 - val_loss: 0.7794 - val_acc: 0.3770\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7740 - acc: 0.3782 - val_loss: 0.7790 - val_acc: 0.3770\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7736 - acc: 0.3782 - val_loss: 0.7787 - val_acc: 0.3770\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7733 - acc: 0.3782 - val_loss: 0.7783 - val_acc: 0.3770\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7730 - acc: 0.3782 - val_loss: 0.7779 - val_acc: 0.3770\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7726 - acc: 0.3782 - val_loss: 0.7776 - val_acc: 0.3770\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7723 - acc: 0.3782 - val_loss: 0.7773 - val_acc: 0.3770\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7720 - acc: 0.3782 - val_loss: 0.7769 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7717 - acc: 0.3782 - val_loss: 0.7766 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7714 - acc: 0.3782 - val_loss: 0.7762 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7711 - acc: 0.3782 - val_loss: 0.7759 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7707 - acc: 0.3782 - val_loss: 0.7755 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7704 - acc: 0.3782 - val_loss: 0.7752 - val_acc: 0.3934\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7397 - acc: 0.4404 - val_loss: 0.7471 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7393 - acc: 0.4404 - val_loss: 0.7468 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7390 - acc: 0.4404 - val_loss: 0.7464 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7387 - acc: 0.4404 - val_loss: 0.7461 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7384 - acc: 0.4404 - val_loss: 0.7457 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7380 - acc: 0.4404 - val_loss: 0.7454 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7377 - acc: 0.4404 - val_loss: 0.7451 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7374 - acc: 0.4456 - val_loss: 0.7447 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7371 - acc: 0.4456 - val_loss: 0.7444 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7368 - acc: 0.4456 - val_loss: 0.7441 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7365 - acc: 0.4456 - val_loss: 0.7437 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7362 - acc: 0.4456 - val_loss: 0.7434 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7359 - acc: 0.4456 - val_loss: 0.7431 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7356 - acc: 0.4456 - val_loss: 0.7428 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7353 - acc: 0.4456 - val_loss: 0.7425 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7350 - acc: 0.4456 - val_loss: 0.7422 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7347 - acc: 0.4456 - val_loss: 0.7419 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7344 - acc: 0.4456 - val_loss: 0.7415 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7341 - acc: 0.4456 - val_loss: 0.7412 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7338 - acc: 0.4456 - val_loss: 0.7409 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6810 - acc: 0.5876 - val_loss: 0.7116 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6807 - acc: 0.5876 - val_loss: 0.7112 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6803 - acc: 0.5876 - val_loss: 0.7108 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6800 - acc: 0.5876 - val_loss: 0.7104 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6797 - acc: 0.5876 - val_loss: 0.7100 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6794 - acc: 0.5876 - val_loss: 0.7096 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6790 - acc: 0.5876 - val_loss: 0.7092 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6787 - acc: 0.5876 - val_loss: 0.7088 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6784 - acc: 0.5876 - val_loss: 0.7084 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6781 - acc: 0.5876 - val_loss: 0.7081 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6778 - acc: 0.5876 - val_loss: 0.7077 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6775 - acc: 0.5876 - val_loss: 0.7074 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6772 - acc: 0.5876 - val_loss: 0.7070 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6768 - acc: 0.5876 - val_loss: 0.7066 - val_acc: 0.5410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6765 - acc: 0.5876 - val_loss: 0.7062 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6762 - acc: 0.5876 - val_loss: 0.7058 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6759 - acc: 0.5876 - val_loss: 0.7055 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6756 - acc: 0.5876 - val_loss: 0.7051 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6753 - acc: 0.5876 - val_loss: 0.7047 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6750 - acc: 0.5876 - val_loss: 0.7044 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7036 - acc: 0.4639 - val_loss: 0.7043 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7033 - acc: 0.4639 - val_loss: 0.7039 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7029 - acc: 0.4639 - val_loss: 0.7036 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7026 - acc: 0.4639 - val_loss: 0.7032 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7023 - acc: 0.4639 - val_loss: 0.7029 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7020 - acc: 0.4639 - val_loss: 0.7026 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7016 - acc: 0.4691 - val_loss: 0.7022 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7013 - acc: 0.4691 - val_loss: 0.7019 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7010 - acc: 0.4691 - val_loss: 0.7016 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7007 - acc: 0.4691 - val_loss: 0.7012 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7003 - acc: 0.4691 - val_loss: 0.7009 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7000 - acc: 0.4691 - val_loss: 0.7005 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6997 - acc: 0.4691 - val_loss: 0.7002 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6994 - acc: 0.4691 - val_loss: 0.6998 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6990 - acc: 0.4691 - val_loss: 0.6995 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6987 - acc: 0.4691 - val_loss: 0.6992 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6984 - acc: 0.4691 - val_loss: 0.6988 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6981 - acc: 0.4691 - val_loss: 0.6985 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6978 - acc: 0.4691 - val_loss: 0.6982 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6975 - acc: 0.4691 - val_loss: 0.6978 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6441 - acc: 0.6701 - val_loss: 0.6184 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6438 - acc: 0.6701 - val_loss: 0.6181 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6435 - acc: 0.6701 - val_loss: 0.6179 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6433 - acc: 0.6701 - val_loss: 0.6176 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6430 - acc: 0.6701 - val_loss: 0.6173 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6427 - acc: 0.6701 - val_loss: 0.6170 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6424 - acc: 0.6701 - val_loss: 0.6167 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6421 - acc: 0.6701 - val_loss: 0.6164 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6418 - acc: 0.6701 - val_loss: 0.6161 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6416 - acc: 0.6753 - val_loss: 0.6158 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6413 - acc: 0.6804 - val_loss: 0.6155 - val_acc: 0.7213\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6410 - acc: 0.6804 - val_loss: 0.6152 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6407 - acc: 0.6804 - val_loss: 0.6150 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6405 - acc: 0.6804 - val_loss: 0.6147 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6402 - acc: 0.6856 - val_loss: 0.6144 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6399 - acc: 0.6907 - val_loss: 0.6141 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6396 - acc: 0.6959 - val_loss: 0.6138 - val_acc: 0.7213\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6394 - acc: 0.6959 - val_loss: 0.6135 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6391 - acc: 0.6959 - val_loss: 0.6133 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6388 - acc: 0.6959 - val_loss: 0.6130 - val_acc: 0.7213\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7009 - acc: 0.4922 - val_loss: 0.7092 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7004 - acc: 0.4922 - val_loss: 0.7088 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6999 - acc: 0.4922 - val_loss: 0.7083 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6994 - acc: 0.4974 - val_loss: 0.7077 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6990 - acc: 0.5026 - val_loss: 0.7072 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6985 - acc: 0.5026 - val_loss: 0.7068 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6981 - acc: 0.5078 - val_loss: 0.7063 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6977 - acc: 0.5130 - val_loss: 0.7059 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6972 - acc: 0.5181 - val_loss: 0.7054 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6968 - acc: 0.5233 - val_loss: 0.7049 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6964 - acc: 0.5233 - val_loss: 0.7044 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6959 - acc: 0.5233 - val_loss: 0.7040 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6954 - acc: 0.5233 - val_loss: 0.7035 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6950 - acc: 0.5233 - val_loss: 0.7030 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6946 - acc: 0.5233 - val_loss: 0.7025 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6941 - acc: 0.5337 - val_loss: 0.7021 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6937 - acc: 0.5337 - val_loss: 0.7016 - val_acc: 0.5082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6933 - acc: 0.5389 - val_loss: 0.7012 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6929 - acc: 0.5389 - val_loss: 0.7007 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6925 - acc: 0.5389 - val_loss: 0.7003 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6995 - acc: 0.5389 - val_loss: 0.7010 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6990 - acc: 0.5389 - val_loss: 0.7004 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6986 - acc: 0.5389 - val_loss: 0.6999 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6981 - acc: 0.5389 - val_loss: 0.6994 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6977 - acc: 0.5440 - val_loss: 0.6989 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6972 - acc: 0.5440 - val_loss: 0.6984 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6968 - acc: 0.5492 - val_loss: 0.6978 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6963 - acc: 0.5492 - val_loss: 0.6973 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6959 - acc: 0.5492 - val_loss: 0.6968 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6955 - acc: 0.5544 - val_loss: 0.6963 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6950 - acc: 0.5596 - val_loss: 0.6958 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6946 - acc: 0.5699 - val_loss: 0.6953 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6942 - acc: 0.5699 - val_loss: 0.6948 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6937 - acc: 0.5699 - val_loss: 0.6943 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6933 - acc: 0.5699 - val_loss: 0.6938 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6929 - acc: 0.5699 - val_loss: 0.6933 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6925 - acc: 0.5699 - val_loss: 0.6928 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6921 - acc: 0.5699 - val_loss: 0.6924 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6917 - acc: 0.5699 - val_loss: 0.6919 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6913 - acc: 0.5699 - val_loss: 0.6914 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7114 - acc: 0.5361 - val_loss: 0.7061 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7108 - acc: 0.5361 - val_loss: 0.7055 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7103 - acc: 0.5361 - val_loss: 0.7049 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7097 - acc: 0.5361 - val_loss: 0.7044 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7092 - acc: 0.5361 - val_loss: 0.7038 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7086 - acc: 0.5361 - val_loss: 0.7032 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7081 - acc: 0.5361 - val_loss: 0.7026 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7076 - acc: 0.5412 - val_loss: 0.7021 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7071 - acc: 0.5412 - val_loss: 0.7016 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7066 - acc: 0.5412 - val_loss: 0.7010 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7061 - acc: 0.5412 - val_loss: 0.7005 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7056 - acc: 0.5412 - val_loss: 0.7000 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7051 - acc: 0.5412 - val_loss: 0.6994 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7046 - acc: 0.5412 - val_loss: 0.6989 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.6623 - acc: 0.750 - 0s 2ms/step - loss: 0.7041 - acc: 0.5412 - val_loss: 0.6984 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7036 - acc: 0.5412 - val_loss: 0.6978 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7031 - acc: 0.5412 - val_loss: 0.6973 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7026 - acc: 0.5464 - val_loss: 0.6967 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7021 - acc: 0.5464 - val_loss: 0.6962 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7016 - acc: 0.5464 - val_loss: 0.6957 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7323 - acc: 0.3918 - val_loss: 0.7419 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7317 - acc: 0.3918 - val_loss: 0.7413 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7312 - acc: 0.3969 - val_loss: 0.7408 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7307 - acc: 0.3969 - val_loss: 0.7402 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7302 - acc: 0.3969 - val_loss: 0.7397 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7297 - acc: 0.3969 - val_loss: 0.7391 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7293 - acc: 0.4021 - val_loss: 0.7385 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7287 - acc: 0.4072 - val_loss: 0.7380 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7282 - acc: 0.4072 - val_loss: 0.7374 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7277 - acc: 0.4072 - val_loss: 0.7368 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7272 - acc: 0.4072 - val_loss: 0.7364 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7268 - acc: 0.4175 - val_loss: 0.7358 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7263 - acc: 0.4175 - val_loss: 0.7353 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7258 - acc: 0.4175 - val_loss: 0.7348 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7254 - acc: 0.4175 - val_loss: 0.7343 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7249 - acc: 0.4175 - val_loss: 0.7338 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7244 - acc: 0.4175 - val_loss: 0.7332 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7239 - acc: 0.4175 - val_loss: 0.7327 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7234 - acc: 0.4175 - val_loss: 0.7322 - val_acc: 0.4590\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7230 - acc: 0.4175 - val_loss: 0.7316 - val_acc: 0.4590\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7486 - acc: 0.4536 - val_loss: 0.7348 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7480 - acc: 0.4536 - val_loss: 0.7343 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7475 - acc: 0.4536 - val_loss: 0.7337 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7470 - acc: 0.4536 - val_loss: 0.7332 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7465 - acc: 0.4536 - val_loss: 0.7327 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7459 - acc: 0.4536 - val_loss: 0.7322 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7455 - acc: 0.4536 - val_loss: 0.7317 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7450 - acc: 0.4536 - val_loss: 0.7313 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7445 - acc: 0.4536 - val_loss: 0.7308 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7440 - acc: 0.4536 - val_loss: 0.7303 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7435 - acc: 0.4536 - val_loss: 0.7298 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7429 - acc: 0.4536 - val_loss: 0.7293 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7425 - acc: 0.4536 - val_loss: 0.7288 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7420 - acc: 0.4536 - val_loss: 0.7283 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7415 - acc: 0.4588 - val_loss: 0.7278 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7410 - acc: 0.4588 - val_loss: 0.7274 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7405 - acc: 0.4588 - val_loss: 0.7269 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7400 - acc: 0.4588 - val_loss: 0.7265 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7396 - acc: 0.4588 - val_loss: 0.7260 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7391 - acc: 0.4588 - val_loss: 0.7255 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0632 - acc: 0.3368 - val_loss: 1.0991 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0553 - acc: 0.3368 - val_loss: 1.0904 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0481 - acc: 0.3368 - val_loss: 1.0818 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0413 - acc: 0.3368 - val_loss: 1.0741 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0353 - acc: 0.3368 - val_loss: 1.0665 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0288 - acc: 0.3420 - val_loss: 1.0591 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0225 - acc: 0.3420 - val_loss: 1.0522 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0164 - acc: 0.3523 - val_loss: 1.0445 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0099 - acc: 0.3523 - val_loss: 1.0376 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0040 - acc: 0.3575 - val_loss: 1.0302 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9975 - acc: 0.3627 - val_loss: 1.0226 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9914 - acc: 0.3627 - val_loss: 1.0156 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9857 - acc: 0.3627 - val_loss: 1.0092 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9801 - acc: 0.3679 - val_loss: 1.0026 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3568 - acc: 0.375 - 0s 1ms/step - loss: 0.9747 - acc: 0.3731 - val_loss: 0.9953 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9683 - acc: 0.3834 - val_loss: 0.9889 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9630 - acc: 0.3886 - val_loss: 0.9825 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9573 - acc: 0.4041 - val_loss: 0.9753 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9515 - acc: 0.4041 - val_loss: 0.9686 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9457 - acc: 0.4093 - val_loss: 0.9621 - val_acc: 0.4590\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8833 - acc: 0.5285 - val_loss: 0.8749 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8766 - acc: 0.5285 - val_loss: 0.8691 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8702 - acc: 0.5337 - val_loss: 0.8636 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8639 - acc: 0.5389 - val_loss: 0.8579 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8577 - acc: 0.5389 - val_loss: 0.8527 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8521 - acc: 0.5440 - val_loss: 0.8478 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8466 - acc: 0.5492 - val_loss: 0.8433 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8414 - acc: 0.5544 - val_loss: 0.8387 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8364 - acc: 0.5544 - val_loss: 0.8343 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8314 - acc: 0.5596 - val_loss: 0.8296 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8264 - acc: 0.5596 - val_loss: 0.8250 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8213 - acc: 0.5596 - val_loss: 0.8202 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8161 - acc: 0.5699 - val_loss: 0.8158 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8113 - acc: 0.5648 - val_loss: 0.8112 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8063 - acc: 0.5648 - val_loss: 0.8070 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8019 - acc: 0.5648 - val_loss: 0.8031 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7974 - acc: 0.5699 - val_loss: 0.7989 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7928 - acc: 0.5803 - val_loss: 0.7948 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7879 - acc: 0.5855 - val_loss: 0.7909 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7834 - acc: 0.5959 - val_loss: 0.7871 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1126 - acc: 0.2990 - val_loss: 1.0773 - val_acc: 0.3279\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1008 - acc: 0.2990 - val_loss: 1.0673 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0894 - acc: 0.3041 - val_loss: 1.0581 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0785 - acc: 0.3041 - val_loss: 1.0484 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0672 - acc: 0.3093 - val_loss: 1.0389 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0564 - acc: 0.3144 - val_loss: 1.0296 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0455 - acc: 0.3196 - val_loss: 1.0202 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0351 - acc: 0.3247 - val_loss: 1.0110 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0247 - acc: 0.3247 - val_loss: 1.0022 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0145 - acc: 0.3402 - val_loss: 0.9934 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0042 - acc: 0.3351 - val_loss: 0.9847 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9945 - acc: 0.3351 - val_loss: 0.9762 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9851 - acc: 0.3454 - val_loss: 0.9679 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9755 - acc: 0.3505 - val_loss: 0.9595 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9661 - acc: 0.3557 - val_loss: 0.9510 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9563 - acc: 0.3608 - val_loss: 0.9429 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9467 - acc: 0.3608 - val_loss: 0.9347 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9370 - acc: 0.3660 - val_loss: 0.9263 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9274 - acc: 0.3763 - val_loss: 0.9178 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9180 - acc: 0.4021 - val_loss: 0.9095 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7762 - acc: 0.5052 - val_loss: 0.6488 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7724 - acc: 0.5103 - val_loss: 0.6456 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7689 - acc: 0.5155 - val_loss: 0.6423 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7654 - acc: 0.5103 - val_loss: 0.6393 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7621 - acc: 0.5103 - val_loss: 0.6363 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7588 - acc: 0.5155 - val_loss: 0.6335 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7554 - acc: 0.5155 - val_loss: 0.6308 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7523 - acc: 0.5155 - val_loss: 0.6278 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7491 - acc: 0.5155 - val_loss: 0.6253 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7459 - acc: 0.5206 - val_loss: 0.6225 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7429 - acc: 0.5258 - val_loss: 0.6200 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7400 - acc: 0.5258 - val_loss: 0.6172 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7372 - acc: 0.5258 - val_loss: 0.6143 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7342 - acc: 0.5309 - val_loss: 0.6119 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7315 - acc: 0.5309 - val_loss: 0.6094 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7288 - acc: 0.5309 - val_loss: 0.6068 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7259 - acc: 0.5412 - val_loss: 0.6044 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7231 - acc: 0.5464 - val_loss: 0.6017 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7203 - acc: 0.5515 - val_loss: 0.5992 - val_acc: 0.6393\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7174 - acc: 0.5567 - val_loss: 0.5967 - val_acc: 0.6393\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1926 - acc: 0.2835 - val_loss: 1.1287 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1813 - acc: 0.2887 - val_loss: 1.1201 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1717 - acc: 0.2990 - val_loss: 1.1111 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1617 - acc: 0.3041 - val_loss: 1.1026 - val_acc: 0.3607\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1522 - acc: 0.3041 - val_loss: 1.0942 - val_acc: 0.3607\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1423 - acc: 0.3041 - val_loss: 1.0864 - val_acc: 0.3607\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1333 - acc: 0.3041 - val_loss: 1.0784 - val_acc: 0.3607\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1245 - acc: 0.3041 - val_loss: 1.0705 - val_acc: 0.3607\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1155 - acc: 0.3041 - val_loss: 1.0632 - val_acc: 0.3607\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1068 - acc: 0.3144 - val_loss: 1.0558 - val_acc: 0.3607\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0978 - acc: 0.3196 - val_loss: 1.0478 - val_acc: 0.3607\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0889 - acc: 0.3299 - val_loss: 1.0400 - val_acc: 0.3607\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0799 - acc: 0.3299 - val_loss: 1.0326 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0713 - acc: 0.3299 - val_loss: 1.0250 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0629 - acc: 0.3299 - val_loss: 1.0177 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0544 - acc: 0.3402 - val_loss: 1.0106 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0460 - acc: 0.3402 - val_loss: 1.0031 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0378 - acc: 0.3402 - val_loss: 0.9962 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0301 - acc: 0.3402 - val_loss: 0.9892 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0221 - acc: 0.3402 - val_loss: 0.9823 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6131 - acc: 0.6839 - val_loss: 0.5920 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6074 - acc: 0.6995 - val_loss: 0.5861 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6024 - acc: 0.7047 - val_loss: 0.5811 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5978 - acc: 0.7150 - val_loss: 0.5766 - val_acc: 0.7377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5933 - acc: 0.7202 - val_loss: 0.5721 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5890 - acc: 0.7306 - val_loss: 0.5670 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5843 - acc: 0.7306 - val_loss: 0.5623 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5798 - acc: 0.7358 - val_loss: 0.5578 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5754 - acc: 0.7409 - val_loss: 0.5537 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5713 - acc: 0.7461 - val_loss: 0.5491 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5670 - acc: 0.7409 - val_loss: 0.5445 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5625 - acc: 0.7461 - val_loss: 0.5401 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5583 - acc: 0.7461 - val_loss: 0.5359 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5545 - acc: 0.7565 - val_loss: 0.5327 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5509 - acc: 0.7617 - val_loss: 0.5291 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5470 - acc: 0.7617 - val_loss: 0.5253 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5432 - acc: 0.7617 - val_loss: 0.5216 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5396 - acc: 0.7668 - val_loss: 0.5181 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5363 - acc: 0.7772 - val_loss: 0.5146 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5327 - acc: 0.7772 - val_loss: 0.5111 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7806 - acc: 0.4715 - val_loss: 0.8963 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7708 - acc: 0.4819 - val_loss: 0.8851 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7618 - acc: 0.4922 - val_loss: 0.8741 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7530 - acc: 0.5130 - val_loss: 0.8632 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7444 - acc: 0.5181 - val_loss: 0.8527 - val_acc: 0.3770\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7368 - acc: 0.5130 - val_loss: 0.8436 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7288 - acc: 0.5130 - val_loss: 0.8340 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7214 - acc: 0.5130 - val_loss: 0.8256 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7146 - acc: 0.5285 - val_loss: 0.8177 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7083 - acc: 0.5389 - val_loss: 0.8097 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7019 - acc: 0.5492 - val_loss: 0.8007 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6947 - acc: 0.5648 - val_loss: 0.7918 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6879 - acc: 0.5648 - val_loss: 0.7837 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6814 - acc: 0.5751 - val_loss: 0.7761 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6751 - acc: 0.5803 - val_loss: 0.7674 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6679 - acc: 0.5959 - val_loss: 0.7591 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6616 - acc: 0.6062 - val_loss: 0.7514 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6554 - acc: 0.6010 - val_loss: 0.7441 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6497 - acc: 0.6166 - val_loss: 0.7370 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6439 - acc: 0.6218 - val_loss: 0.7304 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5909 - acc: 0.6340 - val_loss: 0.5212 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5844 - acc: 0.6392 - val_loss: 0.5152 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5787 - acc: 0.6546 - val_loss: 0.5095 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5730 - acc: 0.6598 - val_loss: 0.5033 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5672 - acc: 0.6649 - val_loss: 0.4979 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5616 - acc: 0.6753 - val_loss: 0.4924 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5563 - acc: 0.6959 - val_loss: 0.4871 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5514 - acc: 0.7010 - val_loss: 0.4822 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5468 - acc: 0.7113 - val_loss: 0.4774 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5420 - acc: 0.7216 - val_loss: 0.4723 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5372 - acc: 0.7371 - val_loss: 0.4673 - val_acc: 0.7541\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5323 - acc: 0.7371 - val_loss: 0.4630 - val_acc: 0.7541\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5280 - acc: 0.7423 - val_loss: 0.4588 - val_acc: 0.7541\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5238 - acc: 0.7577 - val_loss: 0.4546 - val_acc: 0.7705\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5193 - acc: 0.7577 - val_loss: 0.4503 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5151 - acc: 0.7577 - val_loss: 0.4462 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5112 - acc: 0.7526 - val_loss: 0.4423 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5073 - acc: 0.7577 - val_loss: 0.4384 - val_acc: 0.7869\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5037 - acc: 0.7629 - val_loss: 0.4347 - val_acc: 0.7869\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5000 - acc: 0.7629 - val_loss: 0.4316 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7475 - acc: 0.5722 - val_loss: 0.7377 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7404 - acc: 0.5773 - val_loss: 0.7296 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7338 - acc: 0.5876 - val_loss: 0.7217 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7273 - acc: 0.5876 - val_loss: 0.7139 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7210 - acc: 0.5928 - val_loss: 0.7067 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7147 - acc: 0.6031 - val_loss: 0.6988 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7081 - acc: 0.6031 - val_loss: 0.6908 - val_acc: 0.6230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7017 - acc: 0.6031 - val_loss: 0.6833 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6958 - acc: 0.6082 - val_loss: 0.6761 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6897 - acc: 0.6082 - val_loss: 0.6699 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6846 - acc: 0.6134 - val_loss: 0.6637 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6793 - acc: 0.6134 - val_loss: 0.6580 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6742 - acc: 0.6134 - val_loss: 0.6523 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6689 - acc: 0.6134 - val_loss: 0.6466 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6638 - acc: 0.6134 - val_loss: 0.6406 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6586 - acc: 0.6134 - val_loss: 0.6348 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6533 - acc: 0.6186 - val_loss: 0.6292 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6482 - acc: 0.6237 - val_loss: 0.6236 - val_acc: 0.6066\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6432 - acc: 0.6237 - val_loss: 0.6185 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6385 - acc: 0.6392 - val_loss: 0.6134 - val_acc: 0.6066\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8048 - acc: 0.5206 - val_loss: 0.6714 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7965 - acc: 0.5258 - val_loss: 0.6624 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7882 - acc: 0.5258 - val_loss: 0.6536 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7805 - acc: 0.5309 - val_loss: 0.6453 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7728 - acc: 0.5464 - val_loss: 0.6373 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7652 - acc: 0.5515 - val_loss: 0.6289 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7579 - acc: 0.5619 - val_loss: 0.6213 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7508 - acc: 0.5670 - val_loss: 0.6139 - val_acc: 0.6393\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7439 - acc: 0.5773 - val_loss: 0.6062 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7368 - acc: 0.5928 - val_loss: 0.5992 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7297 - acc: 0.6031 - val_loss: 0.5919 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7228 - acc: 0.6186 - val_loss: 0.5846 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7158 - acc: 0.6289 - val_loss: 0.5784 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7098 - acc: 0.6340 - val_loss: 0.5718 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7035 - acc: 0.6443 - val_loss: 0.5656 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6969 - acc: 0.6443 - val_loss: 0.5594 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6903 - acc: 0.6495 - val_loss: 0.5530 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6843 - acc: 0.6598 - val_loss: 0.5474 - val_acc: 0.7541\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6786 - acc: 0.6598 - val_loss: 0.5423 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6730 - acc: 0.6701 - val_loss: 0.5370 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8693 - acc: 0.2798 - val_loss: 0.8160 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8552 - acc: 0.2902 - val_loss: 0.8020 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8431 - acc: 0.3264 - val_loss: 0.7897 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8314 - acc: 0.3420 - val_loss: 0.7776 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8211 - acc: 0.3575 - val_loss: 0.7673 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8110 - acc: 0.3782 - val_loss: 0.7566 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8007 - acc: 0.3782 - val_loss: 0.7455 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7903 - acc: 0.3938 - val_loss: 0.7359 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7814 - acc: 0.3990 - val_loss: 0.7257 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7712 - acc: 0.3990 - val_loss: 0.7158 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7621 - acc: 0.3990 - val_loss: 0.7060 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7527 - acc: 0.4145 - val_loss: 0.6972 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7438 - acc: 0.4197 - val_loss: 0.6879 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7346 - acc: 0.4456 - val_loss: 0.6786 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7261 - acc: 0.4611 - val_loss: 0.6698 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7180 - acc: 0.4819 - val_loss: 0.6620 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7101 - acc: 0.4974 - val_loss: 0.6534 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7021 - acc: 0.5285 - val_loss: 0.6448 - val_acc: 0.6393\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6943 - acc: 0.5440 - val_loss: 0.6365 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6871 - acc: 0.5492 - val_loss: 0.6287 - val_acc: 0.6885\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8763 - acc: 0.4041 - val_loss: 0.8021 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8602 - acc: 0.4093 - val_loss: 0.7889 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8460 - acc: 0.4145 - val_loss: 0.7773 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8335 - acc: 0.4301 - val_loss: 0.7657 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8204 - acc: 0.4352 - val_loss: 0.7540 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8074 - acc: 0.4352 - val_loss: 0.7430 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7958 - acc: 0.4352 - val_loss: 0.7325 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7842 - acc: 0.4404 - val_loss: 0.7219 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7722 - acc: 0.4508 - val_loss: 0.7111 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7610 - acc: 0.4508 - val_loss: 0.7013 - val_acc: 0.5082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7500 - acc: 0.4560 - val_loss: 0.6909 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7389 - acc: 0.4560 - val_loss: 0.6816 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7289 - acc: 0.4715 - val_loss: 0.6725 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7185 - acc: 0.5026 - val_loss: 0.6630 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7085 - acc: 0.5130 - val_loss: 0.6542 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6989 - acc: 0.5233 - val_loss: 0.6454 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6897 - acc: 0.5492 - val_loss: 0.6374 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6810 - acc: 0.5544 - val_loss: 0.6287 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6725 - acc: 0.5803 - val_loss: 0.6207 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6641 - acc: 0.5855 - val_loss: 0.6124 - val_acc: 0.6066\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8974 - acc: 0.3814 - val_loss: 0.9566 - val_acc: 0.3279\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8772 - acc: 0.3866 - val_loss: 0.9353 - val_acc: 0.3279\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8588 - acc: 0.3918 - val_loss: 0.9131 - val_acc: 0.3279\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8409 - acc: 0.4124 - val_loss: 0.8920 - val_acc: 0.3279\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8230 - acc: 0.4227 - val_loss: 0.8719 - val_acc: 0.3443\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8068 - acc: 0.4381 - val_loss: 0.8538 - val_acc: 0.3443\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7920 - acc: 0.4433 - val_loss: 0.8362 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7769 - acc: 0.4691 - val_loss: 0.8186 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7620 - acc: 0.5206 - val_loss: 0.8024 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7485 - acc: 0.5361 - val_loss: 0.7861 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7348 - acc: 0.5412 - val_loss: 0.7715 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7229 - acc: 0.5464 - val_loss: 0.7576 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7113 - acc: 0.5773 - val_loss: 0.7444 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6997 - acc: 0.5876 - val_loss: 0.7306 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6878 - acc: 0.5979 - val_loss: 0.7165 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6762 - acc: 0.6186 - val_loss: 0.7033 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6648 - acc: 0.6340 - val_loss: 0.6908 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6540 - acc: 0.6443 - val_loss: 0.6784 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6436 - acc: 0.6598 - val_loss: 0.6661 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6332 - acc: 0.6701 - val_loss: 0.6548 - val_acc: 0.5902\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8513 - acc: 0.5515 - val_loss: 0.9243 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8378 - acc: 0.5515 - val_loss: 0.9067 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8238 - acc: 0.5515 - val_loss: 0.8908 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8109 - acc: 0.5567 - val_loss: 0.8753 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7985 - acc: 0.5567 - val_loss: 0.8610 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7872 - acc: 0.5619 - val_loss: 0.8469 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7753 - acc: 0.5619 - val_loss: 0.8337 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7646 - acc: 0.5567 - val_loss: 0.8197 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7532 - acc: 0.5722 - val_loss: 0.8066 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7425 - acc: 0.5825 - val_loss: 0.7934 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7324 - acc: 0.5928 - val_loss: 0.7810 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7221 - acc: 0.5979 - val_loss: 0.7682 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7120 - acc: 0.5979 - val_loss: 0.7566 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7026 - acc: 0.5979 - val_loss: 0.7446 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6931 - acc: 0.5979 - val_loss: 0.7334 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6834 - acc: 0.6031 - val_loss: 0.7226 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6751 - acc: 0.6134 - val_loss: 0.7119 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6667 - acc: 0.6237 - val_loss: 0.7019 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6587 - acc: 0.6237 - val_loss: 0.6931 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6515 - acc: 0.6289 - val_loss: 0.6839 - val_acc: 0.5902\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8047 - acc: 0.4227 - val_loss: 0.6951 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7929 - acc: 0.4330 - val_loss: 0.6850 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7817 - acc: 0.4639 - val_loss: 0.6755 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7712 - acc: 0.4639 - val_loss: 0.6661 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7608 - acc: 0.4691 - val_loss: 0.6574 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7506 - acc: 0.4691 - val_loss: 0.6490 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7408 - acc: 0.4948 - val_loss: 0.6408 - val_acc: 0.6393\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7319 - acc: 0.5052 - val_loss: 0.6325 - val_acc: 0.6393\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7222 - acc: 0.5103 - val_loss: 0.6245 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7131 - acc: 0.5361 - val_loss: 0.6171 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7044 - acc: 0.5619 - val_loss: 0.6100 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6961 - acc: 0.5722 - val_loss: 0.6026 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6874 - acc: 0.5773 - val_loss: 0.5955 - val_acc: 0.7049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6794 - acc: 0.6031 - val_loss: 0.5888 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6715 - acc: 0.6186 - val_loss: 0.5825 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6641 - acc: 0.6392 - val_loss: 0.5763 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6571 - acc: 0.6546 - val_loss: 0.5705 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6501 - acc: 0.6649 - val_loss: 0.5645 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6433 - acc: 0.6701 - val_loss: 0.5587 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6364 - acc: 0.6701 - val_loss: 0.5530 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6692 - acc: 0.6114 - val_loss: 0.6758 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6550 - acc: 0.6580 - val_loss: 0.6616 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6429 - acc: 0.6736 - val_loss: 0.6483 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6310 - acc: 0.6891 - val_loss: 0.6351 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6197 - acc: 0.7098 - val_loss: 0.6230 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6089 - acc: 0.7254 - val_loss: 0.6107 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5988 - acc: 0.7358 - val_loss: 0.5995 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5891 - acc: 0.7461 - val_loss: 0.5893 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5799 - acc: 0.7617 - val_loss: 0.5788 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5708 - acc: 0.7720 - val_loss: 0.5683 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5619 - acc: 0.7772 - val_loss: 0.5591 - val_acc: 0.7541\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5535 - acc: 0.7772 - val_loss: 0.5500 - val_acc: 0.7541\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5455 - acc: 0.7720 - val_loss: 0.5401 - val_acc: 0.7541\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5377 - acc: 0.7720 - val_loss: 0.5316 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5308 - acc: 0.7824 - val_loss: 0.5240 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5240 - acc: 0.7927 - val_loss: 0.5169 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5176 - acc: 0.8031 - val_loss: 0.5094 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5109 - acc: 0.8187 - val_loss: 0.5029 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5050 - acc: 0.8238 - val_loss: 0.4965 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4992 - acc: 0.8187 - val_loss: 0.4907 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8527 - acc: 0.4352 - val_loss: 0.8343 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8327 - acc: 0.4352 - val_loss: 0.8140 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8160 - acc: 0.4508 - val_loss: 0.7958 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8011 - acc: 0.4663 - val_loss: 0.7801 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7879 - acc: 0.4767 - val_loss: 0.7638 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7737 - acc: 0.5026 - val_loss: 0.7485 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7607 - acc: 0.5026 - val_loss: 0.7330 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7472 - acc: 0.5078 - val_loss: 0.7181 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7336 - acc: 0.5130 - val_loss: 0.7029 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7203 - acc: 0.5130 - val_loss: 0.6865 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7069 - acc: 0.5337 - val_loss: 0.6738 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6961 - acc: 0.5285 - val_loss: 0.6605 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6845 - acc: 0.5699 - val_loss: 0.6480 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6732 - acc: 0.5959 - val_loss: 0.6356 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6625 - acc: 0.6218 - val_loss: 0.6229 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6512 - acc: 0.6269 - val_loss: 0.6114 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6415 - acc: 0.6528 - val_loss: 0.6011 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6315 - acc: 0.6528 - val_loss: 0.5905 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6224 - acc: 0.6580 - val_loss: 0.5796 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6128 - acc: 0.6736 - val_loss: 0.5701 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8301 - acc: 0.5258 - val_loss: 0.7920 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8098 - acc: 0.5361 - val_loss: 0.7698 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7900 - acc: 0.5464 - val_loss: 0.7487 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7718 - acc: 0.5567 - val_loss: 0.7286 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7553 - acc: 0.5773 - val_loss: 0.7088 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7381 - acc: 0.5876 - val_loss: 0.6910 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7217 - acc: 0.5928 - val_loss: 0.6736 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7056 - acc: 0.6031 - val_loss: 0.6571 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6913 - acc: 0.6031 - val_loss: 0.6417 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6776 - acc: 0.6134 - val_loss: 0.6264 - val_acc: 0.6393\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6645 - acc: 0.6289 - val_loss: 0.6122 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6515 - acc: 0.6546 - val_loss: 0.5990 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6396 - acc: 0.6598 - val_loss: 0.5861 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6280 - acc: 0.6649 - val_loss: 0.5731 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6162 - acc: 0.6804 - val_loss: 0.5607 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6049 - acc: 0.6856 - val_loss: 0.5484 - val_acc: 0.7377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5936 - acc: 0.6804 - val_loss: 0.5371 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5833 - acc: 0.7062 - val_loss: 0.5263 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5732 - acc: 0.7165 - val_loss: 0.5156 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5633 - acc: 0.7268 - val_loss: 0.5053 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8808 - acc: 0.3969 - val_loss: 0.8354 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8578 - acc: 0.4124 - val_loss: 0.8150 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8377 - acc: 0.4433 - val_loss: 0.7953 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8166 - acc: 0.4485 - val_loss: 0.7769 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7983 - acc: 0.4485 - val_loss: 0.7594 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7809 - acc: 0.4536 - val_loss: 0.7426 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7630 - acc: 0.4691 - val_loss: 0.7251 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7458 - acc: 0.4794 - val_loss: 0.7085 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7294 - acc: 0.4897 - val_loss: 0.6932 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7149 - acc: 0.5052 - val_loss: 0.6795 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7006 - acc: 0.5206 - val_loss: 0.6671 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6873 - acc: 0.5258 - val_loss: 0.6546 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6744 - acc: 0.5464 - val_loss: 0.6423 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6621 - acc: 0.5619 - val_loss: 0.6301 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6506 - acc: 0.5670 - val_loss: 0.6196 - val_acc: 0.6393\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6389 - acc: 0.5773 - val_loss: 0.6086 - val_acc: 0.6557\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6282 - acc: 0.5928 - val_loss: 0.5982 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6173 - acc: 0.6031 - val_loss: 0.5888 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6074 - acc: 0.6134 - val_loss: 0.5787 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5974 - acc: 0.6546 - val_loss: 0.5693 - val_acc: 0.6885\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9110 - acc: 0.4536 - val_loss: 0.8455 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8862 - acc: 0.4536 - val_loss: 0.8233 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8634 - acc: 0.4485 - val_loss: 0.8021 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8409 - acc: 0.4485 - val_loss: 0.7820 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8211 - acc: 0.4433 - val_loss: 0.7628 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8016 - acc: 0.4485 - val_loss: 0.7460 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7838 - acc: 0.4485 - val_loss: 0.7287 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7661 - acc: 0.4639 - val_loss: 0.7140 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7505 - acc: 0.4588 - val_loss: 0.6975 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7331 - acc: 0.4742 - val_loss: 0.6820 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7171 - acc: 0.4845 - val_loss: 0.6670 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7018 - acc: 0.4845 - val_loss: 0.6533 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6876 - acc: 0.4948 - val_loss: 0.6389 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6737 - acc: 0.5103 - val_loss: 0.6260 - val_acc: 0.6393\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6606 - acc: 0.5464 - val_loss: 0.6148 - val_acc: 0.6393\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6494 - acc: 0.5670 - val_loss: 0.6040 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6380 - acc: 0.5722 - val_loss: 0.5929 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6266 - acc: 0.5876 - val_loss: 0.5819 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6155 - acc: 0.6134 - val_loss: 0.5720 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6057 - acc: 0.6289 - val_loss: 0.5632 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6730 - acc: 0.6321 - val_loss: 0.6355 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6497 - acc: 0.6891 - val_loss: 0.6143 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6296 - acc: 0.7098 - val_loss: 0.5961 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6112 - acc: 0.7254 - val_loss: 0.5786 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5942 - acc: 0.7409 - val_loss: 0.5632 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5789 - acc: 0.7461 - val_loss: 0.5491 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5646 - acc: 0.7461 - val_loss: 0.5360 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5516 - acc: 0.7409 - val_loss: 0.5237 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5393 - acc: 0.7513 - val_loss: 0.5117 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5273 - acc: 0.7513 - val_loss: 0.5005 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5159 - acc: 0.7461 - val_loss: 0.4905 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5056 - acc: 0.7668 - val_loss: 0.4814 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4964 - acc: 0.7824 - val_loss: 0.4750 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4882 - acc: 0.7876 - val_loss: 0.4681 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4799 - acc: 0.7927 - val_loss: 0.4612 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4722 - acc: 0.7979 - val_loss: 0.4549 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4648 - acc: 0.7979 - val_loss: 0.4483 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4575 - acc: 0.7979 - val_loss: 0.4425 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4513 - acc: 0.8238 - val_loss: 0.4375 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4459 - acc: 0.8187 - val_loss: 0.4349 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7341 - acc: 0.4974 - val_loss: 0.7643 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7077 - acc: 0.5596 - val_loss: 0.7341 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6865 - acc: 0.5907 - val_loss: 0.7077 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6660 - acc: 0.6321 - val_loss: 0.6827 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6464 - acc: 0.6684 - val_loss: 0.6588 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6305 - acc: 0.6788 - val_loss: 0.6401 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6165 - acc: 0.6788 - val_loss: 0.6223 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6018 - acc: 0.6995 - val_loss: 0.6045 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5882 - acc: 0.7202 - val_loss: 0.5872 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5748 - acc: 0.7150 - val_loss: 0.5708 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5626 - acc: 0.7254 - val_loss: 0.5568 - val_acc: 0.7541\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5514 - acc: 0.7202 - val_loss: 0.5433 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5405 - acc: 0.7306 - val_loss: 0.5302 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5306 - acc: 0.7358 - val_loss: 0.5188 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5208 - acc: 0.7565 - val_loss: 0.5061 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5118 - acc: 0.7720 - val_loss: 0.4966 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5038 - acc: 0.7772 - val_loss: 0.4876 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4962 - acc: 0.7668 - val_loss: 0.4790 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4888 - acc: 0.7720 - val_loss: 0.4708 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4819 - acc: 0.7772 - val_loss: 0.4623 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7707 - acc: 0.5206 - val_loss: 0.8127 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7407 - acc: 0.5464 - val_loss: 0.7793 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7154 - acc: 0.5670 - val_loss: 0.7475 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6894 - acc: 0.5928 - val_loss: 0.7205 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6669 - acc: 0.6443 - val_loss: 0.6941 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6463 - acc: 0.6443 - val_loss: 0.6691 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6268 - acc: 0.6649 - val_loss: 0.6459 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6080 - acc: 0.6907 - val_loss: 0.6246 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5907 - acc: 0.7010 - val_loss: 0.6047 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5751 - acc: 0.7113 - val_loss: 0.5847 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5597 - acc: 0.7320 - val_loss: 0.5673 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5471 - acc: 0.7474 - val_loss: 0.5521 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5342 - acc: 0.7680 - val_loss: 0.5383 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5230 - acc: 0.7784 - val_loss: 0.5246 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5125 - acc: 0.7835 - val_loss: 0.5112 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5023 - acc: 0.7835 - val_loss: 0.4987 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4932 - acc: 0.7938 - val_loss: 0.4878 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4840 - acc: 0.7887 - val_loss: 0.4780 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4761 - acc: 0.7938 - val_loss: 0.4691 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4688 - acc: 0.7887 - val_loss: 0.4599 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7321 - acc: 0.4433 - val_loss: 0.7119 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7047 - acc: 0.4948 - val_loss: 0.6843 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6798 - acc: 0.5412 - val_loss: 0.6592 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6583 - acc: 0.5825 - val_loss: 0.6374 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6384 - acc: 0.6546 - val_loss: 0.6165 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6193 - acc: 0.7165 - val_loss: 0.5993 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6033 - acc: 0.7680 - val_loss: 0.5821 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5872 - acc: 0.7732 - val_loss: 0.5648 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5709 - acc: 0.7938 - val_loss: 0.5490 - val_acc: 0.7049\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5564 - acc: 0.7990 - val_loss: 0.5346 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5428 - acc: 0.8041 - val_loss: 0.5214 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5308 - acc: 0.8041 - val_loss: 0.5098 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5197 - acc: 0.8144 - val_loss: 0.4987 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5094 - acc: 0.8247 - val_loss: 0.4898 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5003 - acc: 0.8402 - val_loss: 0.4810 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4918 - acc: 0.8402 - val_loss: 0.4727 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4831 - acc: 0.8351 - val_loss: 0.4658 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4756 - acc: 0.8402 - val_loss: 0.4594 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4681 - acc: 0.8402 - val_loss: 0.4524 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4610 - acc: 0.8402 - val_loss: 0.4458 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7259 - acc: 0.5103 - val_loss: 0.6732 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6996 - acc: 0.5515 - val_loss: 0.6507 - val_acc: 0.5902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6764 - acc: 0.5979 - val_loss: 0.6305 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6557 - acc: 0.6289 - val_loss: 0.6128 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6362 - acc: 0.6443 - val_loss: 0.5956 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6186 - acc: 0.6701 - val_loss: 0.5807 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6016 - acc: 0.6959 - val_loss: 0.5655 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5858 - acc: 0.7165 - val_loss: 0.5510 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5699 - acc: 0.7216 - val_loss: 0.5382 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5568 - acc: 0.7268 - val_loss: 0.5269 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5437 - acc: 0.7423 - val_loss: 0.5149 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5310 - acc: 0.7680 - val_loss: 0.5045 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5195 - acc: 0.7784 - val_loss: 0.4942 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5087 - acc: 0.7835 - val_loss: 0.4850 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4988 - acc: 0.8041 - val_loss: 0.4779 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4900 - acc: 0.8247 - val_loss: 0.4702 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4816 - acc: 0.8247 - val_loss: 0.4642 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4742 - acc: 0.8299 - val_loss: 0.4575 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4663 - acc: 0.8402 - val_loss: 0.4513 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4591 - acc: 0.8402 - val_loss: 0.4450 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6686 - acc: 0.6528 - val_loss: 0.6583 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6349 - acc: 0.7047 - val_loss: 0.6240 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6068 - acc: 0.7358 - val_loss: 0.5941 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5820 - acc: 0.7668 - val_loss: 0.5695 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5616 - acc: 0.7979 - val_loss: 0.5480 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5436 - acc: 0.8238 - val_loss: 0.5297 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5276 - acc: 0.8187 - val_loss: 0.5129 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5118 - acc: 0.8187 - val_loss: 0.4979 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4977 - acc: 0.8290 - val_loss: 0.4847 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4854 - acc: 0.8342 - val_loss: 0.4712 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4738 - acc: 0.8290 - val_loss: 0.4599 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4628 - acc: 0.8342 - val_loss: 0.4498 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4531 - acc: 0.8394 - val_loss: 0.4411 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4443 - acc: 0.8394 - val_loss: 0.4319 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4360 - acc: 0.8394 - val_loss: 0.4244 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4281 - acc: 0.8290 - val_loss: 0.4174 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4209 - acc: 0.8342 - val_loss: 0.4094 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4138 - acc: 0.8394 - val_loss: 0.4028 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4074 - acc: 0.8394 - val_loss: 0.3965 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4020 - acc: 0.8342 - val_loss: 0.3903 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7262 - acc: 0.4508 - val_loss: 0.6861 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6911 - acc: 0.5337 - val_loss: 0.6543 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6627 - acc: 0.6218 - val_loss: 0.6258 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6362 - acc: 0.6736 - val_loss: 0.5992 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6120 - acc: 0.7150 - val_loss: 0.5751 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5902 - acc: 0.7358 - val_loss: 0.5529 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5708 - acc: 0.7772 - val_loss: 0.5329 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5530 - acc: 0.8083 - val_loss: 0.5151 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5362 - acc: 0.8290 - val_loss: 0.4982 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5208 - acc: 0.8290 - val_loss: 0.4823 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5080 - acc: 0.8290 - val_loss: 0.4689 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4955 - acc: 0.8290 - val_loss: 0.4556 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4836 - acc: 0.8342 - val_loss: 0.4441 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4736 - acc: 0.8342 - val_loss: 0.4333 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4637 - acc: 0.8342 - val_loss: 0.4237 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4550 - acc: 0.8446 - val_loss: 0.4150 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4468 - acc: 0.8446 - val_loss: 0.4068 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4399 - acc: 0.8446 - val_loss: 0.3986 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4334 - acc: 0.8497 - val_loss: 0.3914 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4271 - acc: 0.8497 - val_loss: 0.3853 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7033 - acc: 0.5464 - val_loss: 0.6899 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6659 - acc: 0.6237 - val_loss: 0.6507 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6352 - acc: 0.6701 - val_loss: 0.6190 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6076 - acc: 0.7268 - val_loss: 0.5898 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5817 - acc: 0.7577 - val_loss: 0.5640 - val_acc: 0.7869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5590 - acc: 0.7732 - val_loss: 0.5403 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5390 - acc: 0.7835 - val_loss: 0.5208 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5210 - acc: 0.8247 - val_loss: 0.5027 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5051 - acc: 0.8351 - val_loss: 0.4858 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4903 - acc: 0.8351 - val_loss: 0.4718 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4778 - acc: 0.8402 - val_loss: 0.4593 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4663 - acc: 0.8402 - val_loss: 0.4480 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4557 - acc: 0.8505 - val_loss: 0.4378 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4458 - acc: 0.8505 - val_loss: 0.4279 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4365 - acc: 0.8557 - val_loss: 0.4191 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4283 - acc: 0.8557 - val_loss: 0.4110 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4204 - acc: 0.8557 - val_loss: 0.4041 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4128 - acc: 0.8557 - val_loss: 0.3978 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4064 - acc: 0.8557 - val_loss: 0.3921 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4005 - acc: 0.8608 - val_loss: 0.3856 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7619 - acc: 0.5567 - val_loss: 0.7551 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7227 - acc: 0.5567 - val_loss: 0.7092 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6876 - acc: 0.5567 - val_loss: 0.6704 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6571 - acc: 0.5876 - val_loss: 0.6327 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6287 - acc: 0.6340 - val_loss: 0.6030 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6049 - acc: 0.6649 - val_loss: 0.5738 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5814 - acc: 0.7113 - val_loss: 0.5482 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5611 - acc: 0.7113 - val_loss: 0.5250 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5417 - acc: 0.7320 - val_loss: 0.5044 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5256 - acc: 0.7526 - val_loss: 0.4877 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5121 - acc: 0.7577 - val_loss: 0.4726 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4993 - acc: 0.7784 - val_loss: 0.4577 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4869 - acc: 0.7887 - val_loss: 0.4438 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4756 - acc: 0.8041 - val_loss: 0.4324 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4662 - acc: 0.7887 - val_loss: 0.4228 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4581 - acc: 0.7887 - val_loss: 0.4140 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4495 - acc: 0.7835 - val_loss: 0.4060 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4424 - acc: 0.7938 - val_loss: 0.3992 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4354 - acc: 0.8041 - val_loss: 0.3922 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4289 - acc: 0.8041 - val_loss: 0.3854 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7169 - acc: 0.5155 - val_loss: 0.6651 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6809 - acc: 0.5825 - val_loss: 0.6292 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6501 - acc: 0.6443 - val_loss: 0.5994 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6235 - acc: 0.6649 - val_loss: 0.5721 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5999 - acc: 0.7113 - val_loss: 0.5474 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5767 - acc: 0.7113 - val_loss: 0.5249 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5571 - acc: 0.7629 - val_loss: 0.5041 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5380 - acc: 0.7680 - val_loss: 0.4864 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5216 - acc: 0.7784 - val_loss: 0.4697 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5060 - acc: 0.8041 - val_loss: 0.4544 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4921 - acc: 0.8041 - val_loss: 0.4416 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4794 - acc: 0.8093 - val_loss: 0.4298 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4680 - acc: 0.8093 - val_loss: 0.4193 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4576 - acc: 0.8144 - val_loss: 0.4103 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4490 - acc: 0.8351 - val_loss: 0.4024 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4401 - acc: 0.8402 - val_loss: 0.3948 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4325 - acc: 0.8454 - val_loss: 0.3878 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4258 - acc: 0.8505 - val_loss: 0.3819 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4189 - acc: 0.8557 - val_loss: 0.3766 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4129 - acc: 0.8557 - val_loss: 0.3720 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6421 - acc: 0.7617 - val_loss: 0.5911 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5997 - acc: 0.7876 - val_loss: 0.5506 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5650 - acc: 0.8083 - val_loss: 0.5181 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5357 - acc: 0.8135 - val_loss: 0.4899 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5134 - acc: 0.8342 - val_loss: 0.4701 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4932 - acc: 0.8446 - val_loss: 0.4539 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4768 - acc: 0.8342 - val_loss: 0.4379 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4616 - acc: 0.8394 - val_loss: 0.4230 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4473 - acc: 0.8394 - val_loss: 0.4106 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4353 - acc: 0.8446 - val_loss: 0.4003 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4247 - acc: 0.8497 - val_loss: 0.3916 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4154 - acc: 0.8497 - val_loss: 0.3829 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4064 - acc: 0.8497 - val_loss: 0.3747 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3980 - acc: 0.8497 - val_loss: 0.3675 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3909 - acc: 0.8497 - val_loss: 0.3622 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3841 - acc: 0.8549 - val_loss: 0.3582 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3787 - acc: 0.8549 - val_loss: 0.3535 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3735 - acc: 0.8549 - val_loss: 0.3504 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3686 - acc: 0.8549 - val_loss: 0.3476 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3643 - acc: 0.8549 - val_loss: 0.3439 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6692 - acc: 0.6218 - val_loss: 0.6509 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6245 - acc: 0.7254 - val_loss: 0.6046 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5884 - acc: 0.7824 - val_loss: 0.5665 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5573 - acc: 0.8083 - val_loss: 0.5377 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5329 - acc: 0.8342 - val_loss: 0.5118 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5110 - acc: 0.8394 - val_loss: 0.4883 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4898 - acc: 0.8446 - val_loss: 0.4689 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4735 - acc: 0.8497 - val_loss: 0.4510 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4585 - acc: 0.8497 - val_loss: 0.4356 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4458 - acc: 0.8497 - val_loss: 0.4236 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4355 - acc: 0.8497 - val_loss: 0.4117 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4252 - acc: 0.8497 - val_loss: 0.4006 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4164 - acc: 0.8549 - val_loss: 0.3907 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4080 - acc: 0.8549 - val_loss: 0.3827 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4004 - acc: 0.8601 - val_loss: 0.3764 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3936 - acc: 0.8601 - val_loss: 0.3706 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3877 - acc: 0.8653 - val_loss: 0.3661 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3823 - acc: 0.8653 - val_loss: 0.3612 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3772 - acc: 0.8653 - val_loss: 0.3570 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3730 - acc: 0.8653 - val_loss: 0.3527 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6715 - acc: 0.5258 - val_loss: 0.6648 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6242 - acc: 0.7062 - val_loss: 0.6153 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5876 - acc: 0.7526 - val_loss: 0.5756 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5542 - acc: 0.8041 - val_loss: 0.5404 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5264 - acc: 0.8144 - val_loss: 0.5104 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5036 - acc: 0.8299 - val_loss: 0.4876 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4844 - acc: 0.8299 - val_loss: 0.4663 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4669 - acc: 0.8351 - val_loss: 0.4468 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4515 - acc: 0.8454 - val_loss: 0.4300 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4383 - acc: 0.8505 - val_loss: 0.4183 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4281 - acc: 0.8505 - val_loss: 0.4072 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4179 - acc: 0.8608 - val_loss: 0.3965 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4084 - acc: 0.8608 - val_loss: 0.3874 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4000 - acc: 0.8608 - val_loss: 0.3794 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3927 - acc: 0.8608 - val_loss: 0.3715 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3852 - acc: 0.8608 - val_loss: 0.3656 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3790 - acc: 0.8557 - val_loss: 0.3600 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3732 - acc: 0.8505 - val_loss: 0.3548 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3674 - acc: 0.8454 - val_loss: 0.3512 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3626 - acc: 0.8557 - val_loss: 0.3467 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6986 - acc: 0.4845 - val_loss: 0.6914 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6498 - acc: 0.6495 - val_loss: 0.6446 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6114 - acc: 0.7062 - val_loss: 0.6036 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5778 - acc: 0.7887 - val_loss: 0.5668 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5466 - acc: 0.7938 - val_loss: 0.5396 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5241 - acc: 0.8093 - val_loss: 0.5134 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5023 - acc: 0.8196 - val_loss: 0.4920 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4850 - acc: 0.8299 - val_loss: 0.4717 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4687 - acc: 0.8247 - val_loss: 0.4549 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4549 - acc: 0.8299 - val_loss: 0.4406 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4422 - acc: 0.8299 - val_loss: 0.4289 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4312 - acc: 0.8351 - val_loss: 0.4181 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4222 - acc: 0.8402 - val_loss: 0.4100 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4140 - acc: 0.8351 - val_loss: 0.4017 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4068 - acc: 0.8351 - val_loss: 0.3943 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4001 - acc: 0.8351 - val_loss: 0.3889 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3939 - acc: 0.8351 - val_loss: 0.3832 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3884 - acc: 0.8402 - val_loss: 0.3792 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3836 - acc: 0.8402 - val_loss: 0.3750 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3791 - acc: 0.8351 - val_loss: 0.3719 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6512 - acc: 0.6804 - val_loss: 0.5776 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6084 - acc: 0.7629 - val_loss: 0.5393 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5740 - acc: 0.7938 - val_loss: 0.5063 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5442 - acc: 0.7990 - val_loss: 0.4805 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5190 - acc: 0.8144 - val_loss: 0.4610 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4988 - acc: 0.8299 - val_loss: 0.4434 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4818 - acc: 0.8351 - val_loss: 0.4282 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4661 - acc: 0.8351 - val_loss: 0.4155 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4525 - acc: 0.8351 - val_loss: 0.4042 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4401 - acc: 0.8351 - val_loss: 0.3937 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4292 - acc: 0.8351 - val_loss: 0.3847 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4199 - acc: 0.8402 - val_loss: 0.3774 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4124 - acc: 0.8402 - val_loss: 0.3702 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4049 - acc: 0.8454 - val_loss: 0.3644 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3987 - acc: 0.8505 - val_loss: 0.3600 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3923 - acc: 0.8454 - val_loss: 0.3559 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3862 - acc: 0.8454 - val_loss: 0.3521 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3814 - acc: 0.8454 - val_loss: 0.3486 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3760 - acc: 0.8454 - val_loss: 0.3458 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3717 - acc: 0.8454 - val_loss: 0.3419 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8254 - acc: 0.4611 - val_loss: 0.7773 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7637 - acc: 0.5389 - val_loss: 0.7245 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7159 - acc: 0.5803 - val_loss: 0.6781 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6704 - acc: 0.6269 - val_loss: 0.6376 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6320 - acc: 0.6736 - val_loss: 0.6003 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5985 - acc: 0.6943 - val_loss: 0.5682 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5708 - acc: 0.7047 - val_loss: 0.5403 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5500 - acc: 0.7098 - val_loss: 0.5197 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5290 - acc: 0.7306 - val_loss: 0.5010 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5124 - acc: 0.7461 - val_loss: 0.4836 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4964 - acc: 0.7617 - val_loss: 0.4670 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4811 - acc: 0.7772 - val_loss: 0.4512 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4677 - acc: 0.7824 - val_loss: 0.4382 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4551 - acc: 0.7876 - val_loss: 0.4261 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4428 - acc: 0.7772 - val_loss: 0.4144 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4312 - acc: 0.7772 - val_loss: 0.4044 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4204 - acc: 0.7772 - val_loss: 0.3945 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4107 - acc: 0.7824 - val_loss: 0.3854 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4024 - acc: 0.7824 - val_loss: 0.3777 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3946 - acc: 0.7824 - val_loss: 0.3724 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0564 - acc: 0.4145 - val_loss: 0.9222 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9425 - acc: 0.4145 - val_loss: 0.8223 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8465 - acc: 0.4404 - val_loss: 0.7394 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7656 - acc: 0.4715 - val_loss: 0.6681 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7030 - acc: 0.5181 - val_loss: 0.6185 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6544 - acc: 0.5803 - val_loss: 0.5845 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6203 - acc: 0.6477 - val_loss: 0.5534 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5875 - acc: 0.6684 - val_loss: 0.5281 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5631 - acc: 0.6943 - val_loss: 0.5040 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5396 - acc: 0.7202 - val_loss: 0.4836 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5208 - acc: 0.7409 - val_loss: 0.4680 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5072 - acc: 0.7513 - val_loss: 0.4567 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4944 - acc: 0.7565 - val_loss: 0.4455 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4837 - acc: 0.7668 - val_loss: 0.4355 - val_acc: 0.8197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4738 - acc: 0.7720 - val_loss: 0.4256 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4649 - acc: 0.7720 - val_loss: 0.4163 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4565 - acc: 0.7824 - val_loss: 0.4085 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4496 - acc: 0.7772 - val_loss: 0.3998 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4424 - acc: 0.7876 - val_loss: 0.3941 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4369 - acc: 0.7927 - val_loss: 0.3871 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7466 - acc: 0.5979 - val_loss: 0.6968 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6764 - acc: 0.6546 - val_loss: 0.6429 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6198 - acc: 0.6907 - val_loss: 0.6035 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5764 - acc: 0.7113 - val_loss: 0.5680 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5415 - acc: 0.7320 - val_loss: 0.5373 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5123 - acc: 0.7474 - val_loss: 0.5123 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4894 - acc: 0.7680 - val_loss: 0.4929 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4701 - acc: 0.7784 - val_loss: 0.4766 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4551 - acc: 0.7938 - val_loss: 0.4620 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4420 - acc: 0.8093 - val_loss: 0.4472 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4291 - acc: 0.8041 - val_loss: 0.4346 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4179 - acc: 0.8299 - val_loss: 0.4248 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4098 - acc: 0.8299 - val_loss: 0.4186 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4015 - acc: 0.8402 - val_loss: 0.4123 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3939 - acc: 0.8454 - val_loss: 0.4054 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3874 - acc: 0.8402 - val_loss: 0.3987 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3805 - acc: 0.8454 - val_loss: 0.3951 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3743 - acc: 0.8557 - val_loss: 0.3902 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3696 - acc: 0.8557 - val_loss: 0.3834 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3643 - acc: 0.8608 - val_loss: 0.3804 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8160 - acc: 0.4948 - val_loss: 0.8152 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7623 - acc: 0.5464 - val_loss: 0.7697 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7210 - acc: 0.5670 - val_loss: 0.7285 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6819 - acc: 0.5979 - val_loss: 0.6943 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6474 - acc: 0.6340 - val_loss: 0.6637 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6189 - acc: 0.7010 - val_loss: 0.6352 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5914 - acc: 0.7268 - val_loss: 0.6094 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5673 - acc: 0.7423 - val_loss: 0.5853 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5465 - acc: 0.7526 - val_loss: 0.5645 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5266 - acc: 0.7526 - val_loss: 0.5458 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5097 - acc: 0.7680 - val_loss: 0.5293 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4943 - acc: 0.7784 - val_loss: 0.5134 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4798 - acc: 0.7784 - val_loss: 0.4987 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4685 - acc: 0.7938 - val_loss: 0.4866 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4588 - acc: 0.8041 - val_loss: 0.4790 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4505 - acc: 0.8041 - val_loss: 0.4682 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4418 - acc: 0.8093 - val_loss: 0.4600 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4338 - acc: 0.8144 - val_loss: 0.4531 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4268 - acc: 0.8144 - val_loss: 0.4445 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4202 - acc: 0.8144 - val_loss: 0.4380 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9187 - acc: 0.5361 - val_loss: 0.9888 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8525 - acc: 0.5412 - val_loss: 0.8954 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7931 - acc: 0.5412 - val_loss: 0.8205 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7442 - acc: 0.5619 - val_loss: 0.7552 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7017 - acc: 0.5928 - val_loss: 0.7017 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6674 - acc: 0.6340 - val_loss: 0.6566 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6405 - acc: 0.6649 - val_loss: 0.6171 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6152 - acc: 0.6804 - val_loss: 0.5838 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5936 - acc: 0.6907 - val_loss: 0.5523 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5745 - acc: 0.7062 - val_loss: 0.5226 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5548 - acc: 0.7062 - val_loss: 0.4971 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5390 - acc: 0.7268 - val_loss: 0.4762 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5252 - acc: 0.7526 - val_loss: 0.4577 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5113 - acc: 0.7577 - val_loss: 0.4398 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4994 - acc: 0.7680 - val_loss: 0.4242 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4885 - acc: 0.7680 - val_loss: 0.4130 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4791 - acc: 0.7732 - val_loss: 0.4036 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4710 - acc: 0.7784 - val_loss: 0.3936 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4623 - acc: 0.7938 - val_loss: 0.3839 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4550 - acc: 0.7938 - val_loss: 0.3758 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8687 - acc: 0.3990 - val_loss: 0.7440 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8020 - acc: 0.4301 - val_loss: 0.6894 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7460 - acc: 0.4922 - val_loss: 0.6417 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6948 - acc: 0.5544 - val_loss: 0.6016 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6511 - acc: 0.5959 - val_loss: 0.5684 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6148 - acc: 0.6218 - val_loss: 0.5352 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5812 - acc: 0.6995 - val_loss: 0.5081 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5534 - acc: 0.7358 - val_loss: 0.4844 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5277 - acc: 0.7461 - val_loss: 0.4619 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5056 - acc: 0.7617 - val_loss: 0.4435 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4865 - acc: 0.7720 - val_loss: 0.4266 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4691 - acc: 0.7979 - val_loss: 0.4146 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4539 - acc: 0.8083 - val_loss: 0.4026 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4400 - acc: 0.8187 - val_loss: 0.3910 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4272 - acc: 0.8238 - val_loss: 0.3824 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4151 - acc: 0.8238 - val_loss: 0.3743 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4054 - acc: 0.8342 - val_loss: 0.3669 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3970 - acc: 0.8290 - val_loss: 0.3604 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3891 - acc: 0.8394 - val_loss: 0.3549 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3817 - acc: 0.8394 - val_loss: 0.3501 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6905 - acc: 0.5959 - val_loss: 0.6119 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6262 - acc: 0.6632 - val_loss: 0.5555 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5831 - acc: 0.7047 - val_loss: 0.5166 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5494 - acc: 0.7513 - val_loss: 0.4889 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5216 - acc: 0.7668 - val_loss: 0.4639 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4993 - acc: 0.7772 - val_loss: 0.4460 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4811 - acc: 0.7927 - val_loss: 0.4312 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4652 - acc: 0.7979 - val_loss: 0.4161 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4502 - acc: 0.8031 - val_loss: 0.4044 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4384 - acc: 0.8083 - val_loss: 0.3943 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4271 - acc: 0.8083 - val_loss: 0.3853 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4163 - acc: 0.8083 - val_loss: 0.3792 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4074 - acc: 0.8083 - val_loss: 0.3729 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3991 - acc: 0.8238 - val_loss: 0.3672 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3919 - acc: 0.8394 - val_loss: 0.3616 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3851 - acc: 0.8394 - val_loss: 0.3543 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3780 - acc: 0.8394 - val_loss: 0.3512 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3699 - acc: 0.8394 - val_loss: 0.3490 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3652 - acc: 0.8446 - val_loss: 0.3459 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3615 - acc: 0.8446 - val_loss: 0.3395 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7739 - acc: 0.5464 - val_loss: 0.8375 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6897 - acc: 0.6237 - val_loss: 0.7476 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6312 - acc: 0.6495 - val_loss: 0.6723 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5801 - acc: 0.6804 - val_loss: 0.6120 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5449 - acc: 0.7062 - val_loss: 0.5652 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5140 - acc: 0.7474 - val_loss: 0.5261 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4878 - acc: 0.7577 - val_loss: 0.4947 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4666 - acc: 0.7680 - val_loss: 0.4666 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4462 - acc: 0.7938 - val_loss: 0.4471 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4286 - acc: 0.8093 - val_loss: 0.4285 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4138 - acc: 0.8247 - val_loss: 0.4124 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4014 - acc: 0.8299 - val_loss: 0.3997 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3897 - acc: 0.8351 - val_loss: 0.3884 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3804 - acc: 0.8454 - val_loss: 0.3794 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3716 - acc: 0.8454 - val_loss: 0.3736 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3647 - acc: 0.8557 - val_loss: 0.3672 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3583 - acc: 0.8557 - val_loss: 0.3608 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3515 - acc: 0.8557 - val_loss: 0.3562 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3465 - acc: 0.8557 - val_loss: 0.3511 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3413 - acc: 0.8608 - val_loss: 0.3459 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8843 - acc: 0.4794 - val_loss: 0.8633 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7857 - acc: 0.5825 - val_loss: 0.7577 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7147 - acc: 0.6237 - val_loss: 0.6707 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6518 - acc: 0.6856 - val_loss: 0.6057 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6085 - acc: 0.7113 - val_loss: 0.5595 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5698 - acc: 0.7268 - val_loss: 0.5193 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5385 - acc: 0.7423 - val_loss: 0.4839 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5113 - acc: 0.7526 - val_loss: 0.4582 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4875 - acc: 0.7577 - val_loss: 0.4340 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4658 - acc: 0.7732 - val_loss: 0.4158 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4504 - acc: 0.7990 - val_loss: 0.4018 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4361 - acc: 0.7990 - val_loss: 0.3908 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4238 - acc: 0.8041 - val_loss: 0.3821 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4124 - acc: 0.8093 - val_loss: 0.3762 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4022 - acc: 0.8144 - val_loss: 0.3699 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3937 - acc: 0.8144 - val_loss: 0.3654 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3863 - acc: 0.8196 - val_loss: 0.3617 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3794 - acc: 0.8299 - val_loss: 0.3576 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3732 - acc: 0.8247 - val_loss: 0.3551 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3663 - acc: 0.8247 - val_loss: 0.3531 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7672 - acc: 0.4588 - val_loss: 0.7248 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6848 - acc: 0.5979 - val_loss: 0.6457 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6253 - acc: 0.6959 - val_loss: 0.5819 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5755 - acc: 0.7629 - val_loss: 0.5368 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5385 - acc: 0.8093 - val_loss: 0.5024 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5069 - acc: 0.8299 - val_loss: 0.4733 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4824 - acc: 0.8351 - val_loss: 0.4518 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4621 - acc: 0.8351 - val_loss: 0.4349 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4456 - acc: 0.8351 - val_loss: 0.4207 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4313 - acc: 0.8402 - val_loss: 0.4074 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4193 - acc: 0.8454 - val_loss: 0.3958 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4073 - acc: 0.8402 - val_loss: 0.3872 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3979 - acc: 0.8402 - val_loss: 0.3797 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3892 - acc: 0.8402 - val_loss: 0.3744 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3817 - acc: 0.8402 - val_loss: 0.3690 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3748 - acc: 0.8402 - val_loss: 0.3639 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3688 - acc: 0.8402 - val_loss: 0.3591 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3635 - acc: 0.8402 - val_loss: 0.3568 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3580 - acc: 0.8454 - val_loss: 0.3550 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3549 - acc: 0.8505 - val_loss: 0.3507 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7667 - acc: 0.5130 - val_loss: 0.6535 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6492 - acc: 0.6269 - val_loss: 0.5571 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5681 - acc: 0.7202 - val_loss: 0.4874 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5138 - acc: 0.7772 - val_loss: 0.4419 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4748 - acc: 0.7927 - val_loss: 0.4066 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4422 - acc: 0.8135 - val_loss: 0.3829 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4174 - acc: 0.8187 - val_loss: 0.3644 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3969 - acc: 0.8238 - val_loss: 0.3514 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3813 - acc: 0.8238 - val_loss: 0.3409 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3683 - acc: 0.8238 - val_loss: 0.3333 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3577 - acc: 0.8394 - val_loss: 0.3283 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3480 - acc: 0.8446 - val_loss: 0.3239 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3408 - acc: 0.8446 - val_loss: 0.3199 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3341 - acc: 0.8549 - val_loss: 0.3146 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3289 - acc: 0.8549 - val_loss: 0.3114 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3215 - acc: 0.8601 - val_loss: 0.3107 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3160 - acc: 0.8601 - val_loss: 0.3116 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3101 - acc: 0.8601 - val_loss: 0.3132 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3058 - acc: 0.8601 - val_loss: 0.3124 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3008 - acc: 0.8653 - val_loss: 0.3118 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7209 - acc: 0.5648 - val_loss: 0.6338 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6400 - acc: 0.6632 - val_loss: 0.5566 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5869 - acc: 0.7358 - val_loss: 0.4921 - val_acc: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5398 - acc: 0.7565 - val_loss: 0.4470 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5032 - acc: 0.7927 - val_loss: 0.4179 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4764 - acc: 0.8135 - val_loss: 0.3944 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4543 - acc: 0.8187 - val_loss: 0.3755 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4351 - acc: 0.8187 - val_loss: 0.3593 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4190 - acc: 0.8342 - val_loss: 0.3498 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4076 - acc: 0.8394 - val_loss: 0.3455 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3978 - acc: 0.8394 - val_loss: 0.3377 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3874 - acc: 0.8446 - val_loss: 0.3300 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3798 - acc: 0.8497 - val_loss: 0.3287 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3728 - acc: 0.8497 - val_loss: 0.3273 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3645 - acc: 0.8497 - val_loss: 0.3237 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3574 - acc: 0.8497 - val_loss: 0.3194 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3506 - acc: 0.8497 - val_loss: 0.3170 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3445 - acc: 0.8549 - val_loss: 0.3156 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3392 - acc: 0.8601 - val_loss: 0.3133 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3337 - acc: 0.8601 - val_loss: 0.3112 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8723 - acc: 0.3196 - val_loss: 0.8255 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7507 - acc: 0.5000 - val_loss: 0.7146 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6618 - acc: 0.6443 - val_loss: 0.6302 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5936 - acc: 0.6959 - val_loss: 0.5659 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5441 - acc: 0.7629 - val_loss: 0.5128 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5006 - acc: 0.7990 - val_loss: 0.4711 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4677 - acc: 0.8196 - val_loss: 0.4374 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4404 - acc: 0.8247 - val_loss: 0.4085 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4187 - acc: 0.8454 - val_loss: 0.3867 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3995 - acc: 0.8608 - val_loss: 0.3698 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3854 - acc: 0.8711 - val_loss: 0.3577 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3754 - acc: 0.8711 - val_loss: 0.3503 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3659 - acc: 0.8711 - val_loss: 0.3408 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3555 - acc: 0.8711 - val_loss: 0.3332 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3465 - acc: 0.8763 - val_loss: 0.3258 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3383 - acc: 0.8763 - val_loss: 0.3197 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3320 - acc: 0.8711 - val_loss: 0.3171 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3258 - acc: 0.8763 - val_loss: 0.3162 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3204 - acc: 0.8763 - val_loss: 0.3113 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1771 - acc: 0.937 - 0s 1ms/step - loss: 0.3137 - acc: 0.8814 - val_loss: 0.3070 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6822 - acc: 0.5619 - val_loss: 0.6692 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5914 - acc: 0.6649 - val_loss: 0.5875 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5347 - acc: 0.7268 - val_loss: 0.5233 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4888 - acc: 0.7732 - val_loss: 0.4760 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4538 - acc: 0.7990 - val_loss: 0.4429 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4292 - acc: 0.8093 - val_loss: 0.4185 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4104 - acc: 0.8196 - val_loss: 0.4018 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3954 - acc: 0.8196 - val_loss: 0.3863 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3829 - acc: 0.8247 - val_loss: 0.3756 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3737 - acc: 0.8351 - val_loss: 0.3650 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3655 - acc: 0.8454 - val_loss: 0.3576 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3569 - acc: 0.8505 - val_loss: 0.3531 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3506 - acc: 0.8454 - val_loss: 0.3479 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3442 - acc: 0.8454 - val_loss: 0.3439 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3388 - acc: 0.8557 - val_loss: 0.3438 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3340 - acc: 0.8660 - val_loss: 0.3418 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3297 - acc: 0.8660 - val_loss: 0.3463 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3255 - acc: 0.8711 - val_loss: 0.3455 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3218 - acc: 0.8711 - val_loss: 0.3476 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3183 - acc: 0.8763 - val_loss: 0.3470 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7747 - acc: 0.5155 - val_loss: 0.6486 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6476 - acc: 0.5876 - val_loss: 0.5530 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5605 - acc: 0.7113 - val_loss: 0.4864 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5003 - acc: 0.7835 - val_loss: 0.4476 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4579 - acc: 0.7938 - val_loss: 0.4201 - val_acc: 0.8197\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4284 - acc: 0.8093 - val_loss: 0.3959 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4061 - acc: 0.8196 - val_loss: 0.3785 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3907 - acc: 0.8402 - val_loss: 0.3647 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3779 - acc: 0.8454 - val_loss: 0.3555 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3682 - acc: 0.8557 - val_loss: 0.3486 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3607 - acc: 0.8608 - val_loss: 0.3450 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3540 - acc: 0.8660 - val_loss: 0.3420 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3477 - acc: 0.8711 - val_loss: 0.3391 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3422 - acc: 0.8711 - val_loss: 0.3333 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3364 - acc: 0.8711 - val_loss: 0.3314 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3315 - acc: 0.8711 - val_loss: 0.3302 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3276 - acc: 0.8711 - val_loss: 0.3292 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3233 - acc: 0.8711 - val_loss: 0.3300 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3198 - acc: 0.8660 - val_loss: 0.3343 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3163 - acc: 0.8608 - val_loss: 0.3342 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6736 - acc: 0.5803 - val_loss: 0.5710 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5319 - acc: 0.7565 - val_loss: 0.4689 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4521 - acc: 0.8187 - val_loss: 0.4140 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4080 - acc: 0.8290 - val_loss: 0.3839 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3819 - acc: 0.8290 - val_loss: 0.3693 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3630 - acc: 0.8394 - val_loss: 0.3572 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3477 - acc: 0.8549 - val_loss: 0.3470 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3365 - acc: 0.8446 - val_loss: 0.3405 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3269 - acc: 0.8549 - val_loss: 0.3369 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3191 - acc: 0.8601 - val_loss: 0.3438 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3152 - acc: 0.8653 - val_loss: 0.3445 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3088 - acc: 0.8653 - val_loss: 0.3422 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3015 - acc: 0.8756 - val_loss: 0.3393 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2956 - acc: 0.8705 - val_loss: 0.3378 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6913 - acc: 0.5803 - val_loss: 0.6264 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5739 - acc: 0.6995 - val_loss: 0.5391 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5063 - acc: 0.7720 - val_loss: 0.4784 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4626 - acc: 0.7876 - val_loss: 0.4452 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4356 - acc: 0.8135 - val_loss: 0.4212 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4147 - acc: 0.8238 - val_loss: 0.4028 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3970 - acc: 0.8290 - val_loss: 0.3893 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3831 - acc: 0.8342 - val_loss: 0.3819 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3713 - acc: 0.8394 - val_loss: 0.3731 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3603 - acc: 0.8601 - val_loss: 0.3646 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3510 - acc: 0.8601 - val_loss: 0.3596 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3431 - acc: 0.8653 - val_loss: 0.3567 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3357 - acc: 0.8705 - val_loss: 0.3508 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3293 - acc: 0.8756 - val_loss: 0.3476 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3221 - acc: 0.8756 - val_loss: 0.3475 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4239 - acc: 0.750 - 0s 1ms/step - loss: 0.3171 - acc: 0.8756 - val_loss: 0.3461 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3116 - acc: 0.8808 - val_loss: 0.3434 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3063 - acc: 0.8808 - val_loss: 0.3408 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3014 - acc: 0.8860 - val_loss: 0.3414 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2965 - acc: 0.8860 - val_loss: 0.3404 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7693 - acc: 0.4845 - val_loss: 0.6587 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5931 - acc: 0.7577 - val_loss: 0.5429 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4946 - acc: 0.8041 - val_loss: 0.4679 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4340 - acc: 0.8196 - val_loss: 0.4202 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3966 - acc: 0.8351 - val_loss: 0.3931 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3726 - acc: 0.8454 - val_loss: 0.3747 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3573 - acc: 0.8454 - val_loss: 0.3600 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3427 - acc: 0.8660 - val_loss: 0.3511 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3335 - acc: 0.8660 - val_loss: 0.3427 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3229 - acc: 0.8660 - val_loss: 0.3393 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3130 - acc: 0.8763 - val_loss: 0.3350 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3055 - acc: 0.8866 - val_loss: 0.3330 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2983 - acc: 0.8866 - val_loss: 0.3329 - val_acc: 0.8852\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2922 - acc: 0.8918 - val_loss: 0.3358 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2869 - acc: 0.8969 - val_loss: 0.3355 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2813 - acc: 0.8969 - val_loss: 0.3299 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2765 - acc: 0.9021 - val_loss: 0.3297 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2714 - acc: 0.9021 - val_loss: 0.3283 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2666 - acc: 0.9021 - val_loss: 0.3294 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2620 - acc: 0.9072 - val_loss: 0.3293 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6635 - acc: 0.6134 - val_loss: 0.6122 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5455 - acc: 0.7062 - val_loss: 0.5232 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4785 - acc: 0.7784 - val_loss: 0.4622 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4368 - acc: 0.8093 - val_loss: 0.4254 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4110 - acc: 0.8196 - val_loss: 0.4033 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3928 - acc: 0.8351 - val_loss: 0.3867 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3799 - acc: 0.8454 - val_loss: 0.3759 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3695 - acc: 0.8557 - val_loss: 0.3720 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3621 - acc: 0.8557 - val_loss: 0.3649 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3547 - acc: 0.8608 - val_loss: 0.3608 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3471 - acc: 0.8711 - val_loss: 0.3580 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3410 - acc: 0.8711 - val_loss: 0.3547 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3353 - acc: 0.8763 - val_loss: 0.3514 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3300 - acc: 0.8711 - val_loss: 0.3499 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3259 - acc: 0.8711 - val_loss: 0.3492 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3206 - acc: 0.8660 - val_loss: 0.3484 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3150 - acc: 0.8711 - val_loss: 0.3532 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3117 - acc: 0.8814 - val_loss: 0.3565 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3091 - acc: 0.8814 - val_loss: 0.3601 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3043 - acc: 0.8866 - val_loss: 0.3585 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7607 - acc: 0.5052 - val_loss: 0.6888 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6160 - acc: 0.6753 - val_loss: 0.5724 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5228 - acc: 0.7526 - val_loss: 0.5015 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4681 - acc: 0.7784 - val_loss: 0.4539 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4319 - acc: 0.8041 - val_loss: 0.4222 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4087 - acc: 0.8247 - val_loss: 0.4018 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3887 - acc: 0.8351 - val_loss: 0.3903 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3740 - acc: 0.8351 - val_loss: 0.3804 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3601 - acc: 0.8505 - val_loss: 0.3792 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3513 - acc: 0.8608 - val_loss: 0.3751 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3419 - acc: 0.8608 - val_loss: 0.3702 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3344 - acc: 0.8557 - val_loss: 0.3672 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3259 - acc: 0.8711 - val_loss: 0.3673 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3196 - acc: 0.8763 - val_loss: 0.3659 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3143 - acc: 0.8763 - val_loss: 0.3702 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3084 - acc: 0.8814 - val_loss: 0.3672 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3025 - acc: 0.8814 - val_loss: 0.3618 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2968 - acc: 0.8866 - val_loss: 0.3582 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2925 - acc: 0.8866 - val_loss: 0.3567 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2873 - acc: 0.8969 - val_loss: 0.3539 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6798 - acc: 0.5699 - val_loss: 0.5884 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5142 - acc: 0.7824 - val_loss: 0.4624 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4381 - acc: 0.8238 - val_loss: 0.4019 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3937 - acc: 0.8394 - val_loss: 0.3661 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3679 - acc: 0.8446 - val_loss: 0.3436 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3510 - acc: 0.8601 - val_loss: 0.3313 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3358 - acc: 0.8705 - val_loss: 0.3248 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3240 - acc: 0.8705 - val_loss: 0.3160 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3134 - acc: 0.8653 - val_loss: 0.3159 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3022 - acc: 0.8912 - val_loss: 0.3141 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2919 - acc: 0.9016 - val_loss: 0.3186 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2837 - acc: 0.9119 - val_loss: 0.3273 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2762 - acc: 0.9067 - val_loss: 0.3255 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2714 - acc: 0.9119 - val_loss: 0.3331 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2667 - acc: 0.9067 - val_loss: 0.3282 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5890 - acc: 0.7202 - val_loss: 0.4621 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4736 - acc: 0.8031 - val_loss: 0.3936 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4130 - acc: 0.8290 - val_loss: 0.3565 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3807 - acc: 0.8446 - val_loss: 0.3388 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3576 - acc: 0.8394 - val_loss: 0.3331 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3416 - acc: 0.8446 - val_loss: 0.3286 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3288 - acc: 0.8549 - val_loss: 0.3265 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3181 - acc: 0.8497 - val_loss: 0.3263 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3115 - acc: 0.8653 - val_loss: 0.3265 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3027 - acc: 0.8705 - val_loss: 0.3270 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2944 - acc: 0.8808 - val_loss: 0.3264 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2867 - acc: 0.8808 - val_loss: 0.3293 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2798 - acc: 0.8860 - val_loss: 0.3267 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6331 - acc: 0.6134 - val_loss: 0.5174 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4853 - acc: 0.7887 - val_loss: 0.4235 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4127 - acc: 0.8247 - val_loss: 0.3783 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3766 - acc: 0.8557 - val_loss: 0.3547 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3544 - acc: 0.8660 - val_loss: 0.3345 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3396 - acc: 0.8711 - val_loss: 0.3237 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3242 - acc: 0.8711 - val_loss: 0.3232 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3137 - acc: 0.8763 - val_loss: 0.3261 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3043 - acc: 0.8763 - val_loss: 0.3223 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2962 - acc: 0.8866 - val_loss: 0.3172 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2880 - acc: 0.8969 - val_loss: 0.3186 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2817 - acc: 0.9021 - val_loss: 0.3163 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2753 - acc: 0.9021 - val_loss: 0.3185 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2701 - acc: 0.9021 - val_loss: 0.3245 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2639 - acc: 0.9021 - val_loss: 0.3242 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2579 - acc: 0.8969 - val_loss: 0.3230 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2530 - acc: 0.9021 - val_loss: 0.3172 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7665 - acc: 0.4485 - val_loss: 0.6391 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5515 - acc: 0.7577 - val_loss: 0.4854 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4536 - acc: 0.8144 - val_loss: 0.4082 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4044 - acc: 0.8557 - val_loss: 0.3714 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3769 - acc: 0.8557 - val_loss: 0.3535 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3597 - acc: 0.8505 - val_loss: 0.3397 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3463 - acc: 0.8557 - val_loss: 0.3367 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3397 - acc: 0.8608 - val_loss: 0.3386 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3288 - acc: 0.8660 - val_loss: 0.3384 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3225 - acc: 0.8711 - val_loss: 0.3373 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3160 - acc: 0.8711 - val_loss: 0.3309 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3095 - acc: 0.8711 - val_loss: 0.3313 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3037 - acc: 0.8866 - val_loss: 0.3347 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2975 - acc: 0.8969 - val_loss: 0.3356 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2933 - acc: 0.8969 - val_loss: 0.3313 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2872 - acc: 0.8969 - val_loss: 0.3331 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5885 - acc: 0.7113 - val_loss: 0.4644 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4695 - acc: 0.8144 - val_loss: 0.3930 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4123 - acc: 0.8196 - val_loss: 0.3685 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3870 - acc: 0.8247 - val_loss: 0.3571 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3656 - acc: 0.8351 - val_loss: 0.3465 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3523 - acc: 0.8454 - val_loss: 0.3425 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3397 - acc: 0.8402 - val_loss: 0.3456 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3292 - acc: 0.8454 - val_loss: 0.3487 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3185 - acc: 0.8505 - val_loss: 0.3361 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3112 - acc: 0.8608 - val_loss: 0.3311 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3037 - acc: 0.8608 - val_loss: 0.3354 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2954 - acc: 0.8814 - val_loss: 0.3405 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2886 - acc: 0.8866 - val_loss: 0.3456 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2842 - acc: 0.8866 - val_loss: 0.3467 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2795 - acc: 0.8866 - val_loss: 0.3490 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5887 - acc: 0.6788 - val_loss: 0.4177 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4144 - acc: 0.8342 - val_loss: 0.3382 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3596 - acc: 0.8601 - val_loss: 0.3181 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3326 - acc: 0.8653 - val_loss: 0.3179 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3128 - acc: 0.8653 - val_loss: 0.3192 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2981 - acc: 0.8912 - val_loss: 0.3141 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2842 - acc: 0.9016 - val_loss: 0.3017 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2719 - acc: 0.9016 - val_loss: 0.3036 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2627 - acc: 0.9067 - val_loss: 0.3038 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2518 - acc: 0.9119 - val_loss: 0.3081 - val_acc: 0.9180\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2443 - acc: 0.9119 - val_loss: 0.3141 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2352 - acc: 0.9275 - val_loss: 0.3129 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5919 - acc: 0.6580 - val_loss: 0.4385 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4324 - acc: 0.8238 - val_loss: 0.3658 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3755 - acc: 0.8394 - val_loss: 0.3345 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3494 - acc: 0.8446 - val_loss: 0.3248 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3352 - acc: 0.8394 - val_loss: 0.3263 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3222 - acc: 0.8446 - val_loss: 0.3210 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3104 - acc: 0.8497 - val_loss: 0.3208 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2982 - acc: 0.8549 - val_loss: 0.3081 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2863 - acc: 0.8653 - val_loss: 0.3094 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2776 - acc: 0.8705 - val_loss: 0.3132 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2697 - acc: 0.8808 - val_loss: 0.3108 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2593 - acc: 0.8860 - val_loss: 0.3189 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2513 - acc: 0.9016 - val_loss: 0.3198 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6044 - acc: 0.7165 - val_loss: 0.4397 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4098 - acc: 0.8505 - val_loss: 0.3473 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3525 - acc: 0.8711 - val_loss: 0.3260 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3298 - acc: 0.8763 - val_loss: 0.3199 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3114 - acc: 0.8763 - val_loss: 0.3238 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2972 - acc: 0.8969 - val_loss: 0.3206 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2863 - acc: 0.8918 - val_loss: 0.3159 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2743 - acc: 0.8918 - val_loss: 0.3152 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2654 - acc: 0.8918 - val_loss: 0.3112 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2569 - acc: 0.9021 - val_loss: 0.3072 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2524 - acc: 0.9072 - val_loss: 0.3146 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2437 - acc: 0.9072 - val_loss: 0.3129 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2361 - acc: 0.9021 - val_loss: 0.3051 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2283 - acc: 0.9175 - val_loss: 0.3055 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2222 - acc: 0.9227 - val_loss: 0.3170 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2172 - acc: 0.9124 - val_loss: 0.3183 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2122 - acc: 0.9227 - val_loss: 0.3224 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2052 - acc: 0.9175 - val_loss: 0.3180 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5704 - acc: 0.7010 - val_loss: 0.4308 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4354 - acc: 0.7938 - val_loss: 0.3642 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3863 - acc: 0.8247 - val_loss: 0.3451 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3591 - acc: 0.8299 - val_loss: 0.3369 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3422 - acc: 0.8557 - val_loss: 0.3344 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3282 - acc: 0.8711 - val_loss: 0.3289 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3159 - acc: 0.8711 - val_loss: 0.3313 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3096 - acc: 0.8763 - val_loss: 0.3296 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3011 - acc: 0.8763 - val_loss: 0.3264 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2911 - acc: 0.8814 - val_loss: 0.3249 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2833 - acc: 0.8866 - val_loss: 0.3304 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2758 - acc: 0.8918 - val_loss: 0.3297 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2693 - acc: 0.8969 - val_loss: 0.3364 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2630 - acc: 0.8969 - val_loss: 0.3363 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2543 - acc: 0.9072 - val_loss: 0.3370 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5539 - acc: 0.7680 - val_loss: 0.4323 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4083 - acc: 0.8402 - val_loss: 0.3775 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3658 - acc: 0.8454 - val_loss: 0.3622 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3397 - acc: 0.8557 - val_loss: 0.3552 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3243 - acc: 0.8557 - val_loss: 0.3581 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3125 - acc: 0.8608 - val_loss: 0.3540 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3016 - acc: 0.8711 - val_loss: 0.3528 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2910 - acc: 0.8866 - val_loss: 0.3477 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2820 - acc: 0.8814 - val_loss: 0.3476 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2728 - acc: 0.8866 - val_loss: 0.3614 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2649 - acc: 0.8969 - val_loss: 0.3555 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2563 - acc: 0.9021 - val_loss: 0.3586 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2503 - acc: 0.9124 - val_loss: 0.3550 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2436 - acc: 0.9124 - val_loss: 0.3636 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5676 - acc: 0.7150 - val_loss: 0.4041 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3881 - acc: 0.8342 - val_loss: 0.3335 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3428 - acc: 0.8394 - val_loss: 0.3141 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3180 - acc: 0.8497 - val_loss: 0.3154 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2995 - acc: 0.8653 - val_loss: 0.3184 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2816 - acc: 0.8860 - val_loss: 0.3178 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2681 - acc: 0.8964 - val_loss: 0.3148 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2550 - acc: 0.9119 - val_loss: 0.3221 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5786 - acc: 0.7254 - val_loss: 0.3989 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3900 - acc: 0.8497 - val_loss: 0.3366 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3469 - acc: 0.8653 - val_loss: 0.3206 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3283 - acc: 0.8705 - val_loss: 0.3138 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3141 - acc: 0.8808 - val_loss: 0.3186 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2969 - acc: 0.8860 - val_loss: 0.3182 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2824 - acc: 0.8964 - val_loss: 0.3288 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2702 - acc: 0.8964 - val_loss: 0.3270 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2569 - acc: 0.8912 - val_loss: 0.3317 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5260 - acc: 0.7629 - val_loss: 0.3688 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3658 - acc: 0.8557 - val_loss: 0.3291 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3281 - acc: 0.8763 - val_loss: 0.3180 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3086 - acc: 0.8711 - val_loss: 0.3060 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2889 - acc: 0.8763 - val_loss: 0.3086 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2731 - acc: 0.8866 - val_loss: 0.3074 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2627 - acc: 0.8814 - val_loss: 0.3072 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2501 - acc: 0.8918 - val_loss: 0.3111 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2393 - acc: 0.8969 - val_loss: 0.3174 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5236 - acc: 0.7474 - val_loss: 0.3851 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3842 - acc: 0.8299 - val_loss: 0.3346 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3461 - acc: 0.8454 - val_loss: 0.3216 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3287 - acc: 0.8505 - val_loss: 0.3176 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3110 - acc: 0.8763 - val_loss: 0.3304 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2984 - acc: 0.8763 - val_loss: 0.3364 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2872 - acc: 0.8814 - val_loss: 0.3293 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2744 - acc: 0.8918 - val_loss: 0.3297 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2626 - acc: 0.8918 - val_loss: 0.3361 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5657 - acc: 0.7165 - val_loss: 0.3719 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3966 - acc: 0.8402 - val_loss: 0.3553 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3543 - acc: 0.8454 - val_loss: 0.3455 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3328 - acc: 0.8505 - val_loss: 0.3440 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3147 - acc: 0.8711 - val_loss: 0.3404 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2977 - acc: 0.8814 - val_loss: 0.3407 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2865 - acc: 0.8763 - val_loss: 0.3379 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2729 - acc: 0.8763 - val_loss: 0.3365 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2609 - acc: 0.8918 - val_loss: 0.3363 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2521 - acc: 0.9072 - val_loss: 0.3333 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.9072 - val_loss: 0.3421 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2319 - acc: 0.9175 - val_loss: 0.3398 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2250 - acc: 0.9227 - val_loss: 0.3372 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2147 - acc: 0.9381 - val_loss: 0.3512 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2052 - acc: 0.9278 - val_loss: 0.3441 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5975 - acc: 0.6736 - val_loss: 0.4850 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4189 - acc: 0.8238 - val_loss: 0.3901 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3524 - acc: 0.8394 - val_loss: 0.3448 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3178 - acc: 0.8653 - val_loss: 0.3194 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2954 - acc: 0.8756 - val_loss: 0.3081 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2779 - acc: 0.8756 - val_loss: 0.3148 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2642 - acc: 0.9016 - val_loss: 0.3122 - val_acc: 0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2564 - acc: 0.8964 - val_loss: 0.3101 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2460 - acc: 0.9067 - val_loss: 0.3168 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2365 - acc: 0.9171 - val_loss: 0.3175 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5827 - acc: 0.6943 - val_loss: 0.3421 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4060 - acc: 0.7979 - val_loss: 0.3237 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3732 - acc: 0.8394 - val_loss: 0.3154 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3440 - acc: 0.8601 - val_loss: 0.3032 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3277 - acc: 0.8653 - val_loss: 0.3012 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3105 - acc: 0.8601 - val_loss: 0.3120 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3013 - acc: 0.8653 - val_loss: 0.3201 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2883 - acc: 0.8549 - val_loss: 0.3148 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2785 - acc: 0.8653 - val_loss: 0.3170 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2784 - acc: 0.8808 - val_loss: 0.2981 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2826 - acc: 0.8653 - val_loss: 0.2867 - val_acc: 0.9180\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2766 - acc: 0.8860 - val_loss: 0.3041 - val_acc: 0.9180\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2566 - acc: 0.9016 - val_loss: 0.3237 - val_acc: 0.9180\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2494 - acc: 0.9016 - val_loss: 0.3387 - val_acc: 0.9180\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2407 - acc: 0.9067 - val_loss: 0.3460 - val_acc: 0.9180\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2319 - acc: 0.9171 - val_loss: 0.3701 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5695 - acc: 0.6907 - val_loss: 0.4461 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4052 - acc: 0.8402 - val_loss: 0.3660 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3583 - acc: 0.8660 - val_loss: 0.3622 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3350 - acc: 0.8711 - val_loss: 0.3521 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3222 - acc: 0.8505 - val_loss: 0.3464 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3077 - acc: 0.8711 - val_loss: 0.3371 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2961 - acc: 0.8557 - val_loss: 0.3360 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2829 - acc: 0.8814 - val_loss: 0.3569 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2762 - acc: 0.8969 - val_loss: 0.3605 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2619 - acc: 0.8969 - val_loss: 0.3611 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2512 - acc: 0.9072 - val_loss: 0.3619 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2422 - acc: 0.8969 - val_loss: 0.3646 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6548 - acc: 0.6186 - val_loss: 0.4528 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4586 - acc: 0.7938 - val_loss: 0.3575 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3935 - acc: 0.7990 - val_loss: 0.3161 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3643 - acc: 0.8351 - val_loss: 0.3099 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3495 - acc: 0.8247 - val_loss: 0.3176 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3416 - acc: 0.8144 - val_loss: 0.3263 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3261 - acc: 0.8402 - val_loss: 0.3164 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3119 - acc: 0.8763 - val_loss: 0.3350 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2980 - acc: 0.8918 - val_loss: 0.3350 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5977 - acc: 0.7010 - val_loss: 0.4138 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4089 - acc: 0.8196 - val_loss: 0.3713 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3635 - acc: 0.8402 - val_loss: 0.3702 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3422 - acc: 0.8299 - val_loss: 0.3584 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3244 - acc: 0.8557 - val_loss: 0.3500 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3079 - acc: 0.8711 - val_loss: 0.3548 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2944 - acc: 0.8763 - val_loss: 0.3604 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2811 - acc: 0.8814 - val_loss: 0.3678 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2728 - acc: 0.8814 - val_loss: 0.3847 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2617 - acc: 0.9021 - val_loss: 0.4135 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5758 - acc: 0.7150 - val_loss: 0.3797 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3907 - acc: 0.8238 - val_loss: 0.3391 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3345 - acc: 0.8394 - val_loss: 0.3335 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2970 - acc: 0.8705 - val_loss: 0.3317 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2875 - acc: 0.8756 - val_loss: 0.3248 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2708 - acc: 0.8860 - val_loss: 0.3263 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2649 - acc: 0.8808 - val_loss: 0.3294 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2503 - acc: 0.8860 - val_loss: 0.3273 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2393 - acc: 0.9016 - val_loss: 0.3302 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2254 - acc: 0.9067 - val_loss: 0.3395 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5336 - acc: 0.6943 - val_loss: 0.3876 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3751 - acc: 0.8394 - val_loss: 0.3818 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3514 - acc: 0.8394 - val_loss: 0.3809 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3245 - acc: 0.8446 - val_loss: 0.3479 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2948 - acc: 0.8705 - val_loss: 0.3651 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2872 - acc: 0.8705 - val_loss: 0.3764 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2732 - acc: 0.8601 - val_loss: 0.3706 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2688 - acc: 0.8601 - val_loss: 0.3628 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2612 - acc: 0.8653 - val_loss: 0.3780 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6424 - acc: 0.6237 - val_loss: 0.3547 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3726 - acc: 0.8454 - val_loss: 0.3033 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3279 - acc: 0.8660 - val_loss: 0.3231 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2957 - acc: 0.9072 - val_loss: 0.3204 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2772 - acc: 0.8918 - val_loss: 0.3286 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2656 - acc: 0.8814 - val_loss: 0.3141 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2494 - acc: 0.9021 - val_loss: 0.3155 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5701 - acc: 0.7216 - val_loss: 0.3523 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3808 - acc: 0.8299 - val_loss: 0.3399 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3454 - acc: 0.8557 - val_loss: 0.3414 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3219 - acc: 0.8608 - val_loss: 0.3144 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3013 - acc: 0.8660 - val_loss: 0.3177 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2855 - acc: 0.8711 - val_loss: 0.3077 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2704 - acc: 0.8711 - val_loss: 0.3062 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2587 - acc: 0.9072 - val_loss: 0.3043 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2419 - acc: 0.9072 - val_loss: 0.2954 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2324 - acc: 0.9072 - val_loss: 0.3048 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2145 - acc: 0.9175 - val_loss: 0.3188 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2002 - acc: 0.9278 - val_loss: 0.3356 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1934 - acc: 0.9433 - val_loss: 0.3367 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1921 - acc: 0.9381 - val_loss: 0.3424 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5723 - acc: 0.7423 - val_loss: 0.4236 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3878 - acc: 0.8247 - val_loss: 0.3627 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3417 - acc: 0.8505 - val_loss: 0.3611 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3132 - acc: 0.8660 - val_loss: 0.3749 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2976 - acc: 0.8763 - val_loss: 0.4150 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2787 - acc: 0.8918 - val_loss: 0.3796 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2733 - acc: 0.8969 - val_loss: 0.3713 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2547 - acc: 0.9072 - val_loss: 0.3986 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5695 - acc: 0.6788 - val_loss: 0.3785 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3842 - acc: 0.8290 - val_loss: 0.3820 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3344 - acc: 0.8705 - val_loss: 0.3505 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3025 - acc: 0.8756 - val_loss: 0.3339 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2761 - acc: 0.8808 - val_loss: 0.3284 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2573 - acc: 0.8912 - val_loss: 0.3331 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2427 - acc: 0.9119 - val_loss: 0.3276 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2345 - acc: 0.9171 - val_loss: 0.3719 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2443 - acc: 0.9067 - val_loss: 0.3937 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2605 - acc: 0.8860 - val_loss: 0.4004 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2296 - acc: 0.8912 - val_loss: 0.3779 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1893 - acc: 0.9430 - val_loss: 0.3634 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5141 - acc: 0.7254 - val_loss: 0.3531 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3648 - acc: 0.8394 - val_loss: 0.3313 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3125 - acc: 0.8705 - val_loss: 0.3481 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3035 - acc: 0.8705 - val_loss: 0.3552 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2771 - acc: 0.8912 - val_loss: 0.3530 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2556 - acc: 0.9119 - val_loss: 0.3649 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2393 - acc: 0.9171 - val_loss: 0.3588 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4950 - acc: 0.7577 - val_loss: 0.4073 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3406 - acc: 0.8711 - val_loss: 0.3544 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2893 - acc: 0.8866 - val_loss: 0.3238 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2636 - acc: 0.8969 - val_loss: 0.3099 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2424 - acc: 0.8918 - val_loss: 0.3273 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2389 - acc: 0.9124 - val_loss: 0.3239 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2157 - acc: 0.9124 - val_loss: 0.3022 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1992 - acc: 0.9175 - val_loss: 0.3074 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1799 - acc: 0.9227 - val_loss: 0.3302 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1705 - acc: 0.9330 - val_loss: 0.3531 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1556 - acc: 0.9536 - val_loss: 0.3542 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1519 - acc: 0.9588 - val_loss: 0.3233 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.4719 - acc: 0.7629 - val_loss: 0.3687 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3492 - acc: 0.8454 - val_loss: 0.3525 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3144 - acc: 0.8608 - val_loss: 0.3244 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2912 - acc: 0.8814 - val_loss: 0.3332 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2690 - acc: 0.8969 - val_loss: 0.3373 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2556 - acc: 0.9072 - val_loss: 0.3785 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2438 - acc: 0.8918 - val_loss: 0.3668 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2288 - acc: 0.9175 - val_loss: 0.3688 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5037 - acc: 0.7268 - val_loss: 0.3606 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3708 - acc: 0.8299 - val_loss: 0.3670 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3245 - acc: 0.8608 - val_loss: 0.3611 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2921 - acc: 0.8866 - val_loss: 0.3630 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2742 - acc: 0.9072 - val_loss: 0.3531 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2518 - acc: 0.9072 - val_loss: 0.3687 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2436 - acc: 0.9124 - val_loss: 0.3822 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2516 - acc: 0.8918 - val_loss: 0.4151 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2217 - acc: 0.9278 - val_loss: 0.4097 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2024 - acc: 0.9278 - val_loss: 0.4081 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4822 - acc: 0.7565 - val_loss: 0.3352 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3347 - acc: 0.8601 - val_loss: 0.3386 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2833 - acc: 0.8912 - val_loss: 0.3181 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2486 - acc: 0.9171 - val_loss: 0.3410 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2228 - acc: 0.9275 - val_loss: 0.3430 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2025 - acc: 0.9378 - val_loss: 0.3544 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1852 - acc: 0.9534 - val_loss: 0.3563 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1639 - acc: 0.9585 - val_loss: 0.3613 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4966 - acc: 0.7772 - val_loss: 0.3396 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3474 - acc: 0.8342 - val_loss: 0.3201 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2898 - acc: 0.8601 - val_loss: 0.3009 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2431 - acc: 0.9119 - val_loss: 0.3495 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2327 - acc: 0.9171 - val_loss: 0.3770 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2002 - acc: 0.9223 - val_loss: 0.3916 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1756 - acc: 0.9275 - val_loss: 0.3997 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1499 - acc: 0.9585 - val_loss: 0.4276 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5074 - acc: 0.7268 - val_loss: 0.3752 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3301 - acc: 0.8505 - val_loss: 0.3723 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2945 - acc: 0.8763 - val_loss: 0.3636 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2868 - acc: 0.8608 - val_loss: 0.3285 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2642 - acc: 0.8918 - val_loss: 0.3546 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2345 - acc: 0.8969 - val_loss: 0.3647 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2180 - acc: 0.9021 - val_loss: 0.3585 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1973 - acc: 0.9072 - val_loss: 0.3528 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1790 - acc: 0.9278 - val_loss: 0.3834 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4773 - acc: 0.7680 - val_loss: 0.3158 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3490 - acc: 0.8402 - val_loss: 0.3459 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2979 - acc: 0.8763 - val_loss: 0.3570 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2722 - acc: 0.9021 - val_loss: 0.3856 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2448 - acc: 0.9072 - val_loss: 0.3916 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2167 - acc: 0.9175 - val_loss: 0.3841 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5045 - acc: 0.7474 - val_loss: 0.3320 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3512 - acc: 0.8454 - val_loss: 0.3142 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2824 - acc: 0.8763 - val_loss: 0.3525 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2676 - acc: 0.8918 - val_loss: 0.3720 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2302 - acc: 0.9278 - val_loss: 0.3641 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2099 - acc: 0.9124 - val_loss: 0.4004 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1817 - acc: 0.9227 - val_loss: 0.4429 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5034 - acc: 0.7565 - val_loss: 0.3683 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3108 - acc: 0.8601 - val_loss: 0.3170 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2718 - acc: 0.8860 - val_loss: 0.3160 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2455 - acc: 0.9016 - val_loss: 0.3655 - val_acc: 0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2118 - acc: 0.9275 - val_loss: 0.3684 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2304 - acc: 0.9223 - val_loss: 0.3752 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2638 - acc: 0.8964 - val_loss: 0.4043 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2370 - acc: 0.9171 - val_loss: 0.4057 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4756 - acc: 0.7617 - val_loss: 0.3205 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3612 - acc: 0.8653 - val_loss: 0.3076 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2804 - acc: 0.8808 - val_loss: 0.3111 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2852 - acc: 0.8549 - val_loss: 0.3525 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2376 - acc: 0.8912 - val_loss: 0.3413 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2082 - acc: 0.9171 - val_loss: 0.3668 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1935 - acc: 0.9171 - val_loss: 0.4243 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4585 - acc: 0.7732 - val_loss: 0.3392 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3327 - acc: 0.8918 - val_loss: 0.3234 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2625 - acc: 0.8969 - val_loss: 0.3360 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2346 - acc: 0.9175 - val_loss: 0.3405 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2064 - acc: 0.9227 - val_loss: 0.3325 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1764 - acc: 0.9433 - val_loss: 0.3511 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1589 - acc: 0.9433 - val_loss: 0.3655 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.4973 - acc: 0.7629 - val_loss: 0.3774 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3398 - acc: 0.8660 - val_loss: 0.3356 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2682 - acc: 0.8763 - val_loss: 0.3534 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2372 - acc: 0.9021 - val_loss: 0.3730 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2169 - acc: 0.9227 - val_loss: 0.3743 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2124 - acc: 0.8969 - val_loss: 0.4049 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1831 - acc: 0.9227 - val_loss: 0.4269 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4974 - acc: 0.7784 - val_loss: 0.3276 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3288 - acc: 0.8454 - val_loss: 0.3604 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2860 - acc: 0.8918 - val_loss: 0.3648 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2579 - acc: 0.9072 - val_loss: 0.3907 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2161 - acc: 0.9330 - val_loss: 0.4440 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2069 - acc: 0.9330 - val_loss: 0.4746 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4820 - acc: 0.7617 - val_loss: 0.3422 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2980 - acc: 0.8705 - val_loss: 0.3643 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2377 - acc: 0.9171 - val_loss: 0.3250 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2124 - acc: 0.9430 - val_loss: 0.3998 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1980 - acc: 0.9378 - val_loss: 0.3679 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1484 - acc: 0.9534 - val_loss: 0.4302 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1319 - acc: 0.9741 - val_loss: 0.4705 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2305 - acc: 0.9171 - val_loss: 0.5240 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5467 - acc: 0.7565 - val_loss: 0.3275 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3265 - acc: 0.8394 - val_loss: 0.3530 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2664 - acc: 0.8964 - val_loss: 0.3371 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2169 - acc: 0.9171 - val_loss: 0.4067 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1937 - acc: 0.9275 - val_loss: 0.4459 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1770 - acc: 0.9326 - val_loss: 0.5133 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4790 - acc: 0.8196 - val_loss: 0.3195 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3072 - acc: 0.8814 - val_loss: 0.3208 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2505 - acc: 0.8969 - val_loss: 0.3429 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2196 - acc: 0.9227 - val_loss: 0.3856 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1889 - acc: 0.9330 - val_loss: 0.3863 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1925 - acc: 0.9227 - val_loss: 0.4120 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4769 - acc: 0.7784 - val_loss: 0.3695 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3154 - acc: 0.8608 - val_loss: 0.3293 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2658 - acc: 0.8763 - val_loss: 0.3558 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2559 - acc: 0.9072 - val_loss: 0.4506 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2100 - acc: 0.9227 - val_loss: 0.4116 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2155 - acc: 0.9175 - val_loss: 0.4673 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2063 - acc: 0.9227 - val_loss: 0.5182 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5127 - acc: 0.7784 - val_loss: 0.3439 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3140 - acc: 0.8763 - val_loss: 0.3554 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2731 - acc: 0.9124 - val_loss: 0.3721 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2521 - acc: 0.8969 - val_loss: 0.3855 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1930 - acc: 0.9433 - val_loss: 0.4296 - val_acc: 0.8361\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2024 - acc: 0.9381 - val_loss: 0.4519 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4855 - acc: 0.7668 - val_loss: 0.4401 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3261 - acc: 0.8808 - val_loss: 0.2933 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2958 - acc: 0.8705 - val_loss: 0.3687 - val_acc: 0.9180\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2266 - acc: 0.9016 - val_loss: 0.3592 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1803 - acc: 0.9585 - val_loss: 0.3842 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1689 - acc: 0.9430 - val_loss: 0.4487 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1348 - acc: 0.9637 - val_loss: 0.4768 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4966 - acc: 0.7668 - val_loss: 0.3386 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2973 - acc: 0.8601 - val_loss: 0.3820 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2748 - acc: 0.8653 - val_loss: 0.3794 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2384 - acc: 0.8756 - val_loss: 0.4887 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2216 - acc: 0.8912 - val_loss: 0.4742 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1972 - acc: 0.9275 - val_loss: 0.4791 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4659 - acc: 0.7629 - val_loss: 0.3028 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3350 - acc: 0.8505 - val_loss: 0.3882 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2628 - acc: 0.8763 - val_loss: 0.3610 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.9124 - val_loss: 0.3518 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1720 - acc: 0.9175 - val_loss: 0.4036 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1697 - acc: 0.9227 - val_loss: 0.4457 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5114 - acc: 0.7629 - val_loss: 0.3568 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3564 - acc: 0.8454 - val_loss: 0.4407 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2819 - acc: 0.8763 - val_loss: 0.3477 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2355 - acc: 0.9021 - val_loss: 0.4324 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2043 - acc: 0.9124 - val_loss: 0.4423 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1999 - acc: 0.9227 - val_loss: 0.5432 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1567 - acc: 0.9330 - val_loss: 0.5376 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1395 - acc: 0.9381 - val_loss: 0.6325 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5724 - acc: 0.7680 - val_loss: 0.4364 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3251 - acc: 0.8866 - val_loss: 0.3042 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2889 - acc: 0.8763 - val_loss: 0.4239 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2290 - acc: 0.9227 - val_loss: 0.3796 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1677 - acc: 0.9536 - val_loss: 0.4936 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1400 - acc: 0.9588 - val_loss: 0.5402 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1163 - acc: 0.9742 - val_loss: 0.6421 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4945 - acc: 0.7772 - val_loss: 0.3953 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3365 - acc: 0.8653 - val_loss: 0.3801 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2977 - acc: 0.8756 - val_loss: 0.3387 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2854 - acc: 0.8964 - val_loss: 0.4081 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2699 - acc: 0.9171 - val_loss: 0.4325 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2977 - acc: 0.9067 - val_loss: 0.4376 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2527 - acc: 0.9119 - val_loss: 0.4737 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2110 - acc: 0.9378 - val_loss: 0.3600 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5294 - acc: 0.7824 - val_loss: 0.4232 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4042 - acc: 0.8497 - val_loss: 0.3192 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3159 - acc: 0.8653 - val_loss: 0.3943 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3016 - acc: 0.8808 - val_loss: 0.3726 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3151 - acc: 0.8808 - val_loss: 0.5174 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3416 - acc: 0.8653 - val_loss: 0.6206 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2682 - acc: 0.8808 - val_loss: 0.5280 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5313 - acc: 0.7732 - val_loss: 0.3459 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3541 - acc: 0.8402 - val_loss: 0.3822 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3393 - acc: 0.8814 - val_loss: 0.3826 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2828 - acc: 0.8711 - val_loss: 0.4747 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3130 - acc: 0.8814 - val_loss: 0.5872 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2833 - acc: 0.8866 - val_loss: 0.5888 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5568 - acc: 0.7835 - val_loss: 0.3445 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3835 - acc: 0.8144 - val_loss: 0.3985 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3715 - acc: 0.8505 - val_loss: 0.3647 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2679 - acc: 0.8711 - val_loss: 0.4547 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2448 - acc: 0.8969 - val_loss: 0.4024 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2093 - acc: 0.9072 - val_loss: 0.5671 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6284 - acc: 0.7526 - val_loss: 0.4832 - val_acc: 0.8525\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3967 - acc: 0.7784 - val_loss: 0.4556 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3530 - acc: 0.8299 - val_loss: 0.5598 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3221 - acc: 0.8660 - val_loss: 0.4912 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2823 - acc: 0.8763 - val_loss: 0.4552 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2660 - acc: 0.8918 - val_loss: 0.4603 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2474 - acc: 0.9021 - val_loss: 0.5687 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2282 - acc: 0.9072 - val_loss: 0.6151 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2305 - acc: 0.9021 - val_loss: 0.6570 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2258 - acc: 0.9021 - val_loss: 0.7186 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5017 - acc: 0.7824 - val_loss: 0.3523 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4844 - acc: 0.8394 - val_loss: 0.4208 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3743 - acc: 0.8601 - val_loss: 0.2725 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3873 - acc: 0.8446 - val_loss: 0.4010 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4527 - acc: 0.8549 - val_loss: 0.4682 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3788 - acc: 0.8964 - val_loss: 0.3754 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2622 - acc: 0.9275 - val_loss: 0.3933 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2434 - acc: 0.8964 - val_loss: 0.4873 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5038 - acc: 0.7720 - val_loss: 0.3456 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3611 - acc: 0.8394 - val_loss: 0.3623 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3749 - acc: 0.8446 - val_loss: 0.5267 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2875 - acc: 0.8653 - val_loss: 0.6018 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2226 - acc: 0.8808 - val_loss: 0.7102 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4537 - acc: 0.8860 - val_loss: 1.7600 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5162 - acc: 0.8093 - val_loss: 0.3600 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3990 - acc: 0.8711 - val_loss: 0.5189 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2861 - acc: 0.8660 - val_loss: 0.4193 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2828 - acc: 0.8866 - val_loss: 0.4984 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2624 - acc: 0.8918 - val_loss: 0.8861 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3400 - acc: 0.8969 - val_loss: 0.5097 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5973 - acc: 0.7010 - val_loss: 0.3219 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4144 - acc: 0.8041 - val_loss: 0.3160 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4264 - acc: 0.8557 - val_loss: 0.5771 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3573 - acc: 0.8351 - val_loss: 0.3628 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3245 - acc: 0.8454 - val_loss: 0.4372 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3292 - acc: 0.8505 - val_loss: 0.4812 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2572 - acc: 0.8969 - val_loss: 0.3881 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5188 - acc: 0.7526 - val_loss: 0.4735 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3990 - acc: 0.8247 - val_loss: 0.4023 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3074 - acc: 0.8711 - val_loss: 0.5938 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2490 - acc: 0.8969 - val_loss: 0.5589 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2436 - acc: 0.9021 - val_loss: 0.6849 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1907 - acc: 0.9330 - val_loss: 0.8278 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2374 - acc: 0.9175 - val_loss: 0.9352 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6461 - acc: 0.7617 - val_loss: 0.6552 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5137 - acc: 0.8290 - val_loss: 0.3604 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2961 - acc: 0.8653 - val_loss: 0.4783 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2972 - acc: 0.8860 - val_loss: 0.6421 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3343 - acc: 0.9275 - val_loss: 0.6840 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2233 - acc: 0.9119 - val_loss: 0.7337 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2702 - acc: 0.8808 - val_loss: 0.7570 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6398 - acc: 0.7047 - val_loss: 0.6001 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6864 - acc: 0.8238 - val_loss: 0.4873 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3545 - acc: 0.8497 - val_loss: 0.3496 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2713 - acc: 0.8912 - val_loss: 0.4581 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1999 - acc: 0.9223 - val_loss: 0.7079 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2238 - acc: 0.9171 - val_loss: 0.7639 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2205 - acc: 0.9171 - val_loss: 0.8383 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3814 - acc: 0.8808 - val_loss: 1.0045 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6350 - acc: 0.7629 - val_loss: 0.2257 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5043 - acc: 0.8299 - val_loss: 0.6649 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3237 - acc: 0.8660 - val_loss: 0.6912 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3267 - acc: 0.8866 - val_loss: 0.5152 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2118 - acc: 0.9227 - val_loss: 0.5403 - val_acc: 0.8689\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2188 - acc: 0.8969 - val_loss: 0.9633 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5845 - acc: 0.7113 - val_loss: 0.4177 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5523 - acc: 0.8247 - val_loss: 0.6386 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4074 - acc: 0.8351 - val_loss: 0.5950 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3034 - acc: 0.8351 - val_loss: 0.4137 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2788 - acc: 0.8814 - val_loss: 0.5414 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2253 - acc: 0.9021 - val_loss: 0.5211 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2547 - acc: 0.9072 - val_loss: 0.6403 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3724 - acc: 0.8608 - val_loss: 0.6769 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5432 - acc: 0.8402 - val_loss: 0.9281 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8509 - acc: 0.7320 - val_loss: 0.5645 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6162 - acc: 0.7577 - val_loss: 1.0039 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5490 - acc: 0.8351 - val_loss: 0.7109 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4293 - acc: 0.8557 - val_loss: 0.7850 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3283 - acc: 0.8814 - val_loss: 0.4539 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3169 - acc: 0.8454 - val_loss: 0.6126 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2791 - acc: 0.9072 - val_loss: 0.6453 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1785 - acc: 0.9381 - val_loss: 0.7058 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1493 - acc: 0.9485 - val_loss: 0.8873 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1034 - acc: 0.9691 - val_loss: 0.8749 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8407 - acc: 0.7358 - val_loss: 0.5376 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7335 - acc: 0.7513 - val_loss: 0.6118 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5471 - acc: 0.8342 - val_loss: 0.4465 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4235 - acc: 0.8756 - val_loss: 0.5989 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6565 - acc: 0.8497 - val_loss: 1.9161 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8306 - acc: 0.8342 - val_loss: 1.3372 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5014 - acc: 0.8756 - val_loss: 1.2027 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6882 - acc: 0.8964 - val_loss: 1.2711 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7182 - acc: 0.7565 - val_loss: 2.1106 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8562 - acc: 0.8187 - val_loss: 0.9939 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4884 - acc: 0.8497 - val_loss: 0.6814 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5455 - acc: 0.8549 - val_loss: 0.9516 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8649 - acc: 0.8497 - val_loss: 0.6649 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5204 - acc: 0.8808 - val_loss: 1.1464 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4002 - acc: 0.8705 - val_loss: 0.8883 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7174 - acc: 0.9016 - val_loss: 1.7198 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4344 - acc: 0.9223 - val_loss: 1.9569 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3199 - acc: 0.9223 - val_loss: 1.5973 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8542 - acc: 0.7835 - val_loss: 0.8661 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5622 - acc: 0.8093 - val_loss: 0.9154 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5868 - acc: 0.8299 - val_loss: 0.6479 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4276 - acc: 0.8505 - val_loss: 0.5919 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4690 - acc: 0.8454 - val_loss: 0.8564 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3679 - acc: 0.8969 - val_loss: 0.7588 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3421 - acc: 0.9072 - val_loss: 0.7089 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3267 - acc: 0.8969 - val_loss: 2.7674 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6696 - acc: 0.8763 - val_loss: 1.0733 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8140 - acc: 0.6804 - val_loss: 0.4493 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6431 - acc: 0.8402 - val_loss: 0.5632 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5078 - acc: 0.8041 - val_loss: 0.9721 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5007 - acc: 0.8299 - val_loss: 1.0692 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4262 - acc: 0.8866 - val_loss: 1.0815 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0818 - acc: 0.8557 - val_loss: 1.7336 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9246 - acc: 0.7320 - val_loss: 1.0381 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8185 - acc: 0.7320 - val_loss: 0.5883 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4980 - acc: 0.8660 - val_loss: 0.7218 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2774 - acc: 0.8866 - val_loss: 0.5483 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5037 - acc: 0.8711 - val_loss: 1.0762 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3740 - acc: 0.8660 - val_loss: 1.4216 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4635 - acc: 0.8814 - val_loss: 1.7107 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5356 - acc: 0.8918 - val_loss: 2.9066 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6442 - acc: 0.8711 - val_loss: 1.4735 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1225 - acc: 0.7358 - val_loss: 1.0695 - val_acc: 0.7869\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9358 - acc: 0.7979 - val_loss: 0.5846 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9661 - acc: 0.8238 - val_loss: 2.2708 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1167 - acc: 0.8135 - val_loss: 1.3505 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0373 - acc: 0.8135 - val_loss: 2.1309 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.3283 - acc: 0.8808 - val_loss: 4.3325 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.7549 - acc: 0.8808 - val_loss: 2.1929 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0323 - acc: 0.7254 - val_loss: 1.9571 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3328 - acc: 0.7617 - val_loss: 1.6792 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5252 - acc: 0.8031 - val_loss: 2.3934 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9243 - acc: 0.8497 - val_loss: 1.8421 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.8571 - acc: 0.8031 - val_loss: 3.0742 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6495 - acc: 0.8549 - val_loss: 2.7218 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0187 - acc: 0.8808 - val_loss: 3.4577 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3956 - acc: 0.7216 - val_loss: 1.0527 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8125 - acc: 0.8196 - val_loss: 0.8694 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7319 - acc: 0.8247 - val_loss: 0.8068 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3547 - acc: 0.8918 - val_loss: 0.9292 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3933 - acc: 0.9021 - val_loss: 1.4971 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2879 - acc: 0.9124 - val_loss: 1.3091 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3149 - acc: 0.8969 - val_loss: 1.9224 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7890 - acc: 0.8660 - val_loss: 4.0731 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0841 - acc: 0.6804 - val_loss: 1.4857 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9894 - acc: 0.7423 - val_loss: 0.6603 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6106 - acc: 0.8093 - val_loss: 1.1432 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7719 - acc: 0.8454 - val_loss: 0.8940 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5490 - acc: 0.8660 - val_loss: 0.9123 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3282 - acc: 0.9072 - val_loss: 0.7127 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4350 - acc: 0.8969 - val_loss: 1.3514 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5561 - acc: 0.7577 - val_loss: 0.8535 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5511 - acc: 0.6495 - val_loss: 1.2528 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.4013 - acc: 0.7990 - val_loss: 0.7465 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6324 - acc: 0.8557 - val_loss: 0.7687 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5573 - acc: 0.8247 - val_loss: 0.7577 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2782 - acc: 0.9072 - val_loss: 0.6816 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4547 - acc: 0.9175 - val_loss: 1.2940 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2985 - acc: 0.9330 - val_loss: 0.9316 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5843 - acc: 0.9072 - val_loss: 2.0054 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5303 - acc: 0.9072 - val_loss: 1.5484 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4811 - acc: 0.8969 - val_loss: 1.3733 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1686 - acc: 0.7565 - val_loss: 4.9179 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1116 - acc: 0.7513 - val_loss: 2.2370 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.6514 - acc: 0.8446 - val_loss: 1.9523 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9229 - acc: 0.8446 - val_loss: 1.5695 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6602 - acc: 0.8705 - val_loss: 1.8039 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6666 - acc: 0.9016 - val_loss: 1.6302 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6255 - acc: 0.8808 - val_loss: 1.4686 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4594 - acc: 0.9275 - val_loss: 3.7622 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.6469 - acc: 0.8705 - val_loss: 4.1436 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.7691 - acc: 0.8756 - val_loss: 2.6064 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1718 - acc: 0.8964 - val_loss: 2.0202 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9816 - acc: 0.9119 - val_loss: 2.5307 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0551 - acc: 0.7202 - val_loss: 3.8739 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.5676 - acc: 0.7150 - val_loss: 1.5087 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5567 - acc: 0.8083 - val_loss: 2.4984 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1428 - acc: 0.8394 - val_loss: 2.2310 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0678 - acc: 0.8135 - val_loss: 1.9509 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8123 - acc: 0.8653 - val_loss: 1.5067 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6174 - acc: 0.9119 - val_loss: 2.1656 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4927 - acc: 0.9119 - val_loss: 3.4971 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5639 - acc: 0.9119 - val_loss: 3.8311 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2325 - acc: 0.9637 - val_loss: 3.6005 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2510 - acc: 0.9741 - val_loss: 3.8647 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.0439 - acc: 0.7474 - val_loss: 1.8833 - val_acc: 0.8033\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 1.9055 - acc: 0.8144 - val_loss: 1.9752 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.4337 - acc: 0.8196 - val_loss: 5.1745 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.4782 - acc: 0.8196 - val_loss: 4.4673 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.8176 - acc: 0.8918 - val_loss: 2.4743 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.3003 - acc: 0.8608 - val_loss: 3.4857 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4454 - acc: 0.7320 - val_loss: 1.9419 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1492 - acc: 0.7732 - val_loss: 2.6555 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.7351 - acc: 0.7990 - val_loss: 1.3053 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3656 - acc: 0.8093 - val_loss: 3.2165 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.4529 - acc: 0.7165 - val_loss: 9.2899 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.9759 - acc: 0.8093 - val_loss: 6.2427 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.4263 - acc: 0.8351 - val_loss: 5.3718 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.5062 - acc: 0.8454 - val_loss: 4.4003 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.7121 - acc: 0.7320 - val_loss: 1.8924 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.7173 - acc: 0.7165 - val_loss: 1.9233 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.9269 - acc: 0.8144 - val_loss: 1.5282 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.4948 - acc: 0.8093 - val_loss: 2.3469 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0967 - acc: 0.8763 - val_loss: 2.8818 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2612 - acc: 0.8866 - val_loss: 3.6972 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0660 - acc: 0.8557 - val_loss: 2.3497 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8832 - acc: 0.8918 - val_loss: 2.6489 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.1788 - acc: 0.7150 - val_loss: 5.0607 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.5047 - acc: 0.8135 - val_loss: 5.0919 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.7773 - acc: 0.8394 - val_loss: 4.5570 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.1912 - acc: 0.8290 - val_loss: 2.9503 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.8029 - acc: 0.8394 - val_loss: 5.3588 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.6531 - acc: 0.8653 - val_loss: 8.9899 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.4799 - acc: 0.8964 - val_loss: 2.8566 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.9892 - acc: 0.9016 - val_loss: 4.4820 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.6477 - acc: 0.9119 - val_loss: 5.7033 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.0713 - acc: 0.8342 - val_loss: 5.3698 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.7942 - acc: 0.8808 - val_loss: 6.0644 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3317 - acc: 0.9119 - val_loss: 4.9044 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.1305 - acc: 0.7098 - val_loss: 2.4373 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.2016 - acc: 0.7772 - val_loss: 3.0716 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1474 - acc: 0.8653 - val_loss: 5.7953 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.8015 - acc: 0.8290 - val_loss: 4.2709 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.6528 - acc: 0.7824 - val_loss: 6.8259 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.1563 - acc: 0.8342 - val_loss: 17.1620 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.7617 - acc: 0.7268 - val_loss: 3.2729 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1980 - acc: 0.7784 - val_loss: 7.0929 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.6569 - acc: 0.7990 - val_loss: 5.7033 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.3631 - acc: 0.8299 - val_loss: 5.8561 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.1914 - acc: 0.8196 - val_loss: 2.1627 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.6523 - acc: 0.8814 - val_loss: 5.4515 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8776 - acc: 0.9175 - val_loss: 4.9705 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.3030 - acc: 0.8969 - val_loss: 3.9897 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5943 - acc: 0.9124 - val_loss: 4.3550 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1437 - acc: 0.8763 - val_loss: 6.7982 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.4908 - acc: 0.7165 - val_loss: 0.9571 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.4730 - acc: 0.7526 - val_loss: 7.1911 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.5112 - acc: 0.7784 - val_loss: 6.2386 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.5270 - acc: 0.8041 - val_loss: 8.0349 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.1553 - acc: 0.8454 - val_loss: 5.9514 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.0213 - acc: 0.8608 - val_loss: 7.4379 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.2129 - acc: 0.6753 - val_loss: 6.8874 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.5932 - acc: 0.7784 - val_loss: 7.1768 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.0936 - acc: 0.7887 - val_loss: 2.9759 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1617 - acc: 0.8247 - val_loss: 9.8240 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5673 - acc: 0.8660 - val_loss: 4.0448 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.7619 - acc: 0.8608 - val_loss: 5.7549 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0386 - acc: 0.8918 - val_loss: 8.8746 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2349 - acc: 0.8918 - val_loss: 7.0140 - val_acc: 0.8361\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5512 - acc: 0.7254 - val_loss: 0.6106 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5021 - acc: 0.8342 - val_loss: 0.5413 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3897 - acc: 0.8238 - val_loss: 0.4798 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3540 - acc: 0.8394 - val_loss: 0.3152 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2949 - acc: 0.8705 - val_loss: 0.4491 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4618 - acc: 0.8653 - val_loss: 0.6430 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4254 - acc: 0.8705 - val_loss: 0.3664 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2936 - acc: 0.8705 - val_loss: 0.5158 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2990 - acc: 0.8808 - val_loss: 0.2877 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2394 - acc: 0.8860 - val_loss: 0.4084 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1701 - acc: 0.9326 - val_loss: 0.4153 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1614 - acc: 0.9430 - val_loss: 0.4822 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1887 - acc: 0.9275 - val_loss: 0.5677 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2483 - acc: 0.9119 - val_loss: 0.4732 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6342 - acc: 0.7047 - val_loss: 0.5907 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7471 - acc: 0.8083 - val_loss: 0.5069 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5078 - acc: 0.7876 - val_loss: 0.3912 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3469 - acc: 0.8187 - val_loss: 0.5997 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3084 - acc: 0.8446 - val_loss: 0.6722 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2832 - acc: 0.8601 - val_loss: 0.7064 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2660 - acc: 0.8756 - val_loss: 0.8606 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3631 - acc: 0.8342 - val_loss: 1.0043 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6107 - acc: 0.7887 - val_loss: 0.5440 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5772 - acc: 0.8247 - val_loss: 0.3282 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3665 - acc: 0.8247 - val_loss: 0.4090 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3434 - acc: 0.8711 - val_loss: 0.7063 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3207 - acc: 0.8557 - val_loss: 0.7581 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3219 - acc: 0.8608 - val_loss: 0.4498 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2686 - acc: 0.8918 - val_loss: 1.2309 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.8167 - acc: 0.6907 - val_loss: 0.6929 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6969 - acc: 0.7887 - val_loss: 0.4843 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6607 - acc: 0.7990 - val_loss: 0.6217 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3961 - acc: 0.8351 - val_loss: 0.4708 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3899 - acc: 0.8196 - val_loss: 0.3591 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4298 - acc: 0.8299 - val_loss: 0.6142 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3222 - acc: 0.8557 - val_loss: 0.3343 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2726 - acc: 0.8711 - val_loss: 0.3807 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2518 - acc: 0.8711 - val_loss: 0.3816 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2357 - acc: 0.8763 - val_loss: 0.4153 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2408 - acc: 0.8608 - val_loss: 0.4377 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2220 - acc: 0.8763 - val_loss: 0.5212 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7164 - acc: 0.7268 - val_loss: 0.7612 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5644 - acc: 0.7732 - val_loss: 0.4669 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5122 - acc: 0.8093 - val_loss: 0.4269 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4280 - acc: 0.8144 - val_loss: 0.4912 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3515 - acc: 0.8505 - val_loss: 0.4099 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3529 - acc: 0.8144 - val_loss: 0.6683 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4137 - acc: 0.8454 - val_loss: 0.3990 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3945 - acc: 0.8299 - val_loss: 0.5281 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3973 - acc: 0.8505 - val_loss: 0.6189 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4029 - acc: 0.8041 - val_loss: 0.7610 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5948 - acc: 0.8711 - val_loss: 0.9761 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4044 - acc: 0.8557 - val_loss: 0.8245 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8141 - acc: 0.7461 - val_loss: 0.4623 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5651 - acc: 0.8135 - val_loss: 0.5645 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4808 - acc: 0.8187 - val_loss: 0.4589 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3019 - acc: 0.9067 - val_loss: 0.3945 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3695 - acc: 0.8446 - val_loss: 0.5916 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2565 - acc: 0.9016 - val_loss: 0.5307 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1895 - acc: 0.9119 - val_loss: 0.6230 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1546 - acc: 0.9326 - val_loss: 0.6293 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1510 - acc: 0.9275 - val_loss: 0.6555 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9913 - acc: 0.7202 - val_loss: 0.4520 - val_acc: 0.8525\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5746 - acc: 0.7979 - val_loss: 0.7578 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5395 - acc: 0.8342 - val_loss: 0.4377 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3538 - acc: 0.8601 - val_loss: 0.6425 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8418 - acc: 0.7927 - val_loss: 2.2612 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5618 - acc: 0.8342 - val_loss: 1.1305 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6680 - acc: 0.8083 - val_loss: 3.1900 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8922 - acc: 0.8290 - val_loss: 1.3527 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7484 - acc: 0.7526 - val_loss: 0.3463 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7067 - acc: 0.8454 - val_loss: 0.8646 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6324 - acc: 0.8041 - val_loss: 0.9834 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7219 - acc: 0.8144 - val_loss: 0.5240 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3350 - acc: 0.8814 - val_loss: 0.7858 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3012 - acc: 0.8814 - val_loss: 1.2082 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7949 - acc: 0.7216 - val_loss: 3.1064 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0085 - acc: 0.7577 - val_loss: 0.8468 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6204 - acc: 0.8144 - val_loss: 0.5206 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4255 - acc: 0.7732 - val_loss: 1.0932 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4463 - acc: 0.7990 - val_loss: 0.5052 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3301 - acc: 0.8814 - val_loss: 1.4228 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6759 - acc: 0.8351 - val_loss: 1.0919 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5255 - acc: 0.8557 - val_loss: 1.5583 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5444 - acc: 0.8608 - val_loss: 0.8667 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4138 - acc: 0.8660 - val_loss: 1.1569 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8825 - acc: 0.7423 - val_loss: 0.5205 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5121 - acc: 0.8299 - val_loss: 0.6203 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5740 - acc: 0.8196 - val_loss: 0.8473 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4005 - acc: 0.8660 - val_loss: 0.4731 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4014 - acc: 0.8711 - val_loss: 1.1647 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3143 - acc: 0.8814 - val_loss: 0.6132 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2474 - acc: 0.9227 - val_loss: 1.1853 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4123 - acc: 0.9072 - val_loss: 1.9169 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8720 - acc: 0.8041 - val_loss: 0.6834 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4418 - acc: 0.6943 - val_loss: 0.9658 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9341 - acc: 0.8083 - val_loss: 0.5090 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6563 - acc: 0.8446 - val_loss: 0.9420 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5856 - acc: 0.8342 - val_loss: 0.5996 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.3367 - acc: 0.7668 - val_loss: 1.2188 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7692 - acc: 0.8446 - val_loss: 1.0250 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5772 - acc: 0.8860 - val_loss: 1.1053 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2323 - acc: 0.6943 - val_loss: 1.6032 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2910 - acc: 0.7876 - val_loss: 1.1137 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2216 - acc: 0.7876 - val_loss: 1.4911 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0308 - acc: 0.8342 - val_loss: 1.0695 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2375 - acc: 0.7824 - val_loss: 2.1152 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.4556 - acc: 0.8187 - val_loss: 1.5895 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1962 - acc: 0.7927 - val_loss: 1.6608 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1599 - acc: 0.8549 - val_loss: 1.3643 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7281 - acc: 0.8808 - val_loss: 3.1681 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9502 - acc: 0.7423 - val_loss: 1.3016 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2482 - acc: 0.7990 - val_loss: 1.4561 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9379 - acc: 0.8299 - val_loss: 1.0474 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5757 - acc: 0.8144 - val_loss: 1.1738 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6918 - acc: 0.8660 - val_loss: 0.9016 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6154 - acc: 0.8454 - val_loss: 1.3731 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5989 - acc: 0.8866 - val_loss: 0.8657 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3860 - acc: 0.8711 - val_loss: 1.4622 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5016 - acc: 0.9124 - val_loss: 1.2601 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2486 - acc: 0.9124 - val_loss: 1.6498 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2067 - acc: 0.9227 - val_loss: 1.2285 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2757 - acc: 0.9124 - val_loss: 2.3856 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7730 - acc: 0.6907 - val_loss: 1.0274 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.5270 - acc: 0.7887 - val_loss: 2.1448 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0191 - acc: 0.7577 - val_loss: 0.6111 - val_acc: 0.8197\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6956 - acc: 0.8402 - val_loss: 1.9306 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9734 - acc: 0.8505 - val_loss: 1.9608 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0293 - acc: 0.8093 - val_loss: 2.4192 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9131 - acc: 0.8454 - val_loss: 1.7019 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5066 - acc: 0.8608 - val_loss: 1.1859 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2177 - acc: 0.6804 - val_loss: 1.4124 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2925 - acc: 0.7577 - val_loss: 2.7432 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.7253 - acc: 0.7938 - val_loss: 1.2522 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9995 - acc: 0.7835 - val_loss: 1.5229 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6602 - acc: 0.8299 - val_loss: 1.1159 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4938 - acc: 0.8660 - val_loss: 1.1826 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3093 - acc: 0.9021 - val_loss: 0.9125 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3549 - acc: 0.8866 - val_loss: 1.6088 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2806 - acc: 0.9175 - val_loss: 1.4468 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5105 - acc: 0.8918 - val_loss: 2.0187 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3804 - acc: 0.9021 - val_loss: 3.9105 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5989 - acc: 0.9072 - val_loss: 3.2613 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5898 - acc: 0.7150 - val_loss: 2.7486 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.4355 - acc: 0.7824 - val_loss: 4.2167 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.6515 - acc: 0.7876 - val_loss: 3.2643 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.8909 - acc: 0.8549 - val_loss: 1.3957 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1064 - acc: 0.8290 - val_loss: 1.9070 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8748 - acc: 0.8653 - val_loss: 1.5820 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8103 - acc: 0.8964 - val_loss: 2.5866 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5688 - acc: 0.9067 - val_loss: 2.2447 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4224 - acc: 0.9223 - val_loss: 1.9258 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.2303 - acc: 0.6943 - val_loss: 6.0846 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.1612 - acc: 0.7772 - val_loss: 2.1581 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.8001 - acc: 0.7254 - val_loss: 3.7650 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2415 - acc: 0.8187 - val_loss: 2.8504 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5371 - acc: 0.7979 - val_loss: 3.6694 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3780 - acc: 0.8394 - val_loss: 3.4563 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4897 - acc: 0.8912 - val_loss: 2.2292 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.5875 - acc: 0.6856 - val_loss: 1.6690 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3430 - acc: 0.7835 - val_loss: 1.3491 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.4207 - acc: 0.8144 - val_loss: 2.2716 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1896 - acc: 0.8299 - val_loss: 5.8057 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.9478 - acc: 0.8299 - val_loss: 2.3112 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7753 - acc: 0.8454 - val_loss: 3.0110 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9143 - acc: 0.8814 - val_loss: 3.3633 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1020 - acc: 0.7062 - val_loss: 1.8920 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2339 - acc: 0.7320 - val_loss: 1.2672 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.0344 - acc: 0.7990 - val_loss: 1.4527 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.0113 - acc: 0.7938 - val_loss: 2.7547 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.4165 - acc: 0.8351 - val_loss: 2.3098 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9428 - acc: 0.8247 - val_loss: 1.9727 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.4107 - acc: 0.8660 - val_loss: 3.5715 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.1912 - acc: 0.7268 - val_loss: 3.4443 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.2304 - acc: 0.7526 - val_loss: 3.5925 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1030 - acc: 0.8351 - val_loss: 2.4220 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.4666 - acc: 0.7938 - val_loss: 1.0281 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.9606 - acc: 0.8247 - val_loss: 3.8788 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.6767 - acc: 0.8093 - val_loss: 1.6115 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2123 - acc: 0.8299 - val_loss: 1.9626 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5269 - acc: 0.9021 - val_loss: 1.8981 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4774 - acc: 0.8918 - val_loss: 2.8994 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.5486 - acc: 0.7202 - val_loss: 5.4178 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.4305 - acc: 0.7824 - val_loss: 6.5174 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.3204 - acc: 0.8238 - val_loss: 7.8823 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.8150 - acc: 0.8083 - val_loss: 5.7529 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.6195 - acc: 0.8446 - val_loss: 3.9081 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.2634 - acc: 0.8549 - val_loss: 5.0676 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.0623 - acc: 0.8601 - val_loss: 8.7083 - val_acc: 0.7869\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 3.1397 - acc: 0.8497 - val_loss: 6.3668 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.8242 - acc: 0.8653 - val_loss: 9.8331 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.3438 - acc: 0.9016 - val_loss: 9.6942 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6532 - acc: 0.6632 - val_loss: 6.2313 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.0522 - acc: 0.7772 - val_loss: 2.7600 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.1118 - acc: 0.8187 - val_loss: 3.0484 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3344 - acc: 0.8497 - val_loss: 2.5734 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.3319 - acc: 0.8912 - val_loss: 2.2498 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9025 - acc: 0.8497 - val_loss: 4.7535 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.6035 - acc: 0.8860 - val_loss: 4.3248 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.3704 - acc: 0.8394 - val_loss: 7.7741 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.2920 - acc: 0.8601 - val_loss: 5.1969 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.8416 - acc: 0.8964 - val_loss: 7.7628 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.1705 - acc: 0.7629 - val_loss: 11.3385 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.2569 - acc: 0.7680 - val_loss: 5.0371 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.2101 - acc: 0.7732 - val_loss: 6.6024 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.0277 - acc: 0.8247 - val_loss: 3.8866 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.8842 - acc: 0.8557 - val_loss: 14.4782 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.3839 - acc: 0.8814 - val_loss: 9.0393 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.8720 - acc: 0.8763 - val_loss: 11.9814 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.4195 - acc: 0.8711 - val_loss: 5.6991 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.6694 - acc: 0.8763 - val_loss: 10.2142 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 3.9134 - acc: 0.7268 - val_loss: 3.8788 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.3795 - acc: 0.7320 - val_loss: 3.2562 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.8548 - acc: 0.8299 - val_loss: 3.3627 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.1097 - acc: 0.7835 - val_loss: 7.0812 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.7543 - acc: 0.8505 - val_loss: 3.7728 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.0449 - acc: 0.8196 - val_loss: 6.7367 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2393 - acc: 0.8454 - val_loss: 6.1103 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.5209 - acc: 0.7113 - val_loss: 2.1598 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.4893 - acc: 0.7113 - val_loss: 2.4142 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.1820 - acc: 0.7629 - val_loss: 6.4772 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.0056 - acc: 0.8351 - val_loss: 1.7139 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.4424 - acc: 0.8866 - val_loss: 3.4247 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.7411 - acc: 0.8660 - val_loss: 4.5312 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.3298 - acc: 0.8505 - val_loss: 3.3392 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.4625 - acc: 0.8660 - val_loss: 6.1283 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7392 - acc: 0.9021 - val_loss: 2.8101 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.8318 - acc: 0.6891 - val_loss: 1.9725 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.3826 - acc: 0.7513 - val_loss: 16.8059 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 13.7348 - acc: 0.7254 - val_loss: 18.2832 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 11.9807 - acc: 0.8083 - val_loss: 10.0835 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 11.4619 - acc: 0.8446 - val_loss: 13.6803 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 28.4066 - acc: 0.8394 - val_loss: 71.2093 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.8826 - acc: 0.7047 - val_loss: 3.6063 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.7244 - acc: 0.7720 - val_loss: 8.9986 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.2509 - acc: 0.7927 - val_loss: 9.2323 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.1819 - acc: 0.8290 - val_loss: 17.6454 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 10.2374 - acc: 0.8290 - val_loss: 8.8275 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3482 - acc: 0.8756 - val_loss: 15.4237 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.4839 - acc: 0.7423 - val_loss: 6.1274 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.9109 - acc: 0.7784 - val_loss: 6.9575 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.4702 - acc: 0.8093 - val_loss: 3.4660 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.0381 - acc: 0.8608 - val_loss: 7.2219 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.4605 - acc: 0.8763 - val_loss: 5.0771 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 14.8719 - acc: 0.7732 - val_loss: 8.8247 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 10.6751 - acc: 0.8608 - val_loss: 23.0752 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.2378 - acc: 0.8918 - val_loss: 16.4589 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.8215 - acc: 0.7010 - val_loss: 11.4817 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.7714 - acc: 0.7629 - val_loss: 9.8205 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.8033 - acc: 0.8196 - val_loss: 5.9339 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.5912 - acc: 0.8247 - val_loss: 5.4186 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.7740 - acc: 0.8351 - val_loss: 5.9178 - val_acc: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.9576 - acc: 0.8454 - val_loss: 6.2828 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 10.5360 - acc: 0.7835 - val_loss: 22.0424 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 9.0817 - acc: 0.8505 - val_loss: 11.2853 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.7922 - acc: 0.8660 - val_loss: 13.2866 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.5692 - acc: 0.7577 - val_loss: 11.7774 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 10.8751 - acc: 0.7216 - val_loss: 8.3855 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.8508 - acc: 0.8144 - val_loss: 7.8384 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.2002 - acc: 0.7784 - val_loss: 13.7917 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.3758 - acc: 0.8454 - val_loss: 11.6494 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.2956 - acc: 0.8505 - val_loss: 6.8752 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.9991 - acc: 0.8608 - val_loss: 11.2063 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.1138 - acc: 0.8814 - val_loss: 9.2541 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1076 - acc: 0.9021 - val_loss: 15.3713 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.2572 - acc: 0.9021 - val_loss: 14.2717 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5279 - acc: 0.9124 - val_loss: 14.1348 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 12.5050 - acc: 0.6995 - val_loss: 20.0443 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 12.1090 - acc: 0.7772 - val_loss: 4.8105 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 12.0026 - acc: 0.8290 - val_loss: 20.9068 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 16.0162 - acc: 0.7979 - val_loss: 18.5989 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 11.1096 - acc: 0.8135 - val_loss: 7.6637 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.1656 - acc: 0.8653 - val_loss: 12.3150 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.1199 - acc: 0.8705 - val_loss: 12.7741 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 14.1708 - acc: 0.7047 - val_loss: 20.6339 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 16.3694 - acc: 0.7461 - val_loss: 9.3357 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 10.9429 - acc: 0.7772 - val_loss: 8.3598 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 15.9072 - acc: 0.8238 - val_loss: 16.1368 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.7826 - acc: 0.8653 - val_loss: 14.7572 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.0208 - acc: 0.8912 - val_loss: 13.6550 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 13.4773 - acc: 0.8601 - val_loss: 36.6590 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 17.5744 - acc: 0.8446 - val_loss: 23.1833 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 14.4443 - acc: 0.7165 - val_loss: 20.4250 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 25.8320 - acc: 0.8247 - val_loss: 21.4322 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18.6771 - acc: 0.8041 - val_loss: 15.1508 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 20.6568 - acc: 0.7887 - val_loss: 50.4201 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 25.2070 - acc: 0.8505 - val_loss: 21.5429 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 11.7570 - acc: 0.8608 - val_loss: 37.6410 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 10.1849 - acc: 0.8711 - val_loss: 25.6164 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.3506 - acc: 0.8402 - val_loss: 19.4657 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 14.2992 - acc: 0.6907 - val_loss: 35.5630 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 20.8821 - acc: 0.7165 - val_loss: 14.9760 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 11.3168 - acc: 0.8247 - val_loss: 15.5581 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 27.5196 - acc: 0.7423 - val_loss: 28.9406 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 10.9135 - acc: 0.8144 - val_loss: 30.6470 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.7306 - acc: 0.8660 - val_loss: 22.3512 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 18.8788 - acc: 0.8660 - val_loss: 47.1524 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 15.5264 - acc: 0.7371 - val_loss: 42.4428 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18.2404 - acc: 0.7629 - val_loss: 26.0094 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 26.5094 - acc: 0.7680 - val_loss: 26.5687 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 12.6358 - acc: 0.7680 - val_loss: 22.8602 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 17.0002 - acc: 0.8454 - val_loss: 21.3492 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 12.4310 - acc: 0.8196 - val_loss: 48.6005 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 19.7052 - acc: 0.8454 - val_loss: 31.5055 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 16.0575 - acc: 0.8351 - val_loss: 40.9457 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 19.2699 - acc: 0.8608 - val_loss: 34.4715 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 13.0064 - acc: 0.8763 - val_loss: 48.3665 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7051 - acc: 0.7409 - val_loss: 0.9459 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7123 - acc: 0.8446 - val_loss: 0.5196 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5276 - acc: 0.7927 - val_loss: 0.4078 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4038 - acc: 0.8497 - val_loss: 0.5023 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2985 - acc: 0.8653 - val_loss: 0.4451 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4347 - acc: 0.8446 - val_loss: 1.1379 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6056 - acc: 0.8601 - val_loss: 0.7474 - val_acc: 0.8689\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9025 - acc: 0.8187 - val_loss: 0.8529 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7176 - acc: 0.7150 - val_loss: 0.5564 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5242 - acc: 0.7876 - val_loss: 0.6295 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3897 - acc: 0.8031 - val_loss: 0.4792 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3418 - acc: 0.8135 - val_loss: 1.0181 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3179 - acc: 0.8394 - val_loss: 0.7988 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2835 - acc: 0.8497 - val_loss: 0.9158 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3714 - acc: 0.8135 - val_loss: 0.5895 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3441 - acc: 0.8549 - val_loss: 1.4870 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7355 - acc: 0.7371 - val_loss: 0.5541 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6054 - acc: 0.8093 - val_loss: 0.6190 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6686 - acc: 0.8093 - val_loss: 0.5525 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4482 - acc: 0.8505 - val_loss: 1.1060 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4687 - acc: 0.8196 - val_loss: 0.6563 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7731 - acc: 0.8454 - val_loss: 1.9205 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3785 - acc: 0.8711 - val_loss: 1.3372 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4879 - acc: 0.8351 - val_loss: 0.9151 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6597 - acc: 0.7423 - val_loss: 0.2969 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5845 - acc: 0.8144 - val_loss: 0.4955 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6516 - acc: 0.7887 - val_loss: 0.5750 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4888 - acc: 0.7990 - val_loss: 0.7392 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5898 - acc: 0.7732 - val_loss: 0.8282 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5039 - acc: 0.8351 - val_loss: 0.9222 - val_acc: 0.7049\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8840 - acc: 0.7216 - val_loss: 0.4231 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4881 - acc: 0.7732 - val_loss: 0.6805 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4568 - acc: 0.8093 - val_loss: 0.4950 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4976 - acc: 0.8144 - val_loss: 0.5234 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3681 - acc: 0.8247 - val_loss: 0.5913 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4263 - acc: 0.8505 - val_loss: 0.6346 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0380 - acc: 0.7254 - val_loss: 0.7545 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3156 - acc: 0.7824 - val_loss: 0.8349 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2288 - acc: 0.7358 - val_loss: 0.6507 - val_acc: 0.9180\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3501 - acc: 0.8238 - val_loss: 3.1541 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.6079 - acc: 0.8083 - val_loss: 1.3669 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9244 - acc: 0.8653 - val_loss: 1.4863 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7403 - acc: 0.8497 - val_loss: 0.5413 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.0770 - acc: 0.8860 - val_loss: 2.6928 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7493 - acc: 0.9016 - val_loss: 0.7300 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7154 - acc: 0.8860 - val_loss: 1.9471 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4897 - acc: 0.9119 - val_loss: 1.9422 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8263 - acc: 0.9016 - val_loss: 1.7751 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.7037 - acc: 0.6839 - val_loss: 0.6095 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.5924 - acc: 0.7772 - val_loss: 1.9950 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1564 - acc: 0.7927 - val_loss: 0.7007 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6412 - acc: 0.8238 - val_loss: 2.1258 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8018 - acc: 0.8083 - val_loss: 1.1410 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5405 - acc: 0.8497 - val_loss: 3.1381 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.4076 - acc: 0.7113 - val_loss: 0.7570 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.9060 - acc: 0.8093 - val_loss: 1.3569 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.0747 - acc: 0.8505 - val_loss: 1.2174 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.7652 - acc: 0.8351 - val_loss: 2.0832 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0228 - acc: 0.8402 - val_loss: 1.3805 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5417 - acc: 0.8351 - val_loss: 1.9472 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1189 - acc: 0.6598 - val_loss: 0.4254 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3241 - acc: 0.7629 - val_loss: 1.4754 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1015 - acc: 0.7577 - val_loss: 0.7602 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9893 - acc: 0.8402 - val_loss: 0.8848 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8455 - acc: 0.7577 - val_loss: 1.1181 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6760 - acc: 0.8454 - val_loss: 0.9534 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1635 - acc: 0.6959 - val_loss: 1.1844 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0210 - acc: 0.7629 - val_loss: 0.9478 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1567 - acc: 0.7784 - val_loss: 3.3860 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2360 - acc: 0.8299 - val_loss: 1.3119 - val_acc: 0.7705\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7006 - acc: 0.8093 - val_loss: 1.5976 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6220 - acc: 0.8247 - val_loss: 1.1853 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4859 - acc: 0.8041 - val_loss: 1.3503 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1.6371 - acc: 0.7202 - val_loss: 9.6523 - val_acc: 0.2951\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3780 - acc: 0.7098 - val_loss: 1.6712 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.9246 - acc: 0.8238 - val_loss: 3.3045 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.7241 - acc: 0.8031 - val_loss: 0.8012 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.2360 - acc: 0.8135 - val_loss: 3.3570 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.7884 - acc: 0.8446 - val_loss: 1.2018 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1531 - acc: 0.8549 - val_loss: 1.1174 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.7607 - acc: 0.8705 - val_loss: 4.1704 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.4975 - acc: 0.8187 - val_loss: 3.6072 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.2371 - acc: 0.6477 - val_loss: 1.2909 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.5521 - acc: 0.7927 - val_loss: 1.5869 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.6374 - acc: 0.8187 - val_loss: 1.8229 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.5665 - acc: 0.7876 - val_loss: 1.2483 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2219 - acc: 0.8497 - val_loss: 1.3651 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.5687 - acc: 0.8135 - val_loss: 8.4770 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.8755 - acc: 0.8187 - val_loss: 4.5702 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.7890 - acc: 0.8497 - val_loss: 6.3440 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1064 - acc: 0.8964 - val_loss: 2.9675 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1664 - acc: 0.7113 - val_loss: 1.7932 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1714 - acc: 0.8196 - val_loss: 3.5432 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.9748 - acc: 0.8041 - val_loss: 4.5681 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.7216 - acc: 0.8454 - val_loss: 3.6838 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.6549 - acc: 0.8351 - val_loss: 3.0158 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.4973 - acc: 0.7526 - val_loss: 6.0245 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.6050 - acc: 0.6907 - val_loss: 1.8925 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.2899 - acc: 0.7320 - val_loss: 2.2074 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.3059 - acc: 0.8299 - val_loss: 1.3811 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.4842 - acc: 0.8196 - val_loss: 3.6644 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1706 - acc: 0.8093 - val_loss: 1.7403 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.6826 - acc: 0.7784 - val_loss: 6.6953 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.6358 - acc: 0.8402 - val_loss: 1.2830 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.2645 - acc: 0.7577 - val_loss: 4.5766 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.4540 - acc: 0.7835 - val_loss: 3.8029 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.8664 - acc: 0.8196 - val_loss: 5.5763 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1820 - acc: 0.8402 - val_loss: 2.8199 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6441 - acc: 0.8763 - val_loss: 1.8300 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.2042 - acc: 0.6598 - val_loss: 1.6296 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.3738 - acc: 0.7784 - val_loss: 0.9954 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.4357 - acc: 0.7784 - val_loss: 2.4607 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.6697 - acc: 0.8557 - val_loss: 1.6436 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.0949 - acc: 0.8041 - val_loss: 2.1595 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5342 - acc: 0.8299 - val_loss: 3.2904 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.8561 - acc: 0.8093 - val_loss: 2.8362 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.4282 - acc: 0.6891 - val_loss: 1.6107 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3395 - acc: 0.8238 - val_loss: 6.5314 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.5871 - acc: 0.8031 - val_loss: 2.1859 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.2786 - acc: 0.8497 - val_loss: 2.2268 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.6229 - acc: 0.8756 - val_loss: 2.5176 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2334 - acc: 0.8808 - val_loss: 3.0483 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.2678 - acc: 0.6736 - val_loss: 10.2257 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.7277 - acc: 0.7513 - val_loss: 3.5905 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.7528 - acc: 0.8394 - val_loss: 3.9284 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.5185 - acc: 0.7876 - val_loss: 2.6933 - val_acc: 0.9180\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.5439 - acc: 0.8083 - val_loss: 2.1273 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3004 - acc: 0.8238 - val_loss: 5.5647 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.7095 - acc: 0.8290 - val_loss: 6.5440 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.3861 - acc: 0.8549 - val_loss: 5.1169 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1236 - acc: 0.8964 - val_loss: 6.3588 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5647 - acc: 0.9016 - val_loss: 4.3722 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.4048 - acc: 0.7474 - val_loss: 4.2226 - val_acc: 0.8197\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3866 - acc: 0.7938 - val_loss: 4.2706 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.4625 - acc: 0.8196 - val_loss: 5.5005 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1773 - acc: 0.8969 - val_loss: 4.8440 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.8511 - acc: 0.8711 - val_loss: 6.7519 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.3607 - acc: 0.8557 - val_loss: 5.2208 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.9525 - acc: 0.7577 - val_loss: 16.8915 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.9926 - acc: 0.7165 - val_loss: 3.5501 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.5984 - acc: 0.8041 - val_loss: 2.7737 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.8223 - acc: 0.8041 - val_loss: 4.0025 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.6707 - acc: 0.8299 - val_loss: 6.3062 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.5062 - acc: 0.8557 - val_loss: 3.4816 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.8998 - acc: 0.8557 - val_loss: 4.7432 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.0010 - acc: 0.8711 - val_loss: 4.4269 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.7112 - acc: 0.7062 - val_loss: 2.9463 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.4408 - acc: 0.7680 - val_loss: 3.6920 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.1525 - acc: 0.7680 - val_loss: 4.2570 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.7270 - acc: 0.8299 - val_loss: 2.8425 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5286 - acc: 0.8608 - val_loss: 4.1989 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2243 - acc: 0.8557 - val_loss: 3.6864 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.4171 - acc: 0.8299 - val_loss: 4.7977 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5473 - acc: 0.8660 - val_loss: 8.1798 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.2438 - acc: 0.8711 - val_loss: 5.3401 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 8.0124 - acc: 0.6788 - val_loss: 3.8491 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 12.0511 - acc: 0.8238 - val_loss: 18.9987 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 13.0903 - acc: 0.8394 - val_loss: 7.7315 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.0388 - acc: 0.8912 - val_loss: 5.3031 - val_acc: 0.9180\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.2052 - acc: 0.8342 - val_loss: 5.2857 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.0504 - acc: 0.9016 - val_loss: 8.9651 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.7615 - acc: 0.7409 - val_loss: 14.4287 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 10.7039 - acc: 0.7876 - val_loss: 5.6155 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.6639 - acc: 0.7927 - val_loss: 12.8193 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 18.7668 - acc: 0.7617 - val_loss: 37.4600 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 11.6295 - acc: 0.8497 - val_loss: 17.4490 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.8205 - acc: 0.8653 - val_loss: 29.9108 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 11.4336 - acc: 0.8187 - val_loss: 15.8647 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 6.2031 - acc: 0.6856 - val_loss: 3.7081 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.6200 - acc: 0.8093 - val_loss: 13.9570 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 10.4777 - acc: 0.7680 - val_loss: 11.7444 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.3810 - acc: 0.8041 - val_loss: 5.0423 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 13.7787 - acc: 0.8093 - val_loss: 13.4203 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.9471 - acc: 0.8660 - val_loss: 8.9153 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.7288 - acc: 0.6856 - val_loss: 3.2776 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.4873 - acc: 0.7732 - val_loss: 12.0914 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.2430 - acc: 0.7938 - val_loss: 8.8517 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.9293 - acc: 0.7887 - val_loss: 9.9757 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 10.2733 - acc: 0.7680 - val_loss: 5.9068 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.5581 - acc: 0.8299 - val_loss: 9.5504 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 10.5349 - acc: 0.7165 - val_loss: 16.8180 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 13.7547 - acc: 0.7577 - val_loss: 8.7754 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 9.8043 - acc: 0.7938 - val_loss: 24.0928 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 12.6474 - acc: 0.8041 - val_loss: 13.8105 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.6258 - acc: 0.8402 - val_loss: 18.5877 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 13.2009 - acc: 0.7526 - val_loss: 11.9555 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.0325 - acc: 0.8351 - val_loss: 21.1901 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 16.4066 - acc: 0.6684 - val_loss: 21.7617 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 17.3881 - acc: 0.7565 - val_loss: 27.9472 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 11.3871 - acc: 0.8497 - val_loss: 25.4323 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.9032 - acc: 0.8653 - val_loss: 10.2139 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 4.2679 - acc: 0.8964 - val_loss: 12.8790 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.1747 - acc: 0.8601 - val_loss: 10.4867 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.0710 - acc: 0.9430 - val_loss: 22.9252 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.4248 - acc: 0.8808 - val_loss: 16.5556 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.9058 - acc: 0.9016 - val_loss: 14.4908 - val_acc: 0.8197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 22.5720 - acc: 0.6477 - val_loss: 24.3851 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 16.1712 - acc: 0.7824 - val_loss: 10.1733 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 12.7819 - acc: 0.8135 - val_loss: 18.8617 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.6679 - acc: 0.8238 - val_loss: 7.7224 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2478 - acc: 0.8394 - val_loss: 17.2046 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.6753 - acc: 0.8549 - val_loss: 18.3740 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.7041 - acc: 0.8912 - val_loss: 15.9699 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.7363 - acc: 0.8964 - val_loss: 17.7386 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2272 - acc: 0.9067 - val_loss: 26.5040 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 16.1934 - acc: 0.6289 - val_loss: 8.3932 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 17.6542 - acc: 0.8402 - val_loss: 14.7377 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 12.9861 - acc: 0.8608 - val_loss: 41.4427 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 17.7653 - acc: 0.8505 - val_loss: 12.9169 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.3232 - acc: 0.8505 - val_loss: 14.7013 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.0753 - acc: 0.8351 - val_loss: 14.4588 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 17.4969 - acc: 0.6495 - val_loss: 28.6759 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 22.1351 - acc: 0.7268 - val_loss: 14.5803 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 10.7042 - acc: 0.7887 - val_loss: 7.5783 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.1867 - acc: 0.8247 - val_loss: 5.6964 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.4010 - acc: 0.8247 - val_loss: 14.3777 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.2806 - acc: 0.8763 - val_loss: 31.9139 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.8144 - acc: 0.8660 - val_loss: 14.0381 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 14.0613 - acc: 0.8093 - val_loss: 25.9846 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 13.1392 - acc: 0.8351 - val_loss: 22.5554 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 27.2429 - acc: 0.6856 - val_loss: 117.0239 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 26.3876 - acc: 0.7732 - val_loss: 72.5828 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 29.0318 - acc: 0.7629 - val_loss: 16.2539 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18.0595 - acc: 0.7938 - val_loss: 13.3818 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 14.1961 - acc: 0.8144 - val_loss: 24.4516 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 20.0486 - acc: 0.8351 - val_loss: 37.0164 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 17.0216 - acc: 0.8660 - val_loss: 30.4471 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.7548 - acc: 0.8918 - val_loss: 24.7035 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.6912 - acc: 0.8557 - val_loss: 26.4333 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 31.7761 - acc: 0.6788 - val_loss: 69.7934 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 29.4005 - acc: 0.7565 - val_loss: 21.8832 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 21.1859 - acc: 0.8446 - val_loss: 24.6566 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18.5373 - acc: 0.8394 - val_loss: 73.7019 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 24.0720 - acc: 0.8238 - val_loss: 34.3341 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 14.1946 - acc: 0.8549 - val_loss: 30.2575 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 22.1448 - acc: 0.8756 - val_loss: 36.9135 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 33.9157 - acc: 0.6995 - val_loss: 36.2720 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 22.3935 - acc: 0.7617 - val_loss: 31.4047 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 63.0723 - acc: 0.7979 - val_loss: 87.2473 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 35.7333 - acc: 0.8394 - val_loss: 42.2727 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 25.8630 - acc: 0.8756 - val_loss: 68.0424 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 21.7174 - acc: 0.8756 - val_loss: 64.5699 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 24.9689 - acc: 0.8705 - val_loss: 58.2216 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 42.3753 - acc: 0.7010 - val_loss: 40.9274 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 45.0094 - acc: 0.8093 - val_loss: 64.9668 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 42.0567 - acc: 0.7835 - val_loss: 64.9751 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 58.0827 - acc: 0.7938 - val_loss: 49.5112 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 51.4567 - acc: 0.8196 - val_loss: 97.5159 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 17.4590 - acc: 0.8866 - val_loss: 57.1236 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 32.4319 - acc: 0.7320 - val_loss: 127.2707 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 49.5527 - acc: 0.7320 - val_loss: 75.8564 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 65.5930 - acc: 0.7938 - val_loss: 150.3264 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 61.1556 - acc: 0.8093 - val_loss: 173.5650 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 41.8033 - acc: 0.8351 - val_loss: 47.5939 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 23.8516 - acc: 0.8866 - val_loss: 85.9331 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 29.1956 - acc: 0.8866 - val_loss: 80.5291 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 13.1120 - acc: 0.8866 - val_loss: 60.3301 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 21.3253 - acc: 0.8711 - val_loss: 67.5806 - val_acc: 0.8525\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 8.3743 - acc: 0.9175 - val_loss: 57.8841 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 26.1895 - acc: 0.7268 - val_loss: 29.0895 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 53.6672 - acc: 0.7010 - val_loss: 32.3429 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 45.6595 - acc: 0.7887 - val_loss: 48.1759 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 34.3012 - acc: 0.8093 - val_loss: 56.8220 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 31.9960 - acc: 0.7990 - val_loss: 29.2522 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 24.0880 - acc: 0.8608 - val_loss: 47.5782 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9558 - acc: 0.3005 - val_loss: 0.9405 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9558 - acc: 0.3005 - val_loss: 0.9405 - val_acc: 0.3115\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9557 - acc: 0.3005 - val_loss: 0.9404 - val_acc: 0.3115\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9557 - acc: 0.3005 - val_loss: 0.9404 - val_acc: 0.3115\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9557 - acc: 0.3005 - val_loss: 0.9404 - val_acc: 0.3115\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9556 - acc: 0.3005 - val_loss: 0.9404 - val_acc: 0.3115\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9556 - acc: 0.3005 - val_loss: 0.9403 - val_acc: 0.3115\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9556 - acc: 0.3005 - val_loss: 0.9403 - val_acc: 0.3115\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9555 - acc: 0.3005 - val_loss: 0.9403 - val_acc: 0.3115\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9555 - acc: 0.3005 - val_loss: 0.9402 - val_acc: 0.3115\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9555 - acc: 0.3005 - val_loss: 0.9402 - val_acc: 0.3115\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9554 - acc: 0.3005 - val_loss: 0.9402 - val_acc: 0.3115\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9554 - acc: 0.3005 - val_loss: 0.9402 - val_acc: 0.3115\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9554 - acc: 0.3005 - val_loss: 0.9401 - val_acc: 0.3115\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9553 - acc: 0.3005 - val_loss: 0.9401 - val_acc: 0.3115\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9553 - acc: 0.3005 - val_loss: 0.9401 - val_acc: 0.3115\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9553 - acc: 0.3005 - val_loss: 0.9400 - val_acc: 0.3115\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9552 - acc: 0.3005 - val_loss: 0.9400 - val_acc: 0.3115\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9552 - acc: 0.3005 - val_loss: 0.9400 - val_acc: 0.3115\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9552 - acc: 0.3005 - val_loss: 0.9399 - val_acc: 0.3115\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.8476 - acc: 0.4870 - val_loss: 0.8281 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8476 - acc: 0.4870 - val_loss: 0.8280 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8476 - acc: 0.4870 - val_loss: 0.8280 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8476 - acc: 0.4870 - val_loss: 0.8280 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8475 - acc: 0.4870 - val_loss: 0.8280 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8475 - acc: 0.4870 - val_loss: 0.8279 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8475 - acc: 0.4870 - val_loss: 0.8279 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8474 - acc: 0.4870 - val_loss: 0.8279 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8474 - acc: 0.4870 - val_loss: 0.8279 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8474 - acc: 0.4870 - val_loss: 0.8279 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8474 - acc: 0.4870 - val_loss: 0.8279 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8474 - acc: 0.4870 - val_loss: 0.8278 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8473 - acc: 0.4870 - val_loss: 0.8278 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8473 - acc: 0.4870 - val_loss: 0.8278 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8473 - acc: 0.4870 - val_loss: 0.8278 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8473 - acc: 0.4870 - val_loss: 0.8278 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8473 - acc: 0.4870 - val_loss: 0.8278 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8472 - acc: 0.4870 - val_loss: 0.8277 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8472 - acc: 0.4870 - val_loss: 0.8277 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8472 - acc: 0.4870 - val_loss: 0.8277 - val_acc: 0.5574\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.8788 - acc: 0.3711 - val_loss: 0.8648 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8788 - acc: 0.3969 - val_loss: 0.8647 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8788 - acc: 0.4278 - val_loss: 0.8647 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8787 - acc: 0.4278 - val_loss: 0.8647 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8787 - acc: 0.4278 - val_loss: 0.8646 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8787 - acc: 0.4278 - val_loss: 0.8646 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8786 - acc: 0.4278 - val_loss: 0.8646 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8786 - acc: 0.4278 - val_loss: 0.8645 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8786 - acc: 0.4278 - val_loss: 0.8645 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8785 - acc: 0.4278 - val_loss: 0.8645 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8785 - acc: 0.4278 - val_loss: 0.8644 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8785 - acc: 0.4278 - val_loss: 0.8644 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8785 - acc: 0.4278 - val_loss: 0.8644 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8784 - acc: 0.4278 - val_loss: 0.8643 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8784 - acc: 0.4278 - val_loss: 0.8643 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8784 - acc: 0.4278 - val_loss: 0.8643 - val_acc: 0.4590\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8783 - acc: 0.4278 - val_loss: 0.8642 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8783 - acc: 0.4278 - val_loss: 0.8642 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8783 - acc: 0.4278 - val_loss: 0.8642 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8782 - acc: 0.4278 - val_loss: 0.8641 - val_acc: 0.4590\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.1010 - acc: 0.3557 - val_loss: 0.9441 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1010 - acc: 0.3557 - val_loss: 0.9440 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1009 - acc: 0.3557 - val_loss: 0.9440 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1008 - acc: 0.3557 - val_loss: 0.9439 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1008 - acc: 0.3557 - val_loss: 0.9439 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1007 - acc: 0.3557 - val_loss: 0.9438 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1007 - acc: 0.3557 - val_loss: 0.9438 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1006 - acc: 0.3557 - val_loss: 0.9437 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1006 - acc: 0.3557 - val_loss: 0.9437 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1005 - acc: 0.3557 - val_loss: 0.9436 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1005 - acc: 0.3557 - val_loss: 0.9436 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1004 - acc: 0.3557 - val_loss: 0.9435 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1004 - acc: 0.3557 - val_loss: 0.9435 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1003 - acc: 0.3557 - val_loss: 0.9434 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1003 - acc: 0.3557 - val_loss: 0.9434 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1002 - acc: 0.3557 - val_loss: 0.9433 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1002 - acc: 0.3557 - val_loss: 0.9433 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1001 - acc: 0.3557 - val_loss: 0.9432 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1001 - acc: 0.3557 - val_loss: 0.9432 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1000 - acc: 0.3557 - val_loss: 0.9431 - val_acc: 0.4590\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8875 - acc: 0.5000 - val_loss: 0.8832 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8874 - acc: 0.5000 - val_loss: 0.8832 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8874 - acc: 0.5000 - val_loss: 0.8831 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8873 - acc: 0.5000 - val_loss: 0.8831 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8873 - acc: 0.5000 - val_loss: 0.8831 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8873 - acc: 0.5000 - val_loss: 0.8830 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8872 - acc: 0.5000 - val_loss: 0.8830 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8872 - acc: 0.5000 - val_loss: 0.8829 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8872 - acc: 0.5000 - val_loss: 0.8829 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8871 - acc: 0.5000 - val_loss: 0.8828 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8871 - acc: 0.5000 - val_loss: 0.8828 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8871 - acc: 0.5000 - val_loss: 0.8828 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8870 - acc: 0.5000 - val_loss: 0.8827 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8870 - acc: 0.5000 - val_loss: 0.8827 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8869 - acc: 0.5000 - val_loss: 0.8826 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8869 - acc: 0.5000 - val_loss: 0.8826 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8869 - acc: 0.5000 - val_loss: 0.8826 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8868 - acc: 0.5000 - val_loss: 0.8825 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8868 - acc: 0.5000 - val_loss: 0.8825 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8868 - acc: 0.5000 - val_loss: 0.8824 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8715 - acc: 0.5078 - val_loss: 0.8569 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8714 - acc: 0.5078 - val_loss: 0.8569 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8714 - acc: 0.5078 - val_loss: 0.8568 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8713 - acc: 0.5078 - val_loss: 0.8568 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8712 - acc: 0.5078 - val_loss: 0.8567 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8712 - acc: 0.5078 - val_loss: 0.8567 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8712 - acc: 0.5078 - val_loss: 0.8567 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8711 - acc: 0.5078 - val_loss: 0.8566 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8711 - acc: 0.5078 - val_loss: 0.8566 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8710 - acc: 0.5078 - val_loss: 0.8565 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8710 - acc: 0.5078 - val_loss: 0.8565 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8709 - acc: 0.5078 - val_loss: 0.8565 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8709 - acc: 0.5078 - val_loss: 0.8564 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8708 - acc: 0.5078 - val_loss: 0.8564 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8708 - acc: 0.5078 - val_loss: 0.8564 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8708 - acc: 0.5078 - val_loss: 0.8563 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8707 - acc: 0.5078 - val_loss: 0.8563 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8707 - acc: 0.5078 - val_loss: 0.8562 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8706 - acc: 0.5078 - val_loss: 0.8562 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8706 - acc: 0.5078 - val_loss: 0.8562 - val_acc: 0.4918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7884 - acc: 0.4767 - val_loss: 0.8438 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7884 - acc: 0.4767 - val_loss: 0.8437 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7883 - acc: 0.4767 - val_loss: 0.8437 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7882 - acc: 0.4767 - val_loss: 0.8436 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7882 - acc: 0.4767 - val_loss: 0.8435 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7881 - acc: 0.4767 - val_loss: 0.8435 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7881 - acc: 0.4767 - val_loss: 0.8434 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7880 - acc: 0.4767 - val_loss: 0.8434 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7880 - acc: 0.4767 - val_loss: 0.8433 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7879 - acc: 0.4767 - val_loss: 0.8433 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7879 - acc: 0.4819 - val_loss: 0.8432 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7878 - acc: 0.4819 - val_loss: 0.8431 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7878 - acc: 0.4819 - val_loss: 0.8431 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7877 - acc: 0.4819 - val_loss: 0.8430 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7877 - acc: 0.4819 - val_loss: 0.8430 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7876 - acc: 0.4819 - val_loss: 0.8429 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7876 - acc: 0.4819 - val_loss: 0.8429 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7875 - acc: 0.4819 - val_loss: 0.8428 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7875 - acc: 0.4819 - val_loss: 0.8427 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7874 - acc: 0.4819 - val_loss: 0.8427 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8153 - acc: 0.4124 - val_loss: 0.8590 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8153 - acc: 0.4124 - val_loss: 0.8590 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8153 - acc: 0.4124 - val_loss: 0.8589 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8152 - acc: 0.4124 - val_loss: 0.8589 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8152 - acc: 0.4124 - val_loss: 0.8588 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8151 - acc: 0.4124 - val_loss: 0.8588 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8151 - acc: 0.4124 - val_loss: 0.8587 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8151 - acc: 0.4124 - val_loss: 0.8587 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8150 - acc: 0.4124 - val_loss: 0.8586 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8150 - acc: 0.4124 - val_loss: 0.8586 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8149 - acc: 0.4124 - val_loss: 0.8585 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8149 - acc: 0.4124 - val_loss: 0.8585 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8148 - acc: 0.4124 - val_loss: 0.8584 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8148 - acc: 0.4124 - val_loss: 0.8584 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8148 - acc: 0.4124 - val_loss: 0.8583 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8147 - acc: 0.4124 - val_loss: 0.8583 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8147 - acc: 0.4124 - val_loss: 0.8582 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8146 - acc: 0.4124 - val_loss: 0.8582 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8146 - acc: 0.4124 - val_loss: 0.8582 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8146 - acc: 0.4124 - val_loss: 0.8581 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.9722 - acc: 0.4278 - val_loss: 0.9863 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9721 - acc: 0.4278 - val_loss: 0.9862 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9721 - acc: 0.4278 - val_loss: 0.9862 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9720 - acc: 0.4278 - val_loss: 0.9861 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9720 - acc: 0.4278 - val_loss: 0.9860 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9719 - acc: 0.4278 - val_loss: 0.9860 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9718 - acc: 0.4278 - val_loss: 0.9859 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9718 - acc: 0.4278 - val_loss: 0.9858 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9717 - acc: 0.4278 - val_loss: 0.9858 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9717 - acc: 0.4278 - val_loss: 0.9857 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9716 - acc: 0.4278 - val_loss: 0.9857 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9716 - acc: 0.4278 - val_loss: 0.9856 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9715 - acc: 0.4278 - val_loss: 0.9855 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9715 - acc: 0.4278 - val_loss: 0.9855 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9714 - acc: 0.4278 - val_loss: 0.9854 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9714 - acc: 0.4278 - val_loss: 0.9853 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9713 - acc: 0.4278 - val_loss: 0.9853 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9713 - acc: 0.4278 - val_loss: 0.9852 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9712 - acc: 0.4278 - val_loss: 0.9852 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9712 - acc: 0.4278 - val_loss: 0.9851 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.7544 - acc: 0.5361 - val_loss: 0.6782 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7543 - acc: 0.5361 - val_loss: 0.6781 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7543 - acc: 0.5361 - val_loss: 0.6781 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7542 - acc: 0.5361 - val_loss: 0.6781 - val_acc: 0.6230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7542 - acc: 0.5361 - val_loss: 0.6780 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7541 - acc: 0.5361 - val_loss: 0.6780 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7541 - acc: 0.5361 - val_loss: 0.6779 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7540 - acc: 0.5361 - val_loss: 0.6779 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7540 - acc: 0.5361 - val_loss: 0.6778 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7540 - acc: 0.5361 - val_loss: 0.6778 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7539 - acc: 0.5361 - val_loss: 0.6778 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7539 - acc: 0.5361 - val_loss: 0.6777 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7538 - acc: 0.5361 - val_loss: 0.6777 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7538 - acc: 0.5361 - val_loss: 0.6776 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7538 - acc: 0.5361 - val_loss: 0.6776 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7537 - acc: 0.5361 - val_loss: 0.6776 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7537 - acc: 0.5361 - val_loss: 0.6775 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7536 - acc: 0.5361 - val_loss: 0.6775 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7536 - acc: 0.5361 - val_loss: 0.6774 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7536 - acc: 0.5361 - val_loss: 0.6774 - val_acc: 0.6230\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9343 - acc: 0.3161 - val_loss: 0.9402 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9342 - acc: 0.3161 - val_loss: 0.9401 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9341 - acc: 0.3161 - val_loss: 0.9400 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9340 - acc: 0.3161 - val_loss: 0.9399 - val_acc: 0.3607\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9340 - acc: 0.3161 - val_loss: 0.9399 - val_acc: 0.3607\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9339 - acc: 0.3161 - val_loss: 0.9398 - val_acc: 0.3607\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9338 - acc: 0.3161 - val_loss: 0.9397 - val_acc: 0.3607\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9338 - acc: 0.3161 - val_loss: 0.9396 - val_acc: 0.3607\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9337 - acc: 0.3161 - val_loss: 0.9395 - val_acc: 0.3607\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9336 - acc: 0.3161 - val_loss: 0.9394 - val_acc: 0.3607\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9335 - acc: 0.3161 - val_loss: 0.9394 - val_acc: 0.3607\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9335 - acc: 0.3161 - val_loss: 0.9393 - val_acc: 0.3607\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9334 - acc: 0.3161 - val_loss: 0.9392 - val_acc: 0.3607\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9333 - acc: 0.3161 - val_loss: 0.9391 - val_acc: 0.3607\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9333 - acc: 0.3161 - val_loss: 0.9390 - val_acc: 0.3607\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9332 - acc: 0.3161 - val_loss: 0.9389 - val_acc: 0.3607\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9331 - acc: 0.3161 - val_loss: 0.9389 - val_acc: 0.3607\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9330 - acc: 0.3161 - val_loss: 0.9388 - val_acc: 0.3607\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9330 - acc: 0.3161 - val_loss: 0.9387 - val_acc: 0.3607\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9329 - acc: 0.3161 - val_loss: 0.9386 - val_acc: 0.3607\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0112 - acc: 0.4197 - val_loss: 1.0783 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0111 - acc: 0.4197 - val_loss: 1.0782 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0110 - acc: 0.4197 - val_loss: 1.0781 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0109 - acc: 0.4197 - val_loss: 1.0780 - val_acc: 0.3607\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0109 - acc: 0.4197 - val_loss: 1.0779 - val_acc: 0.3607\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0108 - acc: 0.4197 - val_loss: 1.0778 - val_acc: 0.3607\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0107 - acc: 0.4197 - val_loss: 1.0777 - val_acc: 0.3607\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0106 - acc: 0.4197 - val_loss: 1.0776 - val_acc: 0.3607\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0106 - acc: 0.4197 - val_loss: 1.0775 - val_acc: 0.3607\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0105 - acc: 0.4197 - val_loss: 1.0774 - val_acc: 0.3607\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0104 - acc: 0.4197 - val_loss: 1.0773 - val_acc: 0.3607\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0104 - acc: 0.4197 - val_loss: 1.0772 - val_acc: 0.3607\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0103 - acc: 0.4197 - val_loss: 1.0771 - val_acc: 0.3607\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0102 - acc: 0.4197 - val_loss: 1.0770 - val_acc: 0.3607\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0101 - acc: 0.4197 - val_loss: 1.0769 - val_acc: 0.3607\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0101 - acc: 0.4197 - val_loss: 1.0769 - val_acc: 0.3607\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0100 - acc: 0.4197 - val_loss: 1.0768 - val_acc: 0.3607\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0099 - acc: 0.4197 - val_loss: 1.0767 - val_acc: 0.3607\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0099 - acc: 0.4197 - val_loss: 1.0766 - val_acc: 0.3607\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0098 - acc: 0.4197 - val_loss: 1.0765 - val_acc: 0.3607\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8077 - acc: 0.4588 - val_loss: 0.8512 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8076 - acc: 0.4588 - val_loss: 0.8511 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8075 - acc: 0.4588 - val_loss: 0.8510 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8074 - acc: 0.4588 - val_loss: 0.8510 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8074 - acc: 0.4588 - val_loss: 0.8509 - val_acc: 0.3770\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8073 - acc: 0.4588 - val_loss: 0.8508 - val_acc: 0.3770\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8072 - acc: 0.4588 - val_loss: 0.8507 - val_acc: 0.3770\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8071 - acc: 0.4588 - val_loss: 0.8506 - val_acc: 0.3770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8071 - acc: 0.4588 - val_loss: 0.8505 - val_acc: 0.3770\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8070 - acc: 0.4588 - val_loss: 0.8504 - val_acc: 0.3770\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8069 - acc: 0.4588 - val_loss: 0.8503 - val_acc: 0.3770\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8069 - acc: 0.4588 - val_loss: 0.8503 - val_acc: 0.3770\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8068 - acc: 0.4588 - val_loss: 0.8502 - val_acc: 0.3770\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8067 - acc: 0.4588 - val_loss: 0.8501 - val_acc: 0.3770\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8066 - acc: 0.4588 - val_loss: 0.8500 - val_acc: 0.3770\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8066 - acc: 0.4588 - val_loss: 0.8499 - val_acc: 0.3770\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8065 - acc: 0.4588 - val_loss: 0.8498 - val_acc: 0.3770\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8064 - acc: 0.4588 - val_loss: 0.8498 - val_acc: 0.3770\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8064 - acc: 0.4588 - val_loss: 0.8497 - val_acc: 0.3770\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8063 - acc: 0.4588 - val_loss: 0.8496 - val_acc: 0.3770\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0231 - acc: 0.4433 - val_loss: 1.0057 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0230 - acc: 0.4433 - val_loss: 1.0056 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0229 - acc: 0.4433 - val_loss: 1.0056 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0228 - acc: 0.4433 - val_loss: 1.0055 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0227 - acc: 0.4433 - val_loss: 1.0054 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0226 - acc: 0.4433 - val_loss: 1.0053 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0225 - acc: 0.4433 - val_loss: 1.0052 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0224 - acc: 0.4433 - val_loss: 1.0051 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0223 - acc: 0.4433 - val_loss: 1.0051 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0223 - acc: 0.4433 - val_loss: 1.0050 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0222 - acc: 0.4433 - val_loss: 1.0049 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0221 - acc: 0.4433 - val_loss: 1.0048 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0220 - acc: 0.4433 - val_loss: 1.0047 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0219 - acc: 0.4433 - val_loss: 1.0047 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0218 - acc: 0.4433 - val_loss: 1.0046 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0217 - acc: 0.4433 - val_loss: 1.0045 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0217 - acc: 0.4433 - val_loss: 1.0044 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0216 - acc: 0.4433 - val_loss: 1.0043 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0215 - acc: 0.4433 - val_loss: 1.0043 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0214 - acc: 0.4433 - val_loss: 1.0042 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7228 - acc: 0.5052 - val_loss: 0.8316 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7228 - acc: 0.5052 - val_loss: 0.8315 - val_acc: 0.3115\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7227 - acc: 0.5052 - val_loss: 0.8314 - val_acc: 0.3115\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7227 - acc: 0.5052 - val_loss: 0.8314 - val_acc: 0.3115\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7226 - acc: 0.5052 - val_loss: 0.8313 - val_acc: 0.3115\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7226 - acc: 0.5052 - val_loss: 0.8312 - val_acc: 0.3115\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7225 - acc: 0.5052 - val_loss: 0.8312 - val_acc: 0.3115\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7225 - acc: 0.5052 - val_loss: 0.8311 - val_acc: 0.3115\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7224 - acc: 0.5052 - val_loss: 0.8310 - val_acc: 0.3115\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7224 - acc: 0.5052 - val_loss: 0.8310 - val_acc: 0.3115\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7223 - acc: 0.5052 - val_loss: 0.8309 - val_acc: 0.3115\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7223 - acc: 0.5052 - val_loss: 0.8308 - val_acc: 0.3115\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7222 - acc: 0.5052 - val_loss: 0.8307 - val_acc: 0.2951\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7222 - acc: 0.5052 - val_loss: 0.8307 - val_acc: 0.2951\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7221 - acc: 0.5052 - val_loss: 0.8306 - val_acc: 0.2951\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7221 - acc: 0.5052 - val_loss: 0.8305 - val_acc: 0.2951\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7220 - acc: 0.5052 - val_loss: 0.8305 - val_acc: 0.2951\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7220 - acc: 0.5052 - val_loss: 0.8304 - val_acc: 0.2951\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7219 - acc: 0.5052 - val_loss: 0.8303 - val_acc: 0.2951\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7219 - acc: 0.5052 - val_loss: 0.8303 - val_acc: 0.2951\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7728 - acc: 0.5492 - val_loss: 0.7679 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7727 - acc: 0.5492 - val_loss: 0.7678 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7726 - acc: 0.5492 - val_loss: 0.7677 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7725 - acc: 0.5492 - val_loss: 0.7676 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7724 - acc: 0.5492 - val_loss: 0.7675 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7723 - acc: 0.5492 - val_loss: 0.7675 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7722 - acc: 0.5492 - val_loss: 0.7674 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7721 - acc: 0.5492 - val_loss: 0.7673 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7720 - acc: 0.5492 - val_loss: 0.7672 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7719 - acc: 0.5492 - val_loss: 0.7671 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7718 - acc: 0.5492 - val_loss: 0.7671 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7718 - acc: 0.5492 - val_loss: 0.7670 - val_acc: 0.5902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7717 - acc: 0.5492 - val_loss: 0.7669 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7716 - acc: 0.5492 - val_loss: 0.7668 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7715 - acc: 0.5492 - val_loss: 0.7667 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7714 - acc: 0.5492 - val_loss: 0.7666 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7713 - acc: 0.5492 - val_loss: 0.7666 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7712 - acc: 0.5492 - val_loss: 0.7665 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7712 - acc: 0.5492 - val_loss: 0.7664 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7711 - acc: 0.5492 - val_loss: 0.7663 - val_acc: 0.5902\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6454 - acc: 0.6528 - val_loss: 0.6170 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6453 - acc: 0.6528 - val_loss: 0.6169 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6453 - acc: 0.6528 - val_loss: 0.6169 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6452 - acc: 0.6528 - val_loss: 0.6168 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6451 - acc: 0.6528 - val_loss: 0.6167 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6451 - acc: 0.6528 - val_loss: 0.6166 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6450 - acc: 0.6528 - val_loss: 0.6166 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6449 - acc: 0.6528 - val_loss: 0.6165 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6448 - acc: 0.6528 - val_loss: 0.6164 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6448 - acc: 0.6528 - val_loss: 0.6163 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6447 - acc: 0.6528 - val_loss: 0.6163 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6446 - acc: 0.6528 - val_loss: 0.6162 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6446 - acc: 0.6528 - val_loss: 0.6161 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6445 - acc: 0.6528 - val_loss: 0.6161 - val_acc: 0.6885\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6444 - acc: 0.6528 - val_loss: 0.6160 - val_acc: 0.6885\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6444 - acc: 0.6528 - val_loss: 0.6159 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6443 - acc: 0.6528 - val_loss: 0.6159 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6442 - acc: 0.6528 - val_loss: 0.6158 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6442 - acc: 0.6528 - val_loss: 0.6157 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6441 - acc: 0.6528 - val_loss: 0.6157 - val_acc: 0.6885\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9667 - acc: 0.2784 - val_loss: 0.9741 - val_acc: 0.2787\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9665 - acc: 0.2784 - val_loss: 0.9739 - val_acc: 0.2787\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9664 - acc: 0.2784 - val_loss: 0.9738 - val_acc: 0.2787\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9662 - acc: 0.2784 - val_loss: 0.9736 - val_acc: 0.2787\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9661 - acc: 0.2784 - val_loss: 0.9735 - val_acc: 0.2787\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9659 - acc: 0.2784 - val_loss: 0.9733 - val_acc: 0.2787\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9658 - acc: 0.2784 - val_loss: 0.9732 - val_acc: 0.2787\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9656 - acc: 0.2887 - val_loss: 0.9730 - val_acc: 0.2787\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9655 - acc: 0.2887 - val_loss: 0.9729 - val_acc: 0.2787\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9654 - acc: 0.2887 - val_loss: 0.9727 - val_acc: 0.2787\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9652 - acc: 0.2887 - val_loss: 0.9726 - val_acc: 0.2787\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9651 - acc: 0.2887 - val_loss: 0.9724 - val_acc: 0.2787\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9649 - acc: 0.2887 - val_loss: 0.9723 - val_acc: 0.2787\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9648 - acc: 0.2887 - val_loss: 0.9721 - val_acc: 0.2787\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9646 - acc: 0.2887 - val_loss: 0.9720 - val_acc: 0.2787\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9645 - acc: 0.2887 - val_loss: 0.9718 - val_acc: 0.2787\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9643 - acc: 0.2887 - val_loss: 0.9717 - val_acc: 0.2787\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9642 - acc: 0.2887 - val_loss: 0.9715 - val_acc: 0.2787\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9641 - acc: 0.2887 - val_loss: 0.9714 - val_acc: 0.2787\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9639 - acc: 0.2887 - val_loss: 0.9712 - val_acc: 0.2787\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7122 - acc: 0.5515 - val_loss: 0.6430 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7121 - acc: 0.5515 - val_loss: 0.6429 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7120 - acc: 0.5515 - val_loss: 0.6428 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7119 - acc: 0.5515 - val_loss: 0.6427 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7118 - acc: 0.5515 - val_loss: 0.6426 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7118 - acc: 0.5515 - val_loss: 0.6426 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7117 - acc: 0.5515 - val_loss: 0.6425 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7116 - acc: 0.5515 - val_loss: 0.6424 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7115 - acc: 0.5515 - val_loss: 0.6423 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7114 - acc: 0.5515 - val_loss: 0.6422 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7113 - acc: 0.5515 - val_loss: 0.6421 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7112 - acc: 0.5515 - val_loss: 0.6421 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7112 - acc: 0.5515 - val_loss: 0.6420 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7111 - acc: 0.5515 - val_loss: 0.6419 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7110 - acc: 0.5515 - val_loss: 0.6418 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7109 - acc: 0.5515 - val_loss: 0.6418 - val_acc: 0.5738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7108 - acc: 0.5515 - val_loss: 0.6417 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7107 - acc: 0.5515 - val_loss: 0.6416 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7107 - acc: 0.5515 - val_loss: 0.6415 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7106 - acc: 0.5515 - val_loss: 0.6414 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7371 - acc: 0.5412 - val_loss: 0.7128 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7370 - acc: 0.5412 - val_loss: 0.7127 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7369 - acc: 0.5412 - val_loss: 0.7126 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7368 - acc: 0.5412 - val_loss: 0.7125 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7368 - acc: 0.5412 - val_loss: 0.7124 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7367 - acc: 0.5412 - val_loss: 0.7124 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7366 - acc: 0.5412 - val_loss: 0.7123 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7365 - acc: 0.5412 - val_loss: 0.7122 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7364 - acc: 0.5412 - val_loss: 0.7121 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7364 - acc: 0.5412 - val_loss: 0.7121 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7363 - acc: 0.5412 - val_loss: 0.7120 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7362 - acc: 0.5464 - val_loss: 0.7119 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7361 - acc: 0.5464 - val_loss: 0.7118 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7360 - acc: 0.5464 - val_loss: 0.7118 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7359 - acc: 0.5464 - val_loss: 0.7117 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7359 - acc: 0.5464 - val_loss: 0.7116 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7358 - acc: 0.5464 - val_loss: 0.7115 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7357 - acc: 0.5464 - val_loss: 0.7115 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7356 - acc: 0.5464 - val_loss: 0.7114 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7356 - acc: 0.5464 - val_loss: 0.7113 - val_acc: 0.5902\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6500 - acc: 0.5803 - val_loss: 0.6452 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6498 - acc: 0.5803 - val_loss: 0.6451 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6497 - acc: 0.5803 - val_loss: 0.6450 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6496 - acc: 0.5803 - val_loss: 0.6449 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6495 - acc: 0.5803 - val_loss: 0.6448 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6494 - acc: 0.5803 - val_loss: 0.6447 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6493 - acc: 0.5803 - val_loss: 0.6447 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6492 - acc: 0.5803 - val_loss: 0.6446 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6491 - acc: 0.5803 - val_loss: 0.6445 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6490 - acc: 0.5803 - val_loss: 0.6444 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6489 - acc: 0.5803 - val_loss: 0.6443 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6488 - acc: 0.5803 - val_loss: 0.6442 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6487 - acc: 0.5803 - val_loss: 0.6441 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6486 - acc: 0.5803 - val_loss: 0.6440 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6485 - acc: 0.5803 - val_loss: 0.6439 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6484 - acc: 0.5803 - val_loss: 0.6438 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6484 - acc: 0.5803 - val_loss: 0.6437 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6483 - acc: 0.5803 - val_loss: 0.6436 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6482 - acc: 0.5803 - val_loss: 0.6435 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6481 - acc: 0.5803 - val_loss: 0.6434 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6883 - acc: 0.5544 - val_loss: 0.6223 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6881 - acc: 0.5544 - val_loss: 0.6222 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6880 - acc: 0.5544 - val_loss: 0.6220 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6878 - acc: 0.5544 - val_loss: 0.6219 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6877 - acc: 0.5544 - val_loss: 0.6218 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6876 - acc: 0.5544 - val_loss: 0.6216 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6874 - acc: 0.5544 - val_loss: 0.6215 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6873 - acc: 0.5544 - val_loss: 0.6214 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6872 - acc: 0.5544 - val_loss: 0.6213 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6871 - acc: 0.5544 - val_loss: 0.6212 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6870 - acc: 0.5544 - val_loss: 0.6210 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6869 - acc: 0.5544 - val_loss: 0.6209 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6867 - acc: 0.5544 - val_loss: 0.6208 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6866 - acc: 0.5544 - val_loss: 0.6207 - val_acc: 0.6885\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6865 - acc: 0.5544 - val_loss: 0.6206 - val_acc: 0.6885\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6864 - acc: 0.5544 - val_loss: 0.6204 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6863 - acc: 0.5544 - val_loss: 0.6203 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6862 - acc: 0.5544 - val_loss: 0.6202 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6860 - acc: 0.5544 - val_loss: 0.6201 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6859 - acc: 0.5596 - val_loss: 0.6199 - val_acc: 0.6885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8428 - acc: 0.4124 - val_loss: 0.8957 - val_acc: 0.3443\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8426 - acc: 0.4124 - val_loss: 0.8955 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8424 - acc: 0.4124 - val_loss: 0.8953 - val_acc: 0.3443\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8422 - acc: 0.4124 - val_loss: 0.8951 - val_acc: 0.3443\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8420 - acc: 0.4124 - val_loss: 0.8949 - val_acc: 0.3443\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8419 - acc: 0.4124 - val_loss: 0.8947 - val_acc: 0.3443\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8417 - acc: 0.4124 - val_loss: 0.8945 - val_acc: 0.3443\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8415 - acc: 0.4124 - val_loss: 0.8943 - val_acc: 0.3443\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8413 - acc: 0.4124 - val_loss: 0.8942 - val_acc: 0.3443\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8412 - acc: 0.4124 - val_loss: 0.8940 - val_acc: 0.3443\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8410 - acc: 0.4124 - val_loss: 0.8938 - val_acc: 0.3443\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8409 - acc: 0.4124 - val_loss: 0.8936 - val_acc: 0.3443\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8407 - acc: 0.4124 - val_loss: 0.8934 - val_acc: 0.3443\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8405 - acc: 0.4124 - val_loss: 0.8932 - val_acc: 0.3443\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8403 - acc: 0.4124 - val_loss: 0.8930 - val_acc: 0.3443\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8401 - acc: 0.4124 - val_loss: 0.8928 - val_acc: 0.3443\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8400 - acc: 0.4124 - val_loss: 0.8926 - val_acc: 0.3443\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8398 - acc: 0.4124 - val_loss: 0.8924 - val_acc: 0.3443\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8396 - acc: 0.4124 - val_loss: 0.8922 - val_acc: 0.3443\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8395 - acc: 0.4124 - val_loss: 0.8920 - val_acc: 0.3443\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7349 - acc: 0.4536 - val_loss: 0.7208 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7348 - acc: 0.4536 - val_loss: 0.7206 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7347 - acc: 0.4536 - val_loss: 0.7205 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7345 - acc: 0.4536 - val_loss: 0.7204 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7344 - acc: 0.4536 - val_loss: 0.7202 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7343 - acc: 0.4536 - val_loss: 0.7201 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7342 - acc: 0.4536 - val_loss: 0.7200 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7340 - acc: 0.4536 - val_loss: 0.7198 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7339 - acc: 0.4536 - val_loss: 0.7197 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7338 - acc: 0.4536 - val_loss: 0.7196 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7337 - acc: 0.4536 - val_loss: 0.7195 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7335 - acc: 0.4536 - val_loss: 0.7193 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7334 - acc: 0.4536 - val_loss: 0.7192 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7333 - acc: 0.4536 - val_loss: 0.7191 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7332 - acc: 0.4536 - val_loss: 0.7189 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7330 - acc: 0.4536 - val_loss: 0.7188 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7329 - acc: 0.4536 - val_loss: 0.7187 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7328 - acc: 0.4536 - val_loss: 0.7185 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7327 - acc: 0.4536 - val_loss: 0.7184 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7325 - acc: 0.4536 - val_loss: 0.7183 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7625 - acc: 0.4691 - val_loss: 0.6921 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7623 - acc: 0.4691 - val_loss: 0.6919 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7621 - acc: 0.4691 - val_loss: 0.6918 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7620 - acc: 0.4742 - val_loss: 0.6916 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7619 - acc: 0.4742 - val_loss: 0.6915 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7617 - acc: 0.4742 - val_loss: 0.6914 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7616 - acc: 0.4742 - val_loss: 0.6912 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7615 - acc: 0.4742 - val_loss: 0.6911 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7613 - acc: 0.4742 - val_loss: 0.6910 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7612 - acc: 0.4742 - val_loss: 0.6908 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7610 - acc: 0.4742 - val_loss: 0.6907 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7609 - acc: 0.4742 - val_loss: 0.6906 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7608 - acc: 0.4742 - val_loss: 0.6904 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7606 - acc: 0.4742 - val_loss: 0.6903 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7605 - acc: 0.4742 - val_loss: 0.6902 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7604 - acc: 0.4742 - val_loss: 0.6900 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7602 - acc: 0.4742 - val_loss: 0.6899 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7601 - acc: 0.4742 - val_loss: 0.6898 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7599 - acc: 0.4742 - val_loss: 0.6896 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7598 - acc: 0.4742 - val_loss: 0.6895 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6971 - acc: 0.5130 - val_loss: 0.7230 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6969 - acc: 0.5130 - val_loss: 0.7228 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6967 - acc: 0.5130 - val_loss: 0.7226 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6965 - acc: 0.5181 - val_loss: 0.7224 - val_acc: 0.5246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6963 - acc: 0.5181 - val_loss: 0.7222 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6962 - acc: 0.5181 - val_loss: 0.7220 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6960 - acc: 0.5181 - val_loss: 0.7219 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6959 - acc: 0.5181 - val_loss: 0.7217 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6957 - acc: 0.5181 - val_loss: 0.7215 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6956 - acc: 0.5181 - val_loss: 0.7214 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6954 - acc: 0.5181 - val_loss: 0.7212 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6953 - acc: 0.5181 - val_loss: 0.7210 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6951 - acc: 0.5181 - val_loss: 0.7209 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6950 - acc: 0.5181 - val_loss: 0.7207 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6948 - acc: 0.5181 - val_loss: 0.7206 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6947 - acc: 0.5181 - val_loss: 0.7204 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6946 - acc: 0.5181 - val_loss: 0.7203 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6944 - acc: 0.5181 - val_loss: 0.7201 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6943 - acc: 0.5181 - val_loss: 0.7200 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6942 - acc: 0.5181 - val_loss: 0.7198 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7320 - acc: 0.4508 - val_loss: 0.7301 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7318 - acc: 0.4508 - val_loss: 0.7299 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7316 - acc: 0.4508 - val_loss: 0.7297 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7314 - acc: 0.4508 - val_loss: 0.7295 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7312 - acc: 0.4508 - val_loss: 0.7293 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7311 - acc: 0.4508 - val_loss: 0.7292 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7309 - acc: 0.4508 - val_loss: 0.7290 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7307 - acc: 0.4508 - val_loss: 0.7288 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7306 - acc: 0.4508 - val_loss: 0.7286 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7304 - acc: 0.4508 - val_loss: 0.7284 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7302 - acc: 0.4508 - val_loss: 0.7282 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7300 - acc: 0.4508 - val_loss: 0.7280 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7299 - acc: 0.4508 - val_loss: 0.7279 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7297 - acc: 0.4508 - val_loss: 0.7277 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7296 - acc: 0.4508 - val_loss: 0.7275 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7294 - acc: 0.4508 - val_loss: 0.7273 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7292 - acc: 0.4508 - val_loss: 0.7272 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7291 - acc: 0.4508 - val_loss: 0.7270 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7289 - acc: 0.4508 - val_loss: 0.7268 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7287 - acc: 0.4508 - val_loss: 0.7266 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6475 - acc: 0.6598 - val_loss: 0.6655 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6473 - acc: 0.6598 - val_loss: 0.6654 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6472 - acc: 0.6598 - val_loss: 0.6652 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6470 - acc: 0.6598 - val_loss: 0.6650 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6469 - acc: 0.6598 - val_loss: 0.6648 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6467 - acc: 0.6649 - val_loss: 0.6646 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6465 - acc: 0.6649 - val_loss: 0.6645 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6464 - acc: 0.6649 - val_loss: 0.6643 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6462 - acc: 0.6649 - val_loss: 0.6641 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6460 - acc: 0.6649 - val_loss: 0.6639 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6459 - acc: 0.6649 - val_loss: 0.6637 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6457 - acc: 0.6649 - val_loss: 0.6636 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6456 - acc: 0.6649 - val_loss: 0.6634 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6454 - acc: 0.6649 - val_loss: 0.6632 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6453 - acc: 0.6701 - val_loss: 0.6631 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6451 - acc: 0.6701 - val_loss: 0.6629 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6450 - acc: 0.6701 - val_loss: 0.6627 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6448 - acc: 0.6701 - val_loss: 0.6625 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6447 - acc: 0.6701 - val_loss: 0.6624 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6445 - acc: 0.6753 - val_loss: 0.6622 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6783 - acc: 0.5670 - val_loss: 0.6873 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6781 - acc: 0.5670 - val_loss: 0.6871 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6779 - acc: 0.5670 - val_loss: 0.6868 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6777 - acc: 0.5722 - val_loss: 0.6866 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6775 - acc: 0.5722 - val_loss: 0.6864 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6774 - acc: 0.5722 - val_loss: 0.6862 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6772 - acc: 0.5722 - val_loss: 0.6860 - val_acc: 0.6393\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6770 - acc: 0.5722 - val_loss: 0.6858 - val_acc: 0.6393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6768 - acc: 0.5722 - val_loss: 0.6856 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6767 - acc: 0.5722 - val_loss: 0.6854 - val_acc: 0.6393\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6765 - acc: 0.5722 - val_loss: 0.6852 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6763 - acc: 0.5722 - val_loss: 0.6850 - val_acc: 0.6393\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6761 - acc: 0.5722 - val_loss: 0.6848 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6760 - acc: 0.5722 - val_loss: 0.6846 - val_acc: 0.6393\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6758 - acc: 0.5722 - val_loss: 0.6844 - val_acc: 0.6393\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6756 - acc: 0.5722 - val_loss: 0.6842 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6755 - acc: 0.5773 - val_loss: 0.6840 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6753 - acc: 0.5825 - val_loss: 0.6838 - val_acc: 0.6393\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6751 - acc: 0.5825 - val_loss: 0.6836 - val_acc: 0.6393\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6749 - acc: 0.5825 - val_loss: 0.6834 - val_acc: 0.6393\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7097 - acc: 0.5670 - val_loss: 0.6955 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7094 - acc: 0.5670 - val_loss: 0.6953 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7093 - acc: 0.5670 - val_loss: 0.6950 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7091 - acc: 0.5670 - val_loss: 0.6948 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7089 - acc: 0.5670 - val_loss: 0.6946 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7087 - acc: 0.5670 - val_loss: 0.6944 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7085 - acc: 0.5670 - val_loss: 0.6942 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7083 - acc: 0.5670 - val_loss: 0.6940 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7082 - acc: 0.5670 - val_loss: 0.6938 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7080 - acc: 0.5670 - val_loss: 0.6936 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7078 - acc: 0.5670 - val_loss: 0.6933 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7076 - acc: 0.5670 - val_loss: 0.6931 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7074 - acc: 0.5670 - val_loss: 0.6929 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7072 - acc: 0.5670 - val_loss: 0.6926 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7071 - acc: 0.5670 - val_loss: 0.6924 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7069 - acc: 0.5670 - val_loss: 0.6922 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7067 - acc: 0.5670 - val_loss: 0.6921 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7065 - acc: 0.5670 - val_loss: 0.6919 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7064 - acc: 0.5670 - val_loss: 0.6917 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7062 - acc: 0.5670 - val_loss: 0.6915 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6849 - acc: 0.5285 - val_loss: 0.6887 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6846 - acc: 0.5285 - val_loss: 0.6884 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6844 - acc: 0.5285 - val_loss: 0.6882 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6841 - acc: 0.5285 - val_loss: 0.6879 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6839 - acc: 0.5389 - val_loss: 0.6877 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6837 - acc: 0.5440 - val_loss: 0.6875 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6835 - acc: 0.5440 - val_loss: 0.6872 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6832 - acc: 0.5492 - val_loss: 0.6870 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6830 - acc: 0.5492 - val_loss: 0.6868 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6828 - acc: 0.5492 - val_loss: 0.6866 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6826 - acc: 0.5544 - val_loss: 0.6863 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6824 - acc: 0.5544 - val_loss: 0.6861 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6821 - acc: 0.5544 - val_loss: 0.6859 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6819 - acc: 0.5544 - val_loss: 0.6857 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6817 - acc: 0.5544 - val_loss: 0.6855 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6815 - acc: 0.5544 - val_loss: 0.6853 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6813 - acc: 0.5544 - val_loss: 0.6851 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6811 - acc: 0.5544 - val_loss: 0.6849 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6810 - acc: 0.5544 - val_loss: 0.6847 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6808 - acc: 0.5544 - val_loss: 0.6845 - val_acc: 0.5574\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7021 - acc: 0.4974 - val_loss: 0.7100 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7018 - acc: 0.4974 - val_loss: 0.7097 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7016 - acc: 0.4922 - val_loss: 0.7094 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7013 - acc: 0.4922 - val_loss: 0.7092 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7011 - acc: 0.4974 - val_loss: 0.7089 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7009 - acc: 0.4974 - val_loss: 0.7087 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7007 - acc: 0.4974 - val_loss: 0.7085 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7005 - acc: 0.5026 - val_loss: 0.7083 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7003 - acc: 0.5026 - val_loss: 0.7081 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7001 - acc: 0.5026 - val_loss: 0.7078 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6999 - acc: 0.5026 - val_loss: 0.7076 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6997 - acc: 0.5078 - val_loss: 0.7074 - val_acc: 0.4262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6995 - acc: 0.5078 - val_loss: 0.7072 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6993 - acc: 0.5078 - val_loss: 0.7069 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6991 - acc: 0.5078 - val_loss: 0.7067 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6989 - acc: 0.5078 - val_loss: 0.7065 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6987 - acc: 0.5078 - val_loss: 0.7064 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6986 - acc: 0.5078 - val_loss: 0.7062 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6984 - acc: 0.5078 - val_loss: 0.7060 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6982 - acc: 0.5078 - val_loss: 0.7057 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6879 - acc: 0.5464 - val_loss: 0.7039 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6876 - acc: 0.5464 - val_loss: 0.7036 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6872 - acc: 0.5464 - val_loss: 0.7032 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6869 - acc: 0.5464 - val_loss: 0.7029 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6867 - acc: 0.5464 - val_loss: 0.7026 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6864 - acc: 0.5464 - val_loss: 0.7023 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6861 - acc: 0.5464 - val_loss: 0.7021 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6858 - acc: 0.5464 - val_loss: 0.7018 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6856 - acc: 0.5464 - val_loss: 0.7015 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6853 - acc: 0.5464 - val_loss: 0.7012 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6850 - acc: 0.5515 - val_loss: 0.7009 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6847 - acc: 0.5515 - val_loss: 0.7006 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6845 - acc: 0.5567 - val_loss: 0.7003 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6842 - acc: 0.5567 - val_loss: 0.7000 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6839 - acc: 0.5567 - val_loss: 0.6997 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6836 - acc: 0.5619 - val_loss: 0.6995 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6834 - acc: 0.5670 - val_loss: 0.6992 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6831 - acc: 0.5722 - val_loss: 0.6989 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6829 - acc: 0.5722 - val_loss: 0.6986 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6826 - acc: 0.5773 - val_loss: 0.6984 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7563 - acc: 0.2784 - val_loss: 0.7529 - val_acc: 0.2951\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7560 - acc: 0.2784 - val_loss: 0.7525 - val_acc: 0.2951\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7556 - acc: 0.2784 - val_loss: 0.7522 - val_acc: 0.2951\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7553 - acc: 0.2784 - val_loss: 0.7519 - val_acc: 0.2951\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7551 - acc: 0.2784 - val_loss: 0.7516 - val_acc: 0.3115\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7548 - acc: 0.2784 - val_loss: 0.7513 - val_acc: 0.3115\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7545 - acc: 0.2784 - val_loss: 0.7510 - val_acc: 0.3115\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7542 - acc: 0.2835 - val_loss: 0.7507 - val_acc: 0.3115\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7539 - acc: 0.2835 - val_loss: 0.7504 - val_acc: 0.3115\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7536 - acc: 0.2835 - val_loss: 0.7501 - val_acc: 0.3115\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7534 - acc: 0.2835 - val_loss: 0.7498 - val_acc: 0.3115\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7531 - acc: 0.2887 - val_loss: 0.7495 - val_acc: 0.3115\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7528 - acc: 0.2887 - val_loss: 0.7492 - val_acc: 0.3115\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7525 - acc: 0.2887 - val_loss: 0.7489 - val_acc: 0.3115\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7523 - acc: 0.2887 - val_loss: 0.7486 - val_acc: 0.3115\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7520 - acc: 0.2887 - val_loss: 0.7483 - val_acc: 0.3115\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7517 - acc: 0.2938 - val_loss: 0.7480 - val_acc: 0.3115\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7515 - acc: 0.2938 - val_loss: 0.7477 - val_acc: 0.3115\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7512 - acc: 0.2938 - val_loss: 0.7474 - val_acc: 0.3115\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7509 - acc: 0.2938 - val_loss: 0.7471 - val_acc: 0.3115\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6609 - acc: 0.6546 - val_loss: 0.6145 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6607 - acc: 0.6546 - val_loss: 0.6142 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6604 - acc: 0.6546 - val_loss: 0.6140 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6602 - acc: 0.6546 - val_loss: 0.6137 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6599 - acc: 0.6546 - val_loss: 0.6135 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6597 - acc: 0.6546 - val_loss: 0.6132 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6595 - acc: 0.6546 - val_loss: 0.6130 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6592 - acc: 0.6546 - val_loss: 0.6128 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6590 - acc: 0.6546 - val_loss: 0.6125 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6588 - acc: 0.6546 - val_loss: 0.6123 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6586 - acc: 0.6598 - val_loss: 0.6121 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6583 - acc: 0.6598 - val_loss: 0.6118 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6581 - acc: 0.6598 - val_loss: 0.6116 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6579 - acc: 0.6598 - val_loss: 0.6113 - val_acc: 0.7705\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6576 - acc: 0.6598 - val_loss: 0.6111 - val_acc: 0.7705\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6574 - acc: 0.6598 - val_loss: 0.6108 - val_acc: 0.7705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6572 - acc: 0.6598 - val_loss: 0.6106 - val_acc: 0.7705\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6569 - acc: 0.6598 - val_loss: 0.6103 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6567 - acc: 0.6598 - val_loss: 0.6101 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6565 - acc: 0.6649 - val_loss: 0.6099 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8999 - acc: 0.3938 - val_loss: 0.9974 - val_acc: 0.3443\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8999 - acc: 0.3938 - val_loss: 0.9974 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8998 - acc: 0.3938 - val_loss: 0.9973 - val_acc: 0.3443\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8998 - acc: 0.3938 - val_loss: 0.9973 - val_acc: 0.3443\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8998 - acc: 0.3938 - val_loss: 0.9972 - val_acc: 0.3443\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8997 - acc: 0.3938 - val_loss: 0.9972 - val_acc: 0.3443\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8997 - acc: 0.3938 - val_loss: 0.9972 - val_acc: 0.3443\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8997 - acc: 0.3938 - val_loss: 0.9971 - val_acc: 0.3443\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8997 - acc: 0.3938 - val_loss: 0.9971 - val_acc: 0.3443\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8996 - acc: 0.3938 - val_loss: 0.9970 - val_acc: 0.3443\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8996 - acc: 0.3938 - val_loss: 0.9970 - val_acc: 0.3443\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8996 - acc: 0.3938 - val_loss: 0.9969 - val_acc: 0.3443\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8995 - acc: 0.3938 - val_loss: 0.9969 - val_acc: 0.3443\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8995 - acc: 0.3938 - val_loss: 0.9969 - val_acc: 0.3443\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8995 - acc: 0.3938 - val_loss: 0.9968 - val_acc: 0.3443\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8994 - acc: 0.3938 - val_loss: 0.9968 - val_acc: 0.3443\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8994 - acc: 0.3938 - val_loss: 0.9967 - val_acc: 0.3443\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8994 - acc: 0.3938 - val_loss: 0.9967 - val_acc: 0.3443\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8994 - acc: 0.3938 - val_loss: 0.9967 - val_acc: 0.3443\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8993 - acc: 0.3938 - val_loss: 0.9966 - val_acc: 0.3443\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8532 - acc: 0.4715 - val_loss: 0.9987 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8532 - acc: 0.4715 - val_loss: 0.9987 - val_acc: 0.3115\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8532 - acc: 0.4715 - val_loss: 0.9986 - val_acc: 0.3115\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8531 - acc: 0.4715 - val_loss: 0.9986 - val_acc: 0.3115\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8531 - acc: 0.4715 - val_loss: 0.9985 - val_acc: 0.3115\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8531 - acc: 0.4715 - val_loss: 0.9985 - val_acc: 0.3115\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8530 - acc: 0.4715 - val_loss: 0.9985 - val_acc: 0.3115\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8530 - acc: 0.4715 - val_loss: 0.9984 - val_acc: 0.3115\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8530 - acc: 0.4715 - val_loss: 0.9984 - val_acc: 0.3115\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8530 - acc: 0.4715 - val_loss: 0.9984 - val_acc: 0.3115\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8529 - acc: 0.4715 - val_loss: 0.9983 - val_acc: 0.3115\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8529 - acc: 0.4715 - val_loss: 0.9983 - val_acc: 0.3115\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8529 - acc: 0.4715 - val_loss: 0.9983 - val_acc: 0.3115\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8529 - acc: 0.4715 - val_loss: 0.9982 - val_acc: 0.3115\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8529 - acc: 0.4715 - val_loss: 0.9982 - val_acc: 0.3115\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8528 - acc: 0.4715 - val_loss: 0.9982 - val_acc: 0.3115\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8528 - acc: 0.4715 - val_loss: 0.9981 - val_acc: 0.3115\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8528 - acc: 0.4715 - val_loss: 0.9981 - val_acc: 0.3115\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8528 - acc: 0.4715 - val_loss: 0.9981 - val_acc: 0.3115\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8527 - acc: 0.4715 - val_loss: 0.9980 - val_acc: 0.3115\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7530 - acc: 0.4639 - val_loss: 0.6528 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7530 - acc: 0.4639 - val_loss: 0.6528 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7530 - acc: 0.4639 - val_loss: 0.6528 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7529 - acc: 0.4639 - val_loss: 0.6527 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7529 - acc: 0.4639 - val_loss: 0.6527 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7529 - acc: 0.4639 - val_loss: 0.6527 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7529 - acc: 0.4639 - val_loss: 0.6527 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7529 - acc: 0.4639 - val_loss: 0.6526 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7528 - acc: 0.4639 - val_loss: 0.6526 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7528 - acc: 0.4639 - val_loss: 0.6526 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7528 - acc: 0.4639 - val_loss: 0.6526 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7528 - acc: 0.4639 - val_loss: 0.6525 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7527 - acc: 0.4639 - val_loss: 0.6525 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7527 - acc: 0.4639 - val_loss: 0.6525 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7527 - acc: 0.4639 - val_loss: 0.6525 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7527 - acc: 0.4639 - val_loss: 0.6524 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7527 - acc: 0.4639 - val_loss: 0.6524 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7526 - acc: 0.4639 - val_loss: 0.6524 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7526 - acc: 0.4639 - val_loss: 0.6524 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7526 - acc: 0.4639 - val_loss: 0.6523 - val_acc: 0.5410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8687 - acc: 0.4278 - val_loss: 1.0690 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8687 - acc: 0.4278 - val_loss: 1.0689 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8686 - acc: 0.4278 - val_loss: 1.0689 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8686 - acc: 0.4278 - val_loss: 1.0688 - val_acc: 0.3607\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8685 - acc: 0.4278 - val_loss: 1.0688 - val_acc: 0.3607\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8685 - acc: 0.4278 - val_loss: 1.0687 - val_acc: 0.3607\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8685 - acc: 0.4278 - val_loss: 1.0687 - val_acc: 0.3607\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8684 - acc: 0.4278 - val_loss: 1.0686 - val_acc: 0.3607\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8684 - acc: 0.4278 - val_loss: 1.0685 - val_acc: 0.3607\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8683 - acc: 0.4278 - val_loss: 1.0685 - val_acc: 0.3607\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8683 - acc: 0.4278 - val_loss: 1.0684 - val_acc: 0.3607\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8683 - acc: 0.4278 - val_loss: 1.0684 - val_acc: 0.3607\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8682 - acc: 0.4330 - val_loss: 1.0683 - val_acc: 0.3607\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8682 - acc: 0.4330 - val_loss: 1.0683 - val_acc: 0.3607\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8682 - acc: 0.4330 - val_loss: 1.0682 - val_acc: 0.3607\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8681 - acc: 0.4330 - val_loss: 1.0682 - val_acc: 0.3607\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8681 - acc: 0.4330 - val_loss: 1.0681 - val_acc: 0.3607\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8680 - acc: 0.4330 - val_loss: 1.0681 - val_acc: 0.3607\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8680 - acc: 0.4330 - val_loss: 1.0680 - val_acc: 0.3607\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8679 - acc: 0.4330 - val_loss: 1.0679 - val_acc: 0.3607\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7632 - acc: 0.5928 - val_loss: 0.6871 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7631 - acc: 0.5928 - val_loss: 0.6871 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7631 - acc: 0.5928 - val_loss: 0.6871 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7631 - acc: 0.5928 - val_loss: 0.6870 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7630 - acc: 0.5928 - val_loss: 0.6870 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7630 - acc: 0.5928 - val_loss: 0.6870 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7630 - acc: 0.5928 - val_loss: 0.6869 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7630 - acc: 0.5928 - val_loss: 0.6869 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7629 - acc: 0.5928 - val_loss: 0.6869 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7629 - acc: 0.5928 - val_loss: 0.6869 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7629 - acc: 0.5928 - val_loss: 0.6868 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7628 - acc: 0.5928 - val_loss: 0.6868 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7628 - acc: 0.5928 - val_loss: 0.6868 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7628 - acc: 0.5928 - val_loss: 0.6867 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7628 - acc: 0.5928 - val_loss: 0.6867 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7627 - acc: 0.5928 - val_loss: 0.6867 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7627 - acc: 0.5928 - val_loss: 0.6867 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7627 - acc: 0.5928 - val_loss: 0.6866 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7626 - acc: 0.5928 - val_loss: 0.6866 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7626 - acc: 0.5928 - val_loss: 0.6866 - val_acc: 0.5902\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8381 - acc: 0.4870 - val_loss: 0.8343 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8381 - acc: 0.4870 - val_loss: 0.8342 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8380 - acc: 0.4870 - val_loss: 0.8342 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8380 - acc: 0.4870 - val_loss: 0.8341 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8379 - acc: 0.4870 - val_loss: 0.8341 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8379 - acc: 0.4870 - val_loss: 0.8340 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8379 - acc: 0.4870 - val_loss: 0.8340 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8378 - acc: 0.4870 - val_loss: 0.8339 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8378 - acc: 0.4870 - val_loss: 0.8339 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8377 - acc: 0.4870 - val_loss: 0.8338 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8377 - acc: 0.4870 - val_loss: 0.8338 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8377 - acc: 0.4870 - val_loss: 0.8337 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8376 - acc: 0.4870 - val_loss: 0.8337 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8376 - acc: 0.4870 - val_loss: 0.8336 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8375 - acc: 0.4870 - val_loss: 0.8336 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8375 - acc: 0.4870 - val_loss: 0.8336 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8375 - acc: 0.4870 - val_loss: 0.8335 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8374 - acc: 0.4870 - val_loss: 0.8335 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8374 - acc: 0.4870 - val_loss: 0.8334 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8374 - acc: 0.4870 - val_loss: 0.8334 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8947 - acc: 0.4301 - val_loss: 0.9571 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8947 - acc: 0.4301 - val_loss: 0.9570 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8946 - acc: 0.4301 - val_loss: 0.9570 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8946 - acc: 0.4301 - val_loss: 0.9570 - val_acc: 0.3770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8946 - acc: 0.4301 - val_loss: 0.9569 - val_acc: 0.3770\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8945 - acc: 0.4301 - val_loss: 0.9569 - val_acc: 0.3770\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8945 - acc: 0.4301 - val_loss: 0.9568 - val_acc: 0.3770\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8945 - acc: 0.4301 - val_loss: 0.9568 - val_acc: 0.3770\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8944 - acc: 0.4301 - val_loss: 0.9567 - val_acc: 0.3770\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8944 - acc: 0.4301 - val_loss: 0.9567 - val_acc: 0.3770\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8943 - acc: 0.4301 - val_loss: 0.9567 - val_acc: 0.3770\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8943 - acc: 0.4301 - val_loss: 0.9566 - val_acc: 0.3770\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8943 - acc: 0.4301 - val_loss: 0.9566 - val_acc: 0.3770\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8942 - acc: 0.4301 - val_loss: 0.9565 - val_acc: 0.3770\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8942 - acc: 0.4301 - val_loss: 0.9565 - val_acc: 0.3770\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8942 - acc: 0.4301 - val_loss: 0.9565 - val_acc: 0.3770\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8941 - acc: 0.4301 - val_loss: 0.9564 - val_acc: 0.3770\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8941 - acc: 0.4301 - val_loss: 0.9564 - val_acc: 0.3770\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8940 - acc: 0.4301 - val_loss: 0.9563 - val_acc: 0.3770\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8940 - acc: 0.4301 - val_loss: 0.9563 - val_acc: 0.3770\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7299 - acc: 0.5464 - val_loss: 0.6616 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7299 - acc: 0.5464 - val_loss: 0.6616 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7298 - acc: 0.5464 - val_loss: 0.6616 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7298 - acc: 0.5464 - val_loss: 0.6615 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7298 - acc: 0.5464 - val_loss: 0.6615 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7297 - acc: 0.5464 - val_loss: 0.6615 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7297 - acc: 0.5464 - val_loss: 0.6614 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7296 - acc: 0.5464 - val_loss: 0.6614 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7296 - acc: 0.5464 - val_loss: 0.6613 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7296 - acc: 0.5464 - val_loss: 0.6613 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7295 - acc: 0.5464 - val_loss: 0.6613 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7295 - acc: 0.5464 - val_loss: 0.6612 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7294 - acc: 0.5464 - val_loss: 0.6612 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7294 - acc: 0.5464 - val_loss: 0.6612 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7294 - acc: 0.5464 - val_loss: 0.6611 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7293 - acc: 0.5464 - val_loss: 0.6611 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7293 - acc: 0.5464 - val_loss: 0.6611 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7293 - acc: 0.5464 - val_loss: 0.6610 - val_acc: 0.6066\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7292 - acc: 0.5464 - val_loss: 0.6610 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7292 - acc: 0.5464 - val_loss: 0.6609 - val_acc: 0.6066\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8168 - acc: 0.5155 - val_loss: 0.8624 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8167 - acc: 0.5155 - val_loss: 0.8624 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8167 - acc: 0.5155 - val_loss: 0.8623 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8166 - acc: 0.5155 - val_loss: 0.8622 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8166 - acc: 0.5155 - val_loss: 0.8622 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8165 - acc: 0.5155 - val_loss: 0.8621 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8165 - acc: 0.5155 - val_loss: 0.8621 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8164 - acc: 0.5155 - val_loss: 0.8620 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8164 - acc: 0.5155 - val_loss: 0.8619 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8163 - acc: 0.5155 - val_loss: 0.8619 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8163 - acc: 0.5155 - val_loss: 0.8618 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8162 - acc: 0.5155 - val_loss: 0.8618 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8162 - acc: 0.5155 - val_loss: 0.8617 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8161 - acc: 0.5155 - val_loss: 0.8616 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8161 - acc: 0.5155 - val_loss: 0.8616 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8160 - acc: 0.5155 - val_loss: 0.8615 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8160 - acc: 0.5155 - val_loss: 0.8615 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8159 - acc: 0.5155 - val_loss: 0.8614 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8159 - acc: 0.5155 - val_loss: 0.8614 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8158 - acc: 0.5155 - val_loss: 0.8613 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9782 - acc: 0.4845 - val_loss: 1.2685 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9782 - acc: 0.4845 - val_loss: 1.2684 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9781 - acc: 0.4845 - val_loss: 1.2683 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9780 - acc: 0.4845 - val_loss: 1.2682 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9780 - acc: 0.4845 - val_loss: 1.2681 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9779 - acc: 0.4845 - val_loss: 1.2680 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9778 - acc: 0.4845 - val_loss: 1.2680 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9778 - acc: 0.4845 - val_loss: 1.2679 - val_acc: 0.4098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9777 - acc: 0.4845 - val_loss: 1.2678 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9776 - acc: 0.4845 - val_loss: 1.2677 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9776 - acc: 0.4845 - val_loss: 1.2676 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9775 - acc: 0.4845 - val_loss: 1.2675 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9775 - acc: 0.4845 - val_loss: 1.2675 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9774 - acc: 0.4845 - val_loss: 1.2674 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9773 - acc: 0.4845 - val_loss: 1.2673 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9773 - acc: 0.4845 - val_loss: 1.2672 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9772 - acc: 0.4845 - val_loss: 1.2671 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9771 - acc: 0.4845 - val_loss: 1.2670 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9771 - acc: 0.4845 - val_loss: 1.2669 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9770 - acc: 0.4845 - val_loss: 1.2668 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7981 - acc: 0.4870 - val_loss: 0.9066 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7980 - acc: 0.4870 - val_loss: 0.9065 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7980 - acc: 0.4870 - val_loss: 0.9065 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7979 - acc: 0.4870 - val_loss: 0.9064 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7978 - acc: 0.4870 - val_loss: 0.9063 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7978 - acc: 0.4870 - val_loss: 0.9063 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7977 - acc: 0.4870 - val_loss: 0.9062 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7977 - acc: 0.4870 - val_loss: 0.9061 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7976 - acc: 0.4870 - val_loss: 0.9061 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7976 - acc: 0.4870 - val_loss: 0.9060 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7975 - acc: 0.4870 - val_loss: 0.9059 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7974 - acc: 0.4870 - val_loss: 0.9059 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7974 - acc: 0.4870 - val_loss: 0.9058 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7973 - acc: 0.4870 - val_loss: 0.9057 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7972 - acc: 0.4870 - val_loss: 0.9056 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7972 - acc: 0.4870 - val_loss: 0.9056 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7971 - acc: 0.4870 - val_loss: 0.9055 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7970 - acc: 0.4870 - val_loss: 0.9054 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7970 - acc: 0.4870 - val_loss: 0.9053 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7969 - acc: 0.4870 - val_loss: 0.9053 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8697 - acc: 0.5492 - val_loss: 0.9025 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8696 - acc: 0.5492 - val_loss: 0.9024 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8695 - acc: 0.5492 - val_loss: 0.9023 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8694 - acc: 0.5492 - val_loss: 0.9022 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8693 - acc: 0.5544 - val_loss: 0.9021 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8693 - acc: 0.5544 - val_loss: 0.9020 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8692 - acc: 0.5544 - val_loss: 0.9019 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8691 - acc: 0.5544 - val_loss: 0.9018 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8691 - acc: 0.5544 - val_loss: 0.9017 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8690 - acc: 0.5544 - val_loss: 0.9016 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8689 - acc: 0.5544 - val_loss: 0.9015 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8689 - acc: 0.5544 - val_loss: 0.9014 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8688 - acc: 0.5544 - val_loss: 0.9013 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8687 - acc: 0.5544 - val_loss: 0.9012 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8686 - acc: 0.5544 - val_loss: 0.9011 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8686 - acc: 0.5544 - val_loss: 0.9010 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8685 - acc: 0.5544 - val_loss: 0.9009 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8684 - acc: 0.5544 - val_loss: 0.9008 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8683 - acc: 0.5544 - val_loss: 0.9007 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8683 - acc: 0.5544 - val_loss: 0.9006 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6463 - acc: 0.6495 - val_loss: 0.6218 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6462 - acc: 0.6495 - val_loss: 0.6218 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6462 - acc: 0.6495 - val_loss: 0.6217 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6461 - acc: 0.6495 - val_loss: 0.6217 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6461 - acc: 0.6495 - val_loss: 0.6217 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6460 - acc: 0.6495 - val_loss: 0.6216 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6460 - acc: 0.6495 - val_loss: 0.6216 - val_acc: 0.6393\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6459 - acc: 0.6495 - val_loss: 0.6215 - val_acc: 0.6393\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6459 - acc: 0.6495 - val_loss: 0.6215 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6459 - acc: 0.6495 - val_loss: 0.6214 - val_acc: 0.6393\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6458 - acc: 0.6495 - val_loss: 0.6214 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6458 - acc: 0.6495 - val_loss: 0.6213 - val_acc: 0.6393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6457 - acc: 0.6495 - val_loss: 0.6213 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6457 - acc: 0.6495 - val_loss: 0.6213 - val_acc: 0.6393\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5495 - acc: 0.750 - 0s 2ms/step - loss: 0.6457 - acc: 0.6546 - val_loss: 0.6212 - val_acc: 0.6393\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6456 - acc: 0.6546 - val_loss: 0.6212 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6456 - acc: 0.6546 - val_loss: 0.6211 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6455 - acc: 0.6546 - val_loss: 0.6211 - val_acc: 0.6393\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6455 - acc: 0.6546 - val_loss: 0.6210 - val_acc: 0.6393\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6454 - acc: 0.6546 - val_loss: 0.6210 - val_acc: 0.6393\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7399 - acc: 0.5515 - val_loss: 0.6837 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7398 - acc: 0.5515 - val_loss: 0.6836 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7397 - acc: 0.5515 - val_loss: 0.6836 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7397 - acc: 0.5515 - val_loss: 0.6835 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7396 - acc: 0.5515 - val_loss: 0.6835 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7396 - acc: 0.5515 - val_loss: 0.6834 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7395 - acc: 0.5515 - val_loss: 0.6834 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7395 - acc: 0.5515 - val_loss: 0.6833 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7394 - acc: 0.5515 - val_loss: 0.6833 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7394 - acc: 0.5515 - val_loss: 0.6832 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7393 - acc: 0.5515 - val_loss: 0.6832 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7393 - acc: 0.5515 - val_loss: 0.6831 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7392 - acc: 0.5515 - val_loss: 0.6831 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7392 - acc: 0.5515 - val_loss: 0.6831 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7391 - acc: 0.5515 - val_loss: 0.6830 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7391 - acc: 0.5515 - val_loss: 0.6830 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7390 - acc: 0.5515 - val_loss: 0.6829 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7390 - acc: 0.5515 - val_loss: 0.6829 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7389 - acc: 0.5515 - val_loss: 0.6828 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7389 - acc: 0.5515 - val_loss: 0.6828 - val_acc: 0.6230\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7656 - acc: 0.5052 - val_loss: 0.8057 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7655 - acc: 0.5052 - val_loss: 0.8056 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7655 - acc: 0.5052 - val_loss: 0.8055 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7654 - acc: 0.5052 - val_loss: 0.8054 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7653 - acc: 0.5052 - val_loss: 0.8053 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7653 - acc: 0.5052 - val_loss: 0.8053 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7652 - acc: 0.5052 - val_loss: 0.8052 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7652 - acc: 0.5052 - val_loss: 0.8051 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7651 - acc: 0.5052 - val_loss: 0.8050 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7651 - acc: 0.5052 - val_loss: 0.8050 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7650 - acc: 0.5052 - val_loss: 0.8049 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7650 - acc: 0.5052 - val_loss: 0.8048 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7649 - acc: 0.5052 - val_loss: 0.8048 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7649 - acc: 0.5052 - val_loss: 0.8047 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7648 - acc: 0.5052 - val_loss: 0.8046 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7648 - acc: 0.5052 - val_loss: 0.8045 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7647 - acc: 0.5052 - val_loss: 0.8045 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7647 - acc: 0.5052 - val_loss: 0.8044 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7646 - acc: 0.5052 - val_loss: 0.8043 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7645 - acc: 0.5052 - val_loss: 0.8043 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5953 - acc: 0.7047 - val_loss: 0.6193 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5953 - acc: 0.7047 - val_loss: 0.6192 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5952 - acc: 0.7047 - val_loss: 0.6191 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5951 - acc: 0.7047 - val_loss: 0.6191 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5951 - acc: 0.7047 - val_loss: 0.6190 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5950 - acc: 0.7047 - val_loss: 0.6190 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5950 - acc: 0.7047 - val_loss: 0.6189 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5949 - acc: 0.7047 - val_loss: 0.6189 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5949 - acc: 0.7047 - val_loss: 0.6188 - val_acc: 0.7049\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5949 - acc: 0.7047 - val_loss: 0.6187 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5948 - acc: 0.7047 - val_loss: 0.6187 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5948 - acc: 0.7047 - val_loss: 0.6186 - val_acc: 0.7049\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5947 - acc: 0.7047 - val_loss: 0.6186 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5947 - acc: 0.7047 - val_loss: 0.6185 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5946 - acc: 0.7047 - val_loss: 0.6185 - val_acc: 0.7049\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5946 - acc: 0.7047 - val_loss: 0.6184 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5945 - acc: 0.7047 - val_loss: 0.6184 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5945 - acc: 0.7047 - val_loss: 0.6183 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5944 - acc: 0.7047 - val_loss: 0.6183 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5944 - acc: 0.7047 - val_loss: 0.6182 - val_acc: 0.7049\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8567 - acc: 0.3627 - val_loss: 0.9055 - val_acc: 0.2787\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8566 - acc: 0.3627 - val_loss: 0.9054 - val_acc: 0.2787\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8565 - acc: 0.3627 - val_loss: 0.9053 - val_acc: 0.2787\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8564 - acc: 0.3627 - val_loss: 0.9052 - val_acc: 0.2787\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8563 - acc: 0.3627 - val_loss: 0.9050 - val_acc: 0.2787\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8562 - acc: 0.3627 - val_loss: 0.9049 - val_acc: 0.2787\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8561 - acc: 0.3627 - val_loss: 0.9048 - val_acc: 0.2787\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8560 - acc: 0.3627 - val_loss: 0.9047 - val_acc: 0.2787\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8559 - acc: 0.3627 - val_loss: 0.9046 - val_acc: 0.2787\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8558 - acc: 0.3627 - val_loss: 0.9045 - val_acc: 0.2787\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8557 - acc: 0.3627 - val_loss: 0.9044 - val_acc: 0.2787\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8556 - acc: 0.3627 - val_loss: 0.9043 - val_acc: 0.2787\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8555 - acc: 0.3627 - val_loss: 0.9042 - val_acc: 0.2787\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8554 - acc: 0.3627 - val_loss: 0.9041 - val_acc: 0.2787\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8554 - acc: 0.3627 - val_loss: 0.9039 - val_acc: 0.2787\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8553 - acc: 0.3627 - val_loss: 0.9038 - val_acc: 0.2787\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8552 - acc: 0.3627 - val_loss: 0.9037 - val_acc: 0.2787\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8551 - acc: 0.3627 - val_loss: 0.9036 - val_acc: 0.2787\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8550 - acc: 0.3627 - val_loss: 0.9035 - val_acc: 0.2787\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8549 - acc: 0.3627 - val_loss: 0.9034 - val_acc: 0.2787\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7448 - acc: 0.5103 - val_loss: 0.6899 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7447 - acc: 0.5103 - val_loss: 0.6898 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7446 - acc: 0.5103 - val_loss: 0.6897 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7445 - acc: 0.5103 - val_loss: 0.6896 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7444 - acc: 0.5103 - val_loss: 0.6895 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7443 - acc: 0.5103 - val_loss: 0.6894 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7442 - acc: 0.5103 - val_loss: 0.6893 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7441 - acc: 0.5103 - val_loss: 0.6892 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7441 - acc: 0.5103 - val_loss: 0.6892 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7440 - acc: 0.5103 - val_loss: 0.6891 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7439 - acc: 0.5103 - val_loss: 0.6890 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7438 - acc: 0.5103 - val_loss: 0.6889 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7437 - acc: 0.5103 - val_loss: 0.6888 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7436 - acc: 0.5103 - val_loss: 0.6887 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7435 - acc: 0.5103 - val_loss: 0.6886 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7434 - acc: 0.5103 - val_loss: 0.6885 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7433 - acc: 0.5103 - val_loss: 0.6884 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7433 - acc: 0.5103 - val_loss: 0.6883 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7432 - acc: 0.5103 - val_loss: 0.6882 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7431 - acc: 0.5103 - val_loss: 0.6881 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6103 - acc: 0.6804 - val_loss: 0.6048 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6102 - acc: 0.6804 - val_loss: 0.6047 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6101 - acc: 0.6804 - val_loss: 0.6047 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6100 - acc: 0.6804 - val_loss: 0.6046 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6099 - acc: 0.6804 - val_loss: 0.6045 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6099 - acc: 0.6804 - val_loss: 0.6044 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6098 - acc: 0.6804 - val_loss: 0.6043 - val_acc: 0.6393\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6097 - acc: 0.6804 - val_loss: 0.6042 - val_acc: 0.6393\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6097 - acc: 0.6804 - val_loss: 0.6042 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6096 - acc: 0.6804 - val_loss: 0.6041 - val_acc: 0.6393\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6095 - acc: 0.6804 - val_loss: 0.6040 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6094 - acc: 0.6804 - val_loss: 0.6039 - val_acc: 0.6393\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6094 - acc: 0.6804 - val_loss: 0.6038 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6093 - acc: 0.6804 - val_loss: 0.6037 - val_acc: 0.6393\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6092 - acc: 0.6804 - val_loss: 0.6036 - val_acc: 0.6393\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6092 - acc: 0.6804 - val_loss: 0.6036 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6091 - acc: 0.6804 - val_loss: 0.6035 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6090 - acc: 0.6804 - val_loss: 0.6034 - val_acc: 0.6393\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6089 - acc: 0.6804 - val_loss: 0.6033 - val_acc: 0.6393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6088 - acc: 0.6804 - val_loss: 0.6032 - val_acc: 0.6393\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6749 - acc: 0.5722 - val_loss: 0.6453 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6748 - acc: 0.5722 - val_loss: 0.6453 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6747 - acc: 0.5722 - val_loss: 0.6452 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6747 - acc: 0.5722 - val_loss: 0.6451 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6746 - acc: 0.5722 - val_loss: 0.6450 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6745 - acc: 0.5722 - val_loss: 0.6450 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6745 - acc: 0.5722 - val_loss: 0.6449 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6744 - acc: 0.5722 - val_loss: 0.6448 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6743 - acc: 0.5722 - val_loss: 0.6448 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6743 - acc: 0.5722 - val_loss: 0.6447 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6742 - acc: 0.5722 - val_loss: 0.6446 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6741 - acc: 0.5722 - val_loss: 0.6445 - val_acc: 0.6393\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6741 - acc: 0.5722 - val_loss: 0.6445 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6740 - acc: 0.5722 - val_loss: 0.6444 - val_acc: 0.6393\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6739 - acc: 0.5722 - val_loss: 0.6443 - val_acc: 0.6393\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6739 - acc: 0.5722 - val_loss: 0.6443 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6738 - acc: 0.5722 - val_loss: 0.6442 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6738 - acc: 0.5722 - val_loss: 0.6441 - val_acc: 0.6393\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6737 - acc: 0.5722 - val_loss: 0.6441 - val_acc: 0.6393\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6736 - acc: 0.5722 - val_loss: 0.6440 - val_acc: 0.6393\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7160 - acc: 0.4974 - val_loss: 0.7045 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7159 - acc: 0.4974 - val_loss: 0.7044 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7158 - acc: 0.4974 - val_loss: 0.7043 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7157 - acc: 0.4974 - val_loss: 0.7042 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7156 - acc: 0.4974 - val_loss: 0.7041 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7154 - acc: 0.4974 - val_loss: 0.7040 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7153 - acc: 0.4974 - val_loss: 0.7038 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7152 - acc: 0.4974 - val_loss: 0.7037 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7151 - acc: 0.4974 - val_loss: 0.7036 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7150 - acc: 0.4974 - val_loss: 0.7035 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7149 - acc: 0.4974 - val_loss: 0.7034 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7147 - acc: 0.4974 - val_loss: 0.7033 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7146 - acc: 0.4974 - val_loss: 0.7031 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7145 - acc: 0.4974 - val_loss: 0.7030 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7144 - acc: 0.4974 - val_loss: 0.7029 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7143 - acc: 0.4974 - val_loss: 0.7028 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7142 - acc: 0.4974 - val_loss: 0.7027 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7141 - acc: 0.4974 - val_loss: 0.7026 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7140 - acc: 0.4974 - val_loss: 0.7025 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7139 - acc: 0.4974 - val_loss: 0.7025 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7794 - acc: 0.3886 - val_loss: 0.8409 - val_acc: 0.2951\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7792 - acc: 0.3938 - val_loss: 0.8407 - val_acc: 0.2951\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7791 - acc: 0.3938 - val_loss: 0.8405 - val_acc: 0.2951\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7789 - acc: 0.3938 - val_loss: 0.8404 - val_acc: 0.2951\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7788 - acc: 0.3938 - val_loss: 0.8402 - val_acc: 0.2951\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7787 - acc: 0.3938 - val_loss: 0.8400 - val_acc: 0.2951\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7785 - acc: 0.3938 - val_loss: 0.8399 - val_acc: 0.2951\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7784 - acc: 0.3938 - val_loss: 0.8397 - val_acc: 0.2951\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7783 - acc: 0.3938 - val_loss: 0.8396 - val_acc: 0.2951\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7782 - acc: 0.3938 - val_loss: 0.8394 - val_acc: 0.2951\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7780 - acc: 0.3938 - val_loss: 0.8392 - val_acc: 0.2951\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7779 - acc: 0.3938 - val_loss: 0.8391 - val_acc: 0.2951\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7778 - acc: 0.3938 - val_loss: 0.8389 - val_acc: 0.2951\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7777 - acc: 0.3938 - val_loss: 0.8387 - val_acc: 0.2951\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7775 - acc: 0.3938 - val_loss: 0.8386 - val_acc: 0.2951\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7774 - acc: 0.3938 - val_loss: 0.8384 - val_acc: 0.2951\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7773 - acc: 0.3938 - val_loss: 0.8383 - val_acc: 0.2951\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7772 - acc: 0.3938 - val_loss: 0.8381 - val_acc: 0.2951\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7770 - acc: 0.3938 - val_loss: 0.8379 - val_acc: 0.2951\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7769 - acc: 0.3938 - val_loss: 0.8378 - val_acc: 0.2951\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7971 - acc: 0.4175 - val_loss: 0.7663 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7969 - acc: 0.4175 - val_loss: 0.7661 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7968 - acc: 0.4175 - val_loss: 0.7659 - val_acc: 0.4098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7966 - acc: 0.4175 - val_loss: 0.7658 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7964 - acc: 0.4175 - val_loss: 0.7656 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7963 - acc: 0.4175 - val_loss: 0.7654 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7961 - acc: 0.4175 - val_loss: 0.7653 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7959 - acc: 0.4175 - val_loss: 0.7651 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7958 - acc: 0.4175 - val_loss: 0.7649 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7956 - acc: 0.4175 - val_loss: 0.7648 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7954 - acc: 0.4175 - val_loss: 0.7646 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7953 - acc: 0.4175 - val_loss: 0.7644 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7951 - acc: 0.4227 - val_loss: 0.7642 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7949 - acc: 0.4227 - val_loss: 0.7641 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7948 - acc: 0.4227 - val_loss: 0.7639 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7946 - acc: 0.4278 - val_loss: 0.7637 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7944 - acc: 0.4278 - val_loss: 0.7636 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7942 - acc: 0.4278 - val_loss: 0.7634 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7941 - acc: 0.4278 - val_loss: 0.7632 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7939 - acc: 0.4278 - val_loss: 0.7631 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7596 - acc: 0.4639 - val_loss: 0.7489 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7595 - acc: 0.4639 - val_loss: 0.7487 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7593 - acc: 0.4639 - val_loss: 0.7485 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7592 - acc: 0.4639 - val_loss: 0.7484 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7590 - acc: 0.4639 - val_loss: 0.7482 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7589 - acc: 0.4639 - val_loss: 0.7481 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7587 - acc: 0.4639 - val_loss: 0.7479 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7586 - acc: 0.4639 - val_loss: 0.7477 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7585 - acc: 0.4639 - val_loss: 0.7476 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7583 - acc: 0.4639 - val_loss: 0.7474 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7582 - acc: 0.4639 - val_loss: 0.7473 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7581 - acc: 0.4639 - val_loss: 0.7471 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7579 - acc: 0.4639 - val_loss: 0.7470 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7578 - acc: 0.4639 - val_loss: 0.7468 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7577 - acc: 0.4639 - val_loss: 0.7467 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7575 - acc: 0.4639 - val_loss: 0.7465 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7574 - acc: 0.4639 - val_loss: 0.7464 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7573 - acc: 0.4639 - val_loss: 0.7462 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7571 - acc: 0.4639 - val_loss: 0.7461 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7570 - acc: 0.4639 - val_loss: 0.7459 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7681 - acc: 0.4330 - val_loss: 0.7990 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7679 - acc: 0.4330 - val_loss: 0.7988 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7678 - acc: 0.4330 - val_loss: 0.7987 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7676 - acc: 0.4330 - val_loss: 0.7985 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7675 - acc: 0.4330 - val_loss: 0.7983 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7674 - acc: 0.4330 - val_loss: 0.7982 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7673 - acc: 0.4330 - val_loss: 0.7981 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7671 - acc: 0.4330 - val_loss: 0.7979 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7670 - acc: 0.4330 - val_loss: 0.7977 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7669 - acc: 0.4330 - val_loss: 0.7976 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7667 - acc: 0.4330 - val_loss: 0.7975 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7666 - acc: 0.4330 - val_loss: 0.7973 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7665 - acc: 0.4330 - val_loss: 0.7972 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7664 - acc: 0.4330 - val_loss: 0.7970 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7662 - acc: 0.4330 - val_loss: 0.7969 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7661 - acc: 0.4330 - val_loss: 0.7967 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7660 - acc: 0.4330 - val_loss: 0.7966 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7659 - acc: 0.4330 - val_loss: 0.7964 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7657 - acc: 0.4330 - val_loss: 0.7963 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7656 - acc: 0.4330 - val_loss: 0.7961 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7473 - acc: 0.3627 - val_loss: 0.6831 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7470 - acc: 0.3627 - val_loss: 0.6829 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7468 - acc: 0.3627 - val_loss: 0.6827 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7466 - acc: 0.3627 - val_loss: 0.6825 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7464 - acc: 0.3627 - val_loss: 0.6824 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7463 - acc: 0.3627 - val_loss: 0.6822 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7461 - acc: 0.3627 - val_loss: 0.6820 - val_acc: 0.5574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7459 - acc: 0.3627 - val_loss: 0.6819 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7457 - acc: 0.3627 - val_loss: 0.6817 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7456 - acc: 0.3679 - val_loss: 0.6816 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7455 - acc: 0.3679 - val_loss: 0.6814 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7453 - acc: 0.3679 - val_loss: 0.6813 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7451 - acc: 0.3679 - val_loss: 0.6811 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7449 - acc: 0.3679 - val_loss: 0.6809 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7448 - acc: 0.3679 - val_loss: 0.6808 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7446 - acc: 0.3679 - val_loss: 0.6806 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7444 - acc: 0.3679 - val_loss: 0.6804 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7442 - acc: 0.3679 - val_loss: 0.6802 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7440 - acc: 0.3679 - val_loss: 0.6801 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7439 - acc: 0.3679 - val_loss: 0.6799 - val_acc: 0.5902\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7410 - acc: 0.3834 - val_loss: 0.7572 - val_acc: 0.3443\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7407 - acc: 0.3834 - val_loss: 0.7570 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7405 - acc: 0.3834 - val_loss: 0.7568 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7403 - acc: 0.3834 - val_loss: 0.7566 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7402 - acc: 0.3834 - val_loss: 0.7564 - val_acc: 0.3607\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7400 - acc: 0.3834 - val_loss: 0.7561 - val_acc: 0.3607\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7398 - acc: 0.3834 - val_loss: 0.7559 - val_acc: 0.3770\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.7607 - acc: 0.375 - 0s 2ms/step - loss: 0.7396 - acc: 0.3886 - val_loss: 0.7558 - val_acc: 0.3770\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7395 - acc: 0.3886 - val_loss: 0.7556 - val_acc: 0.3770\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7393 - acc: 0.3938 - val_loss: 0.7554 - val_acc: 0.3770\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7391 - acc: 0.3938 - val_loss: 0.7552 - val_acc: 0.3770\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7389 - acc: 0.3938 - val_loss: 0.7550 - val_acc: 0.3770\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7388 - acc: 0.3938 - val_loss: 0.7548 - val_acc: 0.3607\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7386 - acc: 0.3938 - val_loss: 0.7546 - val_acc: 0.3607\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7384 - acc: 0.3938 - val_loss: 0.7544 - val_acc: 0.3607\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7383 - acc: 0.3938 - val_loss: 0.7542 - val_acc: 0.3770\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7381 - acc: 0.3938 - val_loss: 0.7540 - val_acc: 0.3770\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7380 - acc: 0.4041 - val_loss: 0.7539 - val_acc: 0.3770\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7378 - acc: 0.4041 - val_loss: 0.7537 - val_acc: 0.3770\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7377 - acc: 0.4041 - val_loss: 0.7535 - val_acc: 0.3770\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6942 - acc: 0.5619 - val_loss: 0.7193 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6939 - acc: 0.5619 - val_loss: 0.7191 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6937 - acc: 0.5619 - val_loss: 0.7189 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6936 - acc: 0.5619 - val_loss: 0.7187 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6934 - acc: 0.5619 - val_loss: 0.7185 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.5619 - val_loss: 0.7182 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6930 - acc: 0.5619 - val_loss: 0.7180 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6928 - acc: 0.5619 - val_loss: 0.7178 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6926 - acc: 0.5619 - val_loss: 0.7175 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6924 - acc: 0.5619 - val_loss: 0.7173 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6922 - acc: 0.5619 - val_loss: 0.7171 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.5619 - val_loss: 0.7169 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6918 - acc: 0.5619 - val_loss: 0.7167 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6916 - acc: 0.5619 - val_loss: 0.7165 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6915 - acc: 0.5619 - val_loss: 0.7163 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6913 - acc: 0.5619 - val_loss: 0.7161 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6911 - acc: 0.5619 - val_loss: 0.7159 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6909 - acc: 0.5619 - val_loss: 0.7157 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6907 - acc: 0.5619 - val_loss: 0.7155 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6906 - acc: 0.5619 - val_loss: 0.7153 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7057 - acc: 0.5670 - val_loss: 0.7760 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7055 - acc: 0.5670 - val_loss: 0.7758 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7053 - acc: 0.5670 - val_loss: 0.7755 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7051 - acc: 0.5670 - val_loss: 0.7752 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7049 - acc: 0.5670 - val_loss: 0.7750 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7047 - acc: 0.5670 - val_loss: 0.7748 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7046 - acc: 0.5670 - val_loss: 0.7745 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7044 - acc: 0.5670 - val_loss: 0.7743 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7042 - acc: 0.5670 - val_loss: 0.7741 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7040 - acc: 0.5670 - val_loss: 0.7738 - val_acc: 0.5246\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7039 - acc: 0.5670 - val_loss: 0.7736 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7037 - acc: 0.5670 - val_loss: 0.7734 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7035 - acc: 0.5670 - val_loss: 0.7731 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7034 - acc: 0.5670 - val_loss: 0.7729 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7032 - acc: 0.5670 - val_loss: 0.7727 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7030 - acc: 0.5670 - val_loss: 0.7724 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7028 - acc: 0.5670 - val_loss: 0.7722 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7026 - acc: 0.5670 - val_loss: 0.7719 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7024 - acc: 0.5670 - val_loss: 0.7717 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7023 - acc: 0.5670 - val_loss: 0.7714 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6701 - acc: 0.6546 - val_loss: 0.7110 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6699 - acc: 0.6546 - val_loss: 0.7107 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6697 - acc: 0.6546 - val_loss: 0.7106 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6696 - acc: 0.6546 - val_loss: 0.7104 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6694 - acc: 0.6546 - val_loss: 0.7102 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6692 - acc: 0.6546 - val_loss: 0.7100 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6691 - acc: 0.6546 - val_loss: 0.7098 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6689 - acc: 0.6546 - val_loss: 0.7096 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6687 - acc: 0.6546 - val_loss: 0.7094 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6686 - acc: 0.6546 - val_loss: 0.7092 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6684 - acc: 0.6546 - val_loss: 0.7090 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6683 - acc: 0.6546 - val_loss: 0.7088 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6681 - acc: 0.6546 - val_loss: 0.7086 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6679 - acc: 0.6546 - val_loss: 0.7084 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6678 - acc: 0.6546 - val_loss: 0.7082 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6676 - acc: 0.6546 - val_loss: 0.7080 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6674 - acc: 0.6546 - val_loss: 0.7077 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6672 - acc: 0.6546 - val_loss: 0.7075 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6671 - acc: 0.6546 - val_loss: 0.7073 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6669 - acc: 0.6546 - val_loss: 0.7071 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6354 - acc: 0.7306 - val_loss: 0.6373 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6351 - acc: 0.7306 - val_loss: 0.6371 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6349 - acc: 0.7306 - val_loss: 0.6368 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6347 - acc: 0.7358 - val_loss: 0.6366 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6344 - acc: 0.7358 - val_loss: 0.6363 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6342 - acc: 0.7358 - val_loss: 0.6361 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6340 - acc: 0.7358 - val_loss: 0.6359 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6338 - acc: 0.7409 - val_loss: 0.6356 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6336 - acc: 0.7461 - val_loss: 0.6354 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6334 - acc: 0.7461 - val_loss: 0.6352 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6332 - acc: 0.7461 - val_loss: 0.6350 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6330 - acc: 0.7461 - val_loss: 0.6347 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6328 - acc: 0.7461 - val_loss: 0.6345 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6326 - acc: 0.7461 - val_loss: 0.6343 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6324 - acc: 0.7461 - val_loss: 0.6341 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6322 - acc: 0.7461 - val_loss: 0.6339 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6320 - acc: 0.7461 - val_loss: 0.6337 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6318 - acc: 0.7461 - val_loss: 0.6334 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6316 - acc: 0.7461 - val_loss: 0.6332 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6314 - acc: 0.7461 - val_loss: 0.6330 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7156 - acc: 0.5285 - val_loss: 0.7423 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7153 - acc: 0.5285 - val_loss: 0.7420 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7150 - acc: 0.5285 - val_loss: 0.7417 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7148 - acc: 0.5285 - val_loss: 0.7414 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7145 - acc: 0.5285 - val_loss: 0.7411 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7143 - acc: 0.5285 - val_loss: 0.7408 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7140 - acc: 0.5285 - val_loss: 0.7406 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7138 - acc: 0.5285 - val_loss: 0.7403 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7136 - acc: 0.5285 - val_loss: 0.7401 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7134 - acc: 0.5337 - val_loss: 0.7398 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7132 - acc: 0.5337 - val_loss: 0.7396 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7130 - acc: 0.5337 - val_loss: 0.7394 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7128 - acc: 0.5337 - val_loss: 0.7392 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7127 - acc: 0.5337 - val_loss: 0.7389 - val_acc: 0.4098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7125 - acc: 0.5337 - val_loss: 0.7387 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7123 - acc: 0.5337 - val_loss: 0.7385 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7121 - acc: 0.5337 - val_loss: 0.7382 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7119 - acc: 0.5337 - val_loss: 0.7380 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7116 - acc: 0.5337 - val_loss: 0.7377 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7114 - acc: 0.5337 - val_loss: 0.7375 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6479 - acc: 0.6649 - val_loss: 0.6210 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6476 - acc: 0.6649 - val_loss: 0.6207 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6473 - acc: 0.6649 - val_loss: 0.6204 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6471 - acc: 0.6753 - val_loss: 0.6201 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6468 - acc: 0.6753 - val_loss: 0.6198 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6465 - acc: 0.6753 - val_loss: 0.6196 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6463 - acc: 0.6753 - val_loss: 0.6193 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6461 - acc: 0.6753 - val_loss: 0.6191 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6458 - acc: 0.6753 - val_loss: 0.6189 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6456 - acc: 0.6753 - val_loss: 0.6186 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6454 - acc: 0.6753 - val_loss: 0.6184 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6451 - acc: 0.6753 - val_loss: 0.6181 - val_acc: 0.7377\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6449 - acc: 0.6753 - val_loss: 0.6179 - val_acc: 0.7377\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6447 - acc: 0.6753 - val_loss: 0.6177 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6445 - acc: 0.6804 - val_loss: 0.6174 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6442 - acc: 0.6804 - val_loss: 0.6172 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6440 - acc: 0.6804 - val_loss: 0.6169 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6437 - acc: 0.6804 - val_loss: 0.6167 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6435 - acc: 0.6856 - val_loss: 0.6164 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6433 - acc: 0.6856 - val_loss: 0.6162 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6963 - acc: 0.5412 - val_loss: 0.6909 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6960 - acc: 0.5412 - val_loss: 0.6906 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6957 - acc: 0.5361 - val_loss: 0.6903 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6954 - acc: 0.5361 - val_loss: 0.6900 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6952 - acc: 0.5361 - val_loss: 0.6897 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6949 - acc: 0.5361 - val_loss: 0.6894 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6946 - acc: 0.5361 - val_loss: 0.6891 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6944 - acc: 0.5361 - val_loss: 0.6888 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6942 - acc: 0.5361 - val_loss: 0.6886 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6939 - acc: 0.5412 - val_loss: 0.6883 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6937 - acc: 0.5412 - val_loss: 0.6880 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6934 - acc: 0.5412 - val_loss: 0.6877 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.5464 - val_loss: 0.6874 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6929 - acc: 0.5464 - val_loss: 0.6871 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6927 - acc: 0.5515 - val_loss: 0.6869 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6924 - acc: 0.5515 - val_loss: 0.6866 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6922 - acc: 0.5515 - val_loss: 0.6863 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6919 - acc: 0.5515 - val_loss: 0.6861 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6917 - acc: 0.5515 - val_loss: 0.6858 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6914 - acc: 0.5515 - val_loss: 0.6855 - val_acc: 0.5574\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7254 - acc: 0.4124 - val_loss: 0.7081 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7251 - acc: 0.4124 - val_loss: 0.7078 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7248 - acc: 0.4175 - val_loss: 0.7074 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7245 - acc: 0.4175 - val_loss: 0.7071 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7242 - acc: 0.4175 - val_loss: 0.7069 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7240 - acc: 0.4175 - val_loss: 0.7066 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7237 - acc: 0.4175 - val_loss: 0.7063 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7234 - acc: 0.4175 - val_loss: 0.7059 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7231 - acc: 0.4175 - val_loss: 0.7056 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7228 - acc: 0.4175 - val_loss: 0.7054 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7226 - acc: 0.4227 - val_loss: 0.7051 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7223 - acc: 0.4227 - val_loss: 0.7048 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7220 - acc: 0.4227 - val_loss: 0.7045 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7218 - acc: 0.4227 - val_loss: 0.7042 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7215 - acc: 0.4227 - val_loss: 0.7039 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7212 - acc: 0.4227 - val_loss: 0.7036 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7209 - acc: 0.4227 - val_loss: 0.7033 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7207 - acc: 0.4227 - val_loss: 0.7030 - val_acc: 0.4918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7204 - acc: 0.4278 - val_loss: 0.7027 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7201 - acc: 0.4278 - val_loss: 0.7024 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6091 - acc: 0.6632 - val_loss: 0.4922 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6062 - acc: 0.6632 - val_loss: 0.4899 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6038 - acc: 0.6632 - val_loss: 0.4879 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6018 - acc: 0.6684 - val_loss: 0.4861 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5997 - acc: 0.6684 - val_loss: 0.4844 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5976 - acc: 0.6684 - val_loss: 0.4827 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5957 - acc: 0.6788 - val_loss: 0.4810 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5940 - acc: 0.6788 - val_loss: 0.4796 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5925 - acc: 0.6788 - val_loss: 0.4782 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5908 - acc: 0.6839 - val_loss: 0.4765 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5889 - acc: 0.6891 - val_loss: 0.4749 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5870 - acc: 0.6891 - val_loss: 0.4731 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5851 - acc: 0.6891 - val_loss: 0.4715 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5832 - acc: 0.6943 - val_loss: 0.4701 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5813 - acc: 0.6943 - val_loss: 0.4684 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5796 - acc: 0.6943 - val_loss: 0.4670 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5779 - acc: 0.6943 - val_loss: 0.4654 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5760 - acc: 0.6943 - val_loss: 0.4639 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5743 - acc: 0.6943 - val_loss: 0.4623 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5726 - acc: 0.6943 - val_loss: 0.4609 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7599 - acc: 0.6166 - val_loss: 0.7044 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7571 - acc: 0.6166 - val_loss: 0.7023 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7548 - acc: 0.6166 - val_loss: 0.7003 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7527 - acc: 0.6166 - val_loss: 0.6985 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7507 - acc: 0.6218 - val_loss: 0.6968 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7489 - acc: 0.6218 - val_loss: 0.6952 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7470 - acc: 0.6218 - val_loss: 0.6936 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7454 - acc: 0.6218 - val_loss: 0.6918 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7436 - acc: 0.6269 - val_loss: 0.6902 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7418 - acc: 0.6269 - val_loss: 0.6887 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7401 - acc: 0.6269 - val_loss: 0.6871 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7383 - acc: 0.6321 - val_loss: 0.6858 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7367 - acc: 0.6321 - val_loss: 0.6842 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7349 - acc: 0.6321 - val_loss: 0.6827 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7333 - acc: 0.6321 - val_loss: 0.6812 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7317 - acc: 0.6321 - val_loss: 0.6796 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7300 - acc: 0.6321 - val_loss: 0.6779 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7284 - acc: 0.6321 - val_loss: 0.6763 - val_acc: 0.6066\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7268 - acc: 0.6321 - val_loss: 0.6748 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7253 - acc: 0.6321 - val_loss: 0.6733 - val_acc: 0.6066\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5912 - acc: 0.7371 - val_loss: 0.6913 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5892 - acc: 0.7371 - val_loss: 0.6894 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5879 - acc: 0.7371 - val_loss: 0.6883 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5868 - acc: 0.7423 - val_loss: 0.6869 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5855 - acc: 0.7423 - val_loss: 0.6854 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5842 - acc: 0.7423 - val_loss: 0.6838 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5827 - acc: 0.7423 - val_loss: 0.6823 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5814 - acc: 0.7423 - val_loss: 0.6808 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5802 - acc: 0.7423 - val_loss: 0.6793 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5788 - acc: 0.7423 - val_loss: 0.6778 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5775 - acc: 0.7423 - val_loss: 0.6763 - val_acc: 0.7213\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5762 - acc: 0.7423 - val_loss: 0.6748 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5748 - acc: 0.7423 - val_loss: 0.6731 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5734 - acc: 0.7423 - val_loss: 0.6716 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5721 - acc: 0.7423 - val_loss: 0.6702 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5708 - acc: 0.7423 - val_loss: 0.6688 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5694 - acc: 0.7423 - val_loss: 0.6674 - val_acc: 0.7213\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5681 - acc: 0.7423 - val_loss: 0.6660 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5670 - acc: 0.7423 - val_loss: 0.6646 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5658 - acc: 0.7423 - val_loss: 0.6635 - val_acc: 0.7213\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6926 - acc: 0.5825 - val_loss: 0.7708 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6897 - acc: 0.5928 - val_loss: 0.7672 - val_acc: 0.5574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6870 - acc: 0.6134 - val_loss: 0.7641 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6846 - acc: 0.6186 - val_loss: 0.7611 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6823 - acc: 0.6186 - val_loss: 0.7580 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6799 - acc: 0.6186 - val_loss: 0.7550 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6776 - acc: 0.6186 - val_loss: 0.7516 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6749 - acc: 0.6237 - val_loss: 0.7483 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6726 - acc: 0.6237 - val_loss: 0.7449 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6699 - acc: 0.6289 - val_loss: 0.7420 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6676 - acc: 0.6289 - val_loss: 0.7393 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6656 - acc: 0.6289 - val_loss: 0.7362 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6632 - acc: 0.6289 - val_loss: 0.7332 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6610 - acc: 0.6289 - val_loss: 0.7305 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6590 - acc: 0.6289 - val_loss: 0.7281 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6571 - acc: 0.6289 - val_loss: 0.7258 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6551 - acc: 0.6340 - val_loss: 0.7229 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6528 - acc: 0.6392 - val_loss: 0.7200 - val_acc: 0.6066\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6505 - acc: 0.6443 - val_loss: 0.7172 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6485 - acc: 0.6495 - val_loss: 0.7145 - val_acc: 0.6066\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9122 - acc: 0.4897 - val_loss: 1.0398 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9083 - acc: 0.4897 - val_loss: 1.0345 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9051 - acc: 0.4897 - val_loss: 1.0297 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9019 - acc: 0.4897 - val_loss: 1.0249 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8987 - acc: 0.4948 - val_loss: 1.0202 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8955 - acc: 0.4948 - val_loss: 1.0154 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8925 - acc: 0.5000 - val_loss: 1.0112 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8895 - acc: 0.5000 - val_loss: 1.0067 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8868 - acc: 0.5000 - val_loss: 1.0023 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8836 - acc: 0.5000 - val_loss: 0.9979 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8806 - acc: 0.5052 - val_loss: 0.9926 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8773 - acc: 0.5052 - val_loss: 0.9880 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8744 - acc: 0.5052 - val_loss: 0.9837 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8715 - acc: 0.5103 - val_loss: 0.9796 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8688 - acc: 0.5103 - val_loss: 0.9753 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8659 - acc: 0.5155 - val_loss: 0.9710 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8632 - acc: 0.5155 - val_loss: 0.9668 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8602 - acc: 0.5155 - val_loss: 0.9623 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8574 - acc: 0.5155 - val_loss: 0.9583 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8546 - acc: 0.5206 - val_loss: 0.9540 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7088 - acc: 0.5855 - val_loss: 0.6973 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7043 - acc: 0.5855 - val_loss: 0.6930 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7004 - acc: 0.5907 - val_loss: 0.6890 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6967 - acc: 0.5959 - val_loss: 0.6852 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6933 - acc: 0.6010 - val_loss: 0.6815 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6898 - acc: 0.6062 - val_loss: 0.6778 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6863 - acc: 0.6062 - val_loss: 0.6740 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6828 - acc: 0.6114 - val_loss: 0.6706 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6796 - acc: 0.6114 - val_loss: 0.6673 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6766 - acc: 0.6114 - val_loss: 0.6639 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6735 - acc: 0.6114 - val_loss: 0.6609 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6706 - acc: 0.6114 - val_loss: 0.6581 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6678 - acc: 0.6114 - val_loss: 0.6551 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6648 - acc: 0.6114 - val_loss: 0.6522 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6620 - acc: 0.6114 - val_loss: 0.6489 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6591 - acc: 0.6114 - val_loss: 0.6458 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6564 - acc: 0.6166 - val_loss: 0.6428 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6539 - acc: 0.6166 - val_loss: 0.6405 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6517 - acc: 0.6166 - val_loss: 0.6381 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6492 - acc: 0.6269 - val_loss: 0.6354 - val_acc: 0.6230\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9112 - acc: 0.3834 - val_loss: 0.9164 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9072 - acc: 0.3834 - val_loss: 0.9128 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9035 - acc: 0.3834 - val_loss: 0.9093 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9001 - acc: 0.3834 - val_loss: 0.9057 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8968 - acc: 0.3834 - val_loss: 0.9021 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8934 - acc: 0.3834 - val_loss: 0.8989 - val_acc: 0.4754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8902 - acc: 0.3834 - val_loss: 0.8957 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8872 - acc: 0.3834 - val_loss: 0.8926 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8839 - acc: 0.3834 - val_loss: 0.8891 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8806 - acc: 0.3834 - val_loss: 0.8857 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8774 - acc: 0.3990 - val_loss: 0.8823 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8741 - acc: 0.4041 - val_loss: 0.8789 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8711 - acc: 0.4093 - val_loss: 0.8757 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8683 - acc: 0.4093 - val_loss: 0.8728 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8655 - acc: 0.4093 - val_loss: 0.8701 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8630 - acc: 0.4093 - val_loss: 0.8674 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8607 - acc: 0.4093 - val_loss: 0.8649 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8582 - acc: 0.4093 - val_loss: 0.8623 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8556 - acc: 0.4093 - val_loss: 0.8594 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8530 - acc: 0.4093 - val_loss: 0.8570 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0394 - acc: 0.4588 - val_loss: 0.9644 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0326 - acc: 0.4588 - val_loss: 0.9590 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0261 - acc: 0.4588 - val_loss: 0.9539 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0200 - acc: 0.4588 - val_loss: 0.9487 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0139 - acc: 0.4588 - val_loss: 0.9435 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0079 - acc: 0.4588 - val_loss: 0.9387 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0022 - acc: 0.4588 - val_loss: 0.9338 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9967 - acc: 0.4588 - val_loss: 0.9289 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9908 - acc: 0.4588 - val_loss: 0.9244 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9854 - acc: 0.4588 - val_loss: 0.9197 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9797 - acc: 0.4588 - val_loss: 0.9146 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9738 - acc: 0.4588 - val_loss: 0.9099 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9684 - acc: 0.4588 - val_loss: 0.9051 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9628 - acc: 0.4588 - val_loss: 0.9000 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9569 - acc: 0.4588 - val_loss: 0.8949 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9513 - acc: 0.4639 - val_loss: 0.8900 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9457 - acc: 0.4639 - val_loss: 0.8856 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9406 - acc: 0.4691 - val_loss: 0.8809 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9351 - acc: 0.4691 - val_loss: 0.8760 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9293 - acc: 0.4691 - val_loss: 0.8710 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9161 - acc: 0.3144 - val_loss: 0.9504 - val_acc: 0.2951\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9099 - acc: 0.3196 - val_loss: 0.9435 - val_acc: 0.3115\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9042 - acc: 0.3247 - val_loss: 0.9371 - val_acc: 0.3115\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8985 - acc: 0.3299 - val_loss: 0.9312 - val_acc: 0.3115\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8936 - acc: 0.3351 - val_loss: 0.9253 - val_acc: 0.3115\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8882 - acc: 0.3351 - val_loss: 0.9192 - val_acc: 0.3115\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8830 - acc: 0.3351 - val_loss: 0.9132 - val_acc: 0.3115\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8779 - acc: 0.3402 - val_loss: 0.9071 - val_acc: 0.3115\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8729 - acc: 0.3402 - val_loss: 0.9015 - val_acc: 0.3115\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8683 - acc: 0.3402 - val_loss: 0.8960 - val_acc: 0.3115\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8637 - acc: 0.3402 - val_loss: 0.8901 - val_acc: 0.3279\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8585 - acc: 0.3505 - val_loss: 0.8843 - val_acc: 0.3443\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8538 - acc: 0.3608 - val_loss: 0.8790 - val_acc: 0.3443\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8493 - acc: 0.3608 - val_loss: 0.8735 - val_acc: 0.3443\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8446 - acc: 0.3711 - val_loss: 0.8680 - val_acc: 0.3443\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8401 - acc: 0.3711 - val_loss: 0.8623 - val_acc: 0.3607\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8356 - acc: 0.3711 - val_loss: 0.8568 - val_acc: 0.3770\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8314 - acc: 0.3763 - val_loss: 0.8516 - val_acc: 0.3770\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8271 - acc: 0.3763 - val_loss: 0.8463 - val_acc: 0.3770\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8227 - acc: 0.3763 - val_loss: 0.8415 - val_acc: 0.3770\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.8085 - acc: 0.4845 - val_loss: 0.8150 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8012 - acc: 0.5000 - val_loss: 0.8085 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7950 - acc: 0.5052 - val_loss: 0.8019 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7888 - acc: 0.5052 - val_loss: 0.7959 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7830 - acc: 0.5103 - val_loss: 0.7901 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7775 - acc: 0.5155 - val_loss: 0.7847 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7723 - acc: 0.5206 - val_loss: 0.7795 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7670 - acc: 0.5309 - val_loss: 0.7747 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7622 - acc: 0.5361 - val_loss: 0.7698 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7572 - acc: 0.5412 - val_loss: 0.7650 - val_acc: 0.5574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7523 - acc: 0.5412 - val_loss: 0.7600 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7474 - acc: 0.5412 - val_loss: 0.7554 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7428 - acc: 0.5412 - val_loss: 0.7511 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7386 - acc: 0.5515 - val_loss: 0.7470 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7343 - acc: 0.5515 - val_loss: 0.7425 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7295 - acc: 0.5670 - val_loss: 0.7379 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7252 - acc: 0.5722 - val_loss: 0.7333 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7209 - acc: 0.5773 - val_loss: 0.7291 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7169 - acc: 0.5773 - val_loss: 0.7252 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7129 - acc: 0.5876 - val_loss: 0.7209 - val_acc: 0.5574\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7234 - acc: 0.5492 - val_loss: 0.7126 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7171 - acc: 0.5492 - val_loss: 0.7061 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7122 - acc: 0.5492 - val_loss: 0.7007 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7076 - acc: 0.5596 - val_loss: 0.6955 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7032 - acc: 0.5648 - val_loss: 0.6901 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6988 - acc: 0.5699 - val_loss: 0.6849 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6943 - acc: 0.5699 - val_loss: 0.6797 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6899 - acc: 0.5699 - val_loss: 0.6746 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6859 - acc: 0.5803 - val_loss: 0.6703 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6823 - acc: 0.5803 - val_loss: 0.6658 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6785 - acc: 0.5803 - val_loss: 0.6611 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6745 - acc: 0.5907 - val_loss: 0.6559 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6703 - acc: 0.5907 - val_loss: 0.6511 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6663 - acc: 0.5959 - val_loss: 0.6461 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6626 - acc: 0.6010 - val_loss: 0.6416 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6587 - acc: 0.6062 - val_loss: 0.6374 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6552 - acc: 0.6062 - val_loss: 0.6330 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6516 - acc: 0.6166 - val_loss: 0.6288 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6482 - acc: 0.6269 - val_loss: 0.6249 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6449 - acc: 0.6269 - val_loss: 0.6209 - val_acc: 0.6721\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6381 - acc: 0.6684 - val_loss: 0.6451 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6339 - acc: 0.6788 - val_loss: 0.6414 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6298 - acc: 0.6839 - val_loss: 0.6379 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6262 - acc: 0.6943 - val_loss: 0.6342 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6227 - acc: 0.6943 - val_loss: 0.6308 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6194 - acc: 0.6943 - val_loss: 0.6276 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6162 - acc: 0.6995 - val_loss: 0.6242 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6130 - acc: 0.7098 - val_loss: 0.6210 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6101 - acc: 0.7254 - val_loss: 0.6181 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6071 - acc: 0.7254 - val_loss: 0.6151 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6042 - acc: 0.7306 - val_loss: 0.6121 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6011 - acc: 0.7358 - val_loss: 0.6090 - val_acc: 0.7541\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5982 - acc: 0.7409 - val_loss: 0.6060 - val_acc: 0.7541\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5952 - acc: 0.7409 - val_loss: 0.6028 - val_acc: 0.7541\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5920 - acc: 0.7409 - val_loss: 0.5994 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5891 - acc: 0.7461 - val_loss: 0.5964 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5862 - acc: 0.7461 - val_loss: 0.5934 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5833 - acc: 0.7513 - val_loss: 0.5905 - val_acc: 0.7541\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5805 - acc: 0.7513 - val_loss: 0.5875 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5778 - acc: 0.7565 - val_loss: 0.5848 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7862 - acc: 0.4433 - val_loss: 0.7124 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7784 - acc: 0.4485 - val_loss: 0.7056 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7710 - acc: 0.4588 - val_loss: 0.6988 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7642 - acc: 0.4639 - val_loss: 0.6919 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7570 - acc: 0.4691 - val_loss: 0.6853 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7504 - acc: 0.4794 - val_loss: 0.6789 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7440 - acc: 0.4845 - val_loss: 0.6726 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7373 - acc: 0.4897 - val_loss: 0.6665 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7311 - acc: 0.4897 - val_loss: 0.6607 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7249 - acc: 0.5052 - val_loss: 0.6554 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7195 - acc: 0.5309 - val_loss: 0.6504 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7142 - acc: 0.5361 - val_loss: 0.6456 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7095 - acc: 0.5412 - val_loss: 0.6409 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7046 - acc: 0.5515 - val_loss: 0.6361 - val_acc: 0.6721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7000 - acc: 0.5619 - val_loss: 0.6315 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6954 - acc: 0.5670 - val_loss: 0.6268 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6905 - acc: 0.5773 - val_loss: 0.6220 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6853 - acc: 0.5825 - val_loss: 0.6172 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6801 - acc: 0.5979 - val_loss: 0.6124 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6751 - acc: 0.6082 - val_loss: 0.6076 - val_acc: 0.7049\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7405 - acc: 0.5412 - val_loss: 0.7692 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7322 - acc: 0.5515 - val_loss: 0.7592 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7246 - acc: 0.5567 - val_loss: 0.7500 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7175 - acc: 0.5567 - val_loss: 0.7417 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7109 - acc: 0.5619 - val_loss: 0.7342 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7048 - acc: 0.5773 - val_loss: 0.7263 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6989 - acc: 0.5876 - val_loss: 0.7182 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6925 - acc: 0.5928 - val_loss: 0.7108 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6868 - acc: 0.6031 - val_loss: 0.7038 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6813 - acc: 0.6082 - val_loss: 0.6971 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6760 - acc: 0.6082 - val_loss: 0.6910 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6712 - acc: 0.6134 - val_loss: 0.6850 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6663 - acc: 0.6237 - val_loss: 0.6792 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6617 - acc: 0.6443 - val_loss: 0.6732 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6564 - acc: 0.6443 - val_loss: 0.6668 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6513 - acc: 0.6598 - val_loss: 0.6604 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6463 - acc: 0.6598 - val_loss: 0.6546 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6415 - acc: 0.6598 - val_loss: 0.6489 - val_acc: 0.6393\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6368 - acc: 0.6649 - val_loss: 0.6428 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6321 - acc: 0.6649 - val_loss: 0.6369 - val_acc: 0.6721\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8690 - acc: 0.3763 - val_loss: 0.7939 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8611 - acc: 0.3814 - val_loss: 0.7878 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8544 - acc: 0.3814 - val_loss: 0.7822 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8477 - acc: 0.3814 - val_loss: 0.7764 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8412 - acc: 0.3866 - val_loss: 0.7701 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8344 - acc: 0.3918 - val_loss: 0.7640 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8277 - acc: 0.3969 - val_loss: 0.7582 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8214 - acc: 0.3969 - val_loss: 0.7529 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8159 - acc: 0.3969 - val_loss: 0.7477 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8101 - acc: 0.4021 - val_loss: 0.7426 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8043 - acc: 0.4124 - val_loss: 0.7374 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7984 - acc: 0.4175 - val_loss: 0.7321 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7921 - acc: 0.4278 - val_loss: 0.7270 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7863 - acc: 0.4278 - val_loss: 0.7220 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7806 - acc: 0.4278 - val_loss: 0.7169 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7751 - acc: 0.4278 - val_loss: 0.7121 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7697 - acc: 0.4278 - val_loss: 0.7074 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7642 - acc: 0.4330 - val_loss: 0.7025 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7590 - acc: 0.4536 - val_loss: 0.6976 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7533 - acc: 0.4536 - val_loss: 0.6928 - val_acc: 0.6066\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9292 - acc: 0.3316 - val_loss: 0.8678 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9133 - acc: 0.3368 - val_loss: 0.8541 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9006 - acc: 0.3420 - val_loss: 0.8420 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8888 - acc: 0.3420 - val_loss: 0.8299 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8772 - acc: 0.3420 - val_loss: 0.8189 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8659 - acc: 0.3523 - val_loss: 0.8074 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8548 - acc: 0.3627 - val_loss: 0.7959 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8430 - acc: 0.3679 - val_loss: 0.7842 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8322 - acc: 0.3731 - val_loss: 0.7739 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8224 - acc: 0.3782 - val_loss: 0.7646 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8131 - acc: 0.3782 - val_loss: 0.7556 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8035 - acc: 0.3782 - val_loss: 0.7461 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7937 - acc: 0.3782 - val_loss: 0.7366 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7837 - acc: 0.3834 - val_loss: 0.7277 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7744 - acc: 0.3886 - val_loss: 0.7201 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7662 - acc: 0.3834 - val_loss: 0.7126 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7575 - acc: 0.3990 - val_loss: 0.7041 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7489 - acc: 0.4197 - val_loss: 0.6958 - val_acc: 0.5246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7405 - acc: 0.4301 - val_loss: 0.6876 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7324 - acc: 0.4456 - val_loss: 0.6796 - val_acc: 0.5574\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8001 - acc: 0.4041 - val_loss: 0.7215 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7890 - acc: 0.4093 - val_loss: 0.7122 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7796 - acc: 0.4249 - val_loss: 0.7044 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7720 - acc: 0.4301 - val_loss: 0.6970 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7643 - acc: 0.4456 - val_loss: 0.6895 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7564 - acc: 0.4715 - val_loss: 0.6823 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7491 - acc: 0.4870 - val_loss: 0.6758 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7421 - acc: 0.5078 - val_loss: 0.6693 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7353 - acc: 0.5130 - val_loss: 0.6630 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7288 - acc: 0.5233 - val_loss: 0.6569 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7223 - acc: 0.5440 - val_loss: 0.6508 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7159 - acc: 0.5389 - val_loss: 0.6452 - val_acc: 0.6393\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7104 - acc: 0.5492 - val_loss: 0.6397 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7046 - acc: 0.5544 - val_loss: 0.6341 - val_acc: 0.6393\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6985 - acc: 0.5699 - val_loss: 0.6283 - val_acc: 0.6393\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6925 - acc: 0.5803 - val_loss: 0.6224 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6866 - acc: 0.5855 - val_loss: 0.6168 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6811 - acc: 0.5855 - val_loss: 0.6117 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6760 - acc: 0.5855 - val_loss: 0.6067 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6706 - acc: 0.6010 - val_loss: 0.6016 - val_acc: 0.6885\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6057 - acc: 0.7268 - val_loss: 0.6034 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5983 - acc: 0.7371 - val_loss: 0.5966 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5924 - acc: 0.7423 - val_loss: 0.5898 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5861 - acc: 0.7474 - val_loss: 0.5836 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5804 - acc: 0.7526 - val_loss: 0.5773 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5747 - acc: 0.7577 - val_loss: 0.5710 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5690 - acc: 0.7629 - val_loss: 0.5651 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5635 - acc: 0.7629 - val_loss: 0.5592 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5583 - acc: 0.7629 - val_loss: 0.5533 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5533 - acc: 0.7629 - val_loss: 0.5479 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5484 - acc: 0.7680 - val_loss: 0.5423 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5437 - acc: 0.7629 - val_loss: 0.5371 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5392 - acc: 0.7629 - val_loss: 0.5322 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5349 - acc: 0.7629 - val_loss: 0.5271 - val_acc: 0.7705\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5305 - acc: 0.7680 - val_loss: 0.5224 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5264 - acc: 0.7680 - val_loss: 0.5178 - val_acc: 0.7705\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5224 - acc: 0.7680 - val_loss: 0.5133 - val_acc: 0.7705\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5183 - acc: 0.7732 - val_loss: 0.5091 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5145 - acc: 0.7732 - val_loss: 0.5050 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5107 - acc: 0.7835 - val_loss: 0.5008 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7938 - acc: 0.4433 - val_loss: 0.7702 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7818 - acc: 0.4794 - val_loss: 0.7579 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7710 - acc: 0.4948 - val_loss: 0.7467 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7611 - acc: 0.4948 - val_loss: 0.7364 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7522 - acc: 0.5052 - val_loss: 0.7267 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7431 - acc: 0.5103 - val_loss: 0.7173 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7347 - acc: 0.5206 - val_loss: 0.7073 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7259 - acc: 0.5309 - val_loss: 0.6980 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7176 - acc: 0.5515 - val_loss: 0.6889 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7093 - acc: 0.5619 - val_loss: 0.6799 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7011 - acc: 0.5722 - val_loss: 0.6711 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.5773 - val_loss: 0.6619 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6846 - acc: 0.6031 - val_loss: 0.6534 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6771 - acc: 0.6186 - val_loss: 0.6458 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6705 - acc: 0.6289 - val_loss: 0.6387 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6637 - acc: 0.6495 - val_loss: 0.6314 - val_acc: 0.6557\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6570 - acc: 0.6495 - val_loss: 0.6240 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6502 - acc: 0.6649 - val_loss: 0.6169 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6438 - acc: 0.6649 - val_loss: 0.6100 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6374 - acc: 0.6701 - val_loss: 0.6026 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7368 - acc: 0.5103 - val_loss: 0.8275 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7240 - acc: 0.5258 - val_loss: 0.8129 - val_acc: 0.4098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7135 - acc: 0.5258 - val_loss: 0.7997 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7036 - acc: 0.5515 - val_loss: 0.7872 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6945 - acc: 0.5619 - val_loss: 0.7755 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6858 - acc: 0.5722 - val_loss: 0.7645 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6776 - acc: 0.5825 - val_loss: 0.7534 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6692 - acc: 0.6031 - val_loss: 0.7422 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6611 - acc: 0.6082 - val_loss: 0.7308 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6524 - acc: 0.6186 - val_loss: 0.7199 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6444 - acc: 0.6340 - val_loss: 0.7095 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6366 - acc: 0.6340 - val_loss: 0.6997 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6297 - acc: 0.6495 - val_loss: 0.6905 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6224 - acc: 0.6804 - val_loss: 0.6817 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6160 - acc: 0.6804 - val_loss: 0.6732 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6097 - acc: 0.6804 - val_loss: 0.6654 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6037 - acc: 0.6959 - val_loss: 0.6572 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5975 - acc: 0.7010 - val_loss: 0.6496 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5916 - acc: 0.7062 - val_loss: 0.6419 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5857 - acc: 0.7113 - val_loss: 0.6337 - val_acc: 0.6393\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7820 - acc: 0.3731 - val_loss: 0.7529 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7667 - acc: 0.4145 - val_loss: 0.7378 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7525 - acc: 0.4404 - val_loss: 0.7236 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7392 - acc: 0.4611 - val_loss: 0.7104 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7256 - acc: 0.5026 - val_loss: 0.6968 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7131 - acc: 0.5337 - val_loss: 0.6843 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7018 - acc: 0.5544 - val_loss: 0.6725 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6917 - acc: 0.5596 - val_loss: 0.6626 - val_acc: 0.6393\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6818 - acc: 0.5803 - val_loss: 0.6520 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6717 - acc: 0.5959 - val_loss: 0.6416 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6619 - acc: 0.6062 - val_loss: 0.6316 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6529 - acc: 0.6321 - val_loss: 0.6234 - val_acc: 0.7049\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6454 - acc: 0.6321 - val_loss: 0.6155 - val_acc: 0.7377\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6382 - acc: 0.6477 - val_loss: 0.6070 - val_acc: 0.7541\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6304 - acc: 0.6632 - val_loss: 0.5983 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6225 - acc: 0.6788 - val_loss: 0.5898 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6148 - acc: 0.6788 - val_loss: 0.5816 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6072 - acc: 0.6891 - val_loss: 0.5732 - val_acc: 0.7541\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5997 - acc: 0.6943 - val_loss: 0.5652 - val_acc: 0.7869\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5924 - acc: 0.7098 - val_loss: 0.5575 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.7575 - acc: 0.4041 - val_loss: 0.8089 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7422 - acc: 0.4352 - val_loss: 0.7919 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7290 - acc: 0.4663 - val_loss: 0.7761 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7173 - acc: 0.4922 - val_loss: 0.7624 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7065 - acc: 0.5078 - val_loss: 0.7490 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6959 - acc: 0.5285 - val_loss: 0.7376 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6864 - acc: 0.5544 - val_loss: 0.7273 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6778 - acc: 0.5596 - val_loss: 0.7168 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6682 - acc: 0.5803 - val_loss: 0.7061 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6593 - acc: 0.5855 - val_loss: 0.6963 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6509 - acc: 0.6010 - val_loss: 0.6875 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6435 - acc: 0.6166 - val_loss: 0.6790 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6357 - acc: 0.6321 - val_loss: 0.6696 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6274 - acc: 0.6477 - val_loss: 0.6589 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6188 - acc: 0.6788 - val_loss: 0.6498 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6115 - acc: 0.6891 - val_loss: 0.6417 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6048 - acc: 0.7098 - val_loss: 0.6340 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5984 - acc: 0.7254 - val_loss: 0.6263 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5916 - acc: 0.7461 - val_loss: 0.6176 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5849 - acc: 0.7409 - val_loss: 0.6093 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6084 - acc: 0.6495 - val_loss: 0.6086 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5958 - acc: 0.6598 - val_loss: 0.5974 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5849 - acc: 0.6856 - val_loss: 0.5878 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5756 - acc: 0.6907 - val_loss: 0.5781 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5659 - acc: 0.7113 - val_loss: 0.5689 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5571 - acc: 0.7113 - val_loss: 0.5603 - val_acc: 0.7049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5488 - acc: 0.7268 - val_loss: 0.5517 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5408 - acc: 0.7371 - val_loss: 0.5434 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5332 - acc: 0.7474 - val_loss: 0.5362 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5262 - acc: 0.7526 - val_loss: 0.5286 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5190 - acc: 0.7577 - val_loss: 0.5209 - val_acc: 0.7541\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5121 - acc: 0.7732 - val_loss: 0.5139 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5054 - acc: 0.8093 - val_loss: 0.5071 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4992 - acc: 0.8144 - val_loss: 0.5002 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4931 - acc: 0.8144 - val_loss: 0.4938 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4871 - acc: 0.8247 - val_loss: 0.4874 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4821 - acc: 0.8247 - val_loss: 0.4824 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4772 - acc: 0.8351 - val_loss: 0.4768 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4722 - acc: 0.8351 - val_loss: 0.4718 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4677 - acc: 0.8402 - val_loss: 0.4668 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7506 - acc: 0.4845 - val_loss: 0.6861 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7333 - acc: 0.5000 - val_loss: 0.6696 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7181 - acc: 0.5361 - val_loss: 0.6544 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7035 - acc: 0.5464 - val_loss: 0.6403 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6902 - acc: 0.5722 - val_loss: 0.6271 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6771 - acc: 0.5876 - val_loss: 0.6143 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6641 - acc: 0.6186 - val_loss: 0.6024 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6519 - acc: 0.6186 - val_loss: 0.5904 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6404 - acc: 0.6443 - val_loss: 0.5800 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6299 - acc: 0.6546 - val_loss: 0.5703 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6205 - acc: 0.6753 - val_loss: 0.5610 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6106 - acc: 0.6907 - val_loss: 0.5523 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6015 - acc: 0.7062 - val_loss: 0.5438 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5930 - acc: 0.7268 - val_loss: 0.5355 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5844 - acc: 0.7320 - val_loss: 0.5267 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5754 - acc: 0.7268 - val_loss: 0.5182 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5676 - acc: 0.7371 - val_loss: 0.5095 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5586 - acc: 0.7371 - val_loss: 0.5017 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5510 - acc: 0.7423 - val_loss: 0.4953 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5445 - acc: 0.7526 - val_loss: 0.4893 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.7494 - acc: 0.4124 - val_loss: 0.7139 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7328 - acc: 0.4485 - val_loss: 0.6970 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7180 - acc: 0.4742 - val_loss: 0.6816 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7057 - acc: 0.4897 - val_loss: 0.6682 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6934 - acc: 0.5206 - val_loss: 0.6558 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6816 - acc: 0.5464 - val_loss: 0.6433 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6705 - acc: 0.5825 - val_loss: 0.6317 - val_acc: 0.6393\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6603 - acc: 0.5928 - val_loss: 0.6218 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6511 - acc: 0.6031 - val_loss: 0.6116 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6413 - acc: 0.6237 - val_loss: 0.6017 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6316 - acc: 0.6289 - val_loss: 0.5923 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6232 - acc: 0.6443 - val_loss: 0.5834 - val_acc: 0.7377\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6146 - acc: 0.6598 - val_loss: 0.5749 - val_acc: 0.7377\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6066 - acc: 0.6907 - val_loss: 0.5665 - val_acc: 0.7541\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5987 - acc: 0.7216 - val_loss: 0.5595 - val_acc: 0.7705\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5915 - acc: 0.7268 - val_loss: 0.5522 - val_acc: 0.7705\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5845 - acc: 0.7423 - val_loss: 0.5448 - val_acc: 0.7705\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5779 - acc: 0.7474 - val_loss: 0.5376 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5709 - acc: 0.7577 - val_loss: 0.5313 - val_acc: 0.7869\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5650 - acc: 0.7629 - val_loss: 0.5246 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6537 - acc: 0.6528 - val_loss: 0.6890 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6347 - acc: 0.6943 - val_loss: 0.6732 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6210 - acc: 0.6995 - val_loss: 0.6590 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6086 - acc: 0.7202 - val_loss: 0.6463 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5966 - acc: 0.7358 - val_loss: 0.6331 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5852 - acc: 0.7513 - val_loss: 0.6199 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5750 - acc: 0.7617 - val_loss: 0.6097 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5656 - acc: 0.7720 - val_loss: 0.5995 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5569 - acc: 0.7824 - val_loss: 0.5893 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5481 - acc: 0.7927 - val_loss: 0.5801 - val_acc: 0.7541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5398 - acc: 0.7927 - val_loss: 0.5705 - val_acc: 0.7541\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5310 - acc: 0.8031 - val_loss: 0.5610 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5236 - acc: 0.8135 - val_loss: 0.5517 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5157 - acc: 0.8290 - val_loss: 0.5428 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5086 - acc: 0.8290 - val_loss: 0.5346 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5017 - acc: 0.8342 - val_loss: 0.5273 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4947 - acc: 0.8342 - val_loss: 0.5206 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4887 - acc: 0.8342 - val_loss: 0.5131 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4824 - acc: 0.8342 - val_loss: 0.5076 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4780 - acc: 0.8497 - val_loss: 0.5046 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.7737 - acc: 0.4249 - val_loss: 0.7803 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7497 - acc: 0.4560 - val_loss: 0.7577 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7295 - acc: 0.4456 - val_loss: 0.7366 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7099 - acc: 0.4819 - val_loss: 0.7170 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6925 - acc: 0.5026 - val_loss: 0.6995 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6766 - acc: 0.5181 - val_loss: 0.6858 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6630 - acc: 0.5544 - val_loss: 0.6710 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6493 - acc: 0.5699 - val_loss: 0.6564 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6363 - acc: 0.6166 - val_loss: 0.6422 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6235 - acc: 0.6477 - val_loss: 0.6293 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6125 - acc: 0.6839 - val_loss: 0.6162 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6005 - acc: 0.7098 - val_loss: 0.6037 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5891 - acc: 0.7306 - val_loss: 0.5912 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5782 - acc: 0.7513 - val_loss: 0.5798 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5681 - acc: 0.7668 - val_loss: 0.5693 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5586 - acc: 0.7876 - val_loss: 0.5594 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5501 - acc: 0.7876 - val_loss: 0.5494 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5411 - acc: 0.7927 - val_loss: 0.5397 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5329 - acc: 0.7876 - val_loss: 0.5314 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5257 - acc: 0.7824 - val_loss: 0.5234 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.7925 - acc: 0.4897 - val_loss: 0.8127 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7655 - acc: 0.5052 - val_loss: 0.7848 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7430 - acc: 0.5206 - val_loss: 0.7584 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7215 - acc: 0.5309 - val_loss: 0.7349 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7019 - acc: 0.5464 - val_loss: 0.7125 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6835 - acc: 0.5773 - val_loss: 0.6929 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6677 - acc: 0.5928 - val_loss: 0.6739 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6520 - acc: 0.6289 - val_loss: 0.6568 - val_acc: 0.6393\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6378 - acc: 0.6701 - val_loss: 0.6413 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6241 - acc: 0.6959 - val_loss: 0.6252 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6113 - acc: 0.7216 - val_loss: 0.6103 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5984 - acc: 0.7320 - val_loss: 0.5962 - val_acc: 0.7049\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5865 - acc: 0.7423 - val_loss: 0.5824 - val_acc: 0.7377\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5750 - acc: 0.7526 - val_loss: 0.5700 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5647 - acc: 0.7784 - val_loss: 0.5585 - val_acc: 0.7705\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5548 - acc: 0.7835 - val_loss: 0.5480 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5456 - acc: 0.7990 - val_loss: 0.5390 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5371 - acc: 0.8041 - val_loss: 0.5294 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5286 - acc: 0.8041 - val_loss: 0.5194 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5200 - acc: 0.8093 - val_loss: 0.5095 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7031 - acc: 0.4845 - val_loss: 0.6426 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6830 - acc: 0.5103 - val_loss: 0.6277 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6683 - acc: 0.5361 - val_loss: 0.6128 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6516 - acc: 0.5979 - val_loss: 0.5985 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6372 - acc: 0.6392 - val_loss: 0.5845 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6228 - acc: 0.6649 - val_loss: 0.5721 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6097 - acc: 0.7010 - val_loss: 0.5605 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5975 - acc: 0.6959 - val_loss: 0.5496 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5865 - acc: 0.7165 - val_loss: 0.5394 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5756 - acc: 0.7268 - val_loss: 0.5304 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5659 - acc: 0.7423 - val_loss: 0.5209 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5559 - acc: 0.7371 - val_loss: 0.5121 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5468 - acc: 0.7371 - val_loss: 0.5048 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5387 - acc: 0.7474 - val_loss: 0.4975 - val_acc: 0.7869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5300 - acc: 0.7526 - val_loss: 0.4900 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5221 - acc: 0.7680 - val_loss: 0.4831 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5150 - acc: 0.7680 - val_loss: 0.4768 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5082 - acc: 0.7680 - val_loss: 0.4706 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5019 - acc: 0.7680 - val_loss: 0.4644 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4957 - acc: 0.7732 - val_loss: 0.4589 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6767 - acc: 0.6289 - val_loss: 0.6797 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6573 - acc: 0.6495 - val_loss: 0.6584 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6410 - acc: 0.6753 - val_loss: 0.6401 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6264 - acc: 0.6907 - val_loss: 0.6220 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6120 - acc: 0.7320 - val_loss: 0.6037 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5991 - acc: 0.7474 - val_loss: 0.5876 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5865 - acc: 0.7526 - val_loss: 0.5731 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5753 - acc: 0.7784 - val_loss: 0.5605 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5645 - acc: 0.7629 - val_loss: 0.5476 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5541 - acc: 0.7784 - val_loss: 0.5349 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5443 - acc: 0.7835 - val_loss: 0.5230 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5352 - acc: 0.7938 - val_loss: 0.5129 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5267 - acc: 0.7938 - val_loss: 0.5035 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5193 - acc: 0.7938 - val_loss: 0.4957 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5122 - acc: 0.8041 - val_loss: 0.4880 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5051 - acc: 0.8093 - val_loss: 0.4798 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4979 - acc: 0.8247 - val_loss: 0.4725 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4919 - acc: 0.8299 - val_loss: 0.4661 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4860 - acc: 0.8351 - val_loss: 0.4599 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4803 - acc: 0.8402 - val_loss: 0.4539 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.6846 - acc: 0.5440 - val_loss: 0.6600 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6569 - acc: 0.6269 - val_loss: 0.6346 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6333 - acc: 0.6995 - val_loss: 0.6109 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6123 - acc: 0.7254 - val_loss: 0.5902 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5921 - acc: 0.7617 - val_loss: 0.5710 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5752 - acc: 0.7824 - val_loss: 0.5531 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5597 - acc: 0.7927 - val_loss: 0.5387 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5461 - acc: 0.8083 - val_loss: 0.5242 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5329 - acc: 0.7979 - val_loss: 0.5101 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5200 - acc: 0.8031 - val_loss: 0.4976 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5094 - acc: 0.8083 - val_loss: 0.4882 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4992 - acc: 0.8187 - val_loss: 0.4789 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4912 - acc: 0.8187 - val_loss: 0.4718 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4843 - acc: 0.8238 - val_loss: 0.4651 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4773 - acc: 0.8187 - val_loss: 0.4570 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4692 - acc: 0.8238 - val_loss: 0.4491 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4615 - acc: 0.8290 - val_loss: 0.4411 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4539 - acc: 0.8290 - val_loss: 0.4340 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4473 - acc: 0.8342 - val_loss: 0.4276 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4415 - acc: 0.8394 - val_loss: 0.4214 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6731 - acc: 0.5803 - val_loss: 0.6428 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6481 - acc: 0.6528 - val_loss: 0.6223 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6294 - acc: 0.7047 - val_loss: 0.6045 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6109 - acc: 0.7409 - val_loss: 0.5849 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5923 - acc: 0.7565 - val_loss: 0.5661 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5752 - acc: 0.7565 - val_loss: 0.5497 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5593 - acc: 0.7565 - val_loss: 0.5341 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5444 - acc: 0.7772 - val_loss: 0.5208 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5308 - acc: 0.7720 - val_loss: 0.5076 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5184 - acc: 0.7876 - val_loss: 0.4953 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5060 - acc: 0.7876 - val_loss: 0.4841 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4955 - acc: 0.8187 - val_loss: 0.4742 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4862 - acc: 0.8187 - val_loss: 0.4652 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4775 - acc: 0.8238 - val_loss: 0.4564 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4694 - acc: 0.8290 - val_loss: 0.4477 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4616 - acc: 0.8342 - val_loss: 0.4399 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4550 - acc: 0.8342 - val_loss: 0.4324 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4489 - acc: 0.8342 - val_loss: 0.4254 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4427 - acc: 0.8342 - val_loss: 0.4191 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4368 - acc: 0.8446 - val_loss: 0.4136 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.7009 - acc: 0.4897 - val_loss: 0.6426 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6681 - acc: 0.5515 - val_loss: 0.6115 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6411 - acc: 0.6598 - val_loss: 0.5866 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6185 - acc: 0.7010 - val_loss: 0.5642 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5976 - acc: 0.7680 - val_loss: 0.5443 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5791 - acc: 0.8041 - val_loss: 0.5250 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5612 - acc: 0.8041 - val_loss: 0.5066 - val_acc: 0.9180\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5437 - acc: 0.8144 - val_loss: 0.4898 - val_acc: 0.9344\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5276 - acc: 0.8351 - val_loss: 0.4752 - val_acc: 0.9344\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5137 - acc: 0.8351 - val_loss: 0.4609 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5007 - acc: 0.8402 - val_loss: 0.4481 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4890 - acc: 0.8402 - val_loss: 0.4371 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4789 - acc: 0.8454 - val_loss: 0.4269 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4694 - acc: 0.8454 - val_loss: 0.4168 - val_acc: 0.9180\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4605 - acc: 0.8454 - val_loss: 0.4070 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4512 - acc: 0.8454 - val_loss: 0.3980 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4427 - acc: 0.8402 - val_loss: 0.3900 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4349 - acc: 0.8454 - val_loss: 0.3828 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4271 - acc: 0.8454 - val_loss: 0.3760 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4204 - acc: 0.8454 - val_loss: 0.3699 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6738 - acc: 0.6082 - val_loss: 0.6765 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6447 - acc: 0.6907 - val_loss: 0.6457 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6196 - acc: 0.7268 - val_loss: 0.6181 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5988 - acc: 0.7526 - val_loss: 0.5963 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5811 - acc: 0.7680 - val_loss: 0.5755 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5640 - acc: 0.7835 - val_loss: 0.5568 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5491 - acc: 0.7990 - val_loss: 0.5385 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5341 - acc: 0.8144 - val_loss: 0.5217 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5208 - acc: 0.8093 - val_loss: 0.5058 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5096 - acc: 0.8093 - val_loss: 0.4930 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5003 - acc: 0.8041 - val_loss: 0.4834 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4913 - acc: 0.8093 - val_loss: 0.4725 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4824 - acc: 0.8093 - val_loss: 0.4616 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4735 - acc: 0.8144 - val_loss: 0.4516 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4653 - acc: 0.8196 - val_loss: 0.4430 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4581 - acc: 0.8247 - val_loss: 0.4356 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4514 - acc: 0.8299 - val_loss: 0.4280 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4447 - acc: 0.8299 - val_loss: 0.4214 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4392 - acc: 0.8299 - val_loss: 0.4155 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4338 - acc: 0.8402 - val_loss: 0.4097 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6722 - acc: 0.6598 - val_loss: 0.6456 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6493 - acc: 0.7062 - val_loss: 0.6257 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6320 - acc: 0.7371 - val_loss: 0.6072 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6158 - acc: 0.7423 - val_loss: 0.5907 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6007 - acc: 0.7732 - val_loss: 0.5753 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5860 - acc: 0.7835 - val_loss: 0.5598 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5717 - acc: 0.7990 - val_loss: 0.5453 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5589 - acc: 0.8247 - val_loss: 0.5318 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5463 - acc: 0.8351 - val_loss: 0.5189 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5353 - acc: 0.8351 - val_loss: 0.5093 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5261 - acc: 0.8402 - val_loss: 0.5004 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5159 - acc: 0.8454 - val_loss: 0.4904 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5059 - acc: 0.8454 - val_loss: 0.4807 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4964 - acc: 0.8454 - val_loss: 0.4706 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4871 - acc: 0.8454 - val_loss: 0.4612 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4788 - acc: 0.8505 - val_loss: 0.4520 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4708 - acc: 0.8505 - val_loss: 0.4446 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4642 - acc: 0.8557 - val_loss: 0.4391 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4582 - acc: 0.8557 - val_loss: 0.4336 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4524 - acc: 0.8505 - val_loss: 0.4274 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8422 - acc: 0.4715 - val_loss: 0.8145 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8062 - acc: 0.5026 - val_loss: 0.7828 - val_acc: 0.6230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7759 - acc: 0.5233 - val_loss: 0.7515 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7461 - acc: 0.5492 - val_loss: 0.7238 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7210 - acc: 0.6010 - val_loss: 0.6999 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6972 - acc: 0.6218 - val_loss: 0.6783 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6793 - acc: 0.6321 - val_loss: 0.6616 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6632 - acc: 0.6321 - val_loss: 0.6425 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6452 - acc: 0.6684 - val_loss: 0.6246 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6278 - acc: 0.6891 - val_loss: 0.6080 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6129 - acc: 0.6943 - val_loss: 0.5923 - val_acc: 0.7541\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5987 - acc: 0.7254 - val_loss: 0.5785 - val_acc: 0.7541\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5867 - acc: 0.7358 - val_loss: 0.5637 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5737 - acc: 0.7461 - val_loss: 0.5494 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5615 - acc: 0.7513 - val_loss: 0.5342 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5502 - acc: 0.7513 - val_loss: 0.5219 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5399 - acc: 0.7565 - val_loss: 0.5099 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5308 - acc: 0.7617 - val_loss: 0.4991 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5216 - acc: 0.7668 - val_loss: 0.4871 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5117 - acc: 0.7772 - val_loss: 0.4780 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7941 - acc: 0.4456 - val_loss: 0.7375 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7606 - acc: 0.4663 - val_loss: 0.7121 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7342 - acc: 0.5130 - val_loss: 0.6903 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7121 - acc: 0.5440 - val_loss: 0.6705 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6906 - acc: 0.5855 - val_loss: 0.6516 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6726 - acc: 0.5959 - val_loss: 0.6325 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6536 - acc: 0.6321 - val_loss: 0.6163 - val_acc: 0.6393\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6382 - acc: 0.6269 - val_loss: 0.6026 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6242 - acc: 0.6218 - val_loss: 0.5914 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6125 - acc: 0.6321 - val_loss: 0.5810 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6009 - acc: 0.6528 - val_loss: 0.5709 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5890 - acc: 0.6580 - val_loss: 0.5606 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5778 - acc: 0.6736 - val_loss: 0.5507 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5678 - acc: 0.6736 - val_loss: 0.5414 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5590 - acc: 0.6788 - val_loss: 0.5343 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5509 - acc: 0.6788 - val_loss: 0.5266 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5429 - acc: 0.6788 - val_loss: 0.5196 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5348 - acc: 0.6891 - val_loss: 0.5125 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5272 - acc: 0.6995 - val_loss: 0.5045 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5191 - acc: 0.6943 - val_loss: 0.4963 - val_acc: 0.7213\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7598 - acc: 0.4794 - val_loss: 0.7221 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7247 - acc: 0.5103 - val_loss: 0.6884 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6947 - acc: 0.5464 - val_loss: 0.6606 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6688 - acc: 0.5619 - val_loss: 0.6351 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6459 - acc: 0.6031 - val_loss: 0.6096 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6245 - acc: 0.6289 - val_loss: 0.5886 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6057 - acc: 0.6495 - val_loss: 0.5697 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5886 - acc: 0.6701 - val_loss: 0.5522 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5733 - acc: 0.6753 - val_loss: 0.5349 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5599 - acc: 0.7165 - val_loss: 0.5204 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5476 - acc: 0.7165 - val_loss: 0.5072 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5363 - acc: 0.7320 - val_loss: 0.4946 - val_acc: 0.7541\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5253 - acc: 0.7371 - val_loss: 0.4821 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5143 - acc: 0.7577 - val_loss: 0.4719 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5051 - acc: 0.7732 - val_loss: 0.4618 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4950 - acc: 0.7784 - val_loss: 0.4528 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4861 - acc: 0.7887 - val_loss: 0.4441 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4777 - acc: 0.7938 - val_loss: 0.4367 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4694 - acc: 0.7887 - val_loss: 0.4299 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4623 - acc: 0.7990 - val_loss: 0.4237 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7808 - acc: 0.4381 - val_loss: 0.7015 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7577 - acc: 0.4381 - val_loss: 0.6826 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7372 - acc: 0.4536 - val_loss: 0.6650 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7182 - acc: 0.4588 - val_loss: 0.6494 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7015 - acc: 0.4588 - val_loss: 0.6363 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6879 - acc: 0.4742 - val_loss: 0.6253 - val_acc: 0.5738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6760 - acc: 0.4794 - val_loss: 0.6161 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6653 - acc: 0.4897 - val_loss: 0.6075 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6542 - acc: 0.4897 - val_loss: 0.5988 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6452 - acc: 0.5000 - val_loss: 0.5906 - val_acc: 0.6393\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6356 - acc: 0.5361 - val_loss: 0.5821 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6265 - acc: 0.5567 - val_loss: 0.5738 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6183 - acc: 0.5876 - val_loss: 0.5668 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6108 - acc: 0.6289 - val_loss: 0.5593 - val_acc: 0.6885\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6033 - acc: 0.6392 - val_loss: 0.5522 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5964 - acc: 0.6443 - val_loss: 0.5454 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5895 - acc: 0.6546 - val_loss: 0.5389 - val_acc: 0.7705\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5831 - acc: 0.6701 - val_loss: 0.5329 - val_acc: 0.7869\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5766 - acc: 0.6701 - val_loss: 0.5284 - val_acc: 0.7869\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5709 - acc: 0.6959 - val_loss: 0.5230 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7506 - acc: 0.4485 - val_loss: 0.7294 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7255 - acc: 0.4897 - val_loss: 0.7092 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7052 - acc: 0.5258 - val_loss: 0.6913 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6867 - acc: 0.5670 - val_loss: 0.6759 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6708 - acc: 0.5876 - val_loss: 0.6620 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6555 - acc: 0.5979 - val_loss: 0.6478 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6405 - acc: 0.6443 - val_loss: 0.6351 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6264 - acc: 0.6598 - val_loss: 0.6226 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6118 - acc: 0.6753 - val_loss: 0.6109 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5992 - acc: 0.6907 - val_loss: 0.6004 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5865 - acc: 0.7165 - val_loss: 0.5894 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5747 - acc: 0.7216 - val_loss: 0.5785 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5639 - acc: 0.7423 - val_loss: 0.5693 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5538 - acc: 0.7526 - val_loss: 0.5607 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5447 - acc: 0.7629 - val_loss: 0.5511 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5355 - acc: 0.7577 - val_loss: 0.5425 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5259 - acc: 0.7577 - val_loss: 0.5351 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5176 - acc: 0.7629 - val_loss: 0.5284 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5102 - acc: 0.7732 - val_loss: 0.5220 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5023 - acc: 0.7784 - val_loss: 0.5154 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7192 - acc: 0.5078 - val_loss: 0.7374 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6809 - acc: 0.5751 - val_loss: 0.6990 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6512 - acc: 0.6166 - val_loss: 0.6634 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6249 - acc: 0.6528 - val_loss: 0.6344 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6018 - acc: 0.6580 - val_loss: 0.6087 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5811 - acc: 0.6995 - val_loss: 0.5836 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5600 - acc: 0.7202 - val_loss: 0.5608 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5411 - acc: 0.7358 - val_loss: 0.5368 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5234 - acc: 0.7565 - val_loss: 0.5164 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5063 - acc: 0.7720 - val_loss: 0.4993 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4915 - acc: 0.8031 - val_loss: 0.4823 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4768 - acc: 0.8135 - val_loss: 0.4687 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4639 - acc: 0.8394 - val_loss: 0.4560 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4516 - acc: 0.8446 - val_loss: 0.4450 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4412 - acc: 0.8601 - val_loss: 0.4355 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4306 - acc: 0.8705 - val_loss: 0.4300 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4235 - acc: 0.8601 - val_loss: 0.4245 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4166 - acc: 0.8601 - val_loss: 0.4204 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4105 - acc: 0.8653 - val_loss: 0.4144 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4052 - acc: 0.8653 - val_loss: 0.4079 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7278 - acc: 0.5285 - val_loss: 0.6520 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6851 - acc: 0.5855 - val_loss: 0.6142 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6488 - acc: 0.6477 - val_loss: 0.5817 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6179 - acc: 0.6684 - val_loss: 0.5528 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5917 - acc: 0.6839 - val_loss: 0.5291 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5687 - acc: 0.7098 - val_loss: 0.5106 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5503 - acc: 0.7306 - val_loss: 0.4943 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5328 - acc: 0.7409 - val_loss: 0.4772 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5162 - acc: 0.7668 - val_loss: 0.4637 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5021 - acc: 0.7720 - val_loss: 0.4516 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4914 - acc: 0.7824 - val_loss: 0.4435 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4823 - acc: 0.7927 - val_loss: 0.4361 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4731 - acc: 0.7927 - val_loss: 0.4281 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4630 - acc: 0.7927 - val_loss: 0.4196 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4535 - acc: 0.8135 - val_loss: 0.4121 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4453 - acc: 0.8187 - val_loss: 0.4058 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4386 - acc: 0.8187 - val_loss: 0.3988 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4319 - acc: 0.8187 - val_loss: 0.3933 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4254 - acc: 0.8187 - val_loss: 0.3882 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4206 - acc: 0.8187 - val_loss: 0.3851 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6677 - acc: 0.5979 - val_loss: 0.6015 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6170 - acc: 0.6701 - val_loss: 0.5590 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5774 - acc: 0.6856 - val_loss: 0.5227 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5431 - acc: 0.7165 - val_loss: 0.4932 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5151 - acc: 0.7526 - val_loss: 0.4673 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4901 - acc: 0.7629 - val_loss: 0.4468 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4708 - acc: 0.7680 - val_loss: 0.4333 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4552 - acc: 0.7835 - val_loss: 0.4187 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4402 - acc: 0.7938 - val_loss: 0.4048 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4267 - acc: 0.8196 - val_loss: 0.3918 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4143 - acc: 0.8144 - val_loss: 0.3811 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4029 - acc: 0.8351 - val_loss: 0.3729 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3939 - acc: 0.8402 - val_loss: 0.3663 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3864 - acc: 0.8454 - val_loss: 0.3600 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3802 - acc: 0.8454 - val_loss: 0.3542 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3739 - acc: 0.8505 - val_loss: 0.3488 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3682 - acc: 0.8454 - val_loss: 0.3440 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3638 - acc: 0.8402 - val_loss: 0.3397 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3580 - acc: 0.8505 - val_loss: 0.3366 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3536 - acc: 0.8505 - val_loss: 0.3334 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5904 - acc: 0.6701 - val_loss: 0.5454 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5650 - acc: 0.7010 - val_loss: 0.5251 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5451 - acc: 0.7268 - val_loss: 0.5084 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5285 - acc: 0.7423 - val_loss: 0.4964 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5147 - acc: 0.7526 - val_loss: 0.4836 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5013 - acc: 0.7629 - val_loss: 0.4722 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4892 - acc: 0.7732 - val_loss: 0.4615 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4778 - acc: 0.7732 - val_loss: 0.4516 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4681 - acc: 0.7784 - val_loss: 0.4427 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4601 - acc: 0.7784 - val_loss: 0.4346 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4515 - acc: 0.7887 - val_loss: 0.4271 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4439 - acc: 0.7887 - val_loss: 0.4201 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4376 - acc: 0.7938 - val_loss: 0.4133 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4314 - acc: 0.7990 - val_loss: 0.4076 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4256 - acc: 0.7990 - val_loss: 0.4023 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4205 - acc: 0.7990 - val_loss: 0.3976 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4153 - acc: 0.7990 - val_loss: 0.3945 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4105 - acc: 0.7990 - val_loss: 0.3910 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4066 - acc: 0.8041 - val_loss: 0.3870 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4024 - acc: 0.8093 - val_loss: 0.3852 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9181 - acc: 0.3351 - val_loss: 0.7944 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8558 - acc: 0.3660 - val_loss: 0.7450 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8026 - acc: 0.4124 - val_loss: 0.7024 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7573 - acc: 0.4588 - val_loss: 0.6651 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7182 - acc: 0.5052 - val_loss: 0.6347 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6834 - acc: 0.5515 - val_loss: 0.6066 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6501 - acc: 0.6186 - val_loss: 0.5825 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6218 - acc: 0.6701 - val_loss: 0.5593 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5957 - acc: 0.6856 - val_loss: 0.5388 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5736 - acc: 0.7268 - val_loss: 0.5234 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5537 - acc: 0.7526 - val_loss: 0.5083 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5353 - acc: 0.7423 - val_loss: 0.4950 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5195 - acc: 0.7577 - val_loss: 0.4844 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5061 - acc: 0.7732 - val_loss: 0.4737 - val_acc: 0.7869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4926 - acc: 0.7835 - val_loss: 0.4653 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4809 - acc: 0.7887 - val_loss: 0.4573 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4698 - acc: 0.8041 - val_loss: 0.4507 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4599 - acc: 0.8093 - val_loss: 0.4454 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4504 - acc: 0.8196 - val_loss: 0.4392 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4419 - acc: 0.8299 - val_loss: 0.4333 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7704 - acc: 0.4611 - val_loss: 0.7095 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6978 - acc: 0.5492 - val_loss: 0.6536 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6447 - acc: 0.6684 - val_loss: 0.6122 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6007 - acc: 0.7202 - val_loss: 0.5755 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5619 - acc: 0.7565 - val_loss: 0.5473 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5306 - acc: 0.7876 - val_loss: 0.5255 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5053 - acc: 0.7979 - val_loss: 0.5027 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4825 - acc: 0.8238 - val_loss: 0.4815 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4614 - acc: 0.8497 - val_loss: 0.4650 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4439 - acc: 0.8549 - val_loss: 0.4494 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4271 - acc: 0.8653 - val_loss: 0.4365 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4135 - acc: 0.8601 - val_loss: 0.4247 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4017 - acc: 0.8549 - val_loss: 0.4169 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3927 - acc: 0.8549 - val_loss: 0.4124 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3853 - acc: 0.8394 - val_loss: 0.4095 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3781 - acc: 0.8394 - val_loss: 0.4043 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3711 - acc: 0.8394 - val_loss: 0.3974 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3643 - acc: 0.8394 - val_loss: 0.3945 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3589 - acc: 0.8394 - val_loss: 0.3899 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3544 - acc: 0.8446 - val_loss: 0.3882 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9347 - acc: 0.4041 - val_loss: 1.0001 - val_acc: 0.2951\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8478 - acc: 0.4508 - val_loss: 0.9043 - val_acc: 0.3279\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7771 - acc: 0.5078 - val_loss: 0.8297 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7268 - acc: 0.5596 - val_loss: 0.7695 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6789 - acc: 0.5803 - val_loss: 0.7168 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6385 - acc: 0.6321 - val_loss: 0.6703 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6030 - acc: 0.6684 - val_loss: 0.6316 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5751 - acc: 0.7047 - val_loss: 0.5996 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5503 - acc: 0.7202 - val_loss: 0.5686 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5271 - acc: 0.7254 - val_loss: 0.5425 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5081 - acc: 0.7461 - val_loss: 0.5208 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4914 - acc: 0.7668 - val_loss: 0.5007 - val_acc: 0.7377\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4764 - acc: 0.7824 - val_loss: 0.4857 - val_acc: 0.7541\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4632 - acc: 0.7927 - val_loss: 0.4738 - val_acc: 0.7705\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4524 - acc: 0.7979 - val_loss: 0.4611 - val_acc: 0.7705\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4429 - acc: 0.7979 - val_loss: 0.4528 - val_acc: 0.7705\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4352 - acc: 0.7979 - val_loss: 0.4435 - val_acc: 0.7705\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4274 - acc: 0.7979 - val_loss: 0.4353 - val_acc: 0.7541\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4206 - acc: 0.8135 - val_loss: 0.4289 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4137 - acc: 0.8083 - val_loss: 0.4220 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6986 - acc: 0.5928 - val_loss: 0.6725 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6288 - acc: 0.6495 - val_loss: 0.6162 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5748 - acc: 0.7062 - val_loss: 0.5727 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5334 - acc: 0.7474 - val_loss: 0.5420 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5024 - acc: 0.7629 - val_loss: 0.5163 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4755 - acc: 0.7835 - val_loss: 0.4963 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4548 - acc: 0.7990 - val_loss: 0.4787 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4338 - acc: 0.8041 - val_loss: 0.4659 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4195 - acc: 0.8196 - val_loss: 0.4550 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4064 - acc: 0.8402 - val_loss: 0.4454 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3957 - acc: 0.8557 - val_loss: 0.4368 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3865 - acc: 0.8557 - val_loss: 0.4289 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3775 - acc: 0.8557 - val_loss: 0.4225 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3701 - acc: 0.8608 - val_loss: 0.4183 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3637 - acc: 0.8660 - val_loss: 0.4140 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3583 - acc: 0.8711 - val_loss: 0.4109 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3526 - acc: 0.8763 - val_loss: 0.4074 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3478 - acc: 0.8814 - val_loss: 0.4029 - val_acc: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3430 - acc: 0.8866 - val_loss: 0.3983 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3384 - acc: 0.8969 - val_loss: 0.3930 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8512 - acc: 0.3351 - val_loss: 0.8127 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7762 - acc: 0.3866 - val_loss: 0.7453 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7173 - acc: 0.5052 - val_loss: 0.6942 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6708 - acc: 0.6082 - val_loss: 0.6498 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6321 - acc: 0.6804 - val_loss: 0.6128 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5990 - acc: 0.6907 - val_loss: 0.5797 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5699 - acc: 0.6907 - val_loss: 0.5498 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5454 - acc: 0.7216 - val_loss: 0.5251 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5242 - acc: 0.7474 - val_loss: 0.5027 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5055 - acc: 0.7577 - val_loss: 0.4822 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4910 - acc: 0.7680 - val_loss: 0.4646 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4771 - acc: 0.7887 - val_loss: 0.4491 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4644 - acc: 0.7938 - val_loss: 0.4365 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4537 - acc: 0.7887 - val_loss: 0.4240 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4427 - acc: 0.7990 - val_loss: 0.4141 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4342 - acc: 0.8144 - val_loss: 0.4049 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4260 - acc: 0.8247 - val_loss: 0.3965 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4179 - acc: 0.8402 - val_loss: 0.3895 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4114 - acc: 0.8402 - val_loss: 0.3845 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4055 - acc: 0.8351 - val_loss: 0.3787 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6801 - acc: 0.6031 - val_loss: 0.6561 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6191 - acc: 0.6753 - val_loss: 0.6000 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5787 - acc: 0.6907 - val_loss: 0.5566 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5441 - acc: 0.7165 - val_loss: 0.5180 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5148 - acc: 0.7371 - val_loss: 0.4873 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4919 - acc: 0.7577 - val_loss: 0.4638 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4727 - acc: 0.7990 - val_loss: 0.4452 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4582 - acc: 0.8041 - val_loss: 0.4290 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4448 - acc: 0.8144 - val_loss: 0.4166 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4351 - acc: 0.8196 - val_loss: 0.4059 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4264 - acc: 0.8247 - val_loss: 0.4010 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4187 - acc: 0.8247 - val_loss: 0.3938 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4112 - acc: 0.8299 - val_loss: 0.3884 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4044 - acc: 0.8454 - val_loss: 0.3822 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3978 - acc: 0.8454 - val_loss: 0.3753 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3908 - acc: 0.8454 - val_loss: 0.3690 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3842 - acc: 0.8505 - val_loss: 0.3637 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3783 - acc: 0.8505 - val_loss: 0.3615 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3743 - acc: 0.8557 - val_loss: 0.3605 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3707 - acc: 0.8608 - val_loss: 0.3587 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8796 - acc: 0.3368 - val_loss: 0.8389 - val_acc: 0.3279\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7586 - acc: 0.4197 - val_loss: 0.7335 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6790 - acc: 0.5803 - val_loss: 0.6669 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6227 - acc: 0.7047 - val_loss: 0.6099 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5726 - acc: 0.7306 - val_loss: 0.5582 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5334 - acc: 0.7668 - val_loss: 0.5155 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4998 - acc: 0.7927 - val_loss: 0.4840 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4779 - acc: 0.8031 - val_loss: 0.4643 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4599 - acc: 0.8187 - val_loss: 0.4461 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4415 - acc: 0.8290 - val_loss: 0.4287 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4253 - acc: 0.8238 - val_loss: 0.4154 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4134 - acc: 0.8238 - val_loss: 0.4053 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4024 - acc: 0.8394 - val_loss: 0.3953 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3918 - acc: 0.8446 - val_loss: 0.3849 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3830 - acc: 0.8497 - val_loss: 0.3778 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3762 - acc: 0.8549 - val_loss: 0.3706 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3683 - acc: 0.8549 - val_loss: 0.3641 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3618 - acc: 0.8601 - val_loss: 0.3582 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3540 - acc: 0.8549 - val_loss: 0.3505 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3487 - acc: 0.8705 - val_loss: 0.3443 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6680 - acc: 0.6062 - val_loss: 0.6682 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5930 - acc: 0.7047 - val_loss: 0.6131 - val_acc: 0.7213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5405 - acc: 0.7513 - val_loss: 0.5665 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4972 - acc: 0.8031 - val_loss: 0.5293 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4630 - acc: 0.8135 - val_loss: 0.5007 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4366 - acc: 0.8238 - val_loss: 0.4753 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4149 - acc: 0.8238 - val_loss: 0.4555 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3986 - acc: 0.8290 - val_loss: 0.4420 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3851 - acc: 0.8290 - val_loss: 0.4318 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3742 - acc: 0.8290 - val_loss: 0.4214 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3646 - acc: 0.8238 - val_loss: 0.4131 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3581 - acc: 0.8238 - val_loss: 0.4060 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3521 - acc: 0.8549 - val_loss: 0.3986 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3461 - acc: 0.8601 - val_loss: 0.3924 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3406 - acc: 0.8549 - val_loss: 0.3838 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3352 - acc: 0.8549 - val_loss: 0.3790 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3290 - acc: 0.8653 - val_loss: 0.3737 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3249 - acc: 0.8705 - val_loss: 0.3719 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3206 - acc: 0.8756 - val_loss: 0.3692 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3173 - acc: 0.8808 - val_loss: 0.3651 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6412 - acc: 0.6392 - val_loss: 0.5589 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5515 - acc: 0.7680 - val_loss: 0.4840 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4887 - acc: 0.8196 - val_loss: 0.4365 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4472 - acc: 0.8402 - val_loss: 0.4034 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4193 - acc: 0.8505 - val_loss: 0.3853 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3985 - acc: 0.8557 - val_loss: 0.3694 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3815 - acc: 0.8608 - val_loss: 0.3573 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3677 - acc: 0.8711 - val_loss: 0.3488 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3567 - acc: 0.8711 - val_loss: 0.3420 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3473 - acc: 0.8711 - val_loss: 0.3363 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3399 - acc: 0.8763 - val_loss: 0.3311 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3322 - acc: 0.8763 - val_loss: 0.3270 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3256 - acc: 0.8763 - val_loss: 0.3252 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3196 - acc: 0.8711 - val_loss: 0.3222 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3139 - acc: 0.8814 - val_loss: 0.3230 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3096 - acc: 0.8866 - val_loss: 0.3221 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3054 - acc: 0.8866 - val_loss: 0.3193 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3008 - acc: 0.8918 - val_loss: 0.3157 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2973 - acc: 0.8918 - val_loss: 0.3146 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2930 - acc: 0.8969 - val_loss: 0.3079 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6399 - acc: 0.6495 - val_loss: 0.5089 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5699 - acc: 0.7216 - val_loss: 0.4674 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5219 - acc: 0.7732 - val_loss: 0.4329 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4868 - acc: 0.8093 - val_loss: 0.4067 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4584 - acc: 0.8196 - val_loss: 0.3879 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4360 - acc: 0.8247 - val_loss: 0.3770 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4207 - acc: 0.8196 - val_loss: 0.3709 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4060 - acc: 0.8247 - val_loss: 0.3648 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3941 - acc: 0.8247 - val_loss: 0.3576 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3855 - acc: 0.8351 - val_loss: 0.3532 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3772 - acc: 0.8299 - val_loss: 0.3522 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3699 - acc: 0.8351 - val_loss: 0.3523 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3649 - acc: 0.8454 - val_loss: 0.3558 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3593 - acc: 0.8402 - val_loss: 0.3590 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3558 - acc: 0.8505 - val_loss: 0.3637 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3527 - acc: 0.8505 - val_loss: 0.3655 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8274 - acc: 0.4691 - val_loss: 0.7331 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7012 - acc: 0.5567 - val_loss: 0.6428 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6157 - acc: 0.6649 - val_loss: 0.5708 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5503 - acc: 0.7320 - val_loss: 0.5141 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5017 - acc: 0.8041 - val_loss: 0.4731 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4676 - acc: 0.8247 - val_loss: 0.4403 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4404 - acc: 0.8351 - val_loss: 0.4176 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4212 - acc: 0.8505 - val_loss: 0.3975 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4061 - acc: 0.8557 - val_loss: 0.3833 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3928 - acc: 0.8557 - val_loss: 0.3723 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3837 - acc: 0.8608 - val_loss: 0.3618 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3743 - acc: 0.8608 - val_loss: 0.3554 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3678 - acc: 0.8608 - val_loss: 0.3499 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3610 - acc: 0.8608 - val_loss: 0.3478 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3564 - acc: 0.8608 - val_loss: 0.3429 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3512 - acc: 0.8660 - val_loss: 0.3448 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3489 - acc: 0.8711 - val_loss: 0.3462 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3460 - acc: 0.8660 - val_loss: 0.3457 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3424 - acc: 0.8660 - val_loss: 0.3411 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3383 - acc: 0.8608 - val_loss: 0.3367 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7310 - acc: 0.4974 - val_loss: 0.6229 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5909 - acc: 0.7358 - val_loss: 0.5224 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5194 - acc: 0.7876 - val_loss: 0.4746 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4707 - acc: 0.7927 - val_loss: 0.4405 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4349 - acc: 0.7876 - val_loss: 0.4181 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4069 - acc: 0.7876 - val_loss: 0.4035 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3874 - acc: 0.8083 - val_loss: 0.3918 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3680 - acc: 0.8187 - val_loss: 0.3767 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3530 - acc: 0.8290 - val_loss: 0.3632 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3413 - acc: 0.8394 - val_loss: 0.3509 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3321 - acc: 0.8549 - val_loss: 0.3433 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3259 - acc: 0.8653 - val_loss: 0.3384 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3200 - acc: 0.8653 - val_loss: 0.3349 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3147 - acc: 0.8705 - val_loss: 0.3376 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3084 - acc: 0.8808 - val_loss: 0.3370 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3031 - acc: 0.8860 - val_loss: 0.3350 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2981 - acc: 0.8912 - val_loss: 0.3350 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2928 - acc: 0.8964 - val_loss: 0.3342 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2877 - acc: 0.8964 - val_loss: 0.3337 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2835 - acc: 0.8964 - val_loss: 0.3330 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6788 - acc: 0.5544 - val_loss: 0.5983 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5649 - acc: 0.7461 - val_loss: 0.5086 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4976 - acc: 0.8031 - val_loss: 0.4507 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4548 - acc: 0.8187 - val_loss: 0.4137 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4257 - acc: 0.8238 - val_loss: 0.3874 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4052 - acc: 0.8342 - val_loss: 0.3697 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3882 - acc: 0.8290 - val_loss: 0.3556 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3760 - acc: 0.8394 - val_loss: 0.3452 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3659 - acc: 0.8446 - val_loss: 0.3377 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3574 - acc: 0.8394 - val_loss: 0.3329 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3510 - acc: 0.8446 - val_loss: 0.3304 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3447 - acc: 0.8446 - val_loss: 0.3288 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3378 - acc: 0.8446 - val_loss: 0.3266 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3321 - acc: 0.8549 - val_loss: 0.3285 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3275 - acc: 0.8446 - val_loss: 0.3254 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3234 - acc: 0.8497 - val_loss: 0.3228 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3184 - acc: 0.8497 - val_loss: 0.3223 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3140 - acc: 0.8549 - val_loss: 0.3210 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3102 - acc: 0.8601 - val_loss: 0.3196 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3068 - acc: 0.8653 - val_loss: 0.3169 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7135 - acc: 0.5670 - val_loss: 0.6178 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5773 - acc: 0.6907 - val_loss: 0.4950 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4872 - acc: 0.7990 - val_loss: 0.4211 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4350 - acc: 0.8299 - val_loss: 0.3787 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3999 - acc: 0.8557 - val_loss: 0.3521 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3797 - acc: 0.8814 - val_loss: 0.3371 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3639 - acc: 0.8814 - val_loss: 0.3313 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3522 - acc: 0.8763 - val_loss: 0.3237 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3411 - acc: 0.8763 - val_loss: 0.3186 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3326 - acc: 0.8814 - val_loss: 0.3144 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3245 - acc: 0.8866 - val_loss: 0.3104 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3155 - acc: 0.8866 - val_loss: 0.3068 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3092 - acc: 0.8866 - val_loss: 0.3045 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3026 - acc: 0.8814 - val_loss: 0.3021 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2975 - acc: 0.8814 - val_loss: 0.2979 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2923 - acc: 0.8814 - val_loss: 0.2964 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2880 - acc: 0.8814 - val_loss: 0.2956 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2837 - acc: 0.8918 - val_loss: 0.2976 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2801 - acc: 0.8969 - val_loss: 0.3020 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2766 - acc: 0.9072 - val_loss: 0.3052 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5830 - acc: 0.6907 - val_loss: 0.5113 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5029 - acc: 0.7784 - val_loss: 0.4505 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4558 - acc: 0.8144 - val_loss: 0.4049 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4202 - acc: 0.8144 - val_loss: 0.3764 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3998 - acc: 0.8144 - val_loss: 0.3563 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3828 - acc: 0.8247 - val_loss: 0.3429 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3712 - acc: 0.8351 - val_loss: 0.3369 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3613 - acc: 0.8402 - val_loss: 0.3284 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3543 - acc: 0.8454 - val_loss: 0.3221 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3474 - acc: 0.8351 - val_loss: 0.3211 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3411 - acc: 0.8402 - val_loss: 0.3240 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3380 - acc: 0.8402 - val_loss: 0.3253 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3347 - acc: 0.8557 - val_loss: 0.3251 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3299 - acc: 0.8557 - val_loss: 0.3228 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3253 - acc: 0.8557 - val_loss: 0.3195 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3203 - acc: 0.8557 - val_loss: 0.3146 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3154 - acc: 0.8557 - val_loss: 0.3103 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3108 - acc: 0.8505 - val_loss: 0.3086 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3067 - acc: 0.8505 - val_loss: 0.3086 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3031 - acc: 0.8557 - val_loss: 0.3071 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7468 - acc: 0.4639 - val_loss: 0.6543 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6173 - acc: 0.6649 - val_loss: 0.5574 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5341 - acc: 0.7629 - val_loss: 0.4936 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4815 - acc: 0.8196 - val_loss: 0.4566 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4422 - acc: 0.8144 - val_loss: 0.4271 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4158 - acc: 0.8247 - val_loss: 0.4073 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3959 - acc: 0.8299 - val_loss: 0.3914 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3809 - acc: 0.8402 - val_loss: 0.3836 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3687 - acc: 0.8402 - val_loss: 0.3746 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3591 - acc: 0.8505 - val_loss: 0.3657 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3500 - acc: 0.8454 - val_loss: 0.3583 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3426 - acc: 0.8454 - val_loss: 0.3553 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3362 - acc: 0.8505 - val_loss: 0.3507 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3303 - acc: 0.8557 - val_loss: 0.3467 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3264 - acc: 0.8608 - val_loss: 0.3435 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3216 - acc: 0.8711 - val_loss: 0.3417 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3168 - acc: 0.8711 - val_loss: 0.3411 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3128 - acc: 0.8711 - val_loss: 0.3404 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3084 - acc: 0.8763 - val_loss: 0.3369 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3047 - acc: 0.8763 - val_loss: 0.3360 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6656 - acc: 0.6114 - val_loss: 0.5283 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5247 - acc: 0.7824 - val_loss: 0.4452 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4440 - acc: 0.8394 - val_loss: 0.3866 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3935 - acc: 0.8394 - val_loss: 0.3510 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3630 - acc: 0.8653 - val_loss: 0.3353 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3471 - acc: 0.8808 - val_loss: 0.3253 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3365 - acc: 0.8808 - val_loss: 0.3262 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3259 - acc: 0.8705 - val_loss: 0.3243 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3180 - acc: 0.8705 - val_loss: 0.3263 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3116 - acc: 0.8756 - val_loss: 0.3232 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3039 - acc: 0.8756 - val_loss: 0.3208 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2977 - acc: 0.8860 - val_loss: 0.3183 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2910 - acc: 0.8860 - val_loss: 0.3170 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2872 - acc: 0.8964 - val_loss: 0.3269 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2827 - acc: 0.8964 - val_loss: 0.3233 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2786 - acc: 0.9016 - val_loss: 0.3189 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2744 - acc: 0.9016 - val_loss: 0.3194 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2701 - acc: 0.9016 - val_loss: 0.3204 - val_acc: 0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6621 - acc: 0.6010 - val_loss: 0.5293 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5174 - acc: 0.7979 - val_loss: 0.4425 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4462 - acc: 0.8083 - val_loss: 0.3916 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4031 - acc: 0.8290 - val_loss: 0.3656 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3804 - acc: 0.8238 - val_loss: 0.3527 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3626 - acc: 0.8446 - val_loss: 0.3455 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3492 - acc: 0.8394 - val_loss: 0.3424 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3382 - acc: 0.8446 - val_loss: 0.3416 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3283 - acc: 0.8497 - val_loss: 0.3378 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3201 - acc: 0.8705 - val_loss: 0.3419 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3137 - acc: 0.8705 - val_loss: 0.3422 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3083 - acc: 0.8756 - val_loss: 0.3428 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3032 - acc: 0.8705 - val_loss: 0.3511 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2994 - acc: 0.8808 - val_loss: 0.3503 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6950 - acc: 0.5464 - val_loss: 0.5528 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5280 - acc: 0.7938 - val_loss: 0.4411 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4390 - acc: 0.8454 - val_loss: 0.3807 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3912 - acc: 0.8608 - val_loss: 0.3499 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3619 - acc: 0.8660 - val_loss: 0.3395 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3441 - acc: 0.8711 - val_loss: 0.3358 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3310 - acc: 0.8814 - val_loss: 0.3342 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3197 - acc: 0.8763 - val_loss: 0.3293 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3105 - acc: 0.8814 - val_loss: 0.3242 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3021 - acc: 0.8866 - val_loss: 0.3197 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2947 - acc: 0.8866 - val_loss: 0.3171 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2881 - acc: 0.8763 - val_loss: 0.3115 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2832 - acc: 0.8866 - val_loss: 0.3067 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2784 - acc: 0.8866 - val_loss: 0.2996 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2730 - acc: 0.8866 - val_loss: 0.2987 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2709 - acc: 0.9021 - val_loss: 0.3006 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2662 - acc: 0.9021 - val_loss: 0.3046 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2592 - acc: 0.9072 - val_loss: 0.3086 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2535 - acc: 0.9021 - val_loss: 0.3126 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2485 - acc: 0.9021 - val_loss: 0.3154 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6570 - acc: 0.6134 - val_loss: 0.5413 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5002 - acc: 0.7990 - val_loss: 0.4308 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4240 - acc: 0.8144 - val_loss: 0.3841 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3896 - acc: 0.8196 - val_loss: 0.3614 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3689 - acc: 0.8247 - val_loss: 0.3536 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3561 - acc: 0.8351 - val_loss: 0.3500 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3479 - acc: 0.8351 - val_loss: 0.3552 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3426 - acc: 0.8557 - val_loss: 0.3644 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3364 - acc: 0.8454 - val_loss: 0.3651 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3319 - acc: 0.8505 - val_loss: 0.3645 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3263 - acc: 0.8505 - val_loss: 0.3585 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6250 - acc: 0.6649 - val_loss: 0.5093 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4928 - acc: 0.7835 - val_loss: 0.4159 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4242 - acc: 0.8247 - val_loss: 0.3750 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3926 - acc: 0.8402 - val_loss: 0.3563 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3717 - acc: 0.8454 - val_loss: 0.3431 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3564 - acc: 0.8454 - val_loss: 0.3353 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3446 - acc: 0.8557 - val_loss: 0.3353 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3362 - acc: 0.8608 - val_loss: 0.3362 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3278 - acc: 0.8608 - val_loss: 0.3360 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3203 - acc: 0.8608 - val_loss: 0.3369 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3130 - acc: 0.8711 - val_loss: 0.3419 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3056 - acc: 0.8763 - val_loss: 0.3397 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6243 - acc: 0.7150 - val_loss: 0.4408 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4481 - acc: 0.8342 - val_loss: 0.3680 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3813 - acc: 0.8549 - val_loss: 0.3323 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3546 - acc: 0.8497 - val_loss: 0.3162 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3375 - acc: 0.8497 - val_loss: 0.3105 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3226 - acc: 0.8497 - val_loss: 0.3107 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3125 - acc: 0.8756 - val_loss: 0.3071 - val_acc: 0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3029 - acc: 0.8756 - val_loss: 0.3005 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2936 - acc: 0.8705 - val_loss: 0.3004 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2846 - acc: 0.8705 - val_loss: 0.3134 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2768 - acc: 0.8808 - val_loss: 0.3190 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2687 - acc: 0.8964 - val_loss: 0.3324 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2673 - acc: 0.8912 - val_loss: 0.3331 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2598 - acc: 0.8964 - val_loss: 0.3228 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6027 - acc: 0.6995 - val_loss: 0.4556 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4427 - acc: 0.8238 - val_loss: 0.3702 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3855 - acc: 0.8342 - val_loss: 0.3389 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3589 - acc: 0.8290 - val_loss: 0.3310 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3435 - acc: 0.8342 - val_loss: 0.3307 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3306 - acc: 0.8394 - val_loss: 0.3270 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3184 - acc: 0.8446 - val_loss: 0.3176 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3096 - acc: 0.8705 - val_loss: 0.3144 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2982 - acc: 0.8860 - val_loss: 0.3172 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2988 - acc: 0.8808 - val_loss: 0.3277 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2950 - acc: 0.8808 - val_loss: 0.3332 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2913 - acc: 0.9016 - val_loss: 0.3344 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2831 - acc: 0.9016 - val_loss: 0.3295 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5808 - acc: 0.7371 - val_loss: 0.4223 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4220 - acc: 0.8402 - val_loss: 0.3565 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3697 - acc: 0.8505 - val_loss: 0.3378 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3458 - acc: 0.8608 - val_loss: 0.3364 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3335 - acc: 0.8608 - val_loss: 0.3344 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3200 - acc: 0.8660 - val_loss: 0.3256 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3076 - acc: 0.8814 - val_loss: 0.3112 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2978 - acc: 0.8814 - val_loss: 0.3009 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2893 - acc: 0.8866 - val_loss: 0.2960 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2820 - acc: 0.8918 - val_loss: 0.2949 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2736 - acc: 0.8918 - val_loss: 0.2969 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2656 - acc: 0.8918 - val_loss: 0.2990 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2604 - acc: 0.8866 - val_loss: 0.2988 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2575 - acc: 0.8918 - val_loss: 0.3019 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2494 - acc: 0.8969 - val_loss: 0.2962 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6158 - acc: 0.6804 - val_loss: 0.4528 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4479 - acc: 0.8196 - val_loss: 0.3703 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3926 - acc: 0.8351 - val_loss: 0.3362 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3702 - acc: 0.8454 - val_loss: 0.3198 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3534 - acc: 0.8454 - val_loss: 0.3171 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3408 - acc: 0.8505 - val_loss: 0.3219 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3280 - acc: 0.8608 - val_loss: 0.3248 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3187 - acc: 0.8557 - val_loss: 0.3257 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3080 - acc: 0.8660 - val_loss: 0.3294 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3028 - acc: 0.8660 - val_loss: 0.3252 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6048 - acc: 0.6907 - val_loss: 0.4750 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4436 - acc: 0.8351 - val_loss: 0.3862 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3846 - acc: 0.8402 - val_loss: 0.3540 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3589 - acc: 0.8454 - val_loss: 0.3479 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3471 - acc: 0.8505 - val_loss: 0.3455 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3296 - acc: 0.8505 - val_loss: 0.3329 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3194 - acc: 0.8608 - val_loss: 0.3238 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3103 - acc: 0.8660 - val_loss: 0.3194 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3043 - acc: 0.8660 - val_loss: 0.3236 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2944 - acc: 0.8763 - val_loss: 0.3304 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2880 - acc: 0.8814 - val_loss: 0.3429 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2846 - acc: 0.8969 - val_loss: 0.3486 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2796 - acc: 0.9021 - val_loss: 0.3462 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8784 - acc: 0.5078 - val_loss: 0.5640 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5491 - acc: 0.7098 - val_loss: 0.4171 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4399 - acc: 0.7617 - val_loss: 0.3790 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3901 - acc: 0.7876 - val_loss: 0.3669 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3671 - acc: 0.8238 - val_loss: 0.3561 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3512 - acc: 0.8342 - val_loss: 0.3504 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3408 - acc: 0.8290 - val_loss: 0.3496 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3306 - acc: 0.8446 - val_loss: 0.3456 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3226 - acc: 0.8549 - val_loss: 0.3375 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3123 - acc: 0.8653 - val_loss: 0.3291 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3029 - acc: 0.8808 - val_loss: 0.3291 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2938 - acc: 0.8756 - val_loss: 0.3275 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2880 - acc: 0.8912 - val_loss: 0.3270 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2863 - acc: 0.8964 - val_loss: 0.3240 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2801 - acc: 0.8912 - val_loss: 0.3143 - val_acc: 0.9180\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2779 - acc: 0.8808 - val_loss: 0.3126 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2743 - acc: 0.8964 - val_loss: 0.3129 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2718 - acc: 0.8912 - val_loss: 0.3124 - val_acc: 0.9344\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2718 - acc: 0.8912 - val_loss: 0.3272 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2753 - acc: 0.8912 - val_loss: 0.3381 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7422 - acc: 0.5440 - val_loss: 0.5660 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5147 - acc: 0.7720 - val_loss: 0.4261 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4371 - acc: 0.8135 - val_loss: 0.3694 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4046 - acc: 0.8497 - val_loss: 0.3483 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3884 - acc: 0.8394 - val_loss: 0.3456 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3774 - acc: 0.8342 - val_loss: 0.3492 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3687 - acc: 0.8394 - val_loss: 0.3435 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3610 - acc: 0.8394 - val_loss: 0.3355 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3516 - acc: 0.8394 - val_loss: 0.3377 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3435 - acc: 0.8497 - val_loss: 0.3334 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3347 - acc: 0.8549 - val_loss: 0.3307 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3296 - acc: 0.8705 - val_loss: 0.3443 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3280 - acc: 0.8653 - val_loss: 0.3477 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3245 - acc: 0.8653 - val_loss: 0.3453 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3171 - acc: 0.8653 - val_loss: 0.3389 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3085 - acc: 0.8808 - val_loss: 0.3363 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6722 - acc: 0.6031 - val_loss: 0.6128 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5446 - acc: 0.7680 - val_loss: 0.5462 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4789 - acc: 0.7835 - val_loss: 0.4806 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4231 - acc: 0.8196 - val_loss: 0.4321 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3824 - acc: 0.8557 - val_loss: 0.4046 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3545 - acc: 0.8557 - val_loss: 0.3940 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3350 - acc: 0.8660 - val_loss: 0.3885 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3223 - acc: 0.8763 - val_loss: 0.3932 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3120 - acc: 0.8763 - val_loss: 0.3959 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3036 - acc: 0.8866 - val_loss: 0.3955 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2962 - acc: 0.8918 - val_loss: 0.3932 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2907 - acc: 0.8918 - val_loss: 0.3817 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2795 - acc: 0.8918 - val_loss: 0.3722 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2701 - acc: 0.8866 - val_loss: 0.3662 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2581 - acc: 0.8814 - val_loss: 0.3614 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2559 - acc: 0.8814 - val_loss: 0.3658 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2510 - acc: 0.8866 - val_loss: 0.3696 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2456 - acc: 0.8918 - val_loss: 0.3730 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2387 - acc: 0.8918 - val_loss: 0.3757 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2333 - acc: 0.8866 - val_loss: 0.3783 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6050 - acc: 0.6804 - val_loss: 0.4881 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4666 - acc: 0.7887 - val_loss: 0.4164 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4068 - acc: 0.7990 - val_loss: 0.3794 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3708 - acc: 0.8351 - val_loss: 0.3598 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3467 - acc: 0.8454 - val_loss: 0.3505 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3259 - acc: 0.8608 - val_loss: 0.3313 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3168 - acc: 0.8866 - val_loss: 0.3282 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3080 - acc: 0.8866 - val_loss: 0.3300 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3001 - acc: 0.8814 - val_loss: 0.3319 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2899 - acc: 0.8866 - val_loss: 0.3546 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2859 - acc: 0.8866 - val_loss: 0.3678 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2790 - acc: 0.8866 - val_loss: 0.3674 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7112 - acc: 0.6186 - val_loss: 0.5252 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4898 - acc: 0.7680 - val_loss: 0.4277 - val_acc: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4029 - acc: 0.8196 - val_loss: 0.3925 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3666 - acc: 0.8299 - val_loss: 0.3746 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3416 - acc: 0.8454 - val_loss: 0.3543 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3270 - acc: 0.8608 - val_loss: 0.3459 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3116 - acc: 0.8557 - val_loss: 0.3488 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3028 - acc: 0.8505 - val_loss: 0.3519 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2919 - acc: 0.8505 - val_loss: 0.3557 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2814 - acc: 0.8608 - val_loss: 0.3558 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2769 - acc: 0.8763 - val_loss: 0.3692 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7251 - acc: 0.6218 - val_loss: 0.5229 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4485 - acc: 0.8135 - val_loss: 0.3858 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3918 - acc: 0.8238 - val_loss: 0.3376 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3669 - acc: 0.8342 - val_loss: 0.3203 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3394 - acc: 0.8497 - val_loss: 0.3256 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3191 - acc: 0.8549 - val_loss: 0.3272 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3076 - acc: 0.8653 - val_loss: 0.3244 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2955 - acc: 0.8808 - val_loss: 0.3213 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2857 - acc: 0.8860 - val_loss: 0.3161 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2761 - acc: 0.8860 - val_loss: 0.3192 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2725 - acc: 0.8860 - val_loss: 0.3521 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2719 - acc: 0.8808 - val_loss: 0.3576 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2670 - acc: 0.8912 - val_loss: 0.3429 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2593 - acc: 0.8860 - val_loss: 0.3332 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7125 - acc: 0.5803 - val_loss: 0.4434 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4405 - acc: 0.8083 - val_loss: 0.3498 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3893 - acc: 0.8083 - val_loss: 0.3196 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3639 - acc: 0.8238 - val_loss: 0.3002 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3425 - acc: 0.8342 - val_loss: 0.2968 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3227 - acc: 0.8394 - val_loss: 0.3019 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3042 - acc: 0.8601 - val_loss: 0.3109 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2882 - acc: 0.8705 - val_loss: 0.3192 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2771 - acc: 0.8860 - val_loss: 0.3363 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2783 - acc: 0.8964 - val_loss: 0.3479 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7815 - acc: 0.5567 - val_loss: 0.5432 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4871 - acc: 0.8402 - val_loss: 0.3993 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3932 - acc: 0.8505 - val_loss: 0.3546 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3583 - acc: 0.8505 - val_loss: 0.3543 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3389 - acc: 0.8557 - val_loss: 0.3690 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3253 - acc: 0.8557 - val_loss: 0.3768 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3170 - acc: 0.8608 - val_loss: 0.3819 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3065 - acc: 0.8660 - val_loss: 0.3763 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2959 - acc: 0.8711 - val_loss: 0.3686 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5881 - acc: 0.6753 - val_loss: 0.5138 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4104 - acc: 0.8402 - val_loss: 0.4729 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3783 - acc: 0.8608 - val_loss: 0.4520 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3594 - acc: 0.8557 - val_loss: 0.4158 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3400 - acc: 0.8608 - val_loss: 0.3795 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3235 - acc: 0.8608 - val_loss: 0.3635 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3140 - acc: 0.8660 - val_loss: 0.3651 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3007 - acc: 0.8814 - val_loss: 0.3794 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2941 - acc: 0.8814 - val_loss: 0.3890 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2819 - acc: 0.8918 - val_loss: 0.3761 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2706 - acc: 0.8969 - val_loss: 0.3691 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8135 - acc: 0.5619 - val_loss: 0.5316 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4750 - acc: 0.7784 - val_loss: 0.4339 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4090 - acc: 0.8351 - val_loss: 0.4167 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3838 - acc: 0.8351 - val_loss: 0.4150 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3646 - acc: 0.8557 - val_loss: 0.3959 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3464 - acc: 0.8505 - val_loss: 0.3741 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3318 - acc: 0.8454 - val_loss: 0.3672 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3214 - acc: 0.8660 - val_loss: 0.3510 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3129 - acc: 0.8660 - val_loss: 0.3383 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3016 - acc: 0.8711 - val_loss: 0.3349 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2952 - acc: 0.8866 - val_loss: 0.3298 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2851 - acc: 0.8866 - val_loss: 0.3301 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2764 - acc: 0.8866 - val_loss: 0.3376 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2692 - acc: 0.9021 - val_loss: 0.3380 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2616 - acc: 0.9021 - val_loss: 0.3460 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2546 - acc: 0.9072 - val_loss: 0.3521 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6734 - acc: 0.5803 - val_loss: 0.3815 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3703 - acc: 0.8342 - val_loss: 0.3181 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3385 - acc: 0.8446 - val_loss: 0.2997 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3328 - acc: 0.8497 - val_loss: 0.3145 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3129 - acc: 0.8653 - val_loss: 0.3243 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2946 - acc: 0.8912 - val_loss: 0.3459 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2841 - acc: 0.8860 - val_loss: 0.3503 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2857 - acc: 0.8912 - val_loss: 0.3443 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5171 - acc: 0.7513 - val_loss: 0.3142 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3908 - acc: 0.8187 - val_loss: 0.3027 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3503 - acc: 0.8394 - val_loss: 0.2879 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3179 - acc: 0.8549 - val_loss: 0.2847 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2998 - acc: 0.8549 - val_loss: 0.2829 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2818 - acc: 0.8653 - val_loss: 0.2761 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2816 - acc: 0.8601 - val_loss: 0.2899 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2636 - acc: 0.8705 - val_loss: 0.3146 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2460 - acc: 0.8964 - val_loss: 0.3329 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2303 - acc: 0.9119 - val_loss: 0.3370 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2244 - acc: 0.9119 - val_loss: 0.3386 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5314 - acc: 0.7268 - val_loss: 0.3634 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3537 - acc: 0.8608 - val_loss: 0.3505 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3349 - acc: 0.8557 - val_loss: 0.3337 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3082 - acc: 0.8814 - val_loss: 0.3334 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3018 - acc: 0.8814 - val_loss: 0.3284 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2853 - acc: 0.8814 - val_loss: 0.3311 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2707 - acc: 0.8866 - val_loss: 0.3545 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2619 - acc: 0.9021 - val_loss: 0.3567 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2507 - acc: 0.9021 - val_loss: 0.3461 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2425 - acc: 0.9021 - val_loss: 0.3396 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6734 - acc: 0.6186 - val_loss: 0.3907 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4053 - acc: 0.8093 - val_loss: 0.3269 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3689 - acc: 0.8454 - val_loss: 0.3237 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3509 - acc: 0.8608 - val_loss: 0.3308 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3316 - acc: 0.8557 - val_loss: 0.3446 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3186 - acc: 0.8660 - val_loss: 0.3586 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3044 - acc: 0.8763 - val_loss: 0.3828 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2945 - acc: 0.8918 - val_loss: 0.3835 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6130 - acc: 0.7010 - val_loss: 0.4375 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3895 - acc: 0.8196 - val_loss: 0.4108 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3588 - acc: 0.8454 - val_loss: 0.3999 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3432 - acc: 0.8608 - val_loss: 0.3997 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3262 - acc: 0.8608 - val_loss: 0.4066 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3083 - acc: 0.8814 - val_loss: 0.4115 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2910 - acc: 0.8969 - val_loss: 0.4308 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2778 - acc: 0.9021 - val_loss: 0.4294 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2664 - acc: 0.9124 - val_loss: 0.4218 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4966 - acc: 0.7720 - val_loss: 0.3335 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3399 - acc: 0.8446 - val_loss: 0.3638 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3077 - acc: 0.8653 - val_loss: 0.3557 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2685 - acc: 0.9016 - val_loss: 0.3250 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2464 - acc: 0.8964 - val_loss: 0.3236 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2575 - acc: 0.8964 - val_loss: 0.3467 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2467 - acc: 0.9171 - val_loss: 0.3678 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2371 - acc: 0.9171 - val_loss: 0.3847 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2135 - acc: 0.9119 - val_loss: 0.3939 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2006 - acc: 0.9171 - val_loss: 0.3981 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5368 - acc: 0.7047 - val_loss: 0.3614 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3743 - acc: 0.8497 - val_loss: 0.3712 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3278 - acc: 0.8549 - val_loss: 0.3356 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2911 - acc: 0.8756 - val_loss: 0.3150 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2624 - acc: 0.8912 - val_loss: 0.3248 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2460 - acc: 0.9067 - val_loss: 0.3527 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2275 - acc: 0.9223 - val_loss: 0.3755 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2057 - acc: 0.9326 - val_loss: 0.3673 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1895 - acc: 0.9430 - val_loss: 0.3747 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5862 - acc: 0.6701 - val_loss: 0.3623 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3673 - acc: 0.8402 - val_loss: 0.3478 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3330 - acc: 0.8711 - val_loss: 0.3377 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2888 - acc: 0.8866 - val_loss: 0.3384 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2777 - acc: 0.8660 - val_loss: 0.3521 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2600 - acc: 0.9021 - val_loss: 0.3566 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2499 - acc: 0.9072 - val_loss: 0.3486 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2310 - acc: 0.9072 - val_loss: 0.3453 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6362 - acc: 0.6237 - val_loss: 0.3589 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3864 - acc: 0.7938 - val_loss: 0.3460 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3678 - acc: 0.8196 - val_loss: 0.3454 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3420 - acc: 0.8454 - val_loss: 0.3374 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3120 - acc: 0.8660 - val_loss: 0.3463 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2944 - acc: 0.8969 - val_loss: 0.3706 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2928 - acc: 0.8763 - val_loss: 0.3792 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2833 - acc: 0.8763 - val_loss: 0.3742 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2834 - acc: 0.8660 - val_loss: 0.3642 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5025 - acc: 0.7474 - val_loss: 0.3343 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3676 - acc: 0.8454 - val_loss: 0.3487 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3311 - acc: 0.8454 - val_loss: 0.3736 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2948 - acc: 0.8814 - val_loss: 0.3630 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2794 - acc: 0.9021 - val_loss: 0.3686 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2649 - acc: 0.9021 - val_loss: 0.3683 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4927 - acc: 0.7772 - val_loss: 0.3514 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3464 - acc: 0.8497 - val_loss: 0.3551 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3247 - acc: 0.8808 - val_loss: 0.4106 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2928 - acc: 0.8964 - val_loss: 0.3707 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2789 - acc: 0.8808 - val_loss: 0.3966 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2837 - acc: 0.8912 - val_loss: 0.3946 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4319 - acc: 0.8135 - val_loss: 0.3300 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3374 - acc: 0.8653 - val_loss: 0.3698 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2898 - acc: 0.8860 - val_loss: 0.3506 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2571 - acc: 0.9016 - val_loss: 0.3519 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2266 - acc: 0.9119 - val_loss: 0.3671 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2180 - acc: 0.9275 - val_loss: 0.4232 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5118 - acc: 0.7474 - val_loss: 0.3057 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3395 - acc: 0.8557 - val_loss: 0.3357 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3015 - acc: 0.8763 - val_loss: 0.3507 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2755 - acc: 0.8969 - val_loss: 0.3825 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2757 - acc: 0.8969 - val_loss: 0.3841 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2459 - acc: 0.9175 - val_loss: 0.3605 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4772 - acc: 0.7474 - val_loss: 0.3860 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3760 - acc: 0.8454 - val_loss: 0.3632 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3185 - acc: 0.8763 - val_loss: 0.3739 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2986 - acc: 0.8763 - val_loss: 0.4032 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2776 - acc: 0.8969 - val_loss: 0.3534 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2571 - acc: 0.8969 - val_loss: 0.3756 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2406 - acc: 0.9124 - val_loss: 0.4048 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2219 - acc: 0.9278 - val_loss: 0.4053 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2125 - acc: 0.9175 - val_loss: 0.3896 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1859 - acc: 0.9433 - val_loss: 0.4057 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5252 - acc: 0.7423 - val_loss: 0.3935 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3648 - acc: 0.8351 - val_loss: 0.4190 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3344 - acc: 0.8505 - val_loss: 0.3653 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3347 - acc: 0.8505 - val_loss: 0.3368 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3076 - acc: 0.8866 - val_loss: 0.3315 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2783 - acc: 0.8918 - val_loss: 0.3213 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2824 - acc: 0.8763 - val_loss: 0.3868 - val_acc: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2660 - acc: 0.8918 - val_loss: 0.4025 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2359 - acc: 0.9175 - val_loss: 0.4022 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2232 - acc: 0.9227 - val_loss: 0.4354 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2124 - acc: 0.9227 - val_loss: 0.4107 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4733 - acc: 0.7979 - val_loss: 0.3594 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3619 - acc: 0.8497 - val_loss: 0.3920 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3154 - acc: 0.8705 - val_loss: 0.3347 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2746 - acc: 0.8705 - val_loss: 0.3209 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2305 - acc: 0.9067 - val_loss: 0.3671 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2271 - acc: 0.9326 - val_loss: 0.4536 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2260 - acc: 0.9275 - val_loss: 0.4038 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1849 - acc: 0.9326 - val_loss: 0.3687 - val_acc: 0.9180\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1624 - acc: 0.9482 - val_loss: 0.3925 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4881 - acc: 0.7513 - val_loss: 0.3397 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3366 - acc: 0.8601 - val_loss: 0.2995 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2770 - acc: 0.8912 - val_loss: 0.2903 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2503 - acc: 0.9016 - val_loss: 0.3382 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2242 - acc: 0.9223 - val_loss: 0.3743 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1911 - acc: 0.9223 - val_loss: 0.3795 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1769 - acc: 0.9430 - val_loss: 0.3928 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1658 - acc: 0.9378 - val_loss: 0.4286 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4553 - acc: 0.7990 - val_loss: 0.4114 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3811 - acc: 0.8711 - val_loss: 0.4283 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2652 - acc: 0.8866 - val_loss: 0.3467 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2782 - acc: 0.8918 - val_loss: 0.3747 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2339 - acc: 0.8969 - val_loss: 0.4040 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2207 - acc: 0.9124 - val_loss: 0.4326 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1953 - acc: 0.9175 - val_loss: 0.3982 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1938 - acc: 0.9124 - val_loss: 0.3748 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4793 - acc: 0.7371 - val_loss: 0.4156 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3587 - acc: 0.8608 - val_loss: 0.4223 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3161 - acc: 0.8505 - val_loss: 0.3674 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2638 - acc: 0.8763 - val_loss: 0.3926 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2362 - acc: 0.9072 - val_loss: 0.4049 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1963 - acc: 0.9330 - val_loss: 0.3936 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1790 - acc: 0.9381 - val_loss: 0.4374 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1995 - acc: 0.9278 - val_loss: 0.4779 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5399 - acc: 0.7216 - val_loss: 0.3383 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3469 - acc: 0.8608 - val_loss: 0.4012 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2915 - acc: 0.8763 - val_loss: 0.4058 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2592 - acc: 0.8969 - val_loss: 0.4145 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2329 - acc: 0.9072 - val_loss: 0.4462 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1981 - acc: 0.9175 - val_loss: 0.4812 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4468 - acc: 0.7927 - val_loss: 0.3368 - val_acc: 0.9180\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3535 - acc: 0.8653 - val_loss: 0.3661 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2865 - acc: 0.8860 - val_loss: 0.4593 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2438 - acc: 0.9119 - val_loss: 0.3550 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2066 - acc: 0.9326 - val_loss: 0.3571 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1741 - acc: 0.9378 - val_loss: 0.4025 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4881 - acc: 0.7565 - val_loss: 0.3166 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3239 - acc: 0.8549 - val_loss: 0.3630 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2550 - acc: 0.9067 - val_loss: 0.4059 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2256 - acc: 0.9275 - val_loss: 0.4908 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1940 - acc: 0.9275 - val_loss: 0.4741 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1438 - acc: 0.9430 - val_loss: 0.5006 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4878 - acc: 0.7526 - val_loss: 0.3790 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3498 - acc: 0.8454 - val_loss: 0.3708 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2817 - acc: 0.8866 - val_loss: 0.3320 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2400 - acc: 0.9021 - val_loss: 0.3233 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2302 - acc: 0.9021 - val_loss: 0.3974 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1860 - acc: 0.9227 - val_loss: 0.3897 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2505 - acc: 0.8969 - val_loss: 0.3735 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1979 - acc: 0.9227 - val_loss: 0.5285 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1698 - acc: 0.9227 - val_loss: 0.5673 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5286 - acc: 0.6856 - val_loss: 0.3488 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3606 - acc: 0.8505 - val_loss: 0.2989 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3049 - acc: 0.8660 - val_loss: 0.3393 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2535 - acc: 0.8918 - val_loss: 0.3900 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2240 - acc: 0.8969 - val_loss: 0.4045 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2022 - acc: 0.9175 - val_loss: 0.4340 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2032 - acc: 0.9175 - val_loss: 0.4234 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4649 - acc: 0.7784 - val_loss: 0.4110 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3798 - acc: 0.8454 - val_loss: 0.3871 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2855 - acc: 0.8711 - val_loss: 0.3754 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2433 - acc: 0.8918 - val_loss: 0.4427 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2065 - acc: 0.9278 - val_loss: 0.5093 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1740 - acc: 0.9381 - val_loss: 0.5705 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1745 - acc: 0.9588 - val_loss: 0.6211 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1415 - acc: 0.9742 - val_loss: 0.5550 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4823 - acc: 0.7927 - val_loss: 0.3015 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3694 - acc: 0.8446 - val_loss: 0.2865 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3629 - acc: 0.8135 - val_loss: 0.2738 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3559 - acc: 0.8497 - val_loss: 0.3616 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3489 - acc: 0.8808 - val_loss: 0.4448 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3345 - acc: 0.8756 - val_loss: 0.4310 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3148 - acc: 0.8705 - val_loss: 0.4724 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2698 - acc: 0.8808 - val_loss: 0.3697 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5143 - acc: 0.7772 - val_loss: 0.3819 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4049 - acc: 0.8238 - val_loss: 0.3171 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3730 - acc: 0.8187 - val_loss: 0.4367 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3406 - acc: 0.8446 - val_loss: 0.4447 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3384 - acc: 0.8446 - val_loss: 0.5482 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3009 - acc: 0.8653 - val_loss: 0.6332 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4970 - acc: 0.8187 - val_loss: 0.9517 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5879 - acc: 0.7526 - val_loss: 0.3206 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3855 - acc: 0.8454 - val_loss: 0.4190 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3295 - acc: 0.8557 - val_loss: 0.3087 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3470 - acc: 0.8454 - val_loss: 0.2926 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3068 - acc: 0.8660 - val_loss: 0.3508 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3080 - acc: 0.8557 - val_loss: 0.3951 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2891 - acc: 0.8557 - val_loss: 0.3898 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3123 - acc: 0.8608 - val_loss: 0.4276 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3407 - acc: 0.8660 - val_loss: 0.4208 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5073 - acc: 0.7732 - val_loss: 0.3562 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4102 - acc: 0.8093 - val_loss: 0.4446 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3576 - acc: 0.8660 - val_loss: 0.4998 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2926 - acc: 0.8505 - val_loss: 0.3437 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3086 - acc: 0.8763 - val_loss: 0.3604 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2551 - acc: 0.8814 - val_loss: 0.4913 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2328 - acc: 0.8866 - val_loss: 0.5097 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2069 - acc: 0.9021 - val_loss: 0.5227 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1917 - acc: 0.9124 - val_loss: 0.5638 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4978 - acc: 0.7732 - val_loss: 0.4026 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3658 - acc: 0.8247 - val_loss: 0.3358 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3396 - acc: 0.8351 - val_loss: 0.3743 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3148 - acc: 0.8505 - val_loss: 0.4285 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3002 - acc: 0.8814 - val_loss: 0.4481 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3037 - acc: 0.8763 - val_loss: 0.4824 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3102 - acc: 0.8660 - val_loss: 0.4671 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6971 - acc: 0.7617 - val_loss: 0.3506 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4156 - acc: 0.8187 - val_loss: 0.3956 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3386 - acc: 0.8497 - val_loss: 0.6231 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3943 - acc: 0.8446 - val_loss: 0.6014 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3000 - acc: 0.8705 - val_loss: 0.5117 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3918 - acc: 0.8549 - val_loss: 0.5452 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5552 - acc: 0.7668 - val_loss: 0.3841 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3688 - acc: 0.8394 - val_loss: 0.5349 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3321 - acc: 0.8497 - val_loss: 0.3766 - val_acc: 0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2854 - acc: 0.8808 - val_loss: 0.4773 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2314 - acc: 0.8912 - val_loss: 0.4653 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2364 - acc: 0.8964 - val_loss: 0.5459 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1843 - acc: 0.9171 - val_loss: 0.6206 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1400 - acc: 0.9275 - val_loss: 0.6999 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5570 - acc: 0.7680 - val_loss: 0.3220 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3513 - acc: 0.8402 - val_loss: 0.5956 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3912 - acc: 0.8660 - val_loss: 0.4845 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3320 - acc: 0.8454 - val_loss: 0.3760 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3098 - acc: 0.8557 - val_loss: 0.4700 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2765 - acc: 0.8660 - val_loss: 0.6367 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5159 - acc: 0.7474 - val_loss: 0.3388 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4002 - acc: 0.8402 - val_loss: 0.3867 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3114 - acc: 0.8608 - val_loss: 0.3878 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3297 - acc: 0.8608 - val_loss: 0.6156 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3187 - acc: 0.8454 - val_loss: 0.5127 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2612 - acc: 0.8814 - val_loss: 0.5258 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5229 - acc: 0.7680 - val_loss: 0.3770 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3803 - acc: 0.8711 - val_loss: 0.5057 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3064 - acc: 0.8866 - val_loss: 0.4702 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2888 - acc: 0.8969 - val_loss: 0.6948 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3105 - acc: 0.8866 - val_loss: 0.6538 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3063 - acc: 0.8814 - val_loss: 0.6398 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6260 - acc: 0.6995 - val_loss: 0.8102 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6374 - acc: 0.8187 - val_loss: 0.7682 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8394 - acc: 0.7617 - val_loss: 0.7509 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6486 - acc: 0.7772 - val_loss: 0.6753 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4833 - acc: 0.8290 - val_loss: 0.6902 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6721 - acc: 0.8135 - val_loss: 0.9123 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8823 - acc: 0.7979 - val_loss: 0.6480 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7947 - acc: 0.8187 - val_loss: 0.7385 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5168 - acc: 0.8808 - val_loss: 0.7599 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3564 - acc: 0.9067 - val_loss: 0.7058 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2209 - acc: 0.9482 - val_loss: 0.8020 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1821 - acc: 0.9585 - val_loss: 0.8773 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6883 - acc: 0.7254 - val_loss: 0.2878 - val_acc: 0.9180\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3887 - acc: 0.8238 - val_loss: 0.3248 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4393 - acc: 0.8549 - val_loss: 0.7460 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3767 - acc: 0.8342 - val_loss: 0.5936 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3002 - acc: 0.8705 - val_loss: 0.5834 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3346 - acc: 0.8446 - val_loss: 0.6323 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5677 - acc: 0.7887 - val_loss: 0.4801 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3424 - acc: 0.8660 - val_loss: 0.3078 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4958 - acc: 0.7835 - val_loss: 0.3048 - val_acc: 0.9180\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5403 - acc: 0.8402 - val_loss: 0.5944 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4119 - acc: 0.9021 - val_loss: 0.9098 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4792 - acc: 0.8402 - val_loss: 0.7682 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3027 - acc: 0.8660 - val_loss: 0.5673 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2672 - acc: 0.8763 - val_loss: 0.5487 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6824 - acc: 0.7216 - val_loss: 0.3968 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5454 - acc: 0.7629 - val_loss: 0.4493 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4097 - acc: 0.8351 - val_loss: 0.3347 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3531 - acc: 0.8351 - val_loss: 0.3720 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2879 - acc: 0.8763 - val_loss: 0.4873 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2472 - acc: 0.8866 - val_loss: 0.5817 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2396 - acc: 0.9175 - val_loss: 0.6420 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1854 - acc: 0.9227 - val_loss: 0.7856 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5726 - acc: 0.7629 - val_loss: 0.7871 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8637 - acc: 0.5928 - val_loss: 0.3922 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4641 - acc: 0.8351 - val_loss: 0.7870 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4165 - acc: 0.8763 - val_loss: 0.6077 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3234 - acc: 0.8660 - val_loss: 0.5964 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2708 - acc: 0.8918 - val_loss: 0.5905 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2270 - acc: 0.9124 - val_loss: 0.6213 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7907 - acc: 0.7150 - val_loss: 0.8331 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6712 - acc: 0.7772 - val_loss: 1.0324 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4104 - acc: 0.8912 - val_loss: 0.6331 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2581 - acc: 0.8860 - val_loss: 0.3792 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5284 - acc: 0.8290 - val_loss: 0.7297 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4651 - acc: 0.8446 - val_loss: 0.6117 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3789 - acc: 0.9067 - val_loss: 0.6222 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2429 - acc: 0.9326 - val_loss: 0.6848 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1729 - acc: 0.9326 - val_loss: 0.6802 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.7057 - acc: 0.7098 - val_loss: 2.3037 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8110 - acc: 0.8031 - val_loss: 1.1372 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8262 - acc: 0.8187 - val_loss: 0.6696 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4605 - acc: 0.8135 - val_loss: 0.5652 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3649 - acc: 0.8446 - val_loss: 0.7085 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3280 - acc: 0.8705 - val_loss: 0.5311 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1652 - acc: 0.9275 - val_loss: 0.5588 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2144 - acc: 0.9378 - val_loss: 0.7430 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1694 - acc: 0.9482 - val_loss: 0.9081 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1309 - acc: 0.9430 - val_loss: 1.0753 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0999 - acc: 0.9741 - val_loss: 1.1469 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6223 - acc: 0.7216 - val_loss: 0.4772 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4497 - acc: 0.8454 - val_loss: 0.4205 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2930 - acc: 0.8763 - val_loss: 0.6227 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3181 - acc: 0.8763 - val_loss: 0.8319 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2422 - acc: 0.9021 - val_loss: 0.7536 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3341 - acc: 0.8866 - val_loss: 0.8958 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2393 - acc: 0.9021 - val_loss: 0.9835 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7228 - acc: 0.6959 - val_loss: 0.5872 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7708 - acc: 0.7320 - val_loss: 0.4639 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4166 - acc: 0.8454 - val_loss: 0.4371 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3379 - acc: 0.8660 - val_loss: 0.4262 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2427 - acc: 0.9021 - val_loss: 0.6098 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2024 - acc: 0.9175 - val_loss: 0.6876 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1412 - acc: 0.9330 - val_loss: 0.7904 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1579 - acc: 0.9485 - val_loss: 0.8552 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1296 - acc: 0.9485 - val_loss: 1.0214 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7525 - acc: 0.7113 - val_loss: 0.6772 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6943 - acc: 0.7577 - val_loss: 0.7544 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6368 - acc: 0.8557 - val_loss: 0.5868 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4285 - acc: 0.8144 - val_loss: 0.8414 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3063 - acc: 0.8763 - val_loss: 0.6393 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5866 - acc: 0.8247 - val_loss: 0.7155 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3013 - acc: 0.9021 - val_loss: 0.7821 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3470 - acc: 0.9072 - val_loss: 1.2226 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9474 - acc: 0.7306 - val_loss: 0.4203 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0498 - acc: 0.8549 - val_loss: 0.9999 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0096 - acc: 0.7668 - val_loss: 1.1270 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6185 - acc: 0.8290 - val_loss: 1.2825 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6628 - acc: 0.8756 - val_loss: 1.0025 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9041 - acc: 0.8394 - val_loss: 2.0079 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7873 - acc: 0.7047 - val_loss: 0.6844 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8593 - acc: 0.8083 - val_loss: 0.5564 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6016 - acc: 0.8238 - val_loss: 1.7613 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8674 - acc: 0.8394 - val_loss: 0.8083 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4076 - acc: 0.8808 - val_loss: 1.6857 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4306 - acc: 0.8964 - val_loss: 1.2585 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4147 - acc: 0.9119 - val_loss: 1.7786 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0285 - acc: 0.7010 - val_loss: 1.3939 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0661 - acc: 0.8454 - val_loss: 1.3626 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6209 - acc: 0.8351 - val_loss: 0.9431 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5243 - acc: 0.8505 - val_loss: 0.8793 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3275 - acc: 0.8918 - val_loss: 0.8089 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2588 - acc: 0.9227 - val_loss: 0.9531 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4622 - acc: 0.9124 - val_loss: 1.4107 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4931 - acc: 0.8969 - val_loss: 1.8747 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4916 - acc: 0.8969 - val_loss: 1.4902 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3113 - acc: 0.9227 - val_loss: 1.0669 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6852 - acc: 0.7526 - val_loss: 0.8139 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8931 - acc: 0.8093 - val_loss: 0.8318 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6244 - acc: 0.8196 - val_loss: 0.9236 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6353 - acc: 0.8660 - val_loss: 0.8566 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3328 - acc: 0.8505 - val_loss: 0.9360 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3427 - acc: 0.8763 - val_loss: 0.5745 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5498 - acc: 0.8711 - val_loss: 1.6734 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5110 - acc: 0.8918 - val_loss: 1.6706 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4591 - acc: 0.9072 - val_loss: 1.9064 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3831 - acc: 0.9072 - val_loss: 1.4540 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2346 - acc: 0.9278 - val_loss: 1.5085 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.1263 - acc: 0.6907 - val_loss: 1.3469 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2678 - acc: 0.7990 - val_loss: 1.3779 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9171 - acc: 0.8196 - val_loss: 0.7638 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5006 - acc: 0.8196 - val_loss: 0.7221 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4043 - acc: 0.8608 - val_loss: 0.7112 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3320 - acc: 0.8763 - val_loss: 0.5953 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3815 - acc: 0.7990 - val_loss: 1.1398 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8475 - acc: 0.8454 - val_loss: 1.7239 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5914 - acc: 0.8763 - val_loss: 1.2314 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2302 - acc: 0.9330 - val_loss: 1.5661 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2835 - acc: 0.9330 - val_loss: 1.7690 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.2775 - acc: 0.6943 - val_loss: 1.4357 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9993 - acc: 0.8238 - val_loss: 0.8177 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8151 - acc: 0.8446 - val_loss: 0.4705 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5047 - acc: 0.8912 - val_loss: 0.6170 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5468 - acc: 0.8860 - val_loss: 0.7975 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3015 - acc: 0.9223 - val_loss: 0.8367 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2108 - acc: 0.9326 - val_loss: 0.6572 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5575 - acc: 0.8912 - val_loss: 2.7387 - val_acc: 0.7213\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.0169 - acc: 0.6788 - val_loss: 0.9274 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2413 - acc: 0.8031 - val_loss: 1.1211 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6127 - acc: 0.8290 - val_loss: 1.2314 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3979 - acc: 0.8446 - val_loss: 0.9299 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2432 - acc: 0.8964 - val_loss: 1.2847 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1037 - acc: 0.9585 - val_loss: 1.2457 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.2688 - acc: 0.6907 - val_loss: 1.3709 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2171 - acc: 0.8144 - val_loss: 5.2829 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3509 - acc: 0.7526 - val_loss: 3.5327 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9966 - acc: 0.8660 - val_loss: 3.5846 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1773 - acc: 0.8351 - val_loss: 3.0603 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8670 - acc: 0.8711 - val_loss: 3.7922 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.0001 - acc: 0.6031 - val_loss: 1.8385 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7015 - acc: 0.7990 - val_loss: 1.7929 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9133 - acc: 0.7165 - val_loss: 1.8292 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7861 - acc: 0.8247 - val_loss: 2.6359 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0978 - acc: 0.8299 - val_loss: 2.1317 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5161 - acc: 0.8093 - val_loss: 2.7319 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0379 - acc: 0.8918 - val_loss: 3.3349 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.3022 - acc: 0.6753 - val_loss: 1.6480 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2951 - acc: 0.8299 - val_loss: 3.0094 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2114 - acc: 0.8144 - val_loss: 2.0089 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1485 - acc: 0.8196 - val_loss: 1.1416 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9646 - acc: 0.8505 - val_loss: 1.7355 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6557 - acc: 0.8814 - val_loss: 1.8183 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3156 - acc: 0.9278 - val_loss: 2.7169 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4298 - acc: 0.9124 - val_loss: 1.3399 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4914 - acc: 0.8814 - val_loss: 1.6794 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.3850 - acc: 0.7150 - val_loss: 2.5772 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0128 - acc: 0.8135 - val_loss: 3.7640 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9546 - acc: 0.7306 - val_loss: 3.9053 - val_acc: 0.8033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5457 - acc: 0.7565 - val_loss: 2.3543 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5695 - acc: 0.8446 - val_loss: 4.6076 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6427 - acc: 0.8549 - val_loss: 3.6073 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1892 - acc: 0.8290 - val_loss: 2.9071 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8152 - acc: 0.8808 - val_loss: 4.2013 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2758 - acc: 0.9223 - val_loss: 3.6369 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.2836 - acc: 0.6891 - val_loss: 2.6354 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7345 - acc: 0.6891 - val_loss: 1.8025 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7179 - acc: 0.8238 - val_loss: 2.2020 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3630 - acc: 0.8342 - val_loss: 5.8519 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6613 - acc: 0.6995 - val_loss: 2.1501 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8473 - acc: 0.8238 - val_loss: 5.8414 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6344 - acc: 0.8912 - val_loss: 6.0851 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.6094 - acc: 0.7320 - val_loss: 2.1683 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5478 - acc: 0.8093 - val_loss: 3.2298 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.7607 - acc: 0.7680 - val_loss: 3.3133 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0070 - acc: 0.8608 - val_loss: 4.4029 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5128 - acc: 0.8557 - val_loss: 6.1214 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.5493 - acc: 0.8763 - val_loss: 7.6509 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.7550 - acc: 0.7113 - val_loss: 3.3318 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2056 - acc: 0.7938 - val_loss: 1.4043 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1237 - acc: 0.7784 - val_loss: 2.9225 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9429 - acc: 0.8454 - val_loss: 2.3841 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9212 - acc: 0.8093 - val_loss: 2.4111 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9823 - acc: 0.8918 - val_loss: 2.3700 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5238 - acc: 0.9124 - val_loss: 2.2416 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3.3452 - acc: 0.7062 - val_loss: 2.6862 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1517 - acc: 0.8247 - val_loss: 3.5553 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9852 - acc: 0.7320 - val_loss: 1.5017 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7268 - acc: 0.7835 - val_loss: 3.1906 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5886 - acc: 0.8660 - val_loss: 4.0348 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9475 - acc: 0.8093 - val_loss: 6.0661 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0169 - acc: 0.8144 - val_loss: 11.2033 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1937 - acc: 0.8711 - val_loss: 8.8456 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5392 - acc: 0.7461 - val_loss: 0.5698 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4742 - acc: 0.8290 - val_loss: 0.3301 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4222 - acc: 0.8549 - val_loss: 0.5232 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3233 - acc: 0.8860 - val_loss: 0.5815 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4699 - acc: 0.8549 - val_loss: 0.5862 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3442 - acc: 0.8808 - val_loss: 0.3559 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3158 - acc: 0.8808 - val_loss: 0.4489 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5942 - acc: 0.7617 - val_loss: 0.7784 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4598 - acc: 0.7358 - val_loss: 0.4257 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4626 - acc: 0.8238 - val_loss: 0.5367 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3099 - acc: 0.8238 - val_loss: 0.6687 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2948 - acc: 0.8238 - val_loss: 0.5894 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2858 - acc: 0.8601 - val_loss: 0.6455 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2590 - acc: 0.8705 - val_loss: 0.8603 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5585 - acc: 0.7423 - val_loss: 1.2586 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5773 - acc: 0.7732 - val_loss: 0.7212 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4731 - acc: 0.8660 - val_loss: 0.6154 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4247 - acc: 0.8402 - val_loss: 0.5350 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3703 - acc: 0.8660 - val_loss: 0.6572 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3727 - acc: 0.8505 - val_loss: 0.6796 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3066 - acc: 0.8711 - val_loss: 0.6045 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2580 - acc: 0.8866 - val_loss: 0.5749 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5369 - acc: 0.7887 - val_loss: 0.6375 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6852 - acc: 0.6753 - val_loss: 0.8903 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6274 - acc: 0.7784 - val_loss: 0.5273 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4381 - acc: 0.8144 - val_loss: 0.5754 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5316 - acc: 0.7938 - val_loss: 0.4290 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4806 - acc: 0.7732 - val_loss: 0.4038 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3664 - acc: 0.8299 - val_loss: 0.4192 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4085 - acc: 0.8196 - val_loss: 0.4276 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3306 - acc: 0.8660 - val_loss: 0.4921 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2944 - acc: 0.8557 - val_loss: 0.4220 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2408 - acc: 0.9124 - val_loss: 0.4798 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5994 - acc: 0.7371 - val_loss: 0.4328 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4101 - acc: 0.7938 - val_loss: 0.5316 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3915 - acc: 0.8454 - val_loss: 0.6276 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3686 - acc: 0.8505 - val_loss: 0.6912 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3545 - acc: 0.8763 - val_loss: 0.5490 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2721 - acc: 0.8814 - val_loss: 0.7355 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8107 - acc: 0.7461 - val_loss: 2.0993 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9975 - acc: 0.7306 - val_loss: 1.4924 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8468 - acc: 0.8446 - val_loss: 1.5355 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9819 - acc: 0.8290 - val_loss: 2.6677 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1453 - acc: 0.8031 - val_loss: 1.1530 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8097 - acc: 0.7824 - val_loss: 1.6649 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7451 - acc: 0.8446 - val_loss: 1.4167 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5192 - acc: 0.8601 - val_loss: 0.9300 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6800 - acc: 0.8446 - val_loss: 1.6135 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3833 - acc: 0.8860 - val_loss: 1.0543 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3091 - acc: 0.9016 - val_loss: 0.9349 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2071 - acc: 0.9275 - val_loss: 1.0055 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1743 - acc: 0.9430 - val_loss: 0.8863 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1125 - acc: 0.9689 - val_loss: 0.8007 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1232 - acc: 0.9482 - val_loss: 0.8050 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0883 - acc: 0.9845 - val_loss: 0.8286 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0727 - acc: 0.9845 - val_loss: 0.8822 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0553 - acc: 0.9845 - val_loss: 0.9335 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0467 - acc: 0.9896 - val_loss: 0.9671 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7073 - acc: 0.6839 - val_loss: 1.1101 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6118 - acc: 0.7772 - val_loss: 0.7712 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5028 - acc: 0.8342 - val_loss: 0.6863 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3319 - acc: 0.8705 - val_loss: 0.5201 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3300 - acc: 0.8756 - val_loss: 0.5400 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2840 - acc: 0.8860 - val_loss: 0.5699 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2727 - acc: 0.9119 - val_loss: 0.6474 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2029 - acc: 0.9067 - val_loss: 0.6364 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1797 - acc: 0.9326 - val_loss: 0.8696 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6844 - acc: 0.6907 - val_loss: 0.4786 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5319 - acc: 0.8196 - val_loss: 0.4691 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5369 - acc: 0.8196 - val_loss: 0.6289 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3291 - acc: 0.8763 - val_loss: 0.7861 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4203 - acc: 0.8454 - val_loss: 0.5139 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3484 - acc: 0.8402 - val_loss: 1.0199 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4592 - acc: 0.8299 - val_loss: 0.8483 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7017 - acc: 0.6753 - val_loss: 0.5618 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6727 - acc: 0.8144 - val_loss: 0.8275 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7652 - acc: 0.8144 - val_loss: 0.8463 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5181 - acc: 0.7990 - val_loss: 0.5361 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4270 - acc: 0.8299 - val_loss: 0.6863 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3551 - acc: 0.8454 - val_loss: 0.6595 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3556 - acc: 0.8557 - val_loss: 0.5529 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3565 - acc: 0.8608 - val_loss: 0.4336 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2522 - acc: 0.8918 - val_loss: 0.5128 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2022 - acc: 0.9072 - val_loss: 0.5136 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1824 - acc: 0.9072 - val_loss: 0.5485 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1621 - acc: 0.9381 - val_loss: 0.5373 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1450 - acc: 0.9381 - val_loss: 0.5795 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6778 - acc: 0.7474 - val_loss: 0.6235 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7449 - acc: 0.8041 - val_loss: 1.5483 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6774 - acc: 0.8247 - val_loss: 0.7183 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4853 - acc: 0.8093 - val_loss: 0.4738 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4732 - acc: 0.8144 - val_loss: 0.7197 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5280 - acc: 0.8608 - val_loss: 0.7359 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6165 - acc: 0.8196 - val_loss: 0.7043 - val_acc: 0.7705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5258 - acc: 0.8299 - val_loss: 1.0941 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4309 - acc: 0.8505 - val_loss: 1.2746 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0375 - acc: 0.6321 - val_loss: 1.0775 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1541 - acc: 0.8394 - val_loss: 1.3834 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7756 - acc: 0.7979 - val_loss: 0.7816 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5554 - acc: 0.8756 - val_loss: 0.4357 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3168 - acc: 0.9119 - val_loss: 0.5823 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3891 - acc: 0.9067 - val_loss: 0.6107 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3644 - acc: 0.9016 - val_loss: 0.8309 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2685 - acc: 0.8964 - val_loss: 0.4952 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2766 - acc: 0.9016 - val_loss: 0.7974 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6974 - acc: 0.7358 - val_loss: 3.9560 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1782 - acc: 0.7617 - val_loss: 1.2548 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6165 - acc: 0.8290 - val_loss: 0.7718 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5292 - acc: 0.8497 - val_loss: 1.3303 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6191 - acc: 0.8394 - val_loss: 0.6208 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4806 - acc: 0.8756 - val_loss: 1.6504 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6932 - acc: 0.8601 - val_loss: 1.1876 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4200 - acc: 0.8912 - val_loss: 1.0847 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5660 - acc: 0.8446 - val_loss: 3.0099 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1218 - acc: 0.8705 - val_loss: 2.2158 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9614 - acc: 0.7216 - val_loss: 1.5248 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1613 - acc: 0.7577 - val_loss: 2.2214 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9515 - acc: 0.7938 - val_loss: 1.2006 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8480 - acc: 0.8144 - val_loss: 0.8792 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3860 - acc: 0.8608 - val_loss: 0.9809 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3002 - acc: 0.8814 - val_loss: 0.9139 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1928 - acc: 0.9227 - val_loss: 0.7980 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4095 - acc: 0.9175 - val_loss: 1.3695 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4525 - acc: 0.9072 - val_loss: 0.7767 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6298 - acc: 0.8247 - val_loss: 0.6979 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8221 - acc: 0.8660 - val_loss: 0.8962 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8250 - acc: 0.8711 - val_loss: 1.2350 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1595 - acc: 0.8299 - val_loss: 2.6078 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0125 - acc: 0.8763 - val_loss: 2.2292 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7016 - acc: 0.9124 - val_loss: 1.9262 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8984 - acc: 0.7165 - val_loss: 0.7766 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5432 - acc: 0.8144 - val_loss: 0.8225 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6036 - acc: 0.8196 - val_loss: 0.8679 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5529 - acc: 0.8299 - val_loss: 0.6243 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0066 - acc: 0.7938 - val_loss: 0.6904 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9202 - acc: 0.8041 - val_loss: 1.5479 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0170 - acc: 0.7732 - val_loss: 1.1698 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8931 - acc: 0.7371 - val_loss: 3.6097 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0637 - acc: 0.8557 - val_loss: 2.6935 - val_acc: 0.9180\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0806 - acc: 0.6907 - val_loss: 4.1552 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6081 - acc: 0.7526 - val_loss: 1.8564 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0771 - acc: 0.8763 - val_loss: 1.3629 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6829 - acc: 0.8351 - val_loss: 0.9384 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3023 - acc: 0.8969 - val_loss: 0.5543 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2286 - acc: 0.9330 - val_loss: 0.7597 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2412 - acc: 0.9124 - val_loss: 0.9925 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1909 - acc: 0.9536 - val_loss: 1.1521 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1247 - acc: 0.9639 - val_loss: 1.0819 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1670 - acc: 0.9330 - val_loss: 1.1520 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.4495 - acc: 0.6425 - val_loss: 1.2403 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9365 - acc: 0.7720 - val_loss: 0.6647 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6286 - acc: 0.8083 - val_loss: 0.5917 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8305 - acc: 0.8756 - val_loss: 0.5854 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4614 - acc: 0.8756 - val_loss: 0.5511 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3893 - acc: 0.8601 - val_loss: 0.5267 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3747 - acc: 0.8808 - val_loss: 0.8927 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1391 - acc: 0.9378 - val_loss: 1.2243 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3932 - acc: 0.9223 - val_loss: 2.0301 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7245 - acc: 0.9223 - val_loss: 1.4097 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9293 - acc: 0.9067 - val_loss: 1.1529 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.3540 - acc: 0.6632 - val_loss: 4.3810 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3132 - acc: 0.7409 - val_loss: 2.1298 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5567 - acc: 0.8135 - val_loss: 2.5982 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8337 - acc: 0.7927 - val_loss: 4.5693 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5843 - acc: 0.8601 - val_loss: 4.2956 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7533 - acc: 0.8912 - val_loss: 4.2205 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2792 - acc: 0.9171 - val_loss: 5.4646 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.3824 - acc: 0.6907 - val_loss: 1.3370 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0339 - acc: 0.8041 - val_loss: 0.9206 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5513 - acc: 0.7680 - val_loss: 2.5037 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8254 - acc: 0.8814 - val_loss: 1.9785 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6326 - acc: 0.8814 - val_loss: 1.5503 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7135 - acc: 0.8711 - val_loss: 1.7984 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7691 - acc: 0.8402 - val_loss: 1.6759 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0530 - acc: 0.6701 - val_loss: 1.5832 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6524 - acc: 0.6753 - val_loss: 2.3860 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0360 - acc: 0.8247 - val_loss: 1.6479 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8590 - acc: 0.8402 - val_loss: 1.4062 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2469 - acc: 0.8247 - val_loss: 1.9754 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8408 - acc: 0.8196 - val_loss: 2.8325 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1918 - acc: 0.8402 - val_loss: 1.9225 - val_acc: 0.9180\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6037 - acc: 0.8557 - val_loss: 4.9792 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9707 - acc: 0.8608 - val_loss: 4.1508 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.3260 - acc: 0.6907 - val_loss: 1.9120 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9816 - acc: 0.8144 - val_loss: 3.9313 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5214 - acc: 0.8041 - val_loss: 4.1860 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.2275 - acc: 0.7165 - val_loss: 2.0722 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.7181 - acc: 0.7835 - val_loss: 3.5396 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1401 - acc: 0.7938 - val_loss: 10.2197 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.5127 - acc: 0.7098 - val_loss: 1.2132 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4424 - acc: 0.7876 - val_loss: 3.8998 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0469 - acc: 0.8290 - val_loss: 1.3104 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2551 - acc: 0.8653 - val_loss: 1.8287 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7662 - acc: 0.8912 - val_loss: 1.9213 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5762 - acc: 0.9119 - val_loss: 1.8665 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 3.3651 - acc: 0.6218 - val_loss: 5.0676 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7632 - acc: 0.8187 - val_loss: 5.7736 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3181 - acc: 0.5907 - val_loss: 6.0094 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3230 - acc: 0.8238 - val_loss: 4.9287 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7179 - acc: 0.8497 - val_loss: 3.6959 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5793 - acc: 0.8083 - val_loss: 3.1050 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9237 - acc: 0.8860 - val_loss: 2.7376 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7096 - acc: 0.8912 - val_loss: 3.5041 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4420 - acc: 0.9223 - val_loss: 4.7684 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4584 - acc: 0.9171 - val_loss: 2.7846 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2886 - acc: 0.9430 - val_loss: 3.5182 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1435 - acc: 0.9689 - val_loss: 2.8341 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3.1449 - acc: 0.6392 - val_loss: 6.4342 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7416 - acc: 0.8144 - val_loss: 3.1396 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4730 - acc: 0.8299 - val_loss: 3.0370 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7714 - acc: 0.8454 - val_loss: 2.4019 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0034 - acc: 0.8608 - val_loss: 3.6846 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3041 - acc: 0.8918 - val_loss: 2.8470 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0092 - acc: 0.8660 - val_loss: 2.5281 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6063 - acc: 0.9021 - val_loss: 2.7559 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6744 - acc: 0.9175 - val_loss: 3.4974 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.8379 - acc: 0.6804 - val_loss: 4.9610 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3616 - acc: 0.7938 - val_loss: 1.8497 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8993 - acc: 0.7629 - val_loss: 1.2917 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8582 - acc: 0.8144 - val_loss: 2.4712 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4704 - acc: 0.8660 - val_loss: 2.6086 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3368 - acc: 0.8351 - val_loss: 3.3550 - val_acc: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3101 - acc: 0.8711 - val_loss: 2.0340 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1545 - acc: 0.8608 - val_loss: 3.4645 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.9577 - acc: 0.6340 - val_loss: 2.3910 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1280 - acc: 0.7577 - val_loss: 1.9703 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1498 - acc: 0.7577 - val_loss: 2.3415 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0855 - acc: 0.8093 - val_loss: 2.3309 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1270 - acc: 0.8351 - val_loss: 2.6831 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5692 - acc: 0.8814 - val_loss: 2.7384 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8289 - acc: 0.8402 - val_loss: 3.1544 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.5689 - acc: 0.7150 - val_loss: 8.1457 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9285 - acc: 0.8342 - val_loss: 13.4949 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.3399 - acc: 0.7565 - val_loss: 14.9200 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2307 - acc: 0.8290 - val_loss: 10.8622 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6748 - acc: 0.8342 - val_loss: 6.8382 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9529 - acc: 0.8394 - val_loss: 10.5444 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8585 - acc: 0.8497 - val_loss: 7.8031 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1893 - acc: 0.8860 - val_loss: 5.8172 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0032 - acc: 0.8964 - val_loss: 7.5268 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5123 - acc: 0.9326 - val_loss: 7.6391 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9235 - acc: 0.9534 - val_loss: 5.8572 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4575 - acc: 0.9430 - val_loss: 6.6322 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3593 - acc: 0.9689 - val_loss: 8.1732 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.0263 - acc: 0.6477 - val_loss: 2.1903 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4148 - acc: 0.7565 - val_loss: 7.3914 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4206 - acc: 0.8290 - val_loss: 6.7522 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9761 - acc: 0.7772 - val_loss: 11.9915 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.4819 - acc: 0.8031 - val_loss: 7.1361 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8318 - acc: 0.8394 - val_loss: 6.1367 - val_acc: 0.9180\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 7.7431 - acc: 0.6340 - val_loss: 5.4804 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6680 - acc: 0.7887 - val_loss: 8.1806 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7418 - acc: 0.7732 - val_loss: 6.3322 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6704 - acc: 0.7938 - val_loss: 1.7219 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9208 - acc: 0.8299 - val_loss: 4.8000 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3733 - acc: 0.8299 - val_loss: 8.1956 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4100 - acc: 0.8247 - val_loss: 8.3428 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0202 - acc: 0.8711 - val_loss: 7.8241 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7889 - acc: 0.9330 - val_loss: 6.6812 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 4.6697 - acc: 0.7010 - val_loss: 9.8471 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0497 - acc: 0.7474 - val_loss: 2.5490 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9806 - acc: 0.7732 - val_loss: 8.0551 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1377 - acc: 0.7990 - val_loss: 5.3656 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5422 - acc: 0.8402 - val_loss: 8.1390 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8645 - acc: 0.8247 - val_loss: 6.1370 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0784 - acc: 0.8711 - val_loss: 9.2852 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 7.7492 - acc: 0.6289 - val_loss: 8.6077 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6648 - acc: 0.7526 - val_loss: 11.8510 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.6637 - acc: 0.7320 - val_loss: 8.8273 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3535 - acc: 0.7835 - val_loss: 11.8736 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7611 - acc: 0.8247 - val_loss: 7.9137 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.0860 - acc: 0.8247 - val_loss: 8.0024 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0698 - acc: 0.8711 - val_loss: 7.2423 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0432 - acc: 0.8454 - val_loss: 13.2472 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1093 - acc: 0.8918 - val_loss: 8.9575 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0994 - acc: 0.9227 - val_loss: 7.1360 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0237 - acc: 0.9227 - val_loss: 13.0213 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4685 - acc: 0.9175 - val_loss: 11.7150 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5605 - acc: 0.9588 - val_loss: 12.3241 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2234 - acc: 0.9536 - val_loss: 12.7178 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4612 - acc: 0.9639 - val_loss: 19.6763 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 14.1550 - acc: 0.6321 - val_loss: 17.5087 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.4142 - acc: 0.7876 - val_loss: 18.7571 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.1232 - acc: 0.8394 - val_loss: 8.5582 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9993 - acc: 0.8601 - val_loss: 4.9687 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4028 - acc: 0.8756 - val_loss: 4.3417 - val_acc: 0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6004 - acc: 0.8912 - val_loss: 2.6983 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0508 - acc: 0.9378 - val_loss: 6.6901 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3068 - acc: 0.8912 - val_loss: 7.5538 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0533 - acc: 0.9275 - val_loss: 7.4687 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0496 - acc: 0.9534 - val_loss: 5.8718 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8774 - acc: 0.9637 - val_loss: 5.6649 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 9.6309 - acc: 0.6477 - val_loss: 5.8221 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.2500 - acc: 0.7720 - val_loss: 13.5929 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6133 - acc: 0.8342 - val_loss: 7.3535 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9593 - acc: 0.9119 - val_loss: 13.4057 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5904 - acc: 0.8705 - val_loss: 8.9227 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5143 - acc: 0.9016 - val_loss: 13.1723 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 9.6567 - acc: 0.7320 - val_loss: 8.6498 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.8504 - acc: 0.7474 - val_loss: 8.0428 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6120 - acc: 0.8660 - val_loss: 17.7326 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.8504 - acc: 0.8041 - val_loss: 28.5294 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 24.9089 - acc: 0.7680 - val_loss: 46.5475 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.2673 - acc: 0.7629 - val_loss: 31.9332 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.4141 - acc: 0.8351 - val_loss: 12.9856 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 7.6973 - acc: 0.6546 - val_loss: 13.6377 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.6768 - acc: 0.7732 - val_loss: 31.8417 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.8013 - acc: 0.7732 - val_loss: 6.1109 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.3319 - acc: 0.8041 - val_loss: 14.1296 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8512 - acc: 0.8299 - val_loss: 10.0728 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5391 - acc: 0.8247 - val_loss: 16.4260 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3918 - acc: 0.8351 - val_loss: 12.0208 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4283 - acc: 0.8608 - val_loss: 16.1431 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 9.4719 - acc: 0.7165 - val_loss: 13.2158 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4868 - acc: 0.7010 - val_loss: 12.6164 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.2674 - acc: 0.7938 - val_loss: 6.9191 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1234 - acc: 0.8608 - val_loss: 29.1935 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.9350 - acc: 0.7732 - val_loss: 10.7564 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1078 - acc: 0.8299 - val_loss: 21.6798 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8799 - acc: 0.8505 - val_loss: 22.6120 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8019 - acc: 0.9072 - val_loss: 25.3942 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.7095 - acc: 0.7098 - val_loss: 0.6173 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5582 - acc: 0.8290 - val_loss: 0.6738 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6442 - acc: 0.7824 - val_loss: 0.7016 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4576 - acc: 0.8290 - val_loss: 0.5127 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2993 - acc: 0.8342 - val_loss: 0.5259 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3354 - acc: 0.8290 - val_loss: 0.5040 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3380 - acc: 0.8912 - val_loss: 0.4957 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2678 - acc: 0.8964 - val_loss: 0.5112 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2273 - acc: 0.9016 - val_loss: 0.4799 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2493 - acc: 0.9067 - val_loss: 0.4504 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2653 - acc: 0.8756 - val_loss: 1.1963 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5776 - acc: 0.8290 - val_loss: 0.7741 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6408 - acc: 0.8601 - val_loss: 1.2598 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6682 - acc: 0.8031 - val_loss: 1.1837 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0308 - acc: 0.7720 - val_loss: 3.0995 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7085 - acc: 0.6788 - val_loss: 0.4448 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7826 - acc: 0.7927 - val_loss: 1.0673 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5230 - acc: 0.8290 - val_loss: 0.8135 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4062 - acc: 0.8238 - val_loss: 0.5886 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3869 - acc: 0.8342 - val_loss: 0.4340 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3199 - acc: 0.8135 - val_loss: 0.7355 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5220 - acc: 0.8342 - val_loss: 0.5898 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4600 - acc: 0.8705 - val_loss: 0.6546 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2743 - acc: 0.8860 - val_loss: 0.5652 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2450 - acc: 0.8912 - val_loss: 0.6540 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6036 - acc: 0.7320 - val_loss: 1.1845 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6413 - acc: 0.8608 - val_loss: 0.7644 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6150 - acc: 0.8144 - val_loss: 2.2917 - val_acc: 0.8033\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5862 - acc: 0.8402 - val_loss: 1.4646 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5405 - acc: 0.8299 - val_loss: 1.9325 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5814 - acc: 0.8454 - val_loss: 2.0775 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4718 - acc: 0.8866 - val_loss: 1.2483 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6444 - acc: 0.7268 - val_loss: 0.6630 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5765 - acc: 0.7371 - val_loss: 0.6952 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5146 - acc: 0.8351 - val_loss: 0.4892 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3663 - acc: 0.8299 - val_loss: 0.6043 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3091 - acc: 0.8351 - val_loss: 0.4964 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2702 - acc: 0.8814 - val_loss: 0.7484 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3016 - acc: 0.8660 - val_loss: 0.7664 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2711 - acc: 0.8711 - val_loss: 1.0493 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7995 - acc: 0.7113 - val_loss: 0.7868 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6137 - acc: 0.7526 - val_loss: 0.5005 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5483 - acc: 0.8247 - val_loss: 0.4975 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4676 - acc: 0.8041 - val_loss: 0.7621 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4372 - acc: 0.8196 - val_loss: 0.6725 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3122 - acc: 0.8608 - val_loss: 0.5155 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3457 - acc: 0.8608 - val_loss: 0.7696 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2980 - acc: 0.8557 - val_loss: 0.6273 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0220 - acc: 0.7098 - val_loss: 1.1876 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9337 - acc: 0.8187 - val_loss: 0.8091 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2630 - acc: 0.7720 - val_loss: 0.9614 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2340 - acc: 0.8031 - val_loss: 0.6241 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7126 - acc: 0.8653 - val_loss: 1.1007 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6875 - acc: 0.8549 - val_loss: 1.7036 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9744 - acc: 0.7772 - val_loss: 3.0659 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1964 - acc: 0.8342 - val_loss: 1.5553 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4680 - acc: 0.8860 - val_loss: 0.8401 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9562 - acc: 0.6580 - val_loss: 0.8706 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9547 - acc: 0.7979 - val_loss: 1.1434 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8116 - acc: 0.8394 - val_loss: 0.9029 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5472 - acc: 0.8135 - val_loss: 0.7106 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4866 - acc: 0.8342 - val_loss: 1.1837 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4476 - acc: 0.8342 - val_loss: 1.0067 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5464 - acc: 0.8601 - val_loss: 0.6614 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2062 - acc: 0.8808 - val_loss: 0.6187 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1973 - acc: 0.9067 - val_loss: 0.7522 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1578 - acc: 0.9378 - val_loss: 0.7323 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1229 - acc: 0.9430 - val_loss: 0.9310 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0941 - acc: 0.9741 - val_loss: 1.2007 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1099 - acc: 0.9689 - val_loss: 1.0768 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7266 - acc: 0.7577 - val_loss: 0.7331 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8523 - acc: 0.8351 - val_loss: 1.5617 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8654 - acc: 0.8093 - val_loss: 1.1665 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9567 - acc: 0.8144 - val_loss: 1.0414 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7001 - acc: 0.8351 - val_loss: 0.7172 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8554 - acc: 0.8093 - val_loss: 1.8257 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9559 - acc: 0.8505 - val_loss: 1.2481 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5350 - acc: 0.8763 - val_loss: 0.8445 - val_acc: 0.9180\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2339 - acc: 0.9021 - val_loss: 1.3746 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4034 - acc: 0.9021 - val_loss: 1.1405 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.1215 - acc: 0.7165 - val_loss: 0.4237 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7475 - acc: 0.7577 - val_loss: 0.4883 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7389 - acc: 0.7835 - val_loss: 0.4855 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5474 - acc: 0.8505 - val_loss: 0.4865 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5409 - acc: 0.8041 - val_loss: 0.6536 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4244 - acc: 0.8505 - val_loss: 0.5308 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0545 - acc: 0.6649 - val_loss: 0.7470 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9268 - acc: 0.8454 - val_loss: 0.9427 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7596 - acc: 0.7423 - val_loss: 0.6917 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6060 - acc: 0.8351 - val_loss: 0.9804 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4092 - acc: 0.8660 - val_loss: 1.2384 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3701 - acc: 0.8866 - val_loss: 0.8448 - val_acc: 0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4592 - acc: 0.8608 - val_loss: 1.6696 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3459 - acc: 0.8041 - val_loss: 4.1562 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.4110 - acc: 0.6891 - val_loss: 1.6641 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5306 - acc: 0.7927 - val_loss: 0.5745 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4369 - acc: 0.7254 - val_loss: 1.7793 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0422 - acc: 0.8653 - val_loss: 2.4301 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1209 - acc: 0.8808 - val_loss: 2.1017 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7712 - acc: 0.9171 - val_loss: 2.2404 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4401 - acc: 0.9275 - val_loss: 1.9774 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.4219 - acc: 0.6736 - val_loss: 1.3924 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9466 - acc: 0.7772 - val_loss: 4.9297 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8693 - acc: 0.8135 - val_loss: 4.0590 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8926 - acc: 0.7720 - val_loss: 5.5042 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.6388 - acc: 0.8290 - val_loss: 4.0359 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0244 - acc: 0.8549 - val_loss: 4.4077 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.8800 - acc: 0.7268 - val_loss: 1.6325 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3356 - acc: 0.7732 - val_loss: 1.6573 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9296 - acc: 0.8454 - val_loss: 0.8843 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2246 - acc: 0.8299 - val_loss: 1.0461 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5851 - acc: 0.8711 - val_loss: 1.1153 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3015 - acc: 0.9021 - val_loss: 1.6210 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8446 - acc: 0.8814 - val_loss: 1.1063 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0282 - acc: 0.8763 - val_loss: 2.2504 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 51ms/step - loss: 1.6124 - acc: 0.6546 - val_loss: 3.3072 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7533 - acc: 0.8041 - val_loss: 2.2175 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8819 - acc: 0.7371 - val_loss: 1.6378 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2550 - acc: 0.8247 - val_loss: 2.5049 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8065 - acc: 0.8402 - val_loss: 0.8018 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7378 - acc: 0.8557 - val_loss: 2.0008 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5625 - acc: 0.8814 - val_loss: 1.4104 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4881 - acc: 0.8660 - val_loss: 1.6100 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3098 - acc: 0.9021 - val_loss: 1.4086 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3003 - acc: 0.8969 - val_loss: 1.6782 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.7224 - acc: 0.7577 - val_loss: 2.0365 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4874 - acc: 0.6443 - val_loss: 3.0122 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7399 - acc: 0.8041 - val_loss: 1.1816 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8445 - acc: 0.7887 - val_loss: 2.3316 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1689 - acc: 0.8608 - val_loss: 3.0229 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8705 - acc: 0.8505 - val_loss: 2.6526 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6917 - acc: 0.8814 - val_loss: 1.9565 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7727 - acc: 0.7784 - val_loss: 1.3451 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.8697 - acc: 0.6010 - val_loss: 4.8118 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.8477 - acc: 0.7254 - val_loss: 3.8292 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7870 - acc: 0.7979 - val_loss: 3.4355 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1247 - acc: 0.8135 - val_loss: 3.2065 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6094 - acc: 0.7720 - val_loss: 2.0208 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1900 - acc: 0.8187 - val_loss: 4.8823 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3719 - acc: 0.8446 - val_loss: 3.7469 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9113 - acc: 0.8808 - val_loss: 3.8609 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6196 - acc: 0.8964 - val_loss: 2.1781 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6383 - acc: 0.9326 - val_loss: 2.9181 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.9051 - acc: 0.6684 - val_loss: 1.5430 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0158 - acc: 0.7979 - val_loss: 0.8897 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1116 - acc: 0.8238 - val_loss: 1.3939 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9723 - acc: 0.8135 - val_loss: 1.3414 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1029 - acc: 0.8653 - val_loss: 8.2826 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6142 - acc: 0.6788 - val_loss: 2.8728 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.6838 - acc: 0.8290 - val_loss: 5.0087 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.9263 - acc: 0.7216 - val_loss: 1.6394 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3271 - acc: 0.7784 - val_loss: 2.5619 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1575 - acc: 0.8144 - val_loss: 5.0990 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1018 - acc: 0.8454 - val_loss: 2.0900 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2150 - acc: 0.8660 - val_loss: 1.6731 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1558 - acc: 0.8608 - val_loss: 3.4148 - val_acc: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 4.0591 - acc: 0.6237 - val_loss: 5.0833 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7442 - acc: 0.7784 - val_loss: 3.6339 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.4700 - acc: 0.7629 - val_loss: 2.5219 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2329 - acc: 0.8144 - val_loss: 1.3172 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1713 - acc: 0.7887 - val_loss: 2.4126 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3353 - acc: 0.8505 - val_loss: 3.2355 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9027 - acc: 0.8402 - val_loss: 2.6139 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0412 - acc: 0.8454 - val_loss: 2.9707 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8614 - acc: 0.8711 - val_loss: 4.1289 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 3.1387 - acc: 0.5825 - val_loss: 4.1004 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.6485 - acc: 0.7165 - val_loss: 2.1097 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0912 - acc: 0.8144 - val_loss: 1.2432 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2173 - acc: 0.8402 - val_loss: 3.9740 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.9019 - acc: 0.8144 - val_loss: 3.8831 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.3474 - acc: 0.7990 - val_loss: 7.1168 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8952 - acc: 0.8144 - val_loss: 6.1029 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8751 - acc: 0.8866 - val_loss: 5.4196 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 7.0408 - acc: 0.6788 - val_loss: 9.9847 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5575 - acc: 0.7150 - val_loss: 4.1091 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3698 - acc: 0.7461 - val_loss: 13.4251 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9148 - acc: 0.8446 - val_loss: 5.4397 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7167 - acc: 0.8342 - val_loss: 7.2989 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9140 - acc: 0.8808 - val_loss: 3.4669 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.1093 - acc: 0.8653 - val_loss: 10.7808 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8235 - acc: 0.8497 - val_loss: 4.6458 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7232 - acc: 0.9119 - val_loss: 8.1357 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7287 - acc: 0.9171 - val_loss: 5.6416 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8318 - acc: 0.9223 - val_loss: 6.0963 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.5455 - acc: 0.6632 - val_loss: 4.0392 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.0965 - acc: 0.8083 - val_loss: 4.4347 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.5958 - acc: 0.7876 - val_loss: 6.9773 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.5507 - acc: 0.8238 - val_loss: 5.4245 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9513 - acc: 0.8031 - val_loss: 9.8316 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.2047 - acc: 0.8446 - val_loss: 16.4922 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 5.3948 - acc: 0.7010 - val_loss: 6.4343 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.2531 - acc: 0.7938 - val_loss: 4.2674 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.3628 - acc: 0.8144 - val_loss: 6.7885 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.5748 - acc: 0.8969 - val_loss: 8.4474 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5912 - acc: 0.8660 - val_loss: 7.2870 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9192 - acc: 0.8866 - val_loss: 10.2761 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.5483 - acc: 0.8969 - val_loss: 7.1800 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.3163 - acc: 0.6495 - val_loss: 40.6208 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.1991 - acc: 0.7216 - val_loss: 10.7820 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.7029 - acc: 0.8144 - val_loss: 6.4695 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2217 - acc: 0.8505 - val_loss: 9.1556 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1972 - acc: 0.8093 - val_loss: 5.2137 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.3005 - acc: 0.8608 - val_loss: 8.6452 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.2386 - acc: 0.8144 - val_loss: 8.3904 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.5706 - acc: 0.8557 - val_loss: 8.7399 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1564 - acc: 0.8711 - val_loss: 7.0811 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2063 - acc: 0.9278 - val_loss: 6.0904 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 9.0113 - acc: 0.6701 - val_loss: 5.3460 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1207 - acc: 0.7887 - val_loss: 14.6448 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7716 - acc: 0.7629 - val_loss: 5.4288 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.7625 - acc: 0.7680 - val_loss: 3.9885 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.8590 - acc: 0.8144 - val_loss: 3.9929 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7185 - acc: 0.8660 - val_loss: 3.8587 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9847 - acc: 0.8402 - val_loss: 10.2140 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.8413 - acc: 0.8814 - val_loss: 11.5328 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9739 - acc: 0.8918 - val_loss: 13.4126 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9611 - acc: 0.8660 - val_loss: 9.3938 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.8269 - acc: 0.8660 - val_loss: 14.6245 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 12.6733 - acc: 0.6580 - val_loss: 15.8559 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.4595 - acc: 0.7979 - val_loss: 17.2325 - val_acc: 0.7869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.9868 - acc: 0.8187 - val_loss: 20.3866 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.5274 - acc: 0.8446 - val_loss: 30.5059 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4462 - acc: 0.7772 - val_loss: 16.1597 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.3472 - acc: 0.8808 - val_loss: 48.4637 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 12.3770 - acc: 0.6321 - val_loss: 9.9304 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8789 - acc: 0.8135 - val_loss: 8.4464 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7876 - acc: 0.8135 - val_loss: 13.4543 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.5508 - acc: 0.7617 - val_loss: 14.7814 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 10.0738 - acc: 0.8342 - val_loss: 22.5154 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.7801 - acc: 0.8342 - val_loss: 22.0890 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6679 - acc: 0.8653 - val_loss: 15.8446 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 12.5545 - acc: 0.6134 - val_loss: 11.8573 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 14.4904 - acc: 0.8351 - val_loss: 23.1615 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.8908 - acc: 0.8299 - val_loss: 16.6151 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7966 - acc: 0.8093 - val_loss: 5.7580 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0079 - acc: 0.8351 - val_loss: 5.9487 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.6773 - acc: 0.7732 - val_loss: 15.9310 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4523 - acc: 0.8866 - val_loss: 14.1524 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0044 - acc: 0.8918 - val_loss: 39.3655 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.1296 - acc: 0.9072 - val_loss: 26.2742 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 15.7956 - acc: 0.6907 - val_loss: 21.8188 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3242 - acc: 0.7887 - val_loss: 19.8662 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 13.1571 - acc: 0.7784 - val_loss: 20.8404 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 15.5051 - acc: 0.7990 - val_loss: 16.0939 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.3445 - acc: 0.8814 - val_loss: 10.6498 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.2736 - acc: 0.8454 - val_loss: 17.9262 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.3392 - acc: 0.8969 - val_loss: 12.7819 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.2138 - acc: 0.8196 - val_loss: 16.4360 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0404 - acc: 0.8402 - val_loss: 22.6855 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.0513 - acc: 0.8299 - val_loss: 26.8674 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 12.0363 - acc: 0.6804 - val_loss: 30.4557 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 16.7144 - acc: 0.7629 - val_loss: 9.4612 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.1626 - acc: 0.7938 - val_loss: 10.3599 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.5068 - acc: 0.7680 - val_loss: 4.9920 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.0467 - acc: 0.8196 - val_loss: 11.9268 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.8427 - acc: 0.8247 - val_loss: 16.8037 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.2340 - acc: 0.8454 - val_loss: 25.6502 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.4355 - acc: 0.8660 - val_loss: 13.1251 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.6293 - acc: 0.8866 - val_loss: 12.0493 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 15.7126 - acc: 0.7358 - val_loss: 43.2283 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.9964 - acc: 0.7720 - val_loss: 39.4432 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 19.6422 - acc: 0.7979 - val_loss: 16.0088 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 18.9262 - acc: 0.8187 - val_loss: 39.1766 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.1592 - acc: 0.8808 - val_loss: 27.8334 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.8244 - acc: 0.9067 - val_loss: 25.5089 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.4625 - acc: 0.9223 - val_loss: 21.9783 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.4321 - acc: 0.9016 - val_loss: 29.3261 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 22.3632 - acc: 0.6166 - val_loss: 13.2750 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 25.3174 - acc: 0.8031 - val_loss: 33.3953 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 23.2352 - acc: 0.7979 - val_loss: 17.7533 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.0242 - acc: 0.8394 - val_loss: 11.9856 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.7474 - acc: 0.8601 - val_loss: 14.6100 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3316 - acc: 0.8653 - val_loss: 36.0917 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 8.1662 - acc: 0.8860 - val_loss: 23.5871 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 13.8997 - acc: 0.8808 - val_loss: 26.4068 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 38.9090 - acc: 0.8135 - val_loss: 51.3550 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 20.8411 - acc: 0.6649 - val_loss: 25.3783 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 33.3155 - acc: 0.8144 - val_loss: 33.4091 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 21.4700 - acc: 0.8196 - val_loss: 8.1492 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 22.3760 - acc: 0.8711 - val_loss: 29.5795 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.6385 - acc: 0.8660 - val_loss: 23.9350 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 26.5521 - acc: 0.8557 - val_loss: 33.9810 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.9532 - acc: 0.8866 - val_loss: 30.8897 - val_acc: 0.8197\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 9.6249 - acc: 0.8814 - val_loss: 28.0700 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 27.3428 - acc: 0.6546 - val_loss: 25.8130 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 17.8490 - acc: 0.7835 - val_loss: 30.5815 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 20.6526 - acc: 0.8144 - val_loss: 14.9233 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.3495 - acc: 0.7680 - val_loss: 22.5303 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 11.1311 - acc: 0.8299 - val_loss: 17.3203 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 10.0649 - acc: 0.8711 - val_loss: 34.3778 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 5.9054 - acc: 0.8763 - val_loss: 15.9362 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.4220 - acc: 0.8557 - val_loss: 38.1886 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 23.9069 - acc: 0.6804 - val_loss: 14.2523 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 15.7973 - acc: 0.7165 - val_loss: 10.1378 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 32.1936 - acc: 0.8041 - val_loss: 50.2716 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 36.0738 - acc: 0.8402 - val_loss: 44.9807 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 42.6427 - acc: 0.8557 - val_loss: 42.6388 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 12.3639 - acc: 0.8351 - val_loss: 46.5540 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.7385 - acc: 0.9072 - val_loss: 46.5160 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8932 - acc: 0.4870 - val_loss: 1.0105 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8931 - acc: 0.4870 - val_loss: 1.0105 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8931 - acc: 0.4870 - val_loss: 1.0105 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8931 - acc: 0.4870 - val_loss: 1.0105 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8931 - acc: 0.4870 - val_loss: 1.0104 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8931 - acc: 0.4870 - val_loss: 1.0104 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8931 - acc: 0.4870 - val_loss: 1.0104 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8931 - acc: 0.4870 - val_loss: 1.0104 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8930 - acc: 0.4870 - val_loss: 1.0104 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8930 - acc: 0.4870 - val_loss: 1.0104 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8930 - acc: 0.4870 - val_loss: 1.0103 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8930 - acc: 0.4870 - val_loss: 1.0103 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8930 - acc: 0.4870 - val_loss: 1.0103 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8930 - acc: 0.4870 - val_loss: 1.0103 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8930 - acc: 0.4870 - val_loss: 1.0103 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8930 - acc: 0.4870 - val_loss: 1.0103 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8929 - acc: 0.4870 - val_loss: 1.0102 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8929 - acc: 0.4870 - val_loss: 1.0102 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8929 - acc: 0.4870 - val_loss: 1.0102 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8929 - acc: 0.4870 - val_loss: 1.0102 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8319 - acc: 0.4560 - val_loss: 0.9276 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8319 - acc: 0.4560 - val_loss: 0.9276 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8319 - acc: 0.4560 - val_loss: 0.9276 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8319 - acc: 0.4560 - val_loss: 0.9276 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8319 - acc: 0.4560 - val_loss: 0.9276 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8319 - acc: 0.4560 - val_loss: 0.9275 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8318 - acc: 0.4560 - val_loss: 0.9275 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8318 - acc: 0.4560 - val_loss: 0.9275 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8318 - acc: 0.4560 - val_loss: 0.9275 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8318 - acc: 0.4560 - val_loss: 0.9275 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8318 - acc: 0.4560 - val_loss: 0.9275 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8318 - acc: 0.4560 - val_loss: 0.9274 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8318 - acc: 0.4560 - val_loss: 0.9274 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8317 - acc: 0.4560 - val_loss: 0.9274 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8317 - acc: 0.4560 - val_loss: 0.9274 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8317 - acc: 0.4560 - val_loss: 0.9274 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8317 - acc: 0.4560 - val_loss: 0.9274 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8317 - acc: 0.4560 - val_loss: 0.9274 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8317 - acc: 0.4560 - val_loss: 0.9273 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8317 - acc: 0.4560 - val_loss: 0.9273 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0545 - acc: 0.3608 - val_loss: 1.0013 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0545 - acc: 0.3608 - val_loss: 1.0013 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0545 - acc: 0.3608 - val_loss: 1.0012 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0544 - acc: 0.3608 - val_loss: 1.0012 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0544 - acc: 0.3608 - val_loss: 1.0012 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0544 - acc: 0.3608 - val_loss: 1.0012 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0544 - acc: 0.3608 - val_loss: 1.0011 - val_acc: 0.3934\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0543 - acc: 0.3608 - val_loss: 1.0011 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0543 - acc: 0.3608 - val_loss: 1.0011 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0543 - acc: 0.3608 - val_loss: 1.0011 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0543 - acc: 0.3608 - val_loss: 1.0010 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0542 - acc: 0.3608 - val_loss: 1.0010 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0542 - acc: 0.3608 - val_loss: 1.0010 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0542 - acc: 0.3608 - val_loss: 1.0009 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0542 - acc: 0.3608 - val_loss: 1.0009 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0541 - acc: 0.3608 - val_loss: 1.0009 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0541 - acc: 0.3608 - val_loss: 1.0009 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0541 - acc: 0.3608 - val_loss: 1.0009 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0541 - acc: 0.3608 - val_loss: 1.0008 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0540 - acc: 0.3608 - val_loss: 1.0008 - val_acc: 0.3934\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6978 - acc: 0.5412 - val_loss: 0.6410 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6978 - acc: 0.5464 - val_loss: 0.6410 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6978 - acc: 0.5464 - val_loss: 0.6410 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6978 - acc: 0.5464 - val_loss: 0.6410 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6978 - acc: 0.5464 - val_loss: 0.6410 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6978 - acc: 0.5464 - val_loss: 0.6410 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6978 - acc: 0.5464 - val_loss: 0.6410 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6978 - acc: 0.5464 - val_loss: 0.6409 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6978 - acc: 0.5464 - val_loss: 0.6409 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6978 - acc: 0.5464 - val_loss: 0.6409 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.5464 - val_loss: 0.6409 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.5464 - val_loss: 0.6409 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.5464 - val_loss: 0.6409 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.5464 - val_loss: 0.6409 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.5464 - val_loss: 0.6409 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.5464 - val_loss: 0.6409 - val_acc: 0.6557\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.5464 - val_loss: 0.6409 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.5464 - val_loss: 0.6409 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.5464 - val_loss: 0.6408 - val_acc: 0.6557\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.5464 - val_loss: 0.6408 - val_acc: 0.6557\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9857 - acc: 0.2835 - val_loss: 0.9294 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9857 - acc: 0.2835 - val_loss: 0.9294 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9857 - acc: 0.2835 - val_loss: 0.9294 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9857 - acc: 0.2835 - val_loss: 0.9294 - val_acc: 0.3607\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9856 - acc: 0.2835 - val_loss: 0.9293 - val_acc: 0.3607\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9856 - acc: 0.2835 - val_loss: 0.9293 - val_acc: 0.3607\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9856 - acc: 0.2835 - val_loss: 0.9293 - val_acc: 0.3607\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9856 - acc: 0.2835 - val_loss: 0.9293 - val_acc: 0.3607\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9856 - acc: 0.2835 - val_loss: 0.9293 - val_acc: 0.3607\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9855 - acc: 0.2835 - val_loss: 0.9292 - val_acc: 0.3607\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9855 - acc: 0.2835 - val_loss: 0.9292 - val_acc: 0.3607\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9855 - acc: 0.2835 - val_loss: 0.9292 - val_acc: 0.3607\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9855 - acc: 0.2835 - val_loss: 0.9292 - val_acc: 0.3607\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9855 - acc: 0.2835 - val_loss: 0.9291 - val_acc: 0.3607\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9855 - acc: 0.2835 - val_loss: 0.9291 - val_acc: 0.3607\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9854 - acc: 0.2835 - val_loss: 0.9291 - val_acc: 0.3607\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9854 - acc: 0.2835 - val_loss: 0.9291 - val_acc: 0.3607\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9854 - acc: 0.2835 - val_loss: 0.9291 - val_acc: 0.3607\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9854 - acc: 0.2835 - val_loss: 0.9290 - val_acc: 0.3607\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9854 - acc: 0.2835 - val_loss: 0.9290 - val_acc: 0.3607\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8304 - acc: 0.4922 - val_loss: 0.9148 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8304 - acc: 0.4922 - val_loss: 0.9148 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8303 - acc: 0.4922 - val_loss: 0.9148 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8303 - acc: 0.4922 - val_loss: 0.9148 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8303 - acc: 0.4922 - val_loss: 0.9147 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8303 - acc: 0.4922 - val_loss: 0.9147 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8302 - acc: 0.4922 - val_loss: 0.9147 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8302 - acc: 0.4922 - val_loss: 0.9147 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8302 - acc: 0.4922 - val_loss: 0.9146 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8302 - acc: 0.4922 - val_loss: 0.9146 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8302 - acc: 0.4922 - val_loss: 0.9146 - val_acc: 0.4754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8301 - acc: 0.4922 - val_loss: 0.9146 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8301 - acc: 0.4922 - val_loss: 0.9146 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8301 - acc: 0.4922 - val_loss: 0.9145 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8301 - acc: 0.4922 - val_loss: 0.9145 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8301 - acc: 0.4922 - val_loss: 0.9145 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8300 - acc: 0.4922 - val_loss: 0.9145 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8300 - acc: 0.4922 - val_loss: 0.9145 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8300 - acc: 0.4922 - val_loss: 0.9144 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8300 - acc: 0.4922 - val_loss: 0.9144 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 1.0630 - acc: 0.3264 - val_loss: 0.9614 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0629 - acc: 0.3264 - val_loss: 0.9614 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0629 - acc: 0.3264 - val_loss: 0.9614 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0628 - acc: 0.3264 - val_loss: 0.9613 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0628 - acc: 0.3264 - val_loss: 0.9613 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0628 - acc: 0.3264 - val_loss: 0.9613 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0627 - acc: 0.3264 - val_loss: 0.9612 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0627 - acc: 0.3264 - val_loss: 0.9612 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0627 - acc: 0.3264 - val_loss: 0.9612 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0626 - acc: 0.3264 - val_loss: 0.9612 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0626 - acc: 0.3264 - val_loss: 0.9611 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0626 - acc: 0.3264 - val_loss: 0.9611 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0625 - acc: 0.3264 - val_loss: 0.9611 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0625 - acc: 0.3264 - val_loss: 0.9610 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0625 - acc: 0.3264 - val_loss: 0.9610 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0624 - acc: 0.3264 - val_loss: 0.9610 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0624 - acc: 0.3264 - val_loss: 0.9610 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0624 - acc: 0.3264 - val_loss: 0.9609 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0623 - acc: 0.3264 - val_loss: 0.9609 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0623 - acc: 0.3264 - val_loss: 0.9608 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9538 - acc: 0.3402 - val_loss: 0.9596 - val_acc: 0.3279\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9537 - acc: 0.3402 - val_loss: 0.9595 - val_acc: 0.3279\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9537 - acc: 0.3402 - val_loss: 0.9595 - val_acc: 0.3279\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9537 - acc: 0.3402 - val_loss: 0.9595 - val_acc: 0.3279\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9536 - acc: 0.3402 - val_loss: 0.9594 - val_acc: 0.3279\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9536 - acc: 0.3402 - val_loss: 0.9594 - val_acc: 0.3279\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9536 - acc: 0.3402 - val_loss: 0.9594 - val_acc: 0.3279\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9535 - acc: 0.3402 - val_loss: 0.9593 - val_acc: 0.3279\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9535 - acc: 0.3402 - val_loss: 0.9593 - val_acc: 0.3279\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9535 - acc: 0.3402 - val_loss: 0.9593 - val_acc: 0.3279\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9535 - acc: 0.3402 - val_loss: 0.9592 - val_acc: 0.3279\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9534 - acc: 0.3402 - val_loss: 0.9592 - val_acc: 0.3279\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9534 - acc: 0.3402 - val_loss: 0.9592 - val_acc: 0.3279\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9534 - acc: 0.3402 - val_loss: 0.9592 - val_acc: 0.3279\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9533 - acc: 0.3402 - val_loss: 0.9591 - val_acc: 0.3279\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9533 - acc: 0.3402 - val_loss: 0.9591 - val_acc: 0.3279\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9533 - acc: 0.3402 - val_loss: 0.9591 - val_acc: 0.3279\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9533 - acc: 0.3402 - val_loss: 0.9590 - val_acc: 0.3279\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9532 - acc: 0.3402 - val_loss: 0.9590 - val_acc: 0.3279\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9532 - acc: 0.3402 - val_loss: 0.9590 - val_acc: 0.3279\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0057 - acc: 0.3454 - val_loss: 0.9925 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0056 - acc: 0.3454 - val_loss: 0.9925 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0056 - acc: 0.3454 - val_loss: 0.9925 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0056 - acc: 0.3454 - val_loss: 0.9924 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0056 - acc: 0.3454 - val_loss: 0.9924 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0055 - acc: 0.3454 - val_loss: 0.9924 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0055 - acc: 0.3454 - val_loss: 0.9923 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0055 - acc: 0.3454 - val_loss: 0.9923 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0054 - acc: 0.3454 - val_loss: 0.9923 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0054 - acc: 0.3454 - val_loss: 0.9923 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0054 - acc: 0.3454 - val_loss: 0.9922 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0054 - acc: 0.3454 - val_loss: 0.9922 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0053 - acc: 0.3454 - val_loss: 0.9922 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0053 - acc: 0.3454 - val_loss: 0.9922 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0053 - acc: 0.3454 - val_loss: 0.9921 - val_acc: 0.3934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0053 - acc: 0.3454 - val_loss: 0.9921 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0052 - acc: 0.3454 - val_loss: 0.9921 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0052 - acc: 0.3454 - val_loss: 0.9921 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0052 - acc: 0.3454 - val_loss: 0.9920 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0052 - acc: 0.3454 - val_loss: 0.9920 - val_acc: 0.3934\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8530 - acc: 0.4845 - val_loss: 0.7745 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8529 - acc: 0.4845 - val_loss: 0.7745 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8529 - acc: 0.4845 - val_loss: 0.7744 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8529 - acc: 0.4845 - val_loss: 0.7744 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8529 - acc: 0.4845 - val_loss: 0.7744 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8528 - acc: 0.4845 - val_loss: 0.7744 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8528 - acc: 0.4845 - val_loss: 0.7743 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8528 - acc: 0.4845 - val_loss: 0.7743 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8528 - acc: 0.4845 - val_loss: 0.7743 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8527 - acc: 0.4845 - val_loss: 0.7743 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8527 - acc: 0.4845 - val_loss: 0.7742 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8527 - acc: 0.4845 - val_loss: 0.7742 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8527 - acc: 0.4845 - val_loss: 0.7742 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8527 - acc: 0.4845 - val_loss: 0.7742 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8526 - acc: 0.4845 - val_loss: 0.7741 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8526 - acc: 0.4845 - val_loss: 0.7741 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8526 - acc: 0.4845 - val_loss: 0.7741 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8526 - acc: 0.4845 - val_loss: 0.7741 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8525 - acc: 0.4845 - val_loss: 0.7741 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8525 - acc: 0.4845 - val_loss: 0.7740 - val_acc: 0.5574\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9304 - acc: 0.4767 - val_loss: 0.9115 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9303 - acc: 0.4767 - val_loss: 0.9114 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9303 - acc: 0.4767 - val_loss: 0.9114 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9302 - acc: 0.4767 - val_loss: 0.9113 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9302 - acc: 0.4767 - val_loss: 0.9113 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9301 - acc: 0.4767 - val_loss: 0.9113 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9301 - acc: 0.4767 - val_loss: 0.9113 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9301 - acc: 0.4767 - val_loss: 0.9112 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9300 - acc: 0.4767 - val_loss: 0.9112 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9300 - acc: 0.4767 - val_loss: 0.9112 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9300 - acc: 0.4767 - val_loss: 0.9111 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9299 - acc: 0.4767 - val_loss: 0.9111 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9299 - acc: 0.4767 - val_loss: 0.9111 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9299 - acc: 0.4767 - val_loss: 0.9111 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9299 - acc: 0.4767 - val_loss: 0.9110 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9298 - acc: 0.4767 - val_loss: 0.9110 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9298 - acc: 0.4767 - val_loss: 0.9110 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9298 - acc: 0.4767 - val_loss: 0.9110 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9297 - acc: 0.4767 - val_loss: 0.9109 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9297 - acc: 0.4767 - val_loss: 0.9109 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5446 - acc: 0.7358 - val_loss: 0.6259 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5446 - acc: 0.7358 - val_loss: 0.6259 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5446 - acc: 0.7358 - val_loss: 0.6258 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5446 - acc: 0.7358 - val_loss: 0.6258 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5445 - acc: 0.7358 - val_loss: 0.6258 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5445 - acc: 0.7358 - val_loss: 0.6258 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5445 - acc: 0.7358 - val_loss: 0.6258 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5445 - acc: 0.7358 - val_loss: 0.6257 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5445 - acc: 0.7358 - val_loss: 0.6257 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5445 - acc: 0.7358 - val_loss: 0.6257 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5445 - acc: 0.7358 - val_loss: 0.6257 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5445 - acc: 0.7358 - val_loss: 0.6257 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5444 - acc: 0.7358 - val_loss: 0.6257 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5444 - acc: 0.7358 - val_loss: 0.6257 - val_acc: 0.7705\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5444 - acc: 0.7358 - val_loss: 0.6257 - val_acc: 0.7705\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5444 - acc: 0.7358 - val_loss: 0.6257 - val_acc: 0.7705\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5444 - acc: 0.7358 - val_loss: 0.6256 - val_acc: 0.7705\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5444 - acc: 0.7358 - val_loss: 0.6256 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5444 - acc: 0.7358 - val_loss: 0.6256 - val_acc: 0.7705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5444 - acc: 0.7358 - val_loss: 0.6256 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0367 - acc: 0.2371 - val_loss: 1.1042 - val_acc: 0.2623\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0367 - acc: 0.2371 - val_loss: 1.1041 - val_acc: 0.2623\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0366 - acc: 0.2371 - val_loss: 1.1041 - val_acc: 0.2623\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0365 - acc: 0.2371 - val_loss: 1.1040 - val_acc: 0.2623\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0365 - acc: 0.2371 - val_loss: 1.1039 - val_acc: 0.2623\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0364 - acc: 0.2371 - val_loss: 1.1039 - val_acc: 0.2623\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0364 - acc: 0.2371 - val_loss: 1.1038 - val_acc: 0.2623\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0363 - acc: 0.2371 - val_loss: 1.1037 - val_acc: 0.2623\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0362 - acc: 0.2371 - val_loss: 1.1037 - val_acc: 0.2623\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0362 - acc: 0.2371 - val_loss: 1.1036 - val_acc: 0.2623\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0361 - acc: 0.2371 - val_loss: 1.1036 - val_acc: 0.2623\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0361 - acc: 0.2371 - val_loss: 1.1035 - val_acc: 0.2623\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0360 - acc: 0.2371 - val_loss: 1.1034 - val_acc: 0.2623\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0360 - acc: 0.2371 - val_loss: 1.1034 - val_acc: 0.2623\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0359 - acc: 0.2371 - val_loss: 1.1033 - val_acc: 0.2623\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0358 - acc: 0.2371 - val_loss: 1.1033 - val_acc: 0.2623\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0358 - acc: 0.2371 - val_loss: 1.1032 - val_acc: 0.2623\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0357 - acc: 0.2371 - val_loss: 1.1031 - val_acc: 0.2623\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0357 - acc: 0.2371 - val_loss: 1.1031 - val_acc: 0.2623\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0356 - acc: 0.2371 - val_loss: 1.1030 - val_acc: 0.2623\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6572 - acc: 0.5928 - val_loss: 0.6331 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6571 - acc: 0.5979 - val_loss: 0.6330 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6571 - acc: 0.5979 - val_loss: 0.6330 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6571 - acc: 0.5979 - val_loss: 0.6330 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6570 - acc: 0.5979 - val_loss: 0.6329 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6570 - acc: 0.5979 - val_loss: 0.6329 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6570 - acc: 0.5979 - val_loss: 0.6329 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6569 - acc: 0.5979 - val_loss: 0.6329 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6569 - acc: 0.5979 - val_loss: 0.6328 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6569 - acc: 0.5979 - val_loss: 0.6328 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6569 - acc: 0.5979 - val_loss: 0.6328 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6568 - acc: 0.5979 - val_loss: 0.6327 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6568 - acc: 0.5979 - val_loss: 0.6327 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6568 - acc: 0.5979 - val_loss: 0.6327 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6568 - acc: 0.5979 - val_loss: 0.6326 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6567 - acc: 0.5979 - val_loss: 0.6326 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6567 - acc: 0.5979 - val_loss: 0.6326 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6567 - acc: 0.5979 - val_loss: 0.6325 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6567 - acc: 0.5979 - val_loss: 0.6325 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6566 - acc: 0.5979 - val_loss: 0.6325 - val_acc: 0.6230\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7805 - acc: 0.4691 - val_loss: 0.7043 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7805 - acc: 0.4691 - val_loss: 0.7042 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7804 - acc: 0.4691 - val_loss: 0.7042 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7804 - acc: 0.4691 - val_loss: 0.7042 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7804 - acc: 0.4691 - val_loss: 0.7042 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7803 - acc: 0.4691 - val_loss: 0.7041 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7803 - acc: 0.4691 - val_loss: 0.7041 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7803 - acc: 0.4691 - val_loss: 0.7041 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7802 - acc: 0.4691 - val_loss: 0.7040 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7802 - acc: 0.4691 - val_loss: 0.7040 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7802 - acc: 0.4691 - val_loss: 0.7040 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7801 - acc: 0.4691 - val_loss: 0.7039 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7801 - acc: 0.4691 - val_loss: 0.7039 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7801 - acc: 0.4691 - val_loss: 0.7039 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7800 - acc: 0.4691 - val_loss: 0.7039 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7800 - acc: 0.4691 - val_loss: 0.7038 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7800 - acc: 0.4691 - val_loss: 0.7038 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7800 - acc: 0.4691 - val_loss: 0.7038 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7799 - acc: 0.4691 - val_loss: 0.7037 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7799 - acc: 0.4691 - val_loss: 0.7037 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9004 - acc: 0.3109 - val_loss: 0.9834 - val_acc: 0.1803\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9004 - acc: 0.3109 - val_loss: 0.9833 - val_acc: 0.1803\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9003 - acc: 0.3109 - val_loss: 0.9833 - val_acc: 0.1803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9002 - acc: 0.3109 - val_loss: 0.9832 - val_acc: 0.1803\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9002 - acc: 0.3109 - val_loss: 0.9831 - val_acc: 0.1803\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9001 - acc: 0.3109 - val_loss: 0.9831 - val_acc: 0.1803\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9001 - acc: 0.3109 - val_loss: 0.9830 - val_acc: 0.1803\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9000 - acc: 0.3109 - val_loss: 0.9830 - val_acc: 0.1803\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9000 - acc: 0.3109 - val_loss: 0.9829 - val_acc: 0.1803\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8999 - acc: 0.3109 - val_loss: 0.9829 - val_acc: 0.1803\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8999 - acc: 0.3109 - val_loss: 0.9828 - val_acc: 0.1803\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8998 - acc: 0.3109 - val_loss: 0.9828 - val_acc: 0.1803\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8998 - acc: 0.3109 - val_loss: 0.9827 - val_acc: 0.1803\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8997 - acc: 0.3109 - val_loss: 0.9827 - val_acc: 0.1803\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8997 - acc: 0.3109 - val_loss: 0.9826 - val_acc: 0.1803\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8996 - acc: 0.3109 - val_loss: 0.9826 - val_acc: 0.1803\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8996 - acc: 0.3109 - val_loss: 0.9825 - val_acc: 0.1803\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8995 - acc: 0.3109 - val_loss: 0.9824 - val_acc: 0.1803\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8995 - acc: 0.3109 - val_loss: 0.9824 - val_acc: 0.1803\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8994 - acc: 0.3109 - val_loss: 0.9823 - val_acc: 0.1803\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7547 - acc: 0.5596 - val_loss: 0.7811 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7546 - acc: 0.5596 - val_loss: 0.7811 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7546 - acc: 0.5596 - val_loss: 0.7810 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7545 - acc: 0.5596 - val_loss: 0.7810 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7545 - acc: 0.5596 - val_loss: 0.7809 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7545 - acc: 0.5596 - val_loss: 0.7808 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7544 - acc: 0.5596 - val_loss: 0.7808 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7544 - acc: 0.5596 - val_loss: 0.7807 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7543 - acc: 0.5596 - val_loss: 0.7807 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7543 - acc: 0.5596 - val_loss: 0.7806 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7542 - acc: 0.5596 - val_loss: 0.7806 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7542 - acc: 0.5596 - val_loss: 0.7805 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7541 - acc: 0.5596 - val_loss: 0.7805 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7541 - acc: 0.5596 - val_loss: 0.7804 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7541 - acc: 0.5596 - val_loss: 0.7803 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7540 - acc: 0.5596 - val_loss: 0.7803 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7540 - acc: 0.5596 - val_loss: 0.7802 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7539 - acc: 0.5596 - val_loss: 0.7802 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7539 - acc: 0.5596 - val_loss: 0.7801 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7538 - acc: 0.5596 - val_loss: 0.7801 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6929 - acc: 0.5309 - val_loss: 0.6769 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6928 - acc: 0.5309 - val_loss: 0.6768 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6928 - acc: 0.5309 - val_loss: 0.6768 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6927 - acc: 0.5309 - val_loss: 0.6767 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6927 - acc: 0.5309 - val_loss: 0.6767 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6926 - acc: 0.5309 - val_loss: 0.6766 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6926 - acc: 0.5309 - val_loss: 0.6766 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6925 - acc: 0.5309 - val_loss: 0.6765 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6925 - acc: 0.5309 - val_loss: 0.6765 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6924 - acc: 0.5309 - val_loss: 0.6765 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6924 - acc: 0.5309 - val_loss: 0.6764 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6923 - acc: 0.5309 - val_loss: 0.6764 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6923 - acc: 0.5309 - val_loss: 0.6763 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6922 - acc: 0.5309 - val_loss: 0.6763 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6922 - acc: 0.5309 - val_loss: 0.6762 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6921 - acc: 0.5309 - val_loss: 0.6762 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6921 - acc: 0.5309 - val_loss: 0.6762 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6920 - acc: 0.5309 - val_loss: 0.6761 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6920 - acc: 0.5309 - val_loss: 0.6761 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6919 - acc: 0.5309 - val_loss: 0.6760 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8928 - acc: 0.4072 - val_loss: 1.0315 - val_acc: 0.3443\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8927 - acc: 0.4072 - val_loss: 1.0314 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8926 - acc: 0.4072 - val_loss: 1.0312 - val_acc: 0.3443\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8925 - acc: 0.4072 - val_loss: 1.0311 - val_acc: 0.3443\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8924 - acc: 0.4072 - val_loss: 1.0310 - val_acc: 0.3443\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8924 - acc: 0.4072 - val_loss: 1.0309 - val_acc: 0.3443\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8923 - acc: 0.4072 - val_loss: 1.0309 - val_acc: 0.3443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8922 - acc: 0.4072 - val_loss: 1.0308 - val_acc: 0.3443\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8921 - acc: 0.4072 - val_loss: 1.0307 - val_acc: 0.3443\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8921 - acc: 0.4072 - val_loss: 1.0306 - val_acc: 0.3443\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8920 - acc: 0.4072 - val_loss: 1.0305 - val_acc: 0.3443\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8919 - acc: 0.4072 - val_loss: 1.0304 - val_acc: 0.3443\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8918 - acc: 0.4072 - val_loss: 1.0303 - val_acc: 0.3443\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8917 - acc: 0.4072 - val_loss: 1.0302 - val_acc: 0.3443\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8917 - acc: 0.4124 - val_loss: 1.0301 - val_acc: 0.3443\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8916 - acc: 0.4124 - val_loss: 1.0300 - val_acc: 0.3443\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8915 - acc: 0.4124 - val_loss: 1.0299 - val_acc: 0.3443\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8915 - acc: 0.4124 - val_loss: 1.0298 - val_acc: 0.3443\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8914 - acc: 0.4124 - val_loss: 1.0297 - val_acc: 0.3443\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8913 - acc: 0.4124 - val_loss: 1.0296 - val_acc: 0.3443\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8409 - acc: 0.3814 - val_loss: 0.8800 - val_acc: 0.3279\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8408 - acc: 0.3814 - val_loss: 0.8799 - val_acc: 0.3279\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8407 - acc: 0.3814 - val_loss: 0.8799 - val_acc: 0.3279\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8407 - acc: 0.3814 - val_loss: 0.8798 - val_acc: 0.3279\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8406 - acc: 0.3814 - val_loss: 0.8797 - val_acc: 0.3279\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8405 - acc: 0.3814 - val_loss: 0.8797 - val_acc: 0.3279\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8405 - acc: 0.3814 - val_loss: 0.8796 - val_acc: 0.3279\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8404 - acc: 0.3814 - val_loss: 0.8795 - val_acc: 0.3279\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8404 - acc: 0.3814 - val_loss: 0.8795 - val_acc: 0.3279\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8403 - acc: 0.3814 - val_loss: 0.8794 - val_acc: 0.3279\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8403 - acc: 0.3814 - val_loss: 0.8794 - val_acc: 0.3279\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8402 - acc: 0.3814 - val_loss: 0.8793 - val_acc: 0.3279\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8402 - acc: 0.3814 - val_loss: 0.8792 - val_acc: 0.3279\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8401 - acc: 0.3814 - val_loss: 0.8792 - val_acc: 0.3279\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8400 - acc: 0.3814 - val_loss: 0.8791 - val_acc: 0.3279\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8400 - acc: 0.3814 - val_loss: 0.8791 - val_acc: 0.3279\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8399 - acc: 0.3814 - val_loss: 0.8790 - val_acc: 0.3279\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8399 - acc: 0.3814 - val_loss: 0.8790 - val_acc: 0.3279\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8398 - acc: 0.3814 - val_loss: 0.8789 - val_acc: 0.3279\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8398 - acc: 0.3814 - val_loss: 0.8788 - val_acc: 0.3279\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7237 - acc: 0.5699 - val_loss: 0.7795 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7236 - acc: 0.5699 - val_loss: 0.7794 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7235 - acc: 0.5699 - val_loss: 0.7793 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7234 - acc: 0.5699 - val_loss: 0.7792 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7234 - acc: 0.5699 - val_loss: 0.7791 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7233 - acc: 0.5699 - val_loss: 0.7790 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7233 - acc: 0.5699 - val_loss: 0.7790 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7232 - acc: 0.5699 - val_loss: 0.7789 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7231 - acc: 0.5699 - val_loss: 0.7788 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7231 - acc: 0.5699 - val_loss: 0.7788 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7230 - acc: 0.5699 - val_loss: 0.7787 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7230 - acc: 0.5699 - val_loss: 0.7786 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7229 - acc: 0.5699 - val_loss: 0.7786 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7229 - acc: 0.5699 - val_loss: 0.7785 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7228 - acc: 0.5699 - val_loss: 0.7784 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7228 - acc: 0.5699 - val_loss: 0.7784 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7227 - acc: 0.5699 - val_loss: 0.7783 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7226 - acc: 0.5699 - val_loss: 0.7783 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7226 - acc: 0.5699 - val_loss: 0.7782 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7225 - acc: 0.5699 - val_loss: 0.7781 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7337 - acc: 0.4249 - val_loss: 0.7380 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7336 - acc: 0.4249 - val_loss: 0.7379 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7336 - acc: 0.4301 - val_loss: 0.7378 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7335 - acc: 0.4301 - val_loss: 0.7378 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7334 - acc: 0.4301 - val_loss: 0.7377 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7333 - acc: 0.4301 - val_loss: 0.7376 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7333 - acc: 0.4301 - val_loss: 0.7375 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7332 - acc: 0.4301 - val_loss: 0.7375 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7331 - acc: 0.4301 - val_loss: 0.7374 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7330 - acc: 0.4301 - val_loss: 0.7373 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7330 - acc: 0.4301 - val_loss: 0.7373 - val_acc: 0.4262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7329 - acc: 0.4301 - val_loss: 0.7372 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7328 - acc: 0.4301 - val_loss: 0.7371 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7328 - acc: 0.4301 - val_loss: 0.7371 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7327 - acc: 0.4301 - val_loss: 0.7370 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7327 - acc: 0.4301 - val_loss: 0.7370 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7326 - acc: 0.4301 - val_loss: 0.7369 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7326 - acc: 0.4301 - val_loss: 0.7368 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7325 - acc: 0.4301 - val_loss: 0.7368 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7324 - acc: 0.4301 - val_loss: 0.7367 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6908 - acc: 0.5722 - val_loss: 0.7365 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6907 - acc: 0.5722 - val_loss: 0.7364 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6906 - acc: 0.5722 - val_loss: 0.7363 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6905 - acc: 0.5722 - val_loss: 0.7362 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6905 - acc: 0.5722 - val_loss: 0.7361 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6904 - acc: 0.5722 - val_loss: 0.7360 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6903 - acc: 0.5722 - val_loss: 0.7359 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6902 - acc: 0.5722 - val_loss: 0.7358 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6901 - acc: 0.5722 - val_loss: 0.7357 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6901 - acc: 0.5722 - val_loss: 0.7356 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6900 - acc: 0.5722 - val_loss: 0.7355 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6899 - acc: 0.5722 - val_loss: 0.7355 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6898 - acc: 0.5722 - val_loss: 0.7354 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6897 - acc: 0.5722 - val_loss: 0.7353 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6897 - acc: 0.5722 - val_loss: 0.7352 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6896 - acc: 0.5722 - val_loss: 0.7351 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6895 - acc: 0.5722 - val_loss: 0.7350 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6895 - acc: 0.5722 - val_loss: 0.7349 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6894 - acc: 0.5722 - val_loss: 0.7349 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6893 - acc: 0.5722 - val_loss: 0.7348 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6855 - acc: 0.5464 - val_loss: 0.7283 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6854 - acc: 0.5464 - val_loss: 0.7282 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6854 - acc: 0.5464 - val_loss: 0.7281 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6853 - acc: 0.5464 - val_loss: 0.7280 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6852 - acc: 0.5464 - val_loss: 0.7279 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6852 - acc: 0.5464 - val_loss: 0.7279 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6851 - acc: 0.5464 - val_loss: 0.7278 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6850 - acc: 0.5464 - val_loss: 0.7277 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6850 - acc: 0.5464 - val_loss: 0.7276 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6849 - acc: 0.5464 - val_loss: 0.7275 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6848 - acc: 0.5464 - val_loss: 0.7275 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6848 - acc: 0.5464 - val_loss: 0.7274 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6847 - acc: 0.5464 - val_loss: 0.7273 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6846 - acc: 0.5464 - val_loss: 0.7272 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6846 - acc: 0.5464 - val_loss: 0.7272 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6845 - acc: 0.5464 - val_loss: 0.7271 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6845 - acc: 0.5464 - val_loss: 0.7270 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6844 - acc: 0.5464 - val_loss: 0.7270 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6843 - acc: 0.5464 - val_loss: 0.7269 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6843 - acc: 0.5464 - val_loss: 0.7268 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7293 - acc: 0.4691 - val_loss: 0.7263 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7292 - acc: 0.4691 - val_loss: 0.7262 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7291 - acc: 0.4691 - val_loss: 0.7261 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7290 - acc: 0.4691 - val_loss: 0.7261 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7290 - acc: 0.4691 - val_loss: 0.7260 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7289 - acc: 0.4691 - val_loss: 0.7259 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7288 - acc: 0.4691 - val_loss: 0.7258 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7288 - acc: 0.4691 - val_loss: 0.7258 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7287 - acc: 0.4691 - val_loss: 0.7257 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7286 - acc: 0.4691 - val_loss: 0.7256 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7285 - acc: 0.4691 - val_loss: 0.7255 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7284 - acc: 0.4691 - val_loss: 0.7255 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7284 - acc: 0.4691 - val_loss: 0.7254 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7283 - acc: 0.4691 - val_loss: 0.7253 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7282 - acc: 0.4691 - val_loss: 0.7253 - val_acc: 0.4754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7282 - acc: 0.4691 - val_loss: 0.7252 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7281 - acc: 0.4691 - val_loss: 0.7251 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7280 - acc: 0.4691 - val_loss: 0.7250 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7280 - acc: 0.4691 - val_loss: 0.7250 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7279 - acc: 0.4691 - val_loss: 0.7249 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7369 - acc: 0.4249 - val_loss: 0.7709 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7367 - acc: 0.4249 - val_loss: 0.7707 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7366 - acc: 0.4249 - val_loss: 0.7706 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7365 - acc: 0.4249 - val_loss: 0.7704 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7364 - acc: 0.4249 - val_loss: 0.7703 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7363 - acc: 0.4249 - val_loss: 0.7701 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7362 - acc: 0.4249 - val_loss: 0.7700 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7361 - acc: 0.4249 - val_loss: 0.7699 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7360 - acc: 0.4249 - val_loss: 0.7697 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7359 - acc: 0.4249 - val_loss: 0.7696 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7358 - acc: 0.4249 - val_loss: 0.7695 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7356 - acc: 0.4249 - val_loss: 0.7694 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7355 - acc: 0.4249 - val_loss: 0.7692 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7355 - acc: 0.4249 - val_loss: 0.7691 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7354 - acc: 0.4249 - val_loss: 0.7690 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7353 - acc: 0.4249 - val_loss: 0.7689 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7352 - acc: 0.4249 - val_loss: 0.7688 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7351 - acc: 0.4249 - val_loss: 0.7687 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7350 - acc: 0.4301 - val_loss: 0.7686 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7349 - acc: 0.4301 - val_loss: 0.7684 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8313 - acc: 0.4767 - val_loss: 0.8834 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8311 - acc: 0.4767 - val_loss: 0.8832 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8310 - acc: 0.4767 - val_loss: 0.8830 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8309 - acc: 0.4767 - val_loss: 0.8829 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8308 - acc: 0.4767 - val_loss: 0.8828 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8306 - acc: 0.4767 - val_loss: 0.8826 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8305 - acc: 0.4767 - val_loss: 0.8825 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8304 - acc: 0.4767 - val_loss: 0.8824 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8303 - acc: 0.4767 - val_loss: 0.8823 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8303 - acc: 0.4767 - val_loss: 0.8822 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8302 - acc: 0.4767 - val_loss: 0.8821 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8301 - acc: 0.4767 - val_loss: 0.8820 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8300 - acc: 0.4767 - val_loss: 0.8818 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8299 - acc: 0.4767 - val_loss: 0.8817 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8298 - acc: 0.4767 - val_loss: 0.8816 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8297 - acc: 0.4767 - val_loss: 0.8815 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8296 - acc: 0.4767 - val_loss: 0.8813 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8295 - acc: 0.4767 - val_loss: 0.8812 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8294 - acc: 0.4767 - val_loss: 0.8811 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8293 - acc: 0.4767 - val_loss: 0.8810 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7082 - acc: 0.5515 - val_loss: 0.7055 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7081 - acc: 0.5515 - val_loss: 0.7053 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7080 - acc: 0.5515 - val_loss: 0.7052 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7079 - acc: 0.5515 - val_loss: 0.7051 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7078 - acc: 0.5515 - val_loss: 0.7049 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7077 - acc: 0.5515 - val_loss: 0.7048 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7076 - acc: 0.5515 - val_loss: 0.7047 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7075 - acc: 0.5515 - val_loss: 0.7046 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7074 - acc: 0.5515 - val_loss: 0.7045 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7073 - acc: 0.5515 - val_loss: 0.7044 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7072 - acc: 0.5515 - val_loss: 0.7043 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7071 - acc: 0.5515 - val_loss: 0.7042 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7070 - acc: 0.5515 - val_loss: 0.7041 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7069 - acc: 0.5515 - val_loss: 0.7040 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7068 - acc: 0.5515 - val_loss: 0.7038 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7067 - acc: 0.5515 - val_loss: 0.7037 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7067 - acc: 0.5515 - val_loss: 0.7036 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7066 - acc: 0.5515 - val_loss: 0.7035 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7065 - acc: 0.5515 - val_loss: 0.7034 - val_acc: 0.5082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7064 - acc: 0.5515 - val_loss: 0.7034 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7204 - acc: 0.4588 - val_loss: 0.7109 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7202 - acc: 0.4588 - val_loss: 0.7107 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7201 - acc: 0.4588 - val_loss: 0.7106 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7200 - acc: 0.4588 - val_loss: 0.7105 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7199 - acc: 0.4588 - val_loss: 0.7104 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7198 - acc: 0.4588 - val_loss: 0.7103 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7197 - acc: 0.4588 - val_loss: 0.7102 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7196 - acc: 0.4588 - val_loss: 0.7101 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7195 - acc: 0.4588 - val_loss: 0.7099 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7194 - acc: 0.4588 - val_loss: 0.7098 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7193 - acc: 0.4588 - val_loss: 0.7097 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7192 - acc: 0.4588 - val_loss: 0.7096 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7191 - acc: 0.4639 - val_loss: 0.7095 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7190 - acc: 0.4588 - val_loss: 0.7094 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7189 - acc: 0.4588 - val_loss: 0.7092 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7187 - acc: 0.4588 - val_loss: 0.7091 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7186 - acc: 0.4588 - val_loss: 0.7090 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7185 - acc: 0.4588 - val_loss: 0.7089 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7184 - acc: 0.4639 - val_loss: 0.7088 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7183 - acc: 0.4639 - val_loss: 0.7087 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6867 - acc: 0.5619 - val_loss: 0.6975 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6866 - acc: 0.5619 - val_loss: 0.6974 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6864 - acc: 0.5619 - val_loss: 0.6973 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6863 - acc: 0.5619 - val_loss: 0.6972 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6862 - acc: 0.5619 - val_loss: 0.6971 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6861 - acc: 0.5619 - val_loss: 0.6970 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6861 - acc: 0.5567 - val_loss: 0.6969 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6860 - acc: 0.5567 - val_loss: 0.6968 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6859 - acc: 0.5567 - val_loss: 0.6967 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6858 - acc: 0.5567 - val_loss: 0.6966 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6857 - acc: 0.5567 - val_loss: 0.6965 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6856 - acc: 0.5567 - val_loss: 0.6965 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6856 - acc: 0.5567 - val_loss: 0.6964 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6855 - acc: 0.5567 - val_loss: 0.6963 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6854 - acc: 0.5567 - val_loss: 0.6962 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6853 - acc: 0.5567 - val_loss: 0.6961 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6852 - acc: 0.5567 - val_loss: 0.6960 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6851 - acc: 0.5567 - val_loss: 0.6959 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6851 - acc: 0.5567 - val_loss: 0.6958 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6850 - acc: 0.5567 - val_loss: 0.6957 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7015 - acc: 0.4974 - val_loss: 0.7235 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7013 - acc: 0.4974 - val_loss: 0.7233 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7012 - acc: 0.4974 - val_loss: 0.7232 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7010 - acc: 0.4974 - val_loss: 0.7230 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7009 - acc: 0.4974 - val_loss: 0.7229 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7008 - acc: 0.4974 - val_loss: 0.7228 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7007 - acc: 0.4974 - val_loss: 0.7227 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7006 - acc: 0.4974 - val_loss: 0.7225 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7005 - acc: 0.4974 - val_loss: 0.7224 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7004 - acc: 0.4974 - val_loss: 0.7223 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7003 - acc: 0.4974 - val_loss: 0.7222 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7002 - acc: 0.4974 - val_loss: 0.7221 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7001 - acc: 0.4974 - val_loss: 0.7219 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7000 - acc: 0.4974 - val_loss: 0.7218 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6998 - acc: 0.4974 - val_loss: 0.7216 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6997 - acc: 0.4974 - val_loss: 0.7214 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6996 - acc: 0.4974 - val_loss: 0.7213 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6994 - acc: 0.4974 - val_loss: 0.7211 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6993 - acc: 0.4974 - val_loss: 0.7210 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6992 - acc: 0.4922 - val_loss: 0.7209 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7291 - acc: 0.4145 - val_loss: 0.7446 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7289 - acc: 0.4145 - val_loss: 0.7444 - val_acc: 0.3115\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7287 - acc: 0.4145 - val_loss: 0.7443 - val_acc: 0.3115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7286 - acc: 0.4145 - val_loss: 0.7441 - val_acc: 0.3115\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7285 - acc: 0.4145 - val_loss: 0.7440 - val_acc: 0.3115\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7283 - acc: 0.4145 - val_loss: 0.7438 - val_acc: 0.3115\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7282 - acc: 0.4145 - val_loss: 0.7437 - val_acc: 0.3115\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7281 - acc: 0.4145 - val_loss: 0.7436 - val_acc: 0.3115\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7280 - acc: 0.4145 - val_loss: 0.7434 - val_acc: 0.3115\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7278 - acc: 0.4145 - val_loss: 0.7433 - val_acc: 0.3115\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7277 - acc: 0.4145 - val_loss: 0.7432 - val_acc: 0.3115\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7276 - acc: 0.4145 - val_loss: 0.7431 - val_acc: 0.3115\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7275 - acc: 0.4145 - val_loss: 0.7430 - val_acc: 0.3115\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7274 - acc: 0.4145 - val_loss: 0.7429 - val_acc: 0.3115\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7273 - acc: 0.4145 - val_loss: 0.7427 - val_acc: 0.3115\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7272 - acc: 0.4145 - val_loss: 0.7426 - val_acc: 0.3115\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7271 - acc: 0.4145 - val_loss: 0.7425 - val_acc: 0.3115\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7270 - acc: 0.4145 - val_loss: 0.7424 - val_acc: 0.3115\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7269 - acc: 0.4145 - val_loss: 0.7423 - val_acc: 0.3115\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7268 - acc: 0.4145 - val_loss: 0.7422 - val_acc: 0.3115\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6053 - acc: 0.7268 - val_loss: 0.5772 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6052 - acc: 0.7320 - val_loss: 0.5771 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6050 - acc: 0.7320 - val_loss: 0.5769 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6049 - acc: 0.7320 - val_loss: 0.5768 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6048 - acc: 0.7320 - val_loss: 0.5767 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6047 - acc: 0.7320 - val_loss: 0.5766 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6046 - acc: 0.7320 - val_loss: 0.5765 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6045 - acc: 0.7320 - val_loss: 0.5763 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6043 - acc: 0.7320 - val_loss: 0.5762 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6042 - acc: 0.7320 - val_loss: 0.5761 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6041 - acc: 0.7320 - val_loss: 0.5760 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6040 - acc: 0.7320 - val_loss: 0.5759 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6039 - acc: 0.7320 - val_loss: 0.5757 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6037 - acc: 0.7320 - val_loss: 0.5756 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6036 - acc: 0.7320 - val_loss: 0.5755 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6035 - acc: 0.7320 - val_loss: 0.5754 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6034 - acc: 0.7320 - val_loss: 0.5753 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6033 - acc: 0.7320 - val_loss: 0.5752 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6032 - acc: 0.7320 - val_loss: 0.5751 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6031 - acc: 0.7320 - val_loss: 0.5749 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6652 - acc: 0.6443 - val_loss: 0.6585 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6650 - acc: 0.6392 - val_loss: 0.6584 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6649 - acc: 0.6392 - val_loss: 0.6582 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6648 - acc: 0.6392 - val_loss: 0.6581 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6647 - acc: 0.6392 - val_loss: 0.6580 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6646 - acc: 0.6392 - val_loss: 0.6578 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6645 - acc: 0.6392 - val_loss: 0.6577 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6643 - acc: 0.6392 - val_loss: 0.6576 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6642 - acc: 0.6392 - val_loss: 0.6575 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6641 - acc: 0.6392 - val_loss: 0.6574 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6640 - acc: 0.6392 - val_loss: 0.6572 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6639 - acc: 0.6392 - val_loss: 0.6571 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6638 - acc: 0.6392 - val_loss: 0.6570 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6636 - acc: 0.6392 - val_loss: 0.6569 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6635 - acc: 0.6392 - val_loss: 0.6567 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6634 - acc: 0.6392 - val_loss: 0.6566 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6633 - acc: 0.6392 - val_loss: 0.6565 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6632 - acc: 0.6392 - val_loss: 0.6564 - val_acc: 0.6066\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6631 - acc: 0.6392 - val_loss: 0.6563 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6629 - acc: 0.6392 - val_loss: 0.6561 - val_acc: 0.6066\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7427 - acc: 0.3918 - val_loss: 0.7275 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7425 - acc: 0.3918 - val_loss: 0.7273 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7423 - acc: 0.3918 - val_loss: 0.7272 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7422 - acc: 0.3918 - val_loss: 0.7270 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7420 - acc: 0.3918 - val_loss: 0.7269 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7419 - acc: 0.3918 - val_loss: 0.7267 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7418 - acc: 0.3918 - val_loss: 0.7266 - val_acc: 0.4262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7416 - acc: 0.3969 - val_loss: 0.7265 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7415 - acc: 0.3969 - val_loss: 0.7263 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7414 - acc: 0.3969 - val_loss: 0.7262 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7412 - acc: 0.3969 - val_loss: 0.7260 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7411 - acc: 0.3969 - val_loss: 0.7259 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7409 - acc: 0.3969 - val_loss: 0.7257 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7408 - acc: 0.3969 - val_loss: 0.7256 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7406 - acc: 0.3969 - val_loss: 0.7254 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7405 - acc: 0.3969 - val_loss: 0.7253 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7404 - acc: 0.3969 - val_loss: 0.7251 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7402 - acc: 0.4021 - val_loss: 0.7250 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7401 - acc: 0.4021 - val_loss: 0.7249 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7400 - acc: 0.4072 - val_loss: 0.7247 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.7431 - acc: 0.5285 - val_loss: 0.6763 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7431 - acc: 0.5285 - val_loss: 0.6763 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7431 - acc: 0.5285 - val_loss: 0.6763 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7431 - acc: 0.5285 - val_loss: 0.6763 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7430 - acc: 0.5285 - val_loss: 0.6763 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7430 - acc: 0.5285 - val_loss: 0.6763 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7430 - acc: 0.5285 - val_loss: 0.6763 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7430 - acc: 0.5285 - val_loss: 0.6762 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7430 - acc: 0.5285 - val_loss: 0.6762 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7430 - acc: 0.5285 - val_loss: 0.6762 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7430 - acc: 0.5285 - val_loss: 0.6762 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7430 - acc: 0.5285 - val_loss: 0.6762 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7430 - acc: 0.5285 - val_loss: 0.6762 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7430 - acc: 0.5285 - val_loss: 0.6762 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7429 - acc: 0.5285 - val_loss: 0.6762 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7429 - acc: 0.5285 - val_loss: 0.6762 - val_acc: 0.6557\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7429 - acc: 0.5285 - val_loss: 0.6762 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7429 - acc: 0.5285 - val_loss: 0.6762 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7429 - acc: 0.5285 - val_loss: 0.6762 - val_acc: 0.6557\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7429 - acc: 0.5285 - val_loss: 0.6762 - val_acc: 0.6557\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9886 - acc: 0.3938 - val_loss: 1.0146 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9886 - acc: 0.3938 - val_loss: 1.0146 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9886 - acc: 0.3938 - val_loss: 1.0145 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9885 - acc: 0.3990 - val_loss: 1.0145 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9885 - acc: 0.3990 - val_loss: 1.0145 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9885 - acc: 0.3938 - val_loss: 1.0144 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9885 - acc: 0.3938 - val_loss: 1.0144 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9885 - acc: 0.3938 - val_loss: 1.0144 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9884 - acc: 0.3938 - val_loss: 1.0144 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9884 - acc: 0.3938 - val_loss: 1.0144 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9884 - acc: 0.3938 - val_loss: 1.0143 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9884 - acc: 0.3938 - val_loss: 1.0143 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9883 - acc: 0.3938 - val_loss: 1.0143 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9883 - acc: 0.3938 - val_loss: 1.0143 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9883 - acc: 0.3938 - val_loss: 1.0142 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9883 - acc: 0.3938 - val_loss: 1.0142 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9882 - acc: 0.3938 - val_loss: 1.0142 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9882 - acc: 0.3938 - val_loss: 1.0142 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9882 - acc: 0.3938 - val_loss: 1.0141 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9882 - acc: 0.3938 - val_loss: 1.0141 - val_acc: 0.4590\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9618 - acc: 0.4021 - val_loss: 1.0910 - val_acc: 0.3279\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9618 - acc: 0.4021 - val_loss: 1.0910 - val_acc: 0.3279\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9617 - acc: 0.4021 - val_loss: 1.0910 - val_acc: 0.3279\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9617 - acc: 0.4021 - val_loss: 1.0909 - val_acc: 0.3279\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9617 - acc: 0.4021 - val_loss: 1.0909 - val_acc: 0.3279\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9617 - acc: 0.4021 - val_loss: 1.0909 - val_acc: 0.3279\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9616 - acc: 0.4021 - val_loss: 1.0908 - val_acc: 0.3279\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9616 - acc: 0.4021 - val_loss: 1.0908 - val_acc: 0.3279\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9616 - acc: 0.4021 - val_loss: 1.0908 - val_acc: 0.3279\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9616 - acc: 0.4021 - val_loss: 1.0908 - val_acc: 0.3279\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9615 - acc: 0.4021 - val_loss: 1.0907 - val_acc: 0.3279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9615 - acc: 0.4021 - val_loss: 1.0907 - val_acc: 0.3279\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9615 - acc: 0.4021 - val_loss: 1.0907 - val_acc: 0.3279\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9615 - acc: 0.4021 - val_loss: 1.0906 - val_acc: 0.3279\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9614 - acc: 0.4021 - val_loss: 1.0906 - val_acc: 0.3279\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9614 - acc: 0.4021 - val_loss: 1.0906 - val_acc: 0.3279\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9614 - acc: 0.4021 - val_loss: 1.0905 - val_acc: 0.3279\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9614 - acc: 0.4021 - val_loss: 1.0905 - val_acc: 0.3279\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9613 - acc: 0.4021 - val_loss: 1.0905 - val_acc: 0.3279\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9613 - acc: 0.4021 - val_loss: 1.0904 - val_acc: 0.3279\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7958 - acc: 0.5361 - val_loss: 0.7623 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7958 - acc: 0.5361 - val_loss: 0.7623 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7958 - acc: 0.5361 - val_loss: 0.7623 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7958 - acc: 0.5361 - val_loss: 0.7623 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7957 - acc: 0.5361 - val_loss: 0.7623 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7957 - acc: 0.5361 - val_loss: 0.7623 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7957 - acc: 0.5361 - val_loss: 0.7622 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7957 - acc: 0.5361 - val_loss: 0.7622 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7957 - acc: 0.5361 - val_loss: 0.7622 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7957 - acc: 0.5361 - val_loss: 0.7622 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7957 - acc: 0.5361 - val_loss: 0.7622 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7956 - acc: 0.5361 - val_loss: 0.7622 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7956 - acc: 0.5361 - val_loss: 0.7621 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7956 - acc: 0.5361 - val_loss: 0.7621 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7956 - acc: 0.5361 - val_loss: 0.7621 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7956 - acc: 0.5361 - val_loss: 0.7621 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7956 - acc: 0.5361 - val_loss: 0.7621 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7955 - acc: 0.5361 - val_loss: 0.7621 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7955 - acc: 0.5361 - val_loss: 0.7620 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7955 - acc: 0.5361 - val_loss: 0.7620 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6703 - acc: 0.6340 - val_loss: 0.6630 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6703 - acc: 0.6340 - val_loss: 0.6630 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6703 - acc: 0.6340 - val_loss: 0.6630 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6703 - acc: 0.6340 - val_loss: 0.6630 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6703 - acc: 0.6340 - val_loss: 0.6629 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6703 - acc: 0.6340 - val_loss: 0.6629 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6702 - acc: 0.6340 - val_loss: 0.6629 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6702 - acc: 0.6340 - val_loss: 0.6629 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6702 - acc: 0.6340 - val_loss: 0.6629 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6702 - acc: 0.6340 - val_loss: 0.6629 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6702 - acc: 0.6340 - val_loss: 0.6629 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6702 - acc: 0.6340 - val_loss: 0.6629 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6702 - acc: 0.6340 - val_loss: 0.6629 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6702 - acc: 0.6340 - val_loss: 0.6629 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6702 - acc: 0.6340 - val_loss: 0.6628 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6701 - acc: 0.6340 - val_loss: 0.6628 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6701 - acc: 0.6340 - val_loss: 0.6628 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6701 - acc: 0.6340 - val_loss: 0.6628 - val_acc: 0.6066\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6701 - acc: 0.6340 - val_loss: 0.6628 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6701 - acc: 0.6340 - val_loss: 0.6628 - val_acc: 0.6066\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9448 - acc: 0.3886 - val_loss: 0.9771 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9447 - acc: 0.3886 - val_loss: 0.9771 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9447 - acc: 0.3886 - val_loss: 0.9770 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9447 - acc: 0.3886 - val_loss: 0.9770 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9446 - acc: 0.3886 - val_loss: 0.9770 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9446 - acc: 0.3886 - val_loss: 0.9769 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9446 - acc: 0.3886 - val_loss: 0.9769 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9445 - acc: 0.3886 - val_loss: 0.9769 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9445 - acc: 0.3886 - val_loss: 0.9769 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9445 - acc: 0.3886 - val_loss: 0.9768 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9445 - acc: 0.3886 - val_loss: 0.9768 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9444 - acc: 0.3886 - val_loss: 0.9768 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9444 - acc: 0.3886 - val_loss: 0.9767 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9444 - acc: 0.3886 - val_loss: 0.9767 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9444 - acc: 0.3886 - val_loss: 0.9767 - val_acc: 0.4262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9443 - acc: 0.3886 - val_loss: 0.9767 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9443 - acc: 0.3886 - val_loss: 0.9766 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9443 - acc: 0.3886 - val_loss: 0.9766 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9443 - acc: 0.3886 - val_loss: 0.9766 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9442 - acc: 0.3886 - val_loss: 0.9765 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7166 - acc: 0.5233 - val_loss: 0.7505 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7166 - acc: 0.5233 - val_loss: 0.7505 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7166 - acc: 0.5233 - val_loss: 0.7505 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7166 - acc: 0.5233 - val_loss: 0.7505 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7165 - acc: 0.5233 - val_loss: 0.7504 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7165 - acc: 0.5233 - val_loss: 0.7504 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7165 - acc: 0.5233 - val_loss: 0.7504 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7165 - acc: 0.5233 - val_loss: 0.7504 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7165 - acc: 0.5233 - val_loss: 0.7504 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7165 - acc: 0.5233 - val_loss: 0.7504 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7164 - acc: 0.5233 - val_loss: 0.7503 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7164 - acc: 0.5233 - val_loss: 0.7503 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7164 - acc: 0.5233 - val_loss: 0.7503 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7164 - acc: 0.5233 - val_loss: 0.7503 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7164 - acc: 0.5233 - val_loss: 0.7503 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7164 - acc: 0.5233 - val_loss: 0.7503 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7164 - acc: 0.5233 - val_loss: 0.7502 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7163 - acc: 0.5233 - val_loss: 0.7502 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7163 - acc: 0.5233 - val_loss: 0.7502 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7163 - acc: 0.5233 - val_loss: 0.7502 - val_acc: 0.5902\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0086 - acc: 0.3144 - val_loss: 0.9896 - val_acc: 0.2951\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0085 - acc: 0.3144 - val_loss: 0.9896 - val_acc: 0.2951\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0085 - acc: 0.3144 - val_loss: 0.9896 - val_acc: 0.2951\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0085 - acc: 0.3144 - val_loss: 0.9896 - val_acc: 0.2951\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0084 - acc: 0.3144 - val_loss: 0.9895 - val_acc: 0.2951\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0084 - acc: 0.3144 - val_loss: 0.9895 - val_acc: 0.2951\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0084 - acc: 0.3144 - val_loss: 0.9895 - val_acc: 0.2951\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0083 - acc: 0.3144 - val_loss: 0.9894 - val_acc: 0.2951\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0083 - acc: 0.3144 - val_loss: 0.9894 - val_acc: 0.2951\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0083 - acc: 0.3144 - val_loss: 0.9894 - val_acc: 0.2951\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0082 - acc: 0.3144 - val_loss: 0.9894 - val_acc: 0.2951\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0082 - acc: 0.3144 - val_loss: 0.9893 - val_acc: 0.2951\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0082 - acc: 0.3144 - val_loss: 0.9893 - val_acc: 0.2951\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0081 - acc: 0.3144 - val_loss: 0.9893 - val_acc: 0.2951\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0081 - acc: 0.3144 - val_loss: 0.9892 - val_acc: 0.2951\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0081 - acc: 0.3144 - val_loss: 0.9892 - val_acc: 0.2951\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0081 - acc: 0.3144 - val_loss: 0.9892 - val_acc: 0.2951\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0080 - acc: 0.3144 - val_loss: 0.9892 - val_acc: 0.2951\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0080 - acc: 0.3144 - val_loss: 0.9891 - val_acc: 0.2951\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0080 - acc: 0.3144 - val_loss: 0.9891 - val_acc: 0.2951\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7583 - acc: 0.5361 - val_loss: 0.7700 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7583 - acc: 0.5361 - val_loss: 0.7700 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7582 - acc: 0.5361 - val_loss: 0.7700 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7582 - acc: 0.5361 - val_loss: 0.7699 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7582 - acc: 0.5361 - val_loss: 0.7699 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7582 - acc: 0.5361 - val_loss: 0.7699 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7582 - acc: 0.5361 - val_loss: 0.7699 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7581 - acc: 0.5361 - val_loss: 0.7699 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7581 - acc: 0.5361 - val_loss: 0.7698 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7581 - acc: 0.5361 - val_loss: 0.7698 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7581 - acc: 0.5361 - val_loss: 0.7698 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7581 - acc: 0.5361 - val_loss: 0.7698 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7580 - acc: 0.5361 - val_loss: 0.7698 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7580 - acc: 0.5361 - val_loss: 0.7697 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7580 - acc: 0.5361 - val_loss: 0.7697 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7580 - acc: 0.5361 - val_loss: 0.7697 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7580 - acc: 0.5361 - val_loss: 0.7697 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7579 - acc: 0.5361 - val_loss: 0.7697 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7579 - acc: 0.5361 - val_loss: 0.7697 - val_acc: 0.5246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7579 - acc: 0.5361 - val_loss: 0.7696 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6212 - acc: 0.6701 - val_loss: 0.6520 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6211 - acc: 0.6701 - val_loss: 0.6520 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6211 - acc: 0.6701 - val_loss: 0.6519 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6211 - acc: 0.6701 - val_loss: 0.6519 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6211 - acc: 0.6701 - val_loss: 0.6519 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6211 - acc: 0.6701 - val_loss: 0.6519 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6211 - acc: 0.6701 - val_loss: 0.6519 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6211 - acc: 0.6701 - val_loss: 0.6519 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6210 - acc: 0.6701 - val_loss: 0.6519 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6210 - acc: 0.6701 - val_loss: 0.6519 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6210 - acc: 0.6701 - val_loss: 0.6518 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6210 - acc: 0.6701 - val_loss: 0.6518 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6210 - acc: 0.6701 - val_loss: 0.6518 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6210 - acc: 0.6701 - val_loss: 0.6518 - val_acc: 0.6885\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6210 - acc: 0.6701 - val_loss: 0.6518 - val_acc: 0.6885\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6209 - acc: 0.6701 - val_loss: 0.6518 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6209 - acc: 0.6701 - val_loss: 0.6518 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6209 - acc: 0.6701 - val_loss: 0.6518 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6209 - acc: 0.6701 - val_loss: 0.6517 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6209 - acc: 0.6701 - val_loss: 0.6517 - val_acc: 0.6885\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8238 - acc: 0.4663 - val_loss: 0.8896 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8238 - acc: 0.4663 - val_loss: 0.8895 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8237 - acc: 0.4663 - val_loss: 0.8895 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8237 - acc: 0.4663 - val_loss: 0.8894 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8236 - acc: 0.4663 - val_loss: 0.8894 - val_acc: 0.3770\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8236 - acc: 0.4663 - val_loss: 0.8893 - val_acc: 0.3770\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8236 - acc: 0.4663 - val_loss: 0.8893 - val_acc: 0.3770\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8235 - acc: 0.4663 - val_loss: 0.8892 - val_acc: 0.3770\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8235 - acc: 0.4663 - val_loss: 0.8892 - val_acc: 0.3770\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8235 - acc: 0.4663 - val_loss: 0.8891 - val_acc: 0.3770\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8234 - acc: 0.4663 - val_loss: 0.8891 - val_acc: 0.3770\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8234 - acc: 0.4663 - val_loss: 0.8890 - val_acc: 0.3770\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8233 - acc: 0.4663 - val_loss: 0.8890 - val_acc: 0.3770\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8233 - acc: 0.4663 - val_loss: 0.8889 - val_acc: 0.3770\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8233 - acc: 0.4663 - val_loss: 0.8889 - val_acc: 0.3770\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8232 - acc: 0.4663 - val_loss: 0.8888 - val_acc: 0.3770\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8232 - acc: 0.4663 - val_loss: 0.8888 - val_acc: 0.3770\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8231 - acc: 0.4663 - val_loss: 0.8887 - val_acc: 0.3770\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8231 - acc: 0.4663 - val_loss: 0.8887 - val_acc: 0.3770\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8231 - acc: 0.4663 - val_loss: 0.8886 - val_acc: 0.3770\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8286 - acc: 0.4404 - val_loss: 0.7676 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8285 - acc: 0.4404 - val_loss: 0.7675 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8285 - acc: 0.4404 - val_loss: 0.7675 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8285 - acc: 0.4404 - val_loss: 0.7675 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8284 - acc: 0.4404 - val_loss: 0.7674 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8284 - acc: 0.4404 - val_loss: 0.7674 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8284 - acc: 0.4404 - val_loss: 0.7674 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8283 - acc: 0.4404 - val_loss: 0.7674 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8283 - acc: 0.4404 - val_loss: 0.7673 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8283 - acc: 0.4404 - val_loss: 0.7673 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8283 - acc: 0.4404 - val_loss: 0.7673 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8282 - acc: 0.4404 - val_loss: 0.7672 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8282 - acc: 0.4404 - val_loss: 0.7672 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8282 - acc: 0.4404 - val_loss: 0.7672 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8281 - acc: 0.4404 - val_loss: 0.7671 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8281 - acc: 0.4404 - val_loss: 0.7671 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8281 - acc: 0.4404 - val_loss: 0.7671 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8281 - acc: 0.4404 - val_loss: 0.7670 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8280 - acc: 0.4404 - val_loss: 0.7670 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8280 - acc: 0.4404 - val_loss: 0.7670 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7264 - acc: 0.5309 - val_loss: 0.7201 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7264 - acc: 0.5309 - val_loss: 0.7201 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7263 - acc: 0.5309 - val_loss: 0.7200 - val_acc: 0.5410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7263 - acc: 0.5309 - val_loss: 0.7200 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7263 - acc: 0.5309 - val_loss: 0.7199 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7262 - acc: 0.5309 - val_loss: 0.7199 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7262 - acc: 0.5309 - val_loss: 0.7199 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7262 - acc: 0.5309 - val_loss: 0.7198 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7261 - acc: 0.5309 - val_loss: 0.7198 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7261 - acc: 0.5309 - val_loss: 0.7198 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7261 - acc: 0.5309 - val_loss: 0.7197 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7261 - acc: 0.5309 - val_loss: 0.7197 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7260 - acc: 0.5309 - val_loss: 0.7197 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7260 - acc: 0.5309 - val_loss: 0.7196 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7260 - acc: 0.5309 - val_loss: 0.7196 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7259 - acc: 0.5309 - val_loss: 0.7196 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7259 - acc: 0.5309 - val_loss: 0.7195 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7259 - acc: 0.5309 - val_loss: 0.7195 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7259 - acc: 0.5309 - val_loss: 0.7195 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7258 - acc: 0.5309 - val_loss: 0.7194 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0445 - acc: 0.2680 - val_loss: 1.0427 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0444 - acc: 0.2680 - val_loss: 1.0427 - val_acc: 0.3115\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0444 - acc: 0.2680 - val_loss: 1.0426 - val_acc: 0.3115\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0443 - acc: 0.2680 - val_loss: 1.0426 - val_acc: 0.3115\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0443 - acc: 0.2680 - val_loss: 1.0425 - val_acc: 0.3115\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0442 - acc: 0.2680 - val_loss: 1.0425 - val_acc: 0.3115\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0442 - acc: 0.2680 - val_loss: 1.0424 - val_acc: 0.3115\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0441 - acc: 0.2680 - val_loss: 1.0423 - val_acc: 0.3115\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0441 - acc: 0.2680 - val_loss: 1.0423 - val_acc: 0.3115\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0440 - acc: 0.2680 - val_loss: 1.0422 - val_acc: 0.3115\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0440 - acc: 0.2680 - val_loss: 1.0422 - val_acc: 0.3115\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0439 - acc: 0.2680 - val_loss: 1.0421 - val_acc: 0.3115\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0439 - acc: 0.2680 - val_loss: 1.0421 - val_acc: 0.3115\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0438 - acc: 0.2680 - val_loss: 1.0420 - val_acc: 0.3115\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0438 - acc: 0.2680 - val_loss: 1.0420 - val_acc: 0.3115\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0437 - acc: 0.2680 - val_loss: 1.0419 - val_acc: 0.3115\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0437 - acc: 0.2680 - val_loss: 1.0419 - val_acc: 0.3115\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0436 - acc: 0.2680 - val_loss: 1.0418 - val_acc: 0.3115\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0436 - acc: 0.2680 - val_loss: 1.0418 - val_acc: 0.3115\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0435 - acc: 0.2680 - val_loss: 1.0417 - val_acc: 0.3115\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9237 - acc: 0.5258 - val_loss: 0.8830 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9236 - acc: 0.5258 - val_loss: 0.8830 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9236 - acc: 0.5258 - val_loss: 0.8829 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9235 - acc: 0.5258 - val_loss: 0.8829 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9235 - acc: 0.5258 - val_loss: 0.8828 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9234 - acc: 0.5258 - val_loss: 0.8828 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9234 - acc: 0.5258 - val_loss: 0.8827 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9233 - acc: 0.5258 - val_loss: 0.8827 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9233 - acc: 0.5258 - val_loss: 0.8826 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9233 - acc: 0.5258 - val_loss: 0.8826 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9232 - acc: 0.5258 - val_loss: 0.8826 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9232 - acc: 0.5258 - val_loss: 0.8825 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9231 - acc: 0.5258 - val_loss: 0.8825 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9231 - acc: 0.5258 - val_loss: 0.8824 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9231 - acc: 0.5258 - val_loss: 0.8823 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9230 - acc: 0.5258 - val_loss: 0.8823 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9230 - acc: 0.5258 - val_loss: 0.8822 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9229 - acc: 0.5258 - val_loss: 0.8822 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9229 - acc: 0.5258 - val_loss: 0.8822 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9228 - acc: 0.5258 - val_loss: 0.8821 - val_acc: 0.5574\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6872 - acc: 0.6218 - val_loss: 0.6412 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6872 - acc: 0.6218 - val_loss: 0.6412 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6871 - acc: 0.6218 - val_loss: 0.6411 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6871 - acc: 0.6218 - val_loss: 0.6411 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6870 - acc: 0.6218 - val_loss: 0.6411 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6870 - acc: 0.6218 - val_loss: 0.6410 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6870 - acc: 0.6218 - val_loss: 0.6410 - val_acc: 0.6721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6869 - acc: 0.6218 - val_loss: 0.6410 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6869 - acc: 0.6218 - val_loss: 0.6409 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6869 - acc: 0.6218 - val_loss: 0.6409 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6868 - acc: 0.6218 - val_loss: 0.6409 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6868 - acc: 0.6218 - val_loss: 0.6409 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6868 - acc: 0.6218 - val_loss: 0.6408 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6867 - acc: 0.6218 - val_loss: 0.6408 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6867 - acc: 0.6218 - val_loss: 0.6408 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6867 - acc: 0.6218 - val_loss: 0.6408 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6866 - acc: 0.6218 - val_loss: 0.6407 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6866 - acc: 0.6218 - val_loss: 0.6407 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6866 - acc: 0.6218 - val_loss: 0.6407 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6865 - acc: 0.6218 - val_loss: 0.6406 - val_acc: 0.6721\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6496 - acc: 0.6062 - val_loss: 0.6470 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6495 - acc: 0.6062 - val_loss: 0.6470 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6495 - acc: 0.6062 - val_loss: 0.6469 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6494 - acc: 0.6062 - val_loss: 0.6469 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6494 - acc: 0.6062 - val_loss: 0.6469 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6494 - acc: 0.6062 - val_loss: 0.6468 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6493 - acc: 0.6062 - val_loss: 0.6468 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6493 - acc: 0.6062 - val_loss: 0.6468 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6493 - acc: 0.6062 - val_loss: 0.6467 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6492 - acc: 0.6062 - val_loss: 0.6467 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6492 - acc: 0.6062 - val_loss: 0.6467 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6492 - acc: 0.6062 - val_loss: 0.6466 - val_acc: 0.7377\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6491 - acc: 0.6062 - val_loss: 0.6466 - val_acc: 0.7377\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6491 - acc: 0.6062 - val_loss: 0.6466 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6491 - acc: 0.6062 - val_loss: 0.6465 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6491 - acc: 0.6062 - val_loss: 0.6465 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6490 - acc: 0.6062 - val_loss: 0.6465 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6490 - acc: 0.6062 - val_loss: 0.6465 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6490 - acc: 0.6062 - val_loss: 0.6464 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6490 - acc: 0.6062 - val_loss: 0.6464 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8021 - acc: 0.3969 - val_loss: 0.8529 - val_acc: 0.3443\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8020 - acc: 0.3969 - val_loss: 0.8528 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8019 - acc: 0.3969 - val_loss: 0.8527 - val_acc: 0.3443\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8019 - acc: 0.3969 - val_loss: 0.8527 - val_acc: 0.3443\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8018 - acc: 0.3969 - val_loss: 0.8526 - val_acc: 0.3443\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8018 - acc: 0.3969 - val_loss: 0.8526 - val_acc: 0.3443\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8017 - acc: 0.3969 - val_loss: 0.8525 - val_acc: 0.3443\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8017 - acc: 0.3969 - val_loss: 0.8524 - val_acc: 0.3443\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8016 - acc: 0.3969 - val_loss: 0.8524 - val_acc: 0.3443\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8015 - acc: 0.3969 - val_loss: 0.8523 - val_acc: 0.3443\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8015 - acc: 0.3969 - val_loss: 0.8523 - val_acc: 0.3443\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8014 - acc: 0.3969 - val_loss: 0.8522 - val_acc: 0.3443\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8014 - acc: 0.3969 - val_loss: 0.8521 - val_acc: 0.3443\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8013 - acc: 0.3969 - val_loss: 0.8521 - val_acc: 0.3443\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8013 - acc: 0.3969 - val_loss: 0.8520 - val_acc: 0.3443\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8012 - acc: 0.3969 - val_loss: 0.8520 - val_acc: 0.3443\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8012 - acc: 0.3969 - val_loss: 0.8519 - val_acc: 0.3443\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8011 - acc: 0.3969 - val_loss: 0.8518 - val_acc: 0.3443\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8010 - acc: 0.3969 - val_loss: 0.8518 - val_acc: 0.3443\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8010 - acc: 0.3969 - val_loss: 0.8517 - val_acc: 0.3443\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8681 - acc: 0.4588 - val_loss: 0.8897 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8680 - acc: 0.4588 - val_loss: 0.8896 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8680 - acc: 0.4588 - val_loss: 0.8896 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8679 - acc: 0.4588 - val_loss: 0.8895 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8678 - acc: 0.4588 - val_loss: 0.8894 - val_acc: 0.3770\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8678 - acc: 0.4588 - val_loss: 0.8893 - val_acc: 0.3770\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8677 - acc: 0.4588 - val_loss: 0.8893 - val_acc: 0.3770\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8677 - acc: 0.4588 - val_loss: 0.8892 - val_acc: 0.3770\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8676 - acc: 0.4588 - val_loss: 0.8891 - val_acc: 0.3770\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8676 - acc: 0.4588 - val_loss: 0.8891 - val_acc: 0.3770\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8675 - acc: 0.4588 - val_loss: 0.8890 - val_acc: 0.3770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8675 - acc: 0.4588 - val_loss: 0.8889 - val_acc: 0.3770\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8674 - acc: 0.4588 - val_loss: 0.8889 - val_acc: 0.3770\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8674 - acc: 0.4588 - val_loss: 0.8888 - val_acc: 0.3770\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8673 - acc: 0.4588 - val_loss: 0.8887 - val_acc: 0.3770\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8673 - acc: 0.4588 - val_loss: 0.8887 - val_acc: 0.3770\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8672 - acc: 0.4588 - val_loss: 0.8886 - val_acc: 0.3770\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8672 - acc: 0.4588 - val_loss: 0.8885 - val_acc: 0.3770\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8671 - acc: 0.4588 - val_loss: 0.8885 - val_acc: 0.3770\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8670 - acc: 0.4588 - val_loss: 0.8884 - val_acc: 0.3770\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7969 - acc: 0.3763 - val_loss: 0.7742 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7969 - acc: 0.3763 - val_loss: 0.7741 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7968 - acc: 0.3763 - val_loss: 0.7741 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7968 - acc: 0.3763 - val_loss: 0.7740 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7967 - acc: 0.3763 - val_loss: 0.7740 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7967 - acc: 0.3763 - val_loss: 0.7739 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7966 - acc: 0.3763 - val_loss: 0.7739 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7966 - acc: 0.3763 - val_loss: 0.7738 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7965 - acc: 0.3763 - val_loss: 0.7738 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7965 - acc: 0.3763 - val_loss: 0.7737 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7964 - acc: 0.3763 - val_loss: 0.7737 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7964 - acc: 0.3763 - val_loss: 0.7736 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7963 - acc: 0.3763 - val_loss: 0.7736 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7963 - acc: 0.3763 - val_loss: 0.7736 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7963 - acc: 0.3763 - val_loss: 0.7735 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7962 - acc: 0.3763 - val_loss: 0.7735 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7962 - acc: 0.3763 - val_loss: 0.7734 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7961 - acc: 0.3763 - val_loss: 0.7734 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7961 - acc: 0.3763 - val_loss: 0.7733 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7960 - acc: 0.3763 - val_loss: 0.7733 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7563 - acc: 0.4352 - val_loss: 0.6602 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7562 - acc: 0.4352 - val_loss: 0.6601 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7561 - acc: 0.4352 - val_loss: 0.6601 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7561 - acc: 0.4352 - val_loss: 0.6600 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7560 - acc: 0.4352 - val_loss: 0.6599 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7559 - acc: 0.4352 - val_loss: 0.6599 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7559 - acc: 0.4352 - val_loss: 0.6598 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7558 - acc: 0.4352 - val_loss: 0.6597 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7557 - acc: 0.4352 - val_loss: 0.6597 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7557 - acc: 0.4404 - val_loss: 0.6596 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7556 - acc: 0.4404 - val_loss: 0.6596 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7555 - acc: 0.4404 - val_loss: 0.6595 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7555 - acc: 0.4404 - val_loss: 0.6594 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7554 - acc: 0.4404 - val_loss: 0.6594 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7553 - acc: 0.4404 - val_loss: 0.6593 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7553 - acc: 0.4404 - val_loss: 0.6592 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7552 - acc: 0.4404 - val_loss: 0.6592 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7551 - acc: 0.4404 - val_loss: 0.6591 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7551 - acc: 0.4404 - val_loss: 0.6591 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7550 - acc: 0.4404 - val_loss: 0.6590 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7099 - acc: 0.5285 - val_loss: 0.6677 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7099 - acc: 0.5285 - val_loss: 0.6676 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7098 - acc: 0.5285 - val_loss: 0.6676 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7098 - acc: 0.5285 - val_loss: 0.6675 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7097 - acc: 0.5285 - val_loss: 0.6675 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7097 - acc: 0.5285 - val_loss: 0.6674 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7096 - acc: 0.5285 - val_loss: 0.6674 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7096 - acc: 0.5285 - val_loss: 0.6673 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7095 - acc: 0.5285 - val_loss: 0.6673 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7095 - acc: 0.5285 - val_loss: 0.6672 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7094 - acc: 0.5285 - val_loss: 0.6672 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7094 - acc: 0.5285 - val_loss: 0.6671 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7093 - acc: 0.5285 - val_loss: 0.6671 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7093 - acc: 0.5285 - val_loss: 0.6670 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7092 - acc: 0.5285 - val_loss: 0.6670 - val_acc: 0.5902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7092 - acc: 0.5285 - val_loss: 0.6670 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7092 - acc: 0.5285 - val_loss: 0.6669 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7091 - acc: 0.5285 - val_loss: 0.6669 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7091 - acc: 0.5285 - val_loss: 0.6669 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7090 - acc: 0.5285 - val_loss: 0.6668 - val_acc: 0.5902\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7315 - acc: 0.5155 - val_loss: 0.7441 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7314 - acc: 0.5155 - val_loss: 0.7440 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7313 - acc: 0.5155 - val_loss: 0.7439 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7312 - acc: 0.5155 - val_loss: 0.7438 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7312 - acc: 0.5155 - val_loss: 0.7437 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7311 - acc: 0.5155 - val_loss: 0.7436 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7310 - acc: 0.5155 - val_loss: 0.7435 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7309 - acc: 0.5155 - val_loss: 0.7434 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7308 - acc: 0.5155 - val_loss: 0.7433 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7308 - acc: 0.5155 - val_loss: 0.7432 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7307 - acc: 0.5155 - val_loss: 0.7431 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7306 - acc: 0.5155 - val_loss: 0.7430 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7305 - acc: 0.5155 - val_loss: 0.7429 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7305 - acc: 0.5155 - val_loss: 0.7428 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7304 - acc: 0.5155 - val_loss: 0.7428 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7303 - acc: 0.5155 - val_loss: 0.7427 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7302 - acc: 0.5155 - val_loss: 0.7426 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7302 - acc: 0.5155 - val_loss: 0.7425 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7301 - acc: 0.5155 - val_loss: 0.7424 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7300 - acc: 0.5155 - val_loss: 0.7423 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6845 - acc: 0.5928 - val_loss: 0.6216 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6844 - acc: 0.5928 - val_loss: 0.6215 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6843 - acc: 0.5979 - val_loss: 0.6214 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6842 - acc: 0.5979 - val_loss: 0.6213 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6842 - acc: 0.5979 - val_loss: 0.6213 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6841 - acc: 0.5979 - val_loss: 0.6212 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6840 - acc: 0.5979 - val_loss: 0.6211 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6839 - acc: 0.5979 - val_loss: 0.6210 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6839 - acc: 0.5979 - val_loss: 0.6210 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6838 - acc: 0.5979 - val_loss: 0.6209 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6837 - acc: 0.5979 - val_loss: 0.6208 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6837 - acc: 0.5979 - val_loss: 0.6208 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6836 - acc: 0.5979 - val_loss: 0.6207 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6836 - acc: 0.5928 - val_loss: 0.6207 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6835 - acc: 0.5928 - val_loss: 0.6206 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6834 - acc: 0.5928 - val_loss: 0.6205 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6834 - acc: 0.5928 - val_loss: 0.6205 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6833 - acc: 0.5928 - val_loss: 0.6204 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6833 - acc: 0.5928 - val_loss: 0.6204 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6832 - acc: 0.5928 - val_loss: 0.6203 - val_acc: 0.6721\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6978 - acc: 0.5206 - val_loss: 0.7063 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.5206 - val_loss: 0.7062 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 0.5206 - val_loss: 0.7062 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6976 - acc: 0.5206 - val_loss: 0.7061 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6975 - acc: 0.5206 - val_loss: 0.7060 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6975 - acc: 0.5206 - val_loss: 0.7060 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6974 - acc: 0.5206 - val_loss: 0.7059 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6973 - acc: 0.5206 - val_loss: 0.7058 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6973 - acc: 0.5206 - val_loss: 0.7057 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6972 - acc: 0.5206 - val_loss: 0.7057 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6971 - acc: 0.5206 - val_loss: 0.7056 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6971 - acc: 0.5206 - val_loss: 0.7056 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6970 - acc: 0.5206 - val_loss: 0.7055 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6970 - acc: 0.5206 - val_loss: 0.7054 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6969 - acc: 0.5206 - val_loss: 0.7054 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6968 - acc: 0.5206 - val_loss: 0.7053 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6968 - acc: 0.5206 - val_loss: 0.7052 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6967 - acc: 0.5206 - val_loss: 0.7052 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6967 - acc: 0.5206 - val_loss: 0.7051 - val_acc: 0.4918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6966 - acc: 0.5206 - val_loss: 0.7050 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7313 - acc: 0.4301 - val_loss: 0.7418 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7311 - acc: 0.4301 - val_loss: 0.7417 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7310 - acc: 0.4301 - val_loss: 0.7415 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7309 - acc: 0.4301 - val_loss: 0.7414 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7308 - acc: 0.4301 - val_loss: 0.7413 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7307 - acc: 0.4301 - val_loss: 0.7412 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7306 - acc: 0.4301 - val_loss: 0.7411 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7305 - acc: 0.4301 - val_loss: 0.7410 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7304 - acc: 0.4301 - val_loss: 0.7409 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7303 - acc: 0.4301 - val_loss: 0.7408 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7302 - acc: 0.4301 - val_loss: 0.7407 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7301 - acc: 0.4301 - val_loss: 0.7406 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7300 - acc: 0.4301 - val_loss: 0.7405 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7299 - acc: 0.4301 - val_loss: 0.7403 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7298 - acc: 0.4249 - val_loss: 0.7402 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7297 - acc: 0.4249 - val_loss: 0.7401 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7296 - acc: 0.4249 - val_loss: 0.7400 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7295 - acc: 0.4249 - val_loss: 0.7398 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7294 - acc: 0.4249 - val_loss: 0.7397 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7293 - acc: 0.4249 - val_loss: 0.7397 - val_acc: 0.3934\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7065 - acc: 0.5181 - val_loss: 0.6698 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7063 - acc: 0.5181 - val_loss: 0.6697 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7062 - acc: 0.5181 - val_loss: 0.6696 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7061 - acc: 0.5181 - val_loss: 0.6695 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7061 - acc: 0.5181 - val_loss: 0.6695 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7060 - acc: 0.5181 - val_loss: 0.6694 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7059 - acc: 0.5181 - val_loss: 0.6693 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7058 - acc: 0.5181 - val_loss: 0.6692 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7057 - acc: 0.5181 - val_loss: 0.6691 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7056 - acc: 0.5181 - val_loss: 0.6690 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7056 - acc: 0.5181 - val_loss: 0.6690 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7055 - acc: 0.5181 - val_loss: 0.6689 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7054 - acc: 0.5181 - val_loss: 0.6688 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7053 - acc: 0.5285 - val_loss: 0.6687 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7053 - acc: 0.5285 - val_loss: 0.6686 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7052 - acc: 0.5285 - val_loss: 0.6685 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7051 - acc: 0.5285 - val_loss: 0.6685 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7050 - acc: 0.5285 - val_loss: 0.6684 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7050 - acc: 0.5285 - val_loss: 0.6683 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7049 - acc: 0.5285 - val_loss: 0.6682 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6976 - acc: 0.5773 - val_loss: 0.7022 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6975 - acc: 0.5773 - val_loss: 0.7021 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6974 - acc: 0.5773 - val_loss: 0.7019 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6973 - acc: 0.5773 - val_loss: 0.7018 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6972 - acc: 0.5773 - val_loss: 0.7017 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6971 - acc: 0.5773 - val_loss: 0.7016 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6970 - acc: 0.5773 - val_loss: 0.7015 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6969 - acc: 0.5773 - val_loss: 0.7014 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6968 - acc: 0.5773 - val_loss: 0.7013 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6967 - acc: 0.5773 - val_loss: 0.7012 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6966 - acc: 0.5773 - val_loss: 0.7011 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6965 - acc: 0.5773 - val_loss: 0.7010 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6964 - acc: 0.5773 - val_loss: 0.7009 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6963 - acc: 0.5773 - val_loss: 0.7008 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6962 - acc: 0.5773 - val_loss: 0.7007 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6961 - acc: 0.5773 - val_loss: 0.7006 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6960 - acc: 0.5773 - val_loss: 0.7005 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6959 - acc: 0.5773 - val_loss: 0.7004 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6958 - acc: 0.5773 - val_loss: 0.7002 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6957 - acc: 0.5773 - val_loss: 0.7001 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7304 - acc: 0.4227 - val_loss: 0.7317 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7303 - acc: 0.4227 - val_loss: 0.7316 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7302 - acc: 0.4227 - val_loss: 0.7315 - val_acc: 0.4098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7301 - acc: 0.4227 - val_loss: 0.7314 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7300 - acc: 0.4227 - val_loss: 0.7313 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7299 - acc: 0.4227 - val_loss: 0.7312 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7298 - acc: 0.4227 - val_loss: 0.7311 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7297 - acc: 0.4227 - val_loss: 0.7310 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7296 - acc: 0.4227 - val_loss: 0.7309 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7295 - acc: 0.4227 - val_loss: 0.7308 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7294 - acc: 0.4227 - val_loss: 0.7307 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7293 - acc: 0.4227 - val_loss: 0.7306 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7292 - acc: 0.4227 - val_loss: 0.7305 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7292 - acc: 0.4227 - val_loss: 0.7304 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7291 - acc: 0.4227 - val_loss: 0.7303 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7290 - acc: 0.4227 - val_loss: 0.7302 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7289 - acc: 0.4227 - val_loss: 0.7301 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7288 - acc: 0.4227 - val_loss: 0.7300 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7287 - acc: 0.4227 - val_loss: 0.7299 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7286 - acc: 0.4227 - val_loss: 0.7298 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7180 - acc: 0.4691 - val_loss: 0.7306 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7179 - acc: 0.4691 - val_loss: 0.7305 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7178 - acc: 0.4691 - val_loss: 0.7304 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7177 - acc: 0.4691 - val_loss: 0.7303 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7176 - acc: 0.4691 - val_loss: 0.7302 - val_acc: 0.3770\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7175 - acc: 0.4691 - val_loss: 0.7301 - val_acc: 0.3770\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7175 - acc: 0.4691 - val_loss: 0.7300 - val_acc: 0.3770\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7174 - acc: 0.4691 - val_loss: 0.7300 - val_acc: 0.3770\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7173 - acc: 0.4691 - val_loss: 0.7299 - val_acc: 0.3770\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7172 - acc: 0.4691 - val_loss: 0.7298 - val_acc: 0.3770\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7171 - acc: 0.4691 - val_loss: 0.7297 - val_acc: 0.3770\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7170 - acc: 0.4691 - val_loss: 0.7296 - val_acc: 0.3770\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7170 - acc: 0.4691 - val_loss: 0.7295 - val_acc: 0.3770\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7169 - acc: 0.4691 - val_loss: 0.7294 - val_acc: 0.3770\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7168 - acc: 0.4691 - val_loss: 0.7293 - val_acc: 0.3770\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7167 - acc: 0.4691 - val_loss: 0.7292 - val_acc: 0.3770\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7166 - acc: 0.4691 - val_loss: 0.7291 - val_acc: 0.3770\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7165 - acc: 0.4691 - val_loss: 0.7290 - val_acc: 0.3770\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7164 - acc: 0.4691 - val_loss: 0.7289 - val_acc: 0.3770\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7163 - acc: 0.4691 - val_loss: 0.7288 - val_acc: 0.3770\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7286 - acc: 0.3575 - val_loss: 0.7401 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7284 - acc: 0.3575 - val_loss: 0.7400 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7283 - acc: 0.3575 - val_loss: 0.7398 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7281 - acc: 0.3627 - val_loss: 0.7397 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7280 - acc: 0.3627 - val_loss: 0.7396 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7279 - acc: 0.3627 - val_loss: 0.7394 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7278 - acc: 0.3627 - val_loss: 0.7393 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7276 - acc: 0.3627 - val_loss: 0.7392 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7275 - acc: 0.3679 - val_loss: 0.7390 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7274 - acc: 0.3731 - val_loss: 0.7389 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7273 - acc: 0.3731 - val_loss: 0.7388 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7272 - acc: 0.3731 - val_loss: 0.7386 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7270 - acc: 0.3782 - val_loss: 0.7385 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7269 - acc: 0.3834 - val_loss: 0.7383 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7268 - acc: 0.3834 - val_loss: 0.7382 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7267 - acc: 0.3834 - val_loss: 0.7381 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7265 - acc: 0.3834 - val_loss: 0.7380 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7264 - acc: 0.3834 - val_loss: 0.7378 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7263 - acc: 0.3834 - val_loss: 0.7377 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7262 - acc: 0.3834 - val_loss: 0.7376 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6984 - acc: 0.4974 - val_loss: 0.7040 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6982 - acc: 0.4974 - val_loss: 0.7039 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6980 - acc: 0.5026 - val_loss: 0.7037 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6979 - acc: 0.5078 - val_loss: 0.7036 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6978 - acc: 0.5078 - val_loss: 0.7035 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6977 - acc: 0.5078 - val_loss: 0.7034 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6976 - acc: 0.5078 - val_loss: 0.7033 - val_acc: 0.4754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6975 - acc: 0.5078 - val_loss: 0.7032 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6974 - acc: 0.5078 - val_loss: 0.7030 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6973 - acc: 0.5078 - val_loss: 0.7029 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6972 - acc: 0.5078 - val_loss: 0.7028 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6970 - acc: 0.5130 - val_loss: 0.7027 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6969 - acc: 0.5130 - val_loss: 0.7026 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6968 - acc: 0.5130 - val_loss: 0.7024 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6967 - acc: 0.5130 - val_loss: 0.7023 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6966 - acc: 0.5130 - val_loss: 0.7022 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6965 - acc: 0.5130 - val_loss: 0.7021 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6964 - acc: 0.5130 - val_loss: 0.7020 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6963 - acc: 0.5130 - val_loss: 0.7019 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6962 - acc: 0.5130 - val_loss: 0.7018 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7364 - acc: 0.4536 - val_loss: 0.7366 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7362 - acc: 0.4588 - val_loss: 0.7364 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7360 - acc: 0.4588 - val_loss: 0.7362 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7358 - acc: 0.4588 - val_loss: 0.7361 - val_acc: 0.3607\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7357 - acc: 0.4588 - val_loss: 0.7359 - val_acc: 0.3607\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7355 - acc: 0.4588 - val_loss: 0.7358 - val_acc: 0.3607\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7354 - acc: 0.4588 - val_loss: 0.7356 - val_acc: 0.3607\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7352 - acc: 0.4588 - val_loss: 0.7354 - val_acc: 0.3607\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7351 - acc: 0.4588 - val_loss: 0.7353 - val_acc: 0.3607\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7349 - acc: 0.4588 - val_loss: 0.7351 - val_acc: 0.3607\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7347 - acc: 0.4588 - val_loss: 0.7349 - val_acc: 0.3607\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7346 - acc: 0.4588 - val_loss: 0.7348 - val_acc: 0.3607\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7344 - acc: 0.4639 - val_loss: 0.7346 - val_acc: 0.3607\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7342 - acc: 0.4639 - val_loss: 0.7344 - val_acc: 0.3607\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7341 - acc: 0.4639 - val_loss: 0.7342 - val_acc: 0.3607\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7339 - acc: 0.4639 - val_loss: 0.7341 - val_acc: 0.3607\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7338 - acc: 0.4639 - val_loss: 0.7339 - val_acc: 0.3607\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7336 - acc: 0.4639 - val_loss: 0.7338 - val_acc: 0.3607\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7335 - acc: 0.4639 - val_loss: 0.7336 - val_acc: 0.3607\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7333 - acc: 0.4639 - val_loss: 0.7335 - val_acc: 0.3607\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6924 - acc: 0.5103 - val_loss: 0.6860 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6922 - acc: 0.5103 - val_loss: 0.6858 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6920 - acc: 0.5103 - val_loss: 0.6856 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6919 - acc: 0.5103 - val_loss: 0.6855 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6917 - acc: 0.5155 - val_loss: 0.6853 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6915 - acc: 0.5155 - val_loss: 0.6851 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6914 - acc: 0.5155 - val_loss: 0.6849 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6912 - acc: 0.5155 - val_loss: 0.6847 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6911 - acc: 0.5155 - val_loss: 0.6846 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6909 - acc: 0.5155 - val_loss: 0.6844 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6908 - acc: 0.5155 - val_loss: 0.6842 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6907 - acc: 0.5155 - val_loss: 0.6841 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6905 - acc: 0.5155 - val_loss: 0.6839 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6904 - acc: 0.5155 - val_loss: 0.6837 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6902 - acc: 0.5155 - val_loss: 0.6836 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6901 - acc: 0.5155 - val_loss: 0.6834 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6899 - acc: 0.5155 - val_loss: 0.6832 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6898 - acc: 0.5155 - val_loss: 0.6831 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6897 - acc: 0.5155 - val_loss: 0.6829 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6895 - acc: 0.5155 - val_loss: 0.6828 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6230 - acc: 0.7423 - val_loss: 0.5974 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6228 - acc: 0.7423 - val_loss: 0.5973 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6227 - acc: 0.7423 - val_loss: 0.5972 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6226 - acc: 0.7423 - val_loss: 0.5971 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6225 - acc: 0.7423 - val_loss: 0.5970 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6224 - acc: 0.7423 - val_loss: 0.5969 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6223 - acc: 0.7423 - val_loss: 0.5968 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6222 - acc: 0.7423 - val_loss: 0.5967 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6221 - acc: 0.7423 - val_loss: 0.5966 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6220 - acc: 0.7423 - val_loss: 0.5964 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6219 - acc: 0.7423 - val_loss: 0.5963 - val_acc: 0.7869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6218 - acc: 0.7423 - val_loss: 0.5962 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6217 - acc: 0.7423 - val_loss: 0.5961 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6216 - acc: 0.7423 - val_loss: 0.5960 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6215 - acc: 0.7423 - val_loss: 0.5959 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6214 - acc: 0.7423 - val_loss: 0.5958 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6213 - acc: 0.7474 - val_loss: 0.5957 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6212 - acc: 0.7474 - val_loss: 0.5956 - val_acc: 0.7869\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6211 - acc: 0.7474 - val_loss: 0.5955 - val_acc: 0.7869\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6210 - acc: 0.7474 - val_loss: 0.5954 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7166 - acc: 0.5233 - val_loss: 0.6408 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7152 - acc: 0.5233 - val_loss: 0.6397 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7141 - acc: 0.5233 - val_loss: 0.6389 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7132 - acc: 0.5233 - val_loss: 0.6381 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7124 - acc: 0.5233 - val_loss: 0.6374 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7116 - acc: 0.5233 - val_loss: 0.6367 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7107 - acc: 0.5285 - val_loss: 0.6360 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7099 - acc: 0.5285 - val_loss: 0.6353 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7092 - acc: 0.5285 - val_loss: 0.6347 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7085 - acc: 0.5285 - val_loss: 0.6341 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7079 - acc: 0.5337 - val_loss: 0.6334 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7072 - acc: 0.5337 - val_loss: 0.6328 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7065 - acc: 0.5337 - val_loss: 0.6322 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7059 - acc: 0.5337 - val_loss: 0.6317 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7053 - acc: 0.5285 - val_loss: 0.6311 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7047 - acc: 0.5285 - val_loss: 0.6307 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7042 - acc: 0.5337 - val_loss: 0.6302 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7037 - acc: 0.5337 - val_loss: 0.6297 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7032 - acc: 0.5337 - val_loss: 0.6294 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7027 - acc: 0.5337 - val_loss: 0.6289 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8411 - acc: 0.4560 - val_loss: 0.8104 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8386 - acc: 0.4611 - val_loss: 0.8081 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8367 - acc: 0.4663 - val_loss: 0.8061 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8348 - acc: 0.4663 - val_loss: 0.8042 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8331 - acc: 0.4663 - val_loss: 0.8023 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8316 - acc: 0.4663 - val_loss: 0.8005 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8301 - acc: 0.4663 - val_loss: 0.7989 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8289 - acc: 0.4663 - val_loss: 0.7975 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8276 - acc: 0.4663 - val_loss: 0.7960 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8263 - acc: 0.4663 - val_loss: 0.7944 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8250 - acc: 0.4663 - val_loss: 0.7929 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8237 - acc: 0.4715 - val_loss: 0.7915 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8224 - acc: 0.4715 - val_loss: 0.7901 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8212 - acc: 0.4715 - val_loss: 0.7888 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8200 - acc: 0.4715 - val_loss: 0.7876 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8189 - acc: 0.4715 - val_loss: 0.7863 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8176 - acc: 0.4715 - val_loss: 0.7848 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8164 - acc: 0.4715 - val_loss: 0.7833 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8151 - acc: 0.4715 - val_loss: 0.7818 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8138 - acc: 0.4715 - val_loss: 0.7801 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7427 - acc: 0.5103 - val_loss: 0.7651 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7410 - acc: 0.5155 - val_loss: 0.7634 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7393 - acc: 0.5155 - val_loss: 0.7619 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7379 - acc: 0.5155 - val_loss: 0.7604 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7364 - acc: 0.5155 - val_loss: 0.7590 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7350 - acc: 0.5206 - val_loss: 0.7576 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7336 - acc: 0.5206 - val_loss: 0.7563 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7321 - acc: 0.5206 - val_loss: 0.7549 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7307 - acc: 0.5206 - val_loss: 0.7535 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7293 - acc: 0.5206 - val_loss: 0.7520 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7278 - acc: 0.5258 - val_loss: 0.7507 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7265 - acc: 0.5258 - val_loss: 0.7494 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7252 - acc: 0.5309 - val_loss: 0.7482 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7240 - acc: 0.5309 - val_loss: 0.7471 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7227 - acc: 0.5309 - val_loss: 0.7459 - val_acc: 0.5082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7215 - acc: 0.5309 - val_loss: 0.7447 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7203 - acc: 0.5309 - val_loss: 0.7436 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7192 - acc: 0.5309 - val_loss: 0.7424 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7179 - acc: 0.5309 - val_loss: 0.7412 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7168 - acc: 0.5361 - val_loss: 0.7401 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9610 - acc: 0.4433 - val_loss: 0.8455 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9585 - acc: 0.4433 - val_loss: 0.8433 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9561 - acc: 0.4433 - val_loss: 0.8411 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9538 - acc: 0.4433 - val_loss: 0.8390 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9516 - acc: 0.4433 - val_loss: 0.8371 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9495 - acc: 0.4433 - val_loss: 0.8353 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9476 - acc: 0.4433 - val_loss: 0.8336 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9457 - acc: 0.4433 - val_loss: 0.8319 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9439 - acc: 0.4433 - val_loss: 0.8303 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9420 - acc: 0.4433 - val_loss: 0.8285 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9399 - acc: 0.4433 - val_loss: 0.8267 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9379 - acc: 0.4433 - val_loss: 0.8249 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9359 - acc: 0.4433 - val_loss: 0.8232 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9340 - acc: 0.4433 - val_loss: 0.8216 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9321 - acc: 0.4433 - val_loss: 0.8200 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9301 - acc: 0.4433 - val_loss: 0.8186 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9286 - acc: 0.4381 - val_loss: 0.8170 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9268 - acc: 0.4381 - val_loss: 0.8155 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9250 - acc: 0.4330 - val_loss: 0.8139 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9232 - acc: 0.4330 - val_loss: 0.8122 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8495 - acc: 0.5206 - val_loss: 0.8464 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8469 - acc: 0.5155 - val_loss: 0.8442 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8449 - acc: 0.5155 - val_loss: 0.8421 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8428 - acc: 0.5103 - val_loss: 0.8402 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8409 - acc: 0.5155 - val_loss: 0.8384 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8392 - acc: 0.5206 - val_loss: 0.8368 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8375 - acc: 0.5206 - val_loss: 0.8350 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8358 - acc: 0.5206 - val_loss: 0.8332 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8341 - acc: 0.5258 - val_loss: 0.8314 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8324 - acc: 0.5309 - val_loss: 0.8296 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8306 - acc: 0.5309 - val_loss: 0.8278 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8288 - acc: 0.5309 - val_loss: 0.8261 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8271 - acc: 0.5309 - val_loss: 0.8246 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8256 - acc: 0.5309 - val_loss: 0.8230 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8239 - acc: 0.5258 - val_loss: 0.8213 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8222 - acc: 0.5258 - val_loss: 0.8197 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8206 - acc: 0.5258 - val_loss: 0.8181 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8190 - acc: 0.5258 - val_loss: 0.8165 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8175 - acc: 0.5258 - val_loss: 0.8149 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8159 - acc: 0.5258 - val_loss: 0.8132 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9346 - acc: 0.4093 - val_loss: 0.8845 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9309 - acc: 0.4145 - val_loss: 0.8819 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9279 - acc: 0.4145 - val_loss: 0.8797 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9253 - acc: 0.4145 - val_loss: 0.8778 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9229 - acc: 0.4145 - val_loss: 0.8758 - val_acc: 0.3770\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9205 - acc: 0.4145 - val_loss: 0.8737 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9180 - acc: 0.4145 - val_loss: 0.8716 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9154 - acc: 0.4145 - val_loss: 0.8697 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9131 - acc: 0.4145 - val_loss: 0.8677 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9106 - acc: 0.4145 - val_loss: 0.8656 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9082 - acc: 0.4145 - val_loss: 0.8636 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9059 - acc: 0.4197 - val_loss: 0.8617 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9036 - acc: 0.4197 - val_loss: 0.8597 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9013 - acc: 0.4249 - val_loss: 0.8579 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8989 - acc: 0.4249 - val_loss: 0.8558 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8964 - acc: 0.4249 - val_loss: 0.8536 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8938 - acc: 0.4301 - val_loss: 0.8515 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8913 - acc: 0.4301 - val_loss: 0.8496 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8890 - acc: 0.4301 - val_loss: 0.8477 - val_acc: 0.4098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8869 - acc: 0.4301 - val_loss: 0.8459 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9112 - acc: 0.4870 - val_loss: 0.7842 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9068 - acc: 0.4870 - val_loss: 0.7806 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9029 - acc: 0.4870 - val_loss: 0.7773 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8993 - acc: 0.4870 - val_loss: 0.7745 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8965 - acc: 0.4870 - val_loss: 0.7723 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8941 - acc: 0.4870 - val_loss: 0.7701 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8918 - acc: 0.4870 - val_loss: 0.7679 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8893 - acc: 0.4870 - val_loss: 0.7656 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8869 - acc: 0.4870 - val_loss: 0.7632 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8842 - acc: 0.4870 - val_loss: 0.7608 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8816 - acc: 0.4870 - val_loss: 0.7585 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8791 - acc: 0.4870 - val_loss: 0.7562 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8767 - acc: 0.4870 - val_loss: 0.7538 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8740 - acc: 0.4870 - val_loss: 0.7516 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8713 - acc: 0.4870 - val_loss: 0.7494 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8689 - acc: 0.4922 - val_loss: 0.7471 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8660 - acc: 0.4870 - val_loss: 0.7446 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8631 - acc: 0.4870 - val_loss: 0.7419 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8601 - acc: 0.4819 - val_loss: 0.7394 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8574 - acc: 0.4819 - val_loss: 0.7370 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7961 - acc: 0.5155 - val_loss: 0.7844 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7934 - acc: 0.5258 - val_loss: 0.7816 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7910 - acc: 0.5258 - val_loss: 0.7791 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7888 - acc: 0.5258 - val_loss: 0.7765 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7867 - acc: 0.5258 - val_loss: 0.7739 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7845 - acc: 0.5258 - val_loss: 0.7715 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7825 - acc: 0.5258 - val_loss: 0.7692 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7805 - acc: 0.5309 - val_loss: 0.7669 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7785 - acc: 0.5309 - val_loss: 0.7647 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7766 - acc: 0.5258 - val_loss: 0.7626 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7748 - acc: 0.5258 - val_loss: 0.7604 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7728 - acc: 0.5309 - val_loss: 0.7581 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7710 - acc: 0.5309 - val_loss: 0.7561 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7691 - acc: 0.5309 - val_loss: 0.7538 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7673 - acc: 0.5361 - val_loss: 0.7517 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7656 - acc: 0.5361 - val_loss: 0.7495 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7637 - acc: 0.5361 - val_loss: 0.7473 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7618 - acc: 0.5412 - val_loss: 0.7452 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7600 - acc: 0.5412 - val_loss: 0.7432 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7582 - acc: 0.5464 - val_loss: 0.7412 - val_acc: 0.5574\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7990 - acc: 0.4794 - val_loss: 0.7751 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7957 - acc: 0.4794 - val_loss: 0.7722 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7931 - acc: 0.4845 - val_loss: 0.7694 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7906 - acc: 0.4845 - val_loss: 0.7669 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7882 - acc: 0.4897 - val_loss: 0.7643 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7858 - acc: 0.4948 - val_loss: 0.7617 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7833 - acc: 0.4948 - val_loss: 0.7592 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7808 - acc: 0.5000 - val_loss: 0.7567 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7785 - acc: 0.5000 - val_loss: 0.7543 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7761 - acc: 0.5052 - val_loss: 0.7519 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7738 - acc: 0.5052 - val_loss: 0.7495 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7714 - acc: 0.5052 - val_loss: 0.7472 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7692 - acc: 0.5155 - val_loss: 0.7449 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7669 - acc: 0.5206 - val_loss: 0.7427 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7646 - acc: 0.5258 - val_loss: 0.7403 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7624 - acc: 0.5258 - val_loss: 0.7381 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7600 - acc: 0.5258 - val_loss: 0.7359 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7576 - acc: 0.5258 - val_loss: 0.7336 - val_acc: 0.6393\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7553 - acc: 0.5361 - val_loss: 0.7314 - val_acc: 0.6393\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7530 - acc: 0.5412 - val_loss: 0.7292 - val_acc: 0.6393\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 1.1645 - acc: 0.3918 - val_loss: 1.1786 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1589 - acc: 0.3918 - val_loss: 1.1744 - val_acc: 0.3115\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1536 - acc: 0.3969 - val_loss: 1.1704 - val_acc: 0.3115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1487 - acc: 0.3969 - val_loss: 1.1663 - val_acc: 0.3279\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1436 - acc: 0.3969 - val_loss: 1.1624 - val_acc: 0.3279\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1388 - acc: 0.3969 - val_loss: 1.1586 - val_acc: 0.3279\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1341 - acc: 0.4021 - val_loss: 1.1548 - val_acc: 0.3279\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1293 - acc: 0.4021 - val_loss: 1.1511 - val_acc: 0.3279\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1247 - acc: 0.4021 - val_loss: 1.1476 - val_acc: 0.3279\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1203 - acc: 0.4021 - val_loss: 1.1440 - val_acc: 0.3279\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1156 - acc: 0.4021 - val_loss: 1.1403 - val_acc: 0.3279\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1109 - acc: 0.4072 - val_loss: 1.1366 - val_acc: 0.3279\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1064 - acc: 0.4072 - val_loss: 1.1329 - val_acc: 0.3279\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1018 - acc: 0.4072 - val_loss: 1.1293 - val_acc: 0.3279\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0977 - acc: 0.4072 - val_loss: 1.1259 - val_acc: 0.3279\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0939 - acc: 0.4072 - val_loss: 1.1227 - val_acc: 0.3279\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0899 - acc: 0.4072 - val_loss: 1.1194 - val_acc: 0.3279\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0859 - acc: 0.4124 - val_loss: 1.1162 - val_acc: 0.3279\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0819 - acc: 0.4175 - val_loss: 1.1130 - val_acc: 0.3279\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0782 - acc: 0.4175 - val_loss: 1.1099 - val_acc: 0.3279\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6923 - acc: 0.5751 - val_loss: 0.5608 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6885 - acc: 0.5803 - val_loss: 0.5586 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6854 - acc: 0.5751 - val_loss: 0.5563 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6824 - acc: 0.5751 - val_loss: 0.5542 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6795 - acc: 0.5803 - val_loss: 0.5524 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6771 - acc: 0.5803 - val_loss: 0.5506 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6745 - acc: 0.5907 - val_loss: 0.5489 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6721 - acc: 0.6010 - val_loss: 0.5469 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6696 - acc: 0.6010 - val_loss: 0.5447 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6670 - acc: 0.6062 - val_loss: 0.5424 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6644 - acc: 0.6062 - val_loss: 0.5403 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6617 - acc: 0.6062 - val_loss: 0.5383 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6592 - acc: 0.6062 - val_loss: 0.5363 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6567 - acc: 0.6062 - val_loss: 0.5343 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6542 - acc: 0.6062 - val_loss: 0.5326 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6517 - acc: 0.6062 - val_loss: 0.5308 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6493 - acc: 0.6062 - val_loss: 0.5291 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6470 - acc: 0.6114 - val_loss: 0.5275 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6448 - acc: 0.6166 - val_loss: 0.5258 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6425 - acc: 0.6166 - val_loss: 0.5241 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.8864 - acc: 0.3161 - val_loss: 0.9232 - val_acc: 0.2951\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8812 - acc: 0.3264 - val_loss: 0.9172 - val_acc: 0.2951\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8766 - acc: 0.3212 - val_loss: 0.9119 - val_acc: 0.2951\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8724 - acc: 0.3368 - val_loss: 0.9068 - val_acc: 0.2951\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8684 - acc: 0.3420 - val_loss: 0.9022 - val_acc: 0.2951\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8646 - acc: 0.3420 - val_loss: 0.8980 - val_acc: 0.2951\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8612 - acc: 0.3420 - val_loss: 0.8939 - val_acc: 0.2951\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8577 - acc: 0.3420 - val_loss: 0.8902 - val_acc: 0.2951\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8547 - acc: 0.3472 - val_loss: 0.8865 - val_acc: 0.2951\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8518 - acc: 0.3472 - val_loss: 0.8828 - val_acc: 0.2951\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8489 - acc: 0.3472 - val_loss: 0.8788 - val_acc: 0.2951\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8459 - acc: 0.3472 - val_loss: 0.8749 - val_acc: 0.2951\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8428 - acc: 0.3472 - val_loss: 0.8710 - val_acc: 0.2951\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8397 - acc: 0.3523 - val_loss: 0.8672 - val_acc: 0.2951\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8369 - acc: 0.3575 - val_loss: 0.8637 - val_acc: 0.2951\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8342 - acc: 0.3575 - val_loss: 0.8602 - val_acc: 0.2951\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8314 - acc: 0.3627 - val_loss: 0.8565 - val_acc: 0.2951\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8288 - acc: 0.3627 - val_loss: 0.8532 - val_acc: 0.2951\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8263 - acc: 0.3679 - val_loss: 0.8498 - val_acc: 0.2951\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8237 - acc: 0.3679 - val_loss: 0.8462 - val_acc: 0.2951\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7776 - acc: 0.4536 - val_loss: 0.8741 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7730 - acc: 0.4536 - val_loss: 0.8692 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7690 - acc: 0.4588 - val_loss: 0.8645 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7653 - acc: 0.4588 - val_loss: 0.8599 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7616 - acc: 0.4588 - val_loss: 0.8556 - val_acc: 0.3770\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7582 - acc: 0.4691 - val_loss: 0.8515 - val_acc: 0.3607\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7548 - acc: 0.4742 - val_loss: 0.8473 - val_acc: 0.3607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7514 - acc: 0.4794 - val_loss: 0.8431 - val_acc: 0.3607\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7479 - acc: 0.4897 - val_loss: 0.8388 - val_acc: 0.3607\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7442 - acc: 0.5000 - val_loss: 0.8345 - val_acc: 0.3770\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7406 - acc: 0.5000 - val_loss: 0.8301 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7372 - acc: 0.5000 - val_loss: 0.8259 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7338 - acc: 0.5000 - val_loss: 0.8216 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7305 - acc: 0.5052 - val_loss: 0.8174 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7273 - acc: 0.5155 - val_loss: 0.8134 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7241 - acc: 0.5052 - val_loss: 0.8097 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7212 - acc: 0.5052 - val_loss: 0.8061 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7182 - acc: 0.5103 - val_loss: 0.8024 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7151 - acc: 0.5206 - val_loss: 0.7987 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7122 - acc: 0.5361 - val_loss: 0.7948 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9174 - acc: 0.3454 - val_loss: 0.9875 - val_acc: 0.2623\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9119 - acc: 0.3454 - val_loss: 0.9817 - val_acc: 0.2623\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9072 - acc: 0.3505 - val_loss: 0.9761 - val_acc: 0.2623\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9027 - acc: 0.3557 - val_loss: 0.9707 - val_acc: 0.2787\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8983 - acc: 0.3557 - val_loss: 0.9657 - val_acc: 0.2787\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8941 - acc: 0.3557 - val_loss: 0.9609 - val_acc: 0.2787\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8899 - acc: 0.3557 - val_loss: 0.9560 - val_acc: 0.2787\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8859 - acc: 0.3557 - val_loss: 0.9512 - val_acc: 0.2787\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8817 - acc: 0.3711 - val_loss: 0.9467 - val_acc: 0.2787\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8778 - acc: 0.3763 - val_loss: 0.9421 - val_acc: 0.2787\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8740 - acc: 0.3763 - val_loss: 0.9373 - val_acc: 0.2787\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8699 - acc: 0.3763 - val_loss: 0.9324 - val_acc: 0.2787\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8660 - acc: 0.3763 - val_loss: 0.9276 - val_acc: 0.2787\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8620 - acc: 0.3763 - val_loss: 0.9227 - val_acc: 0.2787\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8580 - acc: 0.3814 - val_loss: 0.9179 - val_acc: 0.2951\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8541 - acc: 0.3814 - val_loss: 0.9130 - val_acc: 0.2951\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8501 - acc: 0.3814 - val_loss: 0.9083 - val_acc: 0.2951\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8464 - acc: 0.3814 - val_loss: 0.9036 - val_acc: 0.2951\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8426 - acc: 0.3814 - val_loss: 0.8992 - val_acc: 0.2951\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8391 - acc: 0.3814 - val_loss: 0.8950 - val_acc: 0.2951\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8301 - acc: 0.4639 - val_loss: 0.8098 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8253 - acc: 0.4639 - val_loss: 0.8060 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8214 - acc: 0.4742 - val_loss: 0.8027 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8181 - acc: 0.4742 - val_loss: 0.7992 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8145 - acc: 0.4742 - val_loss: 0.7959 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8112 - acc: 0.4845 - val_loss: 0.7923 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8078 - acc: 0.4845 - val_loss: 0.7890 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8045 - acc: 0.4897 - val_loss: 0.7857 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8013 - acc: 0.4948 - val_loss: 0.7823 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7980 - acc: 0.5000 - val_loss: 0.7793 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7949 - acc: 0.5052 - val_loss: 0.7764 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7919 - acc: 0.5103 - val_loss: 0.7735 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7889 - acc: 0.5103 - val_loss: 0.7705 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7857 - acc: 0.5103 - val_loss: 0.7674 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7825 - acc: 0.5103 - val_loss: 0.7645 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7794 - acc: 0.5155 - val_loss: 0.7619 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7767 - acc: 0.5206 - val_loss: 0.7592 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7736 - acc: 0.5258 - val_loss: 0.7565 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7709 - acc: 0.5258 - val_loss: 0.7540 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7683 - acc: 0.5258 - val_loss: 0.7515 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7213 - acc: 0.5337 - val_loss: 0.7098 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7154 - acc: 0.5389 - val_loss: 0.7051 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7110 - acc: 0.5440 - val_loss: 0.7011 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7073 - acc: 0.5389 - val_loss: 0.6972 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7034 - acc: 0.5389 - val_loss: 0.6927 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6992 - acc: 0.5544 - val_loss: 0.6881 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6952 - acc: 0.5648 - val_loss: 0.6837 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6915 - acc: 0.5855 - val_loss: 0.6796 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6879 - acc: 0.6062 - val_loss: 0.6762 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6846 - acc: 0.6062 - val_loss: 0.6727 - val_acc: 0.6393\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6816 - acc: 0.6114 - val_loss: 0.6691 - val_acc: 0.6393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6784 - acc: 0.6166 - val_loss: 0.6654 - val_acc: 0.6393\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6750 - acc: 0.6166 - val_loss: 0.6613 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6713 - acc: 0.6269 - val_loss: 0.6571 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6677 - acc: 0.6321 - val_loss: 0.6528 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6640 - acc: 0.6477 - val_loss: 0.6488 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6606 - acc: 0.6528 - val_loss: 0.6452 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6575 - acc: 0.6477 - val_loss: 0.6418 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6545 - acc: 0.6528 - val_loss: 0.6385 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6514 - acc: 0.6632 - val_loss: 0.6350 - val_acc: 0.6885\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7001 - acc: 0.5181 - val_loss: 0.7313 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6950 - acc: 0.5233 - val_loss: 0.7268 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6904 - acc: 0.5285 - val_loss: 0.7226 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6864 - acc: 0.5389 - val_loss: 0.7188 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6828 - acc: 0.5337 - val_loss: 0.7154 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6796 - acc: 0.5337 - val_loss: 0.7121 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6765 - acc: 0.5337 - val_loss: 0.7090 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6733 - acc: 0.5389 - val_loss: 0.7058 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6700 - acc: 0.5492 - val_loss: 0.7027 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6668 - acc: 0.5596 - val_loss: 0.6995 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6635 - acc: 0.5596 - val_loss: 0.6961 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6601 - acc: 0.5648 - val_loss: 0.6928 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6568 - acc: 0.5648 - val_loss: 0.6897 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6537 - acc: 0.5648 - val_loss: 0.6868 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6508 - acc: 0.5699 - val_loss: 0.6841 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6481 - acc: 0.5803 - val_loss: 0.6815 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6456 - acc: 0.5855 - val_loss: 0.6787 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6425 - acc: 0.5855 - val_loss: 0.6759 - val_acc: 0.6066\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6397 - acc: 0.6010 - val_loss: 0.6729 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6369 - acc: 0.6114 - val_loss: 0.6702 - val_acc: 0.6066\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6489 - acc: 0.6082 - val_loss: 0.6511 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6427 - acc: 0.6186 - val_loss: 0.6442 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6371 - acc: 0.6340 - val_loss: 0.6385 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6323 - acc: 0.6340 - val_loss: 0.6333 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6276 - acc: 0.6392 - val_loss: 0.6284 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6232 - acc: 0.6443 - val_loss: 0.6234 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6190 - acc: 0.6598 - val_loss: 0.6184 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6146 - acc: 0.6753 - val_loss: 0.6135 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6100 - acc: 0.6804 - val_loss: 0.6085 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6057 - acc: 0.7010 - val_loss: 0.6033 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6015 - acc: 0.7062 - val_loss: 0.5985 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5973 - acc: 0.7165 - val_loss: 0.5938 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5932 - acc: 0.7216 - val_loss: 0.5892 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5891 - acc: 0.7268 - val_loss: 0.5848 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5854 - acc: 0.7268 - val_loss: 0.5807 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5818 - acc: 0.7320 - val_loss: 0.5766 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5782 - acc: 0.7371 - val_loss: 0.5728 - val_acc: 0.7213\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5747 - acc: 0.7371 - val_loss: 0.5692 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5715 - acc: 0.7371 - val_loss: 0.5654 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5681 - acc: 0.7371 - val_loss: 0.5618 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8054 - acc: 0.4381 - val_loss: 0.8346 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7980 - acc: 0.4485 - val_loss: 0.8270 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7915 - acc: 0.4485 - val_loss: 0.8198 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7852 - acc: 0.4536 - val_loss: 0.8132 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7793 - acc: 0.4536 - val_loss: 0.8072 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7740 - acc: 0.4588 - val_loss: 0.8013 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7686 - acc: 0.4639 - val_loss: 0.7955 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7636 - acc: 0.4691 - val_loss: 0.7899 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7587 - acc: 0.4742 - val_loss: 0.7846 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7540 - acc: 0.4794 - val_loss: 0.7788 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7490 - acc: 0.4794 - val_loss: 0.7731 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7442 - acc: 0.4794 - val_loss: 0.7677 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7394 - acc: 0.4794 - val_loss: 0.7620 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7344 - acc: 0.4794 - val_loss: 0.7563 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7295 - acc: 0.4794 - val_loss: 0.7509 - val_acc: 0.5246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7244 - acc: 0.4948 - val_loss: 0.7453 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7194 - acc: 0.4948 - val_loss: 0.7395 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7142 - acc: 0.5155 - val_loss: 0.7343 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7098 - acc: 0.5309 - val_loss: 0.7295 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7054 - acc: 0.5309 - val_loss: 0.7250 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6928 - acc: 0.5928 - val_loss: 0.6824 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6876 - acc: 0.6031 - val_loss: 0.6781 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6835 - acc: 0.6082 - val_loss: 0.6741 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6795 - acc: 0.6082 - val_loss: 0.6703 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6757 - acc: 0.6134 - val_loss: 0.6666 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6720 - acc: 0.6134 - val_loss: 0.6631 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6684 - acc: 0.6186 - val_loss: 0.6596 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6648 - acc: 0.6186 - val_loss: 0.6559 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6610 - acc: 0.6186 - val_loss: 0.6522 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6575 - acc: 0.6289 - val_loss: 0.6488 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6543 - acc: 0.6289 - val_loss: 0.6455 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6511 - acc: 0.6340 - val_loss: 0.6423 - val_acc: 0.6393\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6478 - acc: 0.6392 - val_loss: 0.6392 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6448 - acc: 0.6392 - val_loss: 0.6361 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6417 - acc: 0.6443 - val_loss: 0.6330 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6386 - acc: 0.6495 - val_loss: 0.6301 - val_acc: 0.6557\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6355 - acc: 0.6546 - val_loss: 0.6271 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6325 - acc: 0.6546 - val_loss: 0.6242 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6295 - acc: 0.6598 - val_loss: 0.6214 - val_acc: 0.6557\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6265 - acc: 0.6649 - val_loss: 0.6188 - val_acc: 0.6557\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6496 - acc: 0.6632 - val_loss: 0.6556 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6418 - acc: 0.6891 - val_loss: 0.6489 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6357 - acc: 0.6995 - val_loss: 0.6428 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6301 - acc: 0.6995 - val_loss: 0.6369 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6250 - acc: 0.7047 - val_loss: 0.6313 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6198 - acc: 0.7150 - val_loss: 0.6260 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6147 - acc: 0.7202 - val_loss: 0.6212 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6100 - acc: 0.7306 - val_loss: 0.6164 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6053 - acc: 0.7358 - val_loss: 0.6116 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6007 - acc: 0.7358 - val_loss: 0.6071 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5963 - acc: 0.7409 - val_loss: 0.6031 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5923 - acc: 0.7409 - val_loss: 0.5990 - val_acc: 0.7377\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5882 - acc: 0.7461 - val_loss: 0.5949 - val_acc: 0.7377\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5841 - acc: 0.7461 - val_loss: 0.5909 - val_acc: 0.7541\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5807 - acc: 0.7513 - val_loss: 0.5874 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5777 - acc: 0.7565 - val_loss: 0.5838 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5745 - acc: 0.7617 - val_loss: 0.5800 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5711 - acc: 0.7772 - val_loss: 0.5764 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5678 - acc: 0.7824 - val_loss: 0.5729 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5645 - acc: 0.7876 - val_loss: 0.5698 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6268 - acc: 0.6528 - val_loss: 0.5602 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6197 - acc: 0.6580 - val_loss: 0.5543 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6138 - acc: 0.6632 - val_loss: 0.5484 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6075 - acc: 0.6788 - val_loss: 0.5429 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6019 - acc: 0.6891 - val_loss: 0.5378 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5968 - acc: 0.6943 - val_loss: 0.5334 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5919 - acc: 0.6995 - val_loss: 0.5293 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5873 - acc: 0.7047 - val_loss: 0.5252 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5830 - acc: 0.7150 - val_loss: 0.5218 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5792 - acc: 0.7150 - val_loss: 0.5184 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5756 - acc: 0.7150 - val_loss: 0.5153 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5724 - acc: 0.7358 - val_loss: 0.5124 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5694 - acc: 0.7358 - val_loss: 0.5096 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5665 - acc: 0.7358 - val_loss: 0.5067 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5634 - acc: 0.7358 - val_loss: 0.5037 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5601 - acc: 0.7409 - val_loss: 0.5008 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5569 - acc: 0.7358 - val_loss: 0.4979 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5536 - acc: 0.7461 - val_loss: 0.4950 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5502 - acc: 0.7461 - val_loss: 0.4920 - val_acc: 0.8197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5471 - acc: 0.7461 - val_loss: 0.4891 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7580 - acc: 0.5619 - val_loss: 0.8531 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7476 - acc: 0.5619 - val_loss: 0.8405 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7386 - acc: 0.5619 - val_loss: 0.8288 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7299 - acc: 0.5619 - val_loss: 0.8178 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7223 - acc: 0.5619 - val_loss: 0.8079 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7152 - acc: 0.5670 - val_loss: 0.7985 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7082 - acc: 0.5670 - val_loss: 0.7893 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7015 - acc: 0.5722 - val_loss: 0.7811 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6956 - acc: 0.5722 - val_loss: 0.7729 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6895 - acc: 0.5722 - val_loss: 0.7640 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6827 - acc: 0.5722 - val_loss: 0.7542 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6759 - acc: 0.5722 - val_loss: 0.7448 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6694 - acc: 0.5722 - val_loss: 0.7359 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6629 - acc: 0.5825 - val_loss: 0.7274 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6567 - acc: 0.5876 - val_loss: 0.7189 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6504 - acc: 0.5876 - val_loss: 0.7101 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6442 - acc: 0.5928 - val_loss: 0.7017 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6381 - acc: 0.6134 - val_loss: 0.6938 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6325 - acc: 0.6134 - val_loss: 0.6866 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6273 - acc: 0.6186 - val_loss: 0.6792 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7211 - acc: 0.5412 - val_loss: 0.7233 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7113 - acc: 0.5722 - val_loss: 0.7139 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7038 - acc: 0.5773 - val_loss: 0.7056 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6969 - acc: 0.5825 - val_loss: 0.6979 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6905 - acc: 0.5928 - val_loss: 0.6905 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6841 - acc: 0.5876 - val_loss: 0.6832 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6779 - acc: 0.6031 - val_loss: 0.6763 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6720 - acc: 0.6031 - val_loss: 0.6699 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6667 - acc: 0.6134 - val_loss: 0.6641 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6618 - acc: 0.6134 - val_loss: 0.6581 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6564 - acc: 0.6186 - val_loss: 0.6520 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6513 - acc: 0.6186 - val_loss: 0.6458 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6458 - acc: 0.6289 - val_loss: 0.6395 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6405 - acc: 0.6392 - val_loss: 0.6340 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6356 - acc: 0.6392 - val_loss: 0.6288 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6312 - acc: 0.6495 - val_loss: 0.6233 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6266 - acc: 0.6495 - val_loss: 0.6179 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6220 - acc: 0.6598 - val_loss: 0.6129 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6178 - acc: 0.6701 - val_loss: 0.6079 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6133 - acc: 0.6701 - val_loss: 0.6028 - val_acc: 0.7049\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6890 - acc: 0.5825 - val_loss: 0.6869 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6803 - acc: 0.5979 - val_loss: 0.6784 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6731 - acc: 0.6186 - val_loss: 0.6707 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6666 - acc: 0.6237 - val_loss: 0.6639 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6602 - acc: 0.6443 - val_loss: 0.6571 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6540 - acc: 0.6546 - val_loss: 0.6502 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6481 - acc: 0.6649 - val_loss: 0.6436 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6425 - acc: 0.6753 - val_loss: 0.6374 - val_acc: 0.6393\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6370 - acc: 0.6804 - val_loss: 0.6316 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6318 - acc: 0.6856 - val_loss: 0.6258 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6264 - acc: 0.6907 - val_loss: 0.6203 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6216 - acc: 0.7062 - val_loss: 0.6151 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6170 - acc: 0.7165 - val_loss: 0.6098 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6122 - acc: 0.7268 - val_loss: 0.6045 - val_acc: 0.6885\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6076 - acc: 0.7320 - val_loss: 0.6000 - val_acc: 0.6885\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6035 - acc: 0.7320 - val_loss: 0.5959 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5996 - acc: 0.7320 - val_loss: 0.5923 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5959 - acc: 0.7268 - val_loss: 0.5883 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5921 - acc: 0.7320 - val_loss: 0.5845 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5885 - acc: 0.7371 - val_loss: 0.5805 - val_acc: 0.7049\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6608 - acc: 0.5855 - val_loss: 0.5973 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6493 - acc: 0.6010 - val_loss: 0.5873 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6402 - acc: 0.6218 - val_loss: 0.5787 - val_acc: 0.7705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6317 - acc: 0.6269 - val_loss: 0.5708 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6236 - acc: 0.6477 - val_loss: 0.5633 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6164 - acc: 0.6788 - val_loss: 0.5567 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6092 - acc: 0.6839 - val_loss: 0.5498 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6022 - acc: 0.7047 - val_loss: 0.5430 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5953 - acc: 0.7150 - val_loss: 0.5368 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5888 - acc: 0.7150 - val_loss: 0.5312 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5825 - acc: 0.7306 - val_loss: 0.5260 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5767 - acc: 0.7461 - val_loss: 0.5209 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5715 - acc: 0.7513 - val_loss: 0.5163 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5671 - acc: 0.7565 - val_loss: 0.5124 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5628 - acc: 0.7668 - val_loss: 0.5084 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5588 - acc: 0.7720 - val_loss: 0.5044 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5546 - acc: 0.7668 - val_loss: 0.5001 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5501 - acc: 0.7720 - val_loss: 0.4957 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5454 - acc: 0.7824 - val_loss: 0.4912 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5406 - acc: 0.7876 - val_loss: 0.4866 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7069 - acc: 0.5078 - val_loss: 0.6864 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6938 - acc: 0.5389 - val_loss: 0.6759 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6844 - acc: 0.5596 - val_loss: 0.6684 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6771 - acc: 0.5907 - val_loss: 0.6615 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6707 - acc: 0.6010 - val_loss: 0.6552 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6640 - acc: 0.6166 - val_loss: 0.6479 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6574 - acc: 0.6477 - val_loss: 0.6408 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6504 - acc: 0.6580 - val_loss: 0.6333 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6431 - acc: 0.6788 - val_loss: 0.6259 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6359 - acc: 0.6891 - val_loss: 0.6187 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6289 - acc: 0.7047 - val_loss: 0.6116 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6216 - acc: 0.7202 - val_loss: 0.6054 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6153 - acc: 0.7358 - val_loss: 0.5996 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6095 - acc: 0.7409 - val_loss: 0.5947 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6048 - acc: 0.7461 - val_loss: 0.5898 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5998 - acc: 0.7513 - val_loss: 0.5856 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5952 - acc: 0.7513 - val_loss: 0.5811 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5903 - acc: 0.7461 - val_loss: 0.5768 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5857 - acc: 0.7565 - val_loss: 0.5721 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5809 - acc: 0.7720 - val_loss: 0.5670 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7049 - acc: 0.5258 - val_loss: 0.7120 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6919 - acc: 0.5361 - val_loss: 0.7005 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6817 - acc: 0.5515 - val_loss: 0.6893 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6715 - acc: 0.5515 - val_loss: 0.6785 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6619 - acc: 0.5464 - val_loss: 0.6674 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6519 - acc: 0.5619 - val_loss: 0.6562 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6425 - acc: 0.5773 - val_loss: 0.6450 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6331 - acc: 0.6082 - val_loss: 0.6336 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6232 - acc: 0.6237 - val_loss: 0.6225 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6136 - acc: 0.6546 - val_loss: 0.6117 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6044 - acc: 0.6701 - val_loss: 0.6007 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5952 - acc: 0.6856 - val_loss: 0.5901 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5861 - acc: 0.7010 - val_loss: 0.5801 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5777 - acc: 0.7268 - val_loss: 0.5702 - val_acc: 0.7541\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5694 - acc: 0.7526 - val_loss: 0.5609 - val_acc: 0.7705\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5614 - acc: 0.7629 - val_loss: 0.5520 - val_acc: 0.7705\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5541 - acc: 0.7732 - val_loss: 0.5438 - val_acc: 0.7705\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5471 - acc: 0.7784 - val_loss: 0.5355 - val_acc: 0.7869\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5399 - acc: 0.7887 - val_loss: 0.5276 - val_acc: 0.7869\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5335 - acc: 0.8144 - val_loss: 0.5208 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7258 - acc: 0.4691 - val_loss: 0.7352 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7126 - acc: 0.5000 - val_loss: 0.7218 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7020 - acc: 0.5258 - val_loss: 0.7106 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6923 - acc: 0.5309 - val_loss: 0.7005 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6835 - acc: 0.5825 - val_loss: 0.6906 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6747 - acc: 0.5979 - val_loss: 0.6815 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6666 - acc: 0.6392 - val_loss: 0.6726 - val_acc: 0.5738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6586 - acc: 0.6495 - val_loss: 0.6643 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6509 - acc: 0.6804 - val_loss: 0.6570 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6441 - acc: 0.6907 - val_loss: 0.6493 - val_acc: 0.6393\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6367 - acc: 0.7010 - val_loss: 0.6414 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6293 - acc: 0.7062 - val_loss: 0.6333 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6218 - acc: 0.7216 - val_loss: 0.6256 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6148 - acc: 0.7320 - val_loss: 0.6191 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6089 - acc: 0.7474 - val_loss: 0.6138 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6035 - acc: 0.7526 - val_loss: 0.6085 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5983 - acc: 0.7577 - val_loss: 0.6030 - val_acc: 0.7213\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5931 - acc: 0.7577 - val_loss: 0.5974 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5877 - acc: 0.7629 - val_loss: 0.5919 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5827 - acc: 0.7577 - val_loss: 0.5867 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7443 - acc: 0.4278 - val_loss: 0.7234 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7305 - acc: 0.4639 - val_loss: 0.7105 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7189 - acc: 0.5000 - val_loss: 0.6995 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7082 - acc: 0.5258 - val_loss: 0.6896 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6988 - acc: 0.5464 - val_loss: 0.6805 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6899 - acc: 0.5670 - val_loss: 0.6714 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6808 - acc: 0.5928 - val_loss: 0.6623 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6726 - acc: 0.6134 - val_loss: 0.6539 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6642 - acc: 0.6186 - val_loss: 0.6452 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6556 - acc: 0.6289 - val_loss: 0.6366 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6475 - acc: 0.6443 - val_loss: 0.6295 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6403 - acc: 0.6495 - val_loss: 0.6221 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6333 - acc: 0.6649 - val_loss: 0.6143 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6259 - acc: 0.7062 - val_loss: 0.6065 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6186 - acc: 0.7165 - val_loss: 0.5990 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6117 - acc: 0.7268 - val_loss: 0.5913 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6046 - acc: 0.7371 - val_loss: 0.5842 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5984 - acc: 0.7474 - val_loss: 0.5776 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5923 - acc: 0.7526 - val_loss: 0.5706 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5860 - acc: 0.7526 - val_loss: 0.5640 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7230 - acc: 0.3679 - val_loss: 0.7071 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7036 - acc: 0.4456 - val_loss: 0.6892 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6886 - acc: 0.4974 - val_loss: 0.6750 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6765 - acc: 0.5751 - val_loss: 0.6637 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6655 - acc: 0.6218 - val_loss: 0.6525 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6553 - acc: 0.6528 - val_loss: 0.6417 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6452 - acc: 0.7150 - val_loss: 0.6309 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6365 - acc: 0.7409 - val_loss: 0.6217 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6280 - acc: 0.7720 - val_loss: 0.6121 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6192 - acc: 0.7824 - val_loss: 0.6021 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6103 - acc: 0.7876 - val_loss: 0.5923 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6019 - acc: 0.8031 - val_loss: 0.5836 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5940 - acc: 0.8083 - val_loss: 0.5753 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5864 - acc: 0.8290 - val_loss: 0.5668 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5786 - acc: 0.8394 - val_loss: 0.5586 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5712 - acc: 0.8394 - val_loss: 0.5502 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5639 - acc: 0.8342 - val_loss: 0.5422 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5562 - acc: 0.8290 - val_loss: 0.5346 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5493 - acc: 0.8290 - val_loss: 0.5271 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5423 - acc: 0.8238 - val_loss: 0.5199 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6307 - acc: 0.6788 - val_loss: 0.6004 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6147 - acc: 0.7047 - val_loss: 0.5861 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6020 - acc: 0.7409 - val_loss: 0.5735 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5903 - acc: 0.7513 - val_loss: 0.5629 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5804 - acc: 0.7565 - val_loss: 0.5524 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5709 - acc: 0.7617 - val_loss: 0.5425 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5618 - acc: 0.7772 - val_loss: 0.5342 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5538 - acc: 0.7772 - val_loss: 0.5268 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5467 - acc: 0.7876 - val_loss: 0.5193 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5396 - acc: 0.7876 - val_loss: 0.5120 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5329 - acc: 0.8135 - val_loss: 0.5048 - val_acc: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5267 - acc: 0.8238 - val_loss: 0.4987 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5210 - acc: 0.8290 - val_loss: 0.4921 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5147 - acc: 0.8342 - val_loss: 0.4861 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5095 - acc: 0.8446 - val_loss: 0.4808 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5044 - acc: 0.8446 - val_loss: 0.4765 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5004 - acc: 0.8394 - val_loss: 0.4733 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4971 - acc: 0.8394 - val_loss: 0.4700 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4937 - acc: 0.8342 - val_loss: 0.4664 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4900 - acc: 0.8394 - val_loss: 0.4624 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6881 - acc: 0.5361 - val_loss: 0.6693 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6688 - acc: 0.5773 - val_loss: 0.6519 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6535 - acc: 0.6546 - val_loss: 0.6369 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6390 - acc: 0.6959 - val_loss: 0.6225 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6259 - acc: 0.7216 - val_loss: 0.6088 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6126 - acc: 0.7371 - val_loss: 0.5951 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6000 - acc: 0.7680 - val_loss: 0.5822 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5884 - acc: 0.7784 - val_loss: 0.5718 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5786 - acc: 0.7887 - val_loss: 0.5612 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5689 - acc: 0.7990 - val_loss: 0.5513 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5596 - acc: 0.7990 - val_loss: 0.5420 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5508 - acc: 0.8144 - val_loss: 0.5329 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5420 - acc: 0.8196 - val_loss: 0.5239 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5337 - acc: 0.8196 - val_loss: 0.5150 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5252 - acc: 0.8247 - val_loss: 0.5065 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5172 - acc: 0.8196 - val_loss: 0.4986 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5102 - acc: 0.8299 - val_loss: 0.4912 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5034 - acc: 0.8351 - val_loss: 0.4844 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4969 - acc: 0.8351 - val_loss: 0.4779 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4907 - acc: 0.8351 - val_loss: 0.4714 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6789 - acc: 0.5773 - val_loss: 0.6616 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6600 - acc: 0.6443 - val_loss: 0.6428 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6447 - acc: 0.6753 - val_loss: 0.6258 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6307 - acc: 0.6907 - val_loss: 0.6102 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6178 - acc: 0.7062 - val_loss: 0.5963 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6064 - acc: 0.7268 - val_loss: 0.5845 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5957 - acc: 0.7474 - val_loss: 0.5739 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5868 - acc: 0.7577 - val_loss: 0.5648 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5785 - acc: 0.7577 - val_loss: 0.5557 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5705 - acc: 0.7680 - val_loss: 0.5472 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5627 - acc: 0.7784 - val_loss: 0.5379 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5544 - acc: 0.7835 - val_loss: 0.5282 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5464 - acc: 0.7887 - val_loss: 0.5192 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5389 - acc: 0.7835 - val_loss: 0.5104 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5316 - acc: 0.7835 - val_loss: 0.5021 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5244 - acc: 0.7835 - val_loss: 0.4947 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5181 - acc: 0.7887 - val_loss: 0.4877 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5119 - acc: 0.7990 - val_loss: 0.4818 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5068 - acc: 0.7990 - val_loss: 0.4763 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5017 - acc: 0.8041 - val_loss: 0.4711 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6898 - acc: 0.6134 - val_loss: 0.6813 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6720 - acc: 0.6546 - val_loss: 0.6637 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6567 - acc: 0.6701 - val_loss: 0.6482 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6429 - acc: 0.7010 - val_loss: 0.6336 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6302 - acc: 0.7216 - val_loss: 0.6202 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6178 - acc: 0.7371 - val_loss: 0.6074 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6062 - acc: 0.7474 - val_loss: 0.5949 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5947 - acc: 0.7629 - val_loss: 0.5831 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5837 - acc: 0.7680 - val_loss: 0.5717 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5733 - acc: 0.7835 - val_loss: 0.5610 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5634 - acc: 0.7835 - val_loss: 0.5507 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5542 - acc: 0.7784 - val_loss: 0.5407 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5454 - acc: 0.7938 - val_loss: 0.5318 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5382 - acc: 0.8093 - val_loss: 0.5242 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5318 - acc: 0.8196 - val_loss: 0.5180 - val_acc: 0.8197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5259 - acc: 0.8196 - val_loss: 0.5125 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5201 - acc: 0.8196 - val_loss: 0.5067 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5144 - acc: 0.8247 - val_loss: 0.5004 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5087 - acc: 0.8299 - val_loss: 0.4952 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5038 - acc: 0.8299 - val_loss: 0.4913 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6602 - acc: 0.6477 - val_loss: 0.6590 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6524 - acc: 0.6477 - val_loss: 0.6523 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6462 - acc: 0.6425 - val_loss: 0.6457 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6399 - acc: 0.6425 - val_loss: 0.6400 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6347 - acc: 0.6477 - val_loss: 0.6354 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6298 - acc: 0.6528 - val_loss: 0.6308 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6249 - acc: 0.6684 - val_loss: 0.6259 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6198 - acc: 0.6736 - val_loss: 0.6205 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6143 - acc: 0.6891 - val_loss: 0.6156 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6101 - acc: 0.6891 - val_loss: 0.6127 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6067 - acc: 0.6891 - val_loss: 0.6092 - val_acc: 0.7541\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6031 - acc: 0.6995 - val_loss: 0.6060 - val_acc: 0.7541\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5997 - acc: 0.6995 - val_loss: 0.6026 - val_acc: 0.7377\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5965 - acc: 0.7202 - val_loss: 0.5990 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5929 - acc: 0.7254 - val_loss: 0.5949 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5893 - acc: 0.7306 - val_loss: 0.5905 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5856 - acc: 0.7306 - val_loss: 0.5869 - val_acc: 0.7705\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5825 - acc: 0.7306 - val_loss: 0.5835 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5792 - acc: 0.7409 - val_loss: 0.5794 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5753 - acc: 0.7461 - val_loss: 0.5752 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8995 - acc: 0.4819 - val_loss: 1.1912 - val_acc: 0.3443\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8780 - acc: 0.4922 - val_loss: 1.1599 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8612 - acc: 0.4922 - val_loss: 1.1330 - val_acc: 0.3443\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8468 - acc: 0.4974 - val_loss: 1.1105 - val_acc: 0.3443\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8344 - acc: 0.5078 - val_loss: 1.0896 - val_acc: 0.3607\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8222 - acc: 0.5181 - val_loss: 1.0701 - val_acc: 0.3770\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8110 - acc: 0.5181 - val_loss: 1.0508 - val_acc: 0.3770\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8003 - acc: 0.5233 - val_loss: 1.0336 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7902 - acc: 0.5233 - val_loss: 1.0170 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7810 - acc: 0.5389 - val_loss: 1.0009 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7716 - acc: 0.5440 - val_loss: 0.9851 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7625 - acc: 0.5544 - val_loss: 0.9707 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7539 - acc: 0.5596 - val_loss: 0.9580 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7462 - acc: 0.5648 - val_loss: 0.9448 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7383 - acc: 0.5751 - val_loss: 0.9311 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7304 - acc: 0.5699 - val_loss: 0.9176 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7225 - acc: 0.5699 - val_loss: 0.9042 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7149 - acc: 0.5751 - val_loss: 0.8913 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7073 - acc: 0.5803 - val_loss: 0.8784 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6992 - acc: 0.5855 - val_loss: 0.8641 - val_acc: 0.4590\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.8165 - acc: 0.4536 - val_loss: 0.8142 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7922 - acc: 0.4588 - val_loss: 0.7919 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7736 - acc: 0.4639 - val_loss: 0.7704 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7558 - acc: 0.4794 - val_loss: 0.7516 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7403 - acc: 0.5052 - val_loss: 0.7317 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7242 - acc: 0.5309 - val_loss: 0.7115 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7083 - acc: 0.5464 - val_loss: 0.6925 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6933 - acc: 0.5619 - val_loss: 0.6765 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6793 - acc: 0.5928 - val_loss: 0.6623 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6670 - acc: 0.6134 - val_loss: 0.6482 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6548 - acc: 0.6289 - val_loss: 0.6351 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6430 - acc: 0.6495 - val_loss: 0.6229 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6322 - acc: 0.6753 - val_loss: 0.6111 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6215 - acc: 0.6907 - val_loss: 0.5997 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6113 - acc: 0.6959 - val_loss: 0.5892 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6019 - acc: 0.7062 - val_loss: 0.5798 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5928 - acc: 0.7062 - val_loss: 0.5706 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5842 - acc: 0.7268 - val_loss: 0.5611 - val_acc: 0.7541\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5751 - acc: 0.7371 - val_loss: 0.5520 - val_acc: 0.7377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5671 - acc: 0.7423 - val_loss: 0.5431 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6633 - acc: 0.5567 - val_loss: 0.6264 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6487 - acc: 0.5773 - val_loss: 0.6146 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6364 - acc: 0.5773 - val_loss: 0.6046 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6256 - acc: 0.5876 - val_loss: 0.5953 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6162 - acc: 0.5979 - val_loss: 0.5870 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6072 - acc: 0.5928 - val_loss: 0.5801 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5989 - acc: 0.5928 - val_loss: 0.5726 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5896 - acc: 0.6082 - val_loss: 0.5646 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5803 - acc: 0.6237 - val_loss: 0.5568 - val_acc: 0.7049\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5720 - acc: 0.6289 - val_loss: 0.5504 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5644 - acc: 0.6546 - val_loss: 0.5445 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5581 - acc: 0.6546 - val_loss: 0.5397 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5527 - acc: 0.6649 - val_loss: 0.5353 - val_acc: 0.7377\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5475 - acc: 0.6753 - val_loss: 0.5316 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5428 - acc: 0.6907 - val_loss: 0.5275 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5379 - acc: 0.7010 - val_loss: 0.5228 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5323 - acc: 0.7113 - val_loss: 0.5173 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5270 - acc: 0.7113 - val_loss: 0.5121 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5218 - acc: 0.7113 - val_loss: 0.5071 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5168 - acc: 0.7268 - val_loss: 0.5022 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1116 - acc: 0.2629 - val_loss: 1.2558 - val_acc: 0.2459\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0823 - acc: 0.2732 - val_loss: 1.2190 - val_acc: 0.2787\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0576 - acc: 0.2784 - val_loss: 1.1830 - val_acc: 0.2951\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0363 - acc: 0.3093 - val_loss: 1.1498 - val_acc: 0.3115\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0157 - acc: 0.3144 - val_loss: 1.1221 - val_acc: 0.3115\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9968 - acc: 0.3247 - val_loss: 1.0975 - val_acc: 0.3115\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9802 - acc: 0.3247 - val_loss: 1.0745 - val_acc: 0.3115\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9644 - acc: 0.3247 - val_loss: 1.0517 - val_acc: 0.3115\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9482 - acc: 0.3247 - val_loss: 1.0306 - val_acc: 0.3279\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9334 - acc: 0.3299 - val_loss: 1.0103 - val_acc: 0.3443\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9191 - acc: 0.3402 - val_loss: 0.9911 - val_acc: 0.3443\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9048 - acc: 0.3351 - val_loss: 0.9709 - val_acc: 0.3443\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8909 - acc: 0.3351 - val_loss: 0.9509 - val_acc: 0.3607\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8772 - acc: 0.3454 - val_loss: 0.9319 - val_acc: 0.3770\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8638 - acc: 0.3557 - val_loss: 0.9126 - val_acc: 0.3770\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8505 - acc: 0.3660 - val_loss: 0.8929 - val_acc: 0.3770\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8375 - acc: 0.3814 - val_loss: 0.8746 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8256 - acc: 0.4227 - val_loss: 0.8575 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8148 - acc: 0.4381 - val_loss: 0.8407 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8029 - acc: 0.4381 - val_loss: 0.8232 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9706 - acc: 0.5078 - val_loss: 1.0894 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9313 - acc: 0.5181 - val_loss: 1.0445 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8999 - acc: 0.5233 - val_loss: 1.0056 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8728 - acc: 0.5285 - val_loss: 0.9713 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8477 - acc: 0.5337 - val_loss: 0.9380 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8221 - acc: 0.5389 - val_loss: 0.9051 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8006 - acc: 0.5596 - val_loss: 0.8750 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7792 - acc: 0.5648 - val_loss: 0.8481 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7608 - acc: 0.5699 - val_loss: 0.8250 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7431 - acc: 0.5803 - val_loss: 0.8043 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7275 - acc: 0.6010 - val_loss: 0.7851 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7138 - acc: 0.6166 - val_loss: 0.7680 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6998 - acc: 0.6269 - val_loss: 0.7519 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6873 - acc: 0.6373 - val_loss: 0.7355 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6743 - acc: 0.6425 - val_loss: 0.7207 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6622 - acc: 0.6632 - val_loss: 0.7076 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6519 - acc: 0.6736 - val_loss: 0.6948 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6416 - acc: 0.6736 - val_loss: 0.6812 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6302 - acc: 0.6788 - val_loss: 0.6662 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6186 - acc: 0.6839 - val_loss: 0.6545 - val_acc: 0.6557\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9839 - acc: 0.5181 - val_loss: 1.2648 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9399 - acc: 0.5233 - val_loss: 1.2113 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9066 - acc: 0.5233 - val_loss: 1.1708 - val_acc: 0.4590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8795 - acc: 0.5389 - val_loss: 1.1311 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8532 - acc: 0.5440 - val_loss: 1.0911 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8282 - acc: 0.5440 - val_loss: 1.0555 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8062 - acc: 0.5596 - val_loss: 1.0232 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7856 - acc: 0.5751 - val_loss: 0.9916 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7657 - acc: 0.5907 - val_loss: 0.9646 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7492 - acc: 0.6010 - val_loss: 0.9399 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7332 - acc: 0.6114 - val_loss: 0.9176 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7179 - acc: 0.6269 - val_loss: 0.8947 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7025 - acc: 0.6373 - val_loss: 0.8707 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6869 - acc: 0.6425 - val_loss: 0.8481 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6721 - acc: 0.6528 - val_loss: 0.8257 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6571 - acc: 0.6684 - val_loss: 0.8044 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6434 - acc: 0.6839 - val_loss: 0.7832 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6305 - acc: 0.6839 - val_loss: 0.7664 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6201 - acc: 0.6995 - val_loss: 0.7520 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6103 - acc: 0.7202 - val_loss: 0.7388 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7033 - acc: 0.5567 - val_loss: 0.5990 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6731 - acc: 0.6237 - val_loss: 0.5775 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6506 - acc: 0.6392 - val_loss: 0.5603 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6308 - acc: 0.6753 - val_loss: 0.5454 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6146 - acc: 0.6856 - val_loss: 0.5308 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5979 - acc: 0.6907 - val_loss: 0.5170 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5822 - acc: 0.7165 - val_loss: 0.5048 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5684 - acc: 0.7268 - val_loss: 0.4932 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5557 - acc: 0.7423 - val_loss: 0.4820 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5447 - acc: 0.7526 - val_loss: 0.4711 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5333 - acc: 0.7526 - val_loss: 0.4613 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5234 - acc: 0.7577 - val_loss: 0.4530 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5136 - acc: 0.7577 - val_loss: 0.4455 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5055 - acc: 0.7680 - val_loss: 0.4385 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4971 - acc: 0.7680 - val_loss: 0.4314 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4892 - acc: 0.7680 - val_loss: 0.4249 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4818 - acc: 0.7732 - val_loss: 0.4186 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4748 - acc: 0.7784 - val_loss: 0.4129 - val_acc: 0.7869\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4682 - acc: 0.7835 - val_loss: 0.4077 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4611 - acc: 0.7887 - val_loss: 0.4026 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9986 - acc: 0.5258 - val_loss: 1.0063 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9575 - acc: 0.5258 - val_loss: 0.9563 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9233 - acc: 0.5206 - val_loss: 0.9110 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8923 - acc: 0.5258 - val_loss: 0.8687 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8628 - acc: 0.5412 - val_loss: 0.8299 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8350 - acc: 0.5464 - val_loss: 0.7942 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8087 - acc: 0.5567 - val_loss: 0.7614 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7836 - acc: 0.5619 - val_loss: 0.7308 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7614 - acc: 0.5722 - val_loss: 0.7016 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7388 - acc: 0.5876 - val_loss: 0.6759 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7179 - acc: 0.6289 - val_loss: 0.6524 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7002 - acc: 0.6443 - val_loss: 0.6301 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6814 - acc: 0.6804 - val_loss: 0.6103 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6664 - acc: 0.6856 - val_loss: 0.5924 - val_acc: 0.6885\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6513 - acc: 0.6959 - val_loss: 0.5759 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6366 - acc: 0.7062 - val_loss: 0.5600 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6227 - acc: 0.7216 - val_loss: 0.5451 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6091 - acc: 0.7216 - val_loss: 0.5303 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5966 - acc: 0.7268 - val_loss: 0.5178 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5849 - acc: 0.7320 - val_loss: 0.5069 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9750 - acc: 0.4588 - val_loss: 0.9042 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9393 - acc: 0.4588 - val_loss: 0.8750 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9093 - acc: 0.4794 - val_loss: 0.8489 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8806 - acc: 0.4897 - val_loss: 0.8272 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8568 - acc: 0.5052 - val_loss: 0.8068 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8340 - acc: 0.5412 - val_loss: 0.7863 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8106 - acc: 0.5619 - val_loss: 0.7666 - val_acc: 0.6066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7874 - acc: 0.5722 - val_loss: 0.7477 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7665 - acc: 0.5825 - val_loss: 0.7306 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - acc: 0.5979 - val_loss: 0.7150 - val_acc: 0.6393\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7281 - acc: 0.6186 - val_loss: 0.6991 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7109 - acc: 0.6289 - val_loss: 0.6843 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6957 - acc: 0.6495 - val_loss: 0.6699 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6791 - acc: 0.6598 - val_loss: 0.6575 - val_acc: 0.6885\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6651 - acc: 0.6701 - val_loss: 0.6450 - val_acc: 0.6885\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6512 - acc: 0.6753 - val_loss: 0.6322 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6379 - acc: 0.6753 - val_loss: 0.6201 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6260 - acc: 0.6804 - val_loss: 0.6092 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6146 - acc: 0.6907 - val_loss: 0.5994 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6040 - acc: 0.6907 - val_loss: 0.5891 - val_acc: 0.6885\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5675 - acc: 0.6839 - val_loss: 0.5003 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5370 - acc: 0.7202 - val_loss: 0.4830 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5194 - acc: 0.7461 - val_loss: 0.4735 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5052 - acc: 0.7513 - val_loss: 0.4622 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4912 - acc: 0.7720 - val_loss: 0.4511 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4790 - acc: 0.7824 - val_loss: 0.4411 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4673 - acc: 0.8031 - val_loss: 0.4314 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4570 - acc: 0.8031 - val_loss: 0.4237 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4489 - acc: 0.8083 - val_loss: 0.4167 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4417 - acc: 0.8187 - val_loss: 0.4104 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4340 - acc: 0.8290 - val_loss: 0.4047 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4266 - acc: 0.8342 - val_loss: 0.3990 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4195 - acc: 0.8342 - val_loss: 0.3938 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4126 - acc: 0.8394 - val_loss: 0.3884 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4063 - acc: 0.8342 - val_loss: 0.3835 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4000 - acc: 0.8342 - val_loss: 0.3786 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3938 - acc: 0.8342 - val_loss: 0.3748 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3884 - acc: 0.8342 - val_loss: 0.3712 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3838 - acc: 0.8342 - val_loss: 0.3674 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3795 - acc: 0.8342 - val_loss: 0.3642 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9214 - acc: 0.3990 - val_loss: 0.8781 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8703 - acc: 0.4197 - val_loss: 0.8390 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8328 - acc: 0.4404 - val_loss: 0.8054 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7991 - acc: 0.4560 - val_loss: 0.7725 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7676 - acc: 0.4870 - val_loss: 0.7431 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7391 - acc: 0.5130 - val_loss: 0.7186 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7169 - acc: 0.5440 - val_loss: 0.6973 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6948 - acc: 0.5751 - val_loss: 0.6768 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6732 - acc: 0.5959 - val_loss: 0.6569 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6534 - acc: 0.6321 - val_loss: 0.6394 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6359 - acc: 0.6373 - val_loss: 0.6227 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6204 - acc: 0.6477 - val_loss: 0.6078 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6050 - acc: 0.6788 - val_loss: 0.5948 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5920 - acc: 0.6943 - val_loss: 0.5819 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5796 - acc: 0.6995 - val_loss: 0.5683 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5660 - acc: 0.7202 - val_loss: 0.5541 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5545 - acc: 0.7306 - val_loss: 0.5419 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5439 - acc: 0.7461 - val_loss: 0.5315 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5351 - acc: 0.7513 - val_loss: 0.5231 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5262 - acc: 0.7617 - val_loss: 0.5132 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7191 - acc: 0.4897 - val_loss: 0.6976 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6808 - acc: 0.5103 - val_loss: 0.6661 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6498 - acc: 0.5619 - val_loss: 0.6380 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6230 - acc: 0.5825 - val_loss: 0.6112 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5978 - acc: 0.6340 - val_loss: 0.5885 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5771 - acc: 0.6907 - val_loss: 0.5707 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5592 - acc: 0.7113 - val_loss: 0.5545 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5433 - acc: 0.7474 - val_loss: 0.5393 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5274 - acc: 0.7732 - val_loss: 0.5248 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5134 - acc: 0.7835 - val_loss: 0.5124 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5001 - acc: 0.8093 - val_loss: 0.5002 - val_acc: 0.7377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4878 - acc: 0.8247 - val_loss: 0.4885 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4763 - acc: 0.8247 - val_loss: 0.4774 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4650 - acc: 0.8247 - val_loss: 0.4671 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4546 - acc: 0.8196 - val_loss: 0.4577 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4454 - acc: 0.8196 - val_loss: 0.4495 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4373 - acc: 0.8196 - val_loss: 0.4418 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4301 - acc: 0.8247 - val_loss: 0.4335 - val_acc: 0.7869\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4237 - acc: 0.8299 - val_loss: 0.4255 - val_acc: 0.7869\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4169 - acc: 0.8299 - val_loss: 0.4186 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7485 - acc: 0.5155 - val_loss: 0.6901 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7053 - acc: 0.5567 - val_loss: 0.6562 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6700 - acc: 0.5825 - val_loss: 0.6252 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6391 - acc: 0.6340 - val_loss: 0.5958 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6097 - acc: 0.6804 - val_loss: 0.5695 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5858 - acc: 0.6959 - val_loss: 0.5456 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5613 - acc: 0.7320 - val_loss: 0.5244 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5405 - acc: 0.7474 - val_loss: 0.5054 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5220 - acc: 0.7629 - val_loss: 0.4884 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5053 - acc: 0.7835 - val_loss: 0.4741 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4914 - acc: 0.7887 - val_loss: 0.4622 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4798 - acc: 0.7887 - val_loss: 0.4517 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4684 - acc: 0.7990 - val_loss: 0.4433 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4589 - acc: 0.8144 - val_loss: 0.4360 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4504 - acc: 0.8299 - val_loss: 0.4291 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4421 - acc: 0.8351 - val_loss: 0.4221 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4343 - acc: 0.8299 - val_loss: 0.4152 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4279 - acc: 0.8299 - val_loss: 0.4092 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4218 - acc: 0.8299 - val_loss: 0.4043 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4163 - acc: 0.8299 - val_loss: 0.3991 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7442 - acc: 0.6082 - val_loss: 0.6485 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6958 - acc: 0.6649 - val_loss: 0.6062 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6604 - acc: 0.6701 - val_loss: 0.5673 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6275 - acc: 0.6856 - val_loss: 0.5329 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5962 - acc: 0.7165 - val_loss: 0.5058 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5705 - acc: 0.7165 - val_loss: 0.4840 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5501 - acc: 0.7423 - val_loss: 0.4638 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5317 - acc: 0.7577 - val_loss: 0.4457 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5147 - acc: 0.7629 - val_loss: 0.4325 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5011 - acc: 0.7680 - val_loss: 0.4217 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4895 - acc: 0.7784 - val_loss: 0.4128 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4792 - acc: 0.7990 - val_loss: 0.4045 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4703 - acc: 0.7990 - val_loss: 0.3979 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4609 - acc: 0.8041 - val_loss: 0.3933 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4529 - acc: 0.8196 - val_loss: 0.3882 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4453 - acc: 0.8247 - val_loss: 0.3831 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4375 - acc: 0.8351 - val_loss: 0.3792 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4307 - acc: 0.8351 - val_loss: 0.3760 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4250 - acc: 0.8402 - val_loss: 0.3750 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4204 - acc: 0.8402 - val_loss: 0.3732 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6767 - acc: 0.5803 - val_loss: 0.6254 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6265 - acc: 0.6425 - val_loss: 0.5846 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5901 - acc: 0.6839 - val_loss: 0.5509 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5587 - acc: 0.7254 - val_loss: 0.5207 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5302 - acc: 0.7617 - val_loss: 0.4926 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5056 - acc: 0.7876 - val_loss: 0.4688 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4843 - acc: 0.7979 - val_loss: 0.4521 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4681 - acc: 0.8031 - val_loss: 0.4361 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4522 - acc: 0.7979 - val_loss: 0.4223 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4387 - acc: 0.8083 - val_loss: 0.4131 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4285 - acc: 0.8083 - val_loss: 0.4038 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4191 - acc: 0.8135 - val_loss: 0.3963 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4106 - acc: 0.8135 - val_loss: 0.3900 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4040 - acc: 0.8187 - val_loss: 0.3853 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3979 - acc: 0.8342 - val_loss: 0.3817 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3919 - acc: 0.8394 - val_loss: 0.3775 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3866 - acc: 0.8446 - val_loss: 0.3740 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3816 - acc: 0.8446 - val_loss: 0.3714 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3773 - acc: 0.8497 - val_loss: 0.3692 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3724 - acc: 0.8497 - val_loss: 0.3670 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6525 - acc: 0.6373 - val_loss: 0.5521 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6007 - acc: 0.6839 - val_loss: 0.5217 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5669 - acc: 0.7202 - val_loss: 0.4976 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5400 - acc: 0.7617 - val_loss: 0.4768 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5171 - acc: 0.7668 - val_loss: 0.4574 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4955 - acc: 0.7927 - val_loss: 0.4405 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4768 - acc: 0.8135 - val_loss: 0.4262 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4614 - acc: 0.8238 - val_loss: 0.4126 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4467 - acc: 0.8238 - val_loss: 0.4011 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4343 - acc: 0.8549 - val_loss: 0.3911 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4247 - acc: 0.8549 - val_loss: 0.3819 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4159 - acc: 0.8549 - val_loss: 0.3732 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4080 - acc: 0.8497 - val_loss: 0.3652 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4003 - acc: 0.8497 - val_loss: 0.3586 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3940 - acc: 0.8549 - val_loss: 0.3546 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3880 - acc: 0.8549 - val_loss: 0.3514 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3827 - acc: 0.8601 - val_loss: 0.3498 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3772 - acc: 0.8601 - val_loss: 0.3474 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3723 - acc: 0.8601 - val_loss: 0.3448 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3672 - acc: 0.8549 - val_loss: 0.3420 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6678 - acc: 0.6031 - val_loss: 0.6454 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6146 - acc: 0.6856 - val_loss: 0.6054 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5760 - acc: 0.7216 - val_loss: 0.5738 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5461 - acc: 0.7887 - val_loss: 0.5444 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5176 - acc: 0.8144 - val_loss: 0.5180 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4933 - acc: 0.8196 - val_loss: 0.4959 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4723 - acc: 0.8247 - val_loss: 0.4760 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4550 - acc: 0.8299 - val_loss: 0.4582 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4387 - acc: 0.8351 - val_loss: 0.4422 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4242 - acc: 0.8402 - val_loss: 0.4282 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4119 - acc: 0.8454 - val_loss: 0.4166 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4011 - acc: 0.8505 - val_loss: 0.4073 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3929 - acc: 0.8505 - val_loss: 0.3986 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3844 - acc: 0.8505 - val_loss: 0.3916 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3775 - acc: 0.8505 - val_loss: 0.3842 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3706 - acc: 0.8557 - val_loss: 0.3767 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3641 - acc: 0.8557 - val_loss: 0.3705 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3584 - acc: 0.8557 - val_loss: 0.3661 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3535 - acc: 0.8505 - val_loss: 0.3617 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3493 - acc: 0.8557 - val_loss: 0.3569 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5443 - acc: 0.7629 - val_loss: 0.4932 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5080 - acc: 0.7835 - val_loss: 0.4643 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4822 - acc: 0.7990 - val_loss: 0.4407 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4620 - acc: 0.8093 - val_loss: 0.4210 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4465 - acc: 0.8299 - val_loss: 0.4048 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4322 - acc: 0.8299 - val_loss: 0.3920 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4222 - acc: 0.8299 - val_loss: 0.3838 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4141 - acc: 0.8402 - val_loss: 0.3802 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4093 - acc: 0.8351 - val_loss: 0.3765 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4052 - acc: 0.8299 - val_loss: 0.3730 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4008 - acc: 0.8299 - val_loss: 0.3694 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3960 - acc: 0.8247 - val_loss: 0.3656 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3912 - acc: 0.8402 - val_loss: 0.3620 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3865 - acc: 0.8299 - val_loss: 0.3584 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3814 - acc: 0.8454 - val_loss: 0.3545 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3765 - acc: 0.8454 - val_loss: 0.3508 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3722 - acc: 0.8505 - val_loss: 0.3479 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3691 - acc: 0.8505 - val_loss: 0.3465 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3660 - acc: 0.8454 - val_loss: 0.3430 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3629 - acc: 0.8505 - val_loss: 0.3400 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7970 - acc: 0.4588 - val_loss: 0.7738 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7323 - acc: 0.5206 - val_loss: 0.7242 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6823 - acc: 0.5979 - val_loss: 0.6809 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6406 - acc: 0.6546 - val_loss: 0.6415 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6027 - acc: 0.6753 - val_loss: 0.6059 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5700 - acc: 0.6907 - val_loss: 0.5725 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5390 - acc: 0.7320 - val_loss: 0.5415 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5117 - acc: 0.7629 - val_loss: 0.5145 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4894 - acc: 0.7990 - val_loss: 0.4920 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4711 - acc: 0.8144 - val_loss: 0.4757 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4558 - acc: 0.8196 - val_loss: 0.4602 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4428 - acc: 0.8299 - val_loss: 0.4456 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4315 - acc: 0.8402 - val_loss: 0.4342 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4226 - acc: 0.8299 - val_loss: 0.4239 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4144 - acc: 0.8351 - val_loss: 0.4138 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4073 - acc: 0.8351 - val_loss: 0.4040 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4003 - acc: 0.8351 - val_loss: 0.3952 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3945 - acc: 0.8454 - val_loss: 0.3876 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3888 - acc: 0.8505 - val_loss: 0.3811 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3344 - acc: 0.890 - 0s 4ms/step - loss: 0.3842 - acc: 0.8505 - val_loss: 0.3761 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6236 - acc: 0.6580 - val_loss: 0.5062 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5603 - acc: 0.7409 - val_loss: 0.4667 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5202 - acc: 0.7876 - val_loss: 0.4387 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4912 - acc: 0.8031 - val_loss: 0.4160 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4690 - acc: 0.8031 - val_loss: 0.3995 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4531 - acc: 0.8031 - val_loss: 0.3864 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4408 - acc: 0.8135 - val_loss: 0.3758 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4290 - acc: 0.8238 - val_loss: 0.3685 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4192 - acc: 0.8238 - val_loss: 0.3630 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4095 - acc: 0.8238 - val_loss: 0.3581 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4008 - acc: 0.8238 - val_loss: 0.3524 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3924 - acc: 0.8290 - val_loss: 0.3475 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3847 - acc: 0.8446 - val_loss: 0.3441 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3779 - acc: 0.8549 - val_loss: 0.3422 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3714 - acc: 0.8549 - val_loss: 0.3412 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3669 - acc: 0.8549 - val_loss: 0.3401 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3618 - acc: 0.8549 - val_loss: 0.3373 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3566 - acc: 0.8601 - val_loss: 0.3344 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3518 - acc: 0.8549 - val_loss: 0.3327 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3474 - acc: 0.8549 - val_loss: 0.3319 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7571 - acc: 0.4301 - val_loss: 0.7019 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6715 - acc: 0.6166 - val_loss: 0.6310 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6106 - acc: 0.7202 - val_loss: 0.5768 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5648 - acc: 0.7668 - val_loss: 0.5310 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5252 - acc: 0.7824 - val_loss: 0.4929 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4939 - acc: 0.8031 - val_loss: 0.4617 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4674 - acc: 0.7979 - val_loss: 0.4356 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4470 - acc: 0.7979 - val_loss: 0.4132 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4317 - acc: 0.7979 - val_loss: 0.3958 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4186 - acc: 0.8031 - val_loss: 0.3817 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4070 - acc: 0.8031 - val_loss: 0.3725 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3988 - acc: 0.8187 - val_loss: 0.3684 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3923 - acc: 0.8187 - val_loss: 0.3621 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3858 - acc: 0.8238 - val_loss: 0.3559 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3800 - acc: 0.8290 - val_loss: 0.3510 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3748 - acc: 0.8290 - val_loss: 0.3464 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3699 - acc: 0.8394 - val_loss: 0.3417 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3655 - acc: 0.8394 - val_loss: 0.3378 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3604 - acc: 0.8394 - val_loss: 0.3340 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3567 - acc: 0.8394 - val_loss: 0.3312 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8122 - acc: 0.5361 - val_loss: 0.7076 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7070 - acc: 0.5515 - val_loss: 0.6221 - val_acc: 0.6393\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6357 - acc: 0.6495 - val_loss: 0.5536 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5763 - acc: 0.7320 - val_loss: 0.4964 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5263 - acc: 0.7577 - val_loss: 0.4507 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4857 - acc: 0.7784 - val_loss: 0.4160 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4525 - acc: 0.8247 - val_loss: 0.3921 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4282 - acc: 0.8144 - val_loss: 0.3732 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4070 - acc: 0.8299 - val_loss: 0.3591 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3910 - acc: 0.8402 - val_loss: 0.3503 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3777 - acc: 0.8608 - val_loss: 0.3453 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3683 - acc: 0.8608 - val_loss: 0.3410 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3593 - acc: 0.8711 - val_loss: 0.3373 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3528 - acc: 0.8711 - val_loss: 0.3334 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3469 - acc: 0.8711 - val_loss: 0.3304 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3415 - acc: 0.8711 - val_loss: 0.3276 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3368 - acc: 0.8711 - val_loss: 0.3248 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3330 - acc: 0.8660 - val_loss: 0.3221 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3287 - acc: 0.8660 - val_loss: 0.3196 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3252 - acc: 0.8660 - val_loss: 0.3174 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7077 - acc: 0.6134 - val_loss: 0.6659 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6277 - acc: 0.6856 - val_loss: 0.5903 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5759 - acc: 0.7165 - val_loss: 0.5368 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5382 - acc: 0.7423 - val_loss: 0.4922 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5067 - acc: 0.7526 - val_loss: 0.4586 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4807 - acc: 0.7784 - val_loss: 0.4346 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4633 - acc: 0.7938 - val_loss: 0.4161 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4464 - acc: 0.7938 - val_loss: 0.4003 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4328 - acc: 0.7938 - val_loss: 0.3866 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4224 - acc: 0.8041 - val_loss: 0.3745 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4130 - acc: 0.8144 - val_loss: 0.3661 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4048 - acc: 0.8093 - val_loss: 0.3595 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3978 - acc: 0.8196 - val_loss: 0.3543 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3906 - acc: 0.8196 - val_loss: 0.3505 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3838 - acc: 0.8196 - val_loss: 0.3479 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3783 - acc: 0.8247 - val_loss: 0.3463 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3738 - acc: 0.8247 - val_loss: 0.3458 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3688 - acc: 0.8299 - val_loss: 0.3459 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3638 - acc: 0.8351 - val_loss: 0.3452 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3603 - acc: 0.8402 - val_loss: 0.3440 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6510 - acc: 0.5979 - val_loss: 0.5432 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5670 - acc: 0.7113 - val_loss: 0.4819 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5112 - acc: 0.7629 - val_loss: 0.4380 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4738 - acc: 0.7680 - val_loss: 0.4121 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4475 - acc: 0.7784 - val_loss: 0.3954 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4287 - acc: 0.7887 - val_loss: 0.3812 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4140 - acc: 0.7990 - val_loss: 0.3708 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4003 - acc: 0.8144 - val_loss: 0.3635 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3893 - acc: 0.8299 - val_loss: 0.3577 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3811 - acc: 0.8351 - val_loss: 0.3525 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3749 - acc: 0.8454 - val_loss: 0.3482 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3695 - acc: 0.8505 - val_loss: 0.3450 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3647 - acc: 0.8505 - val_loss: 0.3424 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3602 - acc: 0.8557 - val_loss: 0.3422 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3548 - acc: 0.8557 - val_loss: 0.3439 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3500 - acc: 0.8608 - val_loss: 0.3479 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3436 - acc: 0.8557 - val_loss: 0.3502 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3397 - acc: 0.8660 - val_loss: 0.3515 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3362 - acc: 0.8711 - val_loss: 0.3539 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6474 - acc: 0.6114 - val_loss: 0.5902 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5507 - acc: 0.7824 - val_loss: 0.5193 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4937 - acc: 0.8394 - val_loss: 0.4653 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4471 - acc: 0.8394 - val_loss: 0.4283 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4171 - acc: 0.8601 - val_loss: 0.4031 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3941 - acc: 0.8497 - val_loss: 0.3822 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3762 - acc: 0.8446 - val_loss: 0.3655 - val_acc: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3640 - acc: 0.8497 - val_loss: 0.3541 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3543 - acc: 0.8549 - val_loss: 0.3508 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3479 - acc: 0.8601 - val_loss: 0.3469 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3435 - acc: 0.8601 - val_loss: 0.3427 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3382 - acc: 0.8549 - val_loss: 0.3377 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3357 - acc: 0.8601 - val_loss: 0.3319 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3324 - acc: 0.8653 - val_loss: 0.3271 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3295 - acc: 0.8653 - val_loss: 0.3241 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3265 - acc: 0.8653 - val_loss: 0.3239 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3222 - acc: 0.8601 - val_loss: 0.3240 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3182 - acc: 0.8601 - val_loss: 0.3233 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3149 - acc: 0.8549 - val_loss: 0.3219 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3125 - acc: 0.8549 - val_loss: 0.3202 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6750 - acc: 0.5803 - val_loss: 0.5773 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5734 - acc: 0.7772 - val_loss: 0.4992 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5069 - acc: 0.8135 - val_loss: 0.4497 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4637 - acc: 0.8187 - val_loss: 0.4154 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4344 - acc: 0.8135 - val_loss: 0.3961 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4159 - acc: 0.8187 - val_loss: 0.3830 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4018 - acc: 0.8394 - val_loss: 0.3725 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3910 - acc: 0.8394 - val_loss: 0.3647 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3823 - acc: 0.8446 - val_loss: 0.3566 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3744 - acc: 0.8446 - val_loss: 0.3492 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3670 - acc: 0.8497 - val_loss: 0.3462 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3617 - acc: 0.8549 - val_loss: 0.3429 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3566 - acc: 0.8601 - val_loss: 0.3396 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3514 - acc: 0.8601 - val_loss: 0.3362 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3480 - acc: 0.8497 - val_loss: 0.3313 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3442 - acc: 0.8497 - val_loss: 0.3272 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3411 - acc: 0.8497 - val_loss: 0.3241 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3382 - acc: 0.8497 - val_loss: 0.3220 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3361 - acc: 0.8497 - val_loss: 0.3194 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3346 - acc: 0.8497 - val_loss: 0.3186 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6498 - acc: 0.6392 - val_loss: 0.5655 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5497 - acc: 0.7887 - val_loss: 0.4920 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4916 - acc: 0.8299 - val_loss: 0.4523 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4557 - acc: 0.8351 - val_loss: 0.4238 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4276 - acc: 0.8505 - val_loss: 0.3986 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4056 - acc: 0.8505 - val_loss: 0.3783 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3864 - acc: 0.8505 - val_loss: 0.3625 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3736 - acc: 0.8660 - val_loss: 0.3495 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3644 - acc: 0.8711 - val_loss: 0.3392 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3542 - acc: 0.8608 - val_loss: 0.3315 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3467 - acc: 0.8763 - val_loss: 0.3252 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3409 - acc: 0.8814 - val_loss: 0.3202 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3350 - acc: 0.8814 - val_loss: 0.3160 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3298 - acc: 0.8763 - val_loss: 0.3130 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3248 - acc: 0.8814 - val_loss: 0.3108 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3200 - acc: 0.8814 - val_loss: 0.3097 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3166 - acc: 0.8763 - val_loss: 0.3080 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3118 - acc: 0.8763 - val_loss: 0.3072 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3088 - acc: 0.8763 - val_loss: 0.3072 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3062 - acc: 0.8763 - val_loss: 0.3079 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6625 - acc: 0.5928 - val_loss: 0.5622 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5626 - acc: 0.8041 - val_loss: 0.4847 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5010 - acc: 0.8196 - val_loss: 0.4319 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4557 - acc: 0.8299 - val_loss: 0.4007 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4266 - acc: 0.8351 - val_loss: 0.3790 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4040 - acc: 0.8454 - val_loss: 0.3644 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3870 - acc: 0.8454 - val_loss: 0.3543 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3739 - acc: 0.8402 - val_loss: 0.3470 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3637 - acc: 0.8402 - val_loss: 0.3396 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3557 - acc: 0.8505 - val_loss: 0.3312 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3492 - acc: 0.8454 - val_loss: 0.3236 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3443 - acc: 0.8402 - val_loss: 0.3198 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3407 - acc: 0.8454 - val_loss: 0.3203 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3370 - acc: 0.8454 - val_loss: 0.3199 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3337 - acc: 0.8454 - val_loss: 0.3193 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3314 - acc: 0.8505 - val_loss: 0.3184 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3275 - acc: 0.8505 - val_loss: 0.3176 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3236 - acc: 0.8608 - val_loss: 0.3166 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3204 - acc: 0.8711 - val_loss: 0.3162 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3174 - acc: 0.8711 - val_loss: 0.3164 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7811 - acc: 0.3299 - val_loss: 0.6752 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6621 - acc: 0.6134 - val_loss: 0.5931 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5842 - acc: 0.7680 - val_loss: 0.5417 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5331 - acc: 0.7938 - val_loss: 0.4994 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4905 - acc: 0.8247 - val_loss: 0.4679 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4588 - acc: 0.8402 - val_loss: 0.4410 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4318 - acc: 0.8454 - val_loss: 0.4184 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4129 - acc: 0.8454 - val_loss: 0.4016 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3976 - acc: 0.8505 - val_loss: 0.3898 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3852 - acc: 0.8505 - val_loss: 0.3809 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3743 - acc: 0.8505 - val_loss: 0.3766 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3664 - acc: 0.8454 - val_loss: 0.3722 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3576 - acc: 0.8557 - val_loss: 0.3682 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3515 - acc: 0.8608 - val_loss: 0.3648 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3451 - acc: 0.8608 - val_loss: 0.3601 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3396 - acc: 0.8660 - val_loss: 0.3555 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3347 - acc: 0.8711 - val_loss: 0.3506 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3299 - acc: 0.8711 - val_loss: 0.3462 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3249 - acc: 0.8763 - val_loss: 0.3381 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3213 - acc: 0.8711 - val_loss: 0.3332 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6760 - acc: 0.5803 - val_loss: 0.5548 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5291 - acc: 0.8187 - val_loss: 0.4642 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4511 - acc: 0.8238 - val_loss: 0.4137 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4065 - acc: 0.8446 - val_loss: 0.3820 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3803 - acc: 0.8394 - val_loss: 0.3638 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3630 - acc: 0.8394 - val_loss: 0.3585 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3521 - acc: 0.8497 - val_loss: 0.3626 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3453 - acc: 0.8549 - val_loss: 0.3645 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3394 - acc: 0.8549 - val_loss: 0.3663 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3334 - acc: 0.8601 - val_loss: 0.3662 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3276 - acc: 0.8653 - val_loss: 0.3624 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6477 - acc: 0.6684 - val_loss: 0.5230 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5208 - acc: 0.8135 - val_loss: 0.4499 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4623 - acc: 0.8238 - val_loss: 0.4053 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4217 - acc: 0.8187 - val_loss: 0.3782 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3957 - acc: 0.8238 - val_loss: 0.3623 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3800 - acc: 0.8290 - val_loss: 0.3513 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3691 - acc: 0.8238 - val_loss: 0.3461 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3588 - acc: 0.8290 - val_loss: 0.3408 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3520 - acc: 0.8342 - val_loss: 0.3361 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3458 - acc: 0.8446 - val_loss: 0.3327 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3390 - acc: 0.8446 - val_loss: 0.3320 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3328 - acc: 0.8497 - val_loss: 0.3310 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3262 - acc: 0.8497 - val_loss: 0.3299 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3194 - acc: 0.8549 - val_loss: 0.3276 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3097 - acc: 0.8601 - val_loss: 0.3281 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3093 - acc: 0.8653 - val_loss: 0.3335 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3047 - acc: 0.8653 - val_loss: 0.3360 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3047 - acc: 0.8756 - val_loss: 0.3371 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3038 - acc: 0.8756 - val_loss: 0.3372 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6326 - acc: 0.6907 - val_loss: 0.5160 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4971 - acc: 0.8505 - val_loss: 0.4311 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4260 - acc: 0.8608 - val_loss: 0.3902 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3879 - acc: 0.8660 - val_loss: 0.3698 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3625 - acc: 0.8711 - val_loss: 0.3601 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3464 - acc: 0.8763 - val_loss: 0.3524 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3347 - acc: 0.8763 - val_loss: 0.3445 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3249 - acc: 0.8763 - val_loss: 0.3378 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3186 - acc: 0.8763 - val_loss: 0.3318 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3124 - acc: 0.8763 - val_loss: 0.3283 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3077 - acc: 0.8763 - val_loss: 0.3272 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3034 - acc: 0.8814 - val_loss: 0.3264 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2989 - acc: 0.8814 - val_loss: 0.3250 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2955 - acc: 0.8918 - val_loss: 0.3235 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2924 - acc: 0.8918 - val_loss: 0.3220 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2892 - acc: 0.8814 - val_loss: 0.3197 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2854 - acc: 0.8814 - val_loss: 0.3173 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2850 - acc: 0.8866 - val_loss: 0.3162 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2794 - acc: 0.8918 - val_loss: 0.3133 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2722 - acc: 0.8918 - val_loss: 0.3128 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6919 - acc: 0.5567 - val_loss: 0.5785 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5586 - acc: 0.7938 - val_loss: 0.4923 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4847 - acc: 0.8196 - val_loss: 0.4318 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4367 - acc: 0.8402 - val_loss: 0.3915 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4042 - acc: 0.8299 - val_loss: 0.3681 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3856 - acc: 0.8299 - val_loss: 0.3557 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3762 - acc: 0.8351 - val_loss: 0.3473 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3663 - acc: 0.8351 - val_loss: 0.3420 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3602 - acc: 0.8299 - val_loss: 0.3379 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3539 - acc: 0.8402 - val_loss: 0.3334 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3476 - acc: 0.8454 - val_loss: 0.3290 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3445 - acc: 0.8454 - val_loss: 0.3270 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3394 - acc: 0.8505 - val_loss: 0.3273 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3342 - acc: 0.8557 - val_loss: 0.3321 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3266 - acc: 0.8608 - val_loss: 0.3412 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3228 - acc: 0.8711 - val_loss: 0.3460 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3192 - acc: 0.8763 - val_loss: 0.3465 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6907 - acc: 0.5464 - val_loss: 0.5250 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5426 - acc: 0.7990 - val_loss: 0.4348 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4674 - acc: 0.8247 - val_loss: 0.3880 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4323 - acc: 0.8247 - val_loss: 0.3660 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4087 - acc: 0.8299 - val_loss: 0.3549 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3936 - acc: 0.8402 - val_loss: 0.3476 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3797 - acc: 0.8402 - val_loss: 0.3430 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3681 - acc: 0.8402 - val_loss: 0.3379 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3573 - acc: 0.8454 - val_loss: 0.3340 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3508 - acc: 0.8454 - val_loss: 0.3348 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3450 - acc: 0.8608 - val_loss: 0.3339 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3389 - acc: 0.8608 - val_loss: 0.3337 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3334 - acc: 0.8608 - val_loss: 0.3341 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3281 - acc: 0.8608 - val_loss: 0.3361 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3236 - acc: 0.8660 - val_loss: 0.3404 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3210 - acc: 0.8660 - val_loss: 0.3432 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3171 - acc: 0.8660 - val_loss: 0.3434 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9078 - acc: 0.4715 - val_loss: 0.7470 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6708 - acc: 0.6166 - val_loss: 0.5854 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5441 - acc: 0.7617 - val_loss: 0.4906 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4750 - acc: 0.7927 - val_loss: 0.4360 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4385 - acc: 0.8083 - val_loss: 0.4201 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4187 - acc: 0.8031 - val_loss: 0.4102 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4046 - acc: 0.8083 - val_loss: 0.3999 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3912 - acc: 0.8187 - val_loss: 0.3903 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3797 - acc: 0.8342 - val_loss: 0.3852 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3702 - acc: 0.8342 - val_loss: 0.3811 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3601 - acc: 0.8394 - val_loss: 0.3707 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3494 - acc: 0.8549 - val_loss: 0.3607 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3466 - acc: 0.8446 - val_loss: 0.3553 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3440 - acc: 0.8549 - val_loss: 0.3469 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3415 - acc: 0.8549 - val_loss: 0.3384 - val_acc: 0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3362 - acc: 0.8653 - val_loss: 0.3363 - val_acc: 0.9180\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3349 - acc: 0.8653 - val_loss: 0.3395 - val_acc: 0.9180\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3311 - acc: 0.8705 - val_loss: 0.3575 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3311 - acc: 0.8601 - val_loss: 0.3840 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3305 - acc: 0.8653 - val_loss: 0.4020 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7976 - acc: 0.5078 - val_loss: 0.8076 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6265 - acc: 0.6736 - val_loss: 0.6656 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5309 - acc: 0.7306 - val_loss: 0.5778 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4723 - acc: 0.7824 - val_loss: 0.5220 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4414 - acc: 0.7927 - val_loss: 0.4923 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4212 - acc: 0.8083 - val_loss: 0.4801 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4023 - acc: 0.8135 - val_loss: 0.4704 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3857 - acc: 0.8238 - val_loss: 0.4645 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3726 - acc: 0.8290 - val_loss: 0.4599 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3616 - acc: 0.8342 - val_loss: 0.4547 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3537 - acc: 0.8342 - val_loss: 0.4497 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3457 - acc: 0.8446 - val_loss: 0.4425 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3407 - acc: 0.8497 - val_loss: 0.4384 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3374 - acc: 0.8497 - val_loss: 0.4397 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3354 - acc: 0.8601 - val_loss: 0.4433 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3326 - acc: 0.8549 - val_loss: 0.4550 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3366 - acc: 0.8705 - val_loss: 0.4764 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3393 - acc: 0.8756 - val_loss: 0.4928 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5903 - acc: 0.6649 - val_loss: 0.4533 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4961 - acc: 0.7835 - val_loss: 0.3858 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4543 - acc: 0.8196 - val_loss: 0.3551 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4256 - acc: 0.8351 - val_loss: 0.3460 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4074 - acc: 0.8505 - val_loss: 0.3488 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3960 - acc: 0.8454 - val_loss: 0.3541 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3838 - acc: 0.8454 - val_loss: 0.3529 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3714 - acc: 0.8454 - val_loss: 0.3478 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3595 - acc: 0.8505 - val_loss: 0.3410 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3477 - acc: 0.8660 - val_loss: 0.3294 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3374 - acc: 0.8814 - val_loss: 0.3221 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3310 - acc: 0.8814 - val_loss: 0.3189 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3233 - acc: 0.8763 - val_loss: 0.3177 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3166 - acc: 0.8763 - val_loss: 0.3141 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3141 - acc: 0.8608 - val_loss: 0.3133 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3149 - acc: 0.8660 - val_loss: 0.3140 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3134 - acc: 0.8711 - val_loss: 0.3174 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3082 - acc: 0.8711 - val_loss: 0.3211 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3021 - acc: 0.8711 - val_loss: 0.3257 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2955 - acc: 0.8763 - val_loss: 0.3348 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6304 - acc: 0.6804 - val_loss: 0.5419 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5310 - acc: 0.7423 - val_loss: 0.4688 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4710 - acc: 0.7835 - val_loss: 0.4273 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4317 - acc: 0.7887 - val_loss: 0.4009 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4024 - acc: 0.7990 - val_loss: 0.3860 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3809 - acc: 0.8144 - val_loss: 0.3723 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3655 - acc: 0.8299 - val_loss: 0.3606 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3538 - acc: 0.8299 - val_loss: 0.3529 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3442 - acc: 0.8247 - val_loss: 0.3491 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3388 - acc: 0.8247 - val_loss: 0.3488 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3347 - acc: 0.8402 - val_loss: 0.3539 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3288 - acc: 0.8299 - val_loss: 0.3522 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3273 - acc: 0.8299 - val_loss: 0.3544 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3224 - acc: 0.8351 - val_loss: 0.3568 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3182 - acc: 0.8351 - val_loss: 0.3621 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6126 - acc: 0.6753 - val_loss: 0.5058 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4885 - acc: 0.7938 - val_loss: 0.4413 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4376 - acc: 0.7990 - val_loss: 0.4021 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4083 - acc: 0.8196 - val_loss: 0.3761 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3866 - acc: 0.8247 - val_loss: 0.3668 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3741 - acc: 0.8299 - val_loss: 0.3629 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3649 - acc: 0.8402 - val_loss: 0.3546 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3575 - acc: 0.8402 - val_loss: 0.3442 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3515 - acc: 0.8402 - val_loss: 0.3378 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3479 - acc: 0.8505 - val_loss: 0.3327 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3407 - acc: 0.8608 - val_loss: 0.3322 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3354 - acc: 0.8608 - val_loss: 0.3428 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3326 - acc: 0.8660 - val_loss: 0.3535 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3303 - acc: 0.8814 - val_loss: 0.3691 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3303 - acc: 0.8660 - val_loss: 0.3759 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3287 - acc: 0.8608 - val_loss: 0.3825 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8695 - acc: 0.4301 - val_loss: 0.5979 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5893 - acc: 0.7306 - val_loss: 0.4409 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4706 - acc: 0.7824 - val_loss: 0.3727 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4046 - acc: 0.7979 - val_loss: 0.3521 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3717 - acc: 0.8135 - val_loss: 0.3507 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3537 - acc: 0.8497 - val_loss: 0.3581 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3446 - acc: 0.8601 - val_loss: 0.3668 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3381 - acc: 0.8705 - val_loss: 0.3693 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3312 - acc: 0.8756 - val_loss: 0.3640 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3235 - acc: 0.8860 - val_loss: 0.3552 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0084 - acc: 0.4404 - val_loss: 0.6502 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6659 - acc: 0.6062 - val_loss: 0.5091 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5042 - acc: 0.7461 - val_loss: 0.4361 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4297 - acc: 0.8238 - val_loss: 0.3950 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3993 - acc: 0.8290 - val_loss: 0.3607 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3786 - acc: 0.8601 - val_loss: 0.3427 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3649 - acc: 0.8653 - val_loss: 0.3385 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3537 - acc: 0.8601 - val_loss: 0.3314 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3464 - acc: 0.8497 - val_loss: 0.3212 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3370 - acc: 0.8653 - val_loss: 0.3139 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3285 - acc: 0.8653 - val_loss: 0.3118 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3257 - acc: 0.8653 - val_loss: 0.3164 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3270 - acc: 0.8601 - val_loss: 0.3227 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3286 - acc: 0.8653 - val_loss: 0.3295 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3247 - acc: 0.8705 - val_loss: 0.3326 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3193 - acc: 0.8601 - val_loss: 0.3371 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7092 - acc: 0.5567 - val_loss: 0.4817 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4822 - acc: 0.7887 - val_loss: 0.3890 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4092 - acc: 0.8454 - val_loss: 0.3486 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3748 - acc: 0.8299 - val_loss: 0.3331 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3649 - acc: 0.8299 - val_loss: 0.3294 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3533 - acc: 0.8351 - val_loss: 0.3284 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3464 - acc: 0.8505 - val_loss: 0.3321 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3365 - acc: 0.8660 - val_loss: 0.3407 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3278 - acc: 0.8814 - val_loss: 0.3467 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3249 - acc: 0.8814 - val_loss: 0.3472 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3147 - acc: 0.8866 - val_loss: 0.3456 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9358 - acc: 0.4948 - val_loss: 0.6184 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6440 - acc: 0.6753 - val_loss: 0.4526 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5091 - acc: 0.7629 - val_loss: 0.3816 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4412 - acc: 0.7835 - val_loss: 0.3481 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4093 - acc: 0.7938 - val_loss: 0.3333 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3935 - acc: 0.8041 - val_loss: 0.3278 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3842 - acc: 0.7990 - val_loss: 0.3258 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3735 - acc: 0.8041 - val_loss: 0.3248 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3631 - acc: 0.8093 - val_loss: 0.3265 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3555 - acc: 0.8247 - val_loss: 0.3298 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3503 - acc: 0.8402 - val_loss: 0.3340 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3443 - acc: 0.8454 - val_loss: 0.3330 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3415 - acc: 0.8505 - val_loss: 0.3307 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6834 - acc: 0.5928 - val_loss: 0.5434 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5258 - acc: 0.7887 - val_loss: 0.4668 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4491 - acc: 0.8196 - val_loss: 0.4159 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4052 - acc: 0.8299 - val_loss: 0.3842 - val_acc: 0.8197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3799 - acc: 0.8299 - val_loss: 0.3711 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3675 - acc: 0.8402 - val_loss: 0.3797 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3556 - acc: 0.8557 - val_loss: 0.4009 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3489 - acc: 0.8608 - val_loss: 0.4231 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3455 - acc: 0.8660 - val_loss: 0.4360 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3414 - acc: 0.8660 - val_loss: 0.4414 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5277 - acc: 0.7409 - val_loss: 0.3747 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3994 - acc: 0.8446 - val_loss: 0.3658 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3644 - acc: 0.8549 - val_loss: 0.3565 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3452 - acc: 0.8446 - val_loss: 0.3511 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3312 - acc: 0.8497 - val_loss: 0.3439 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3163 - acc: 0.8705 - val_loss: 0.3245 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3047 - acc: 0.8601 - val_loss: 0.3218 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2967 - acc: 0.8653 - val_loss: 0.3262 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2913 - acc: 0.8756 - val_loss: 0.3401 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2862 - acc: 0.8964 - val_loss: 0.3614 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2839 - acc: 0.8912 - val_loss: 0.3776 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2841 - acc: 0.8964 - val_loss: 0.3777 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7784 - acc: 0.4663 - val_loss: 0.4817 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4665 - acc: 0.8290 - val_loss: 0.3611 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3885 - acc: 0.8394 - val_loss: 0.3105 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3731 - acc: 0.8549 - val_loss: 0.2873 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3640 - acc: 0.8446 - val_loss: 0.2751 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3502 - acc: 0.8497 - val_loss: 0.2688 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3408 - acc: 0.8549 - val_loss: 0.2702 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3315 - acc: 0.8601 - val_loss: 0.2767 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3221 - acc: 0.8653 - val_loss: 0.2849 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3121 - acc: 0.8705 - val_loss: 0.2984 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3013 - acc: 0.8860 - val_loss: 0.3211 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7299 - acc: 0.5361 - val_loss: 0.4359 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4227 - acc: 0.8247 - val_loss: 0.3323 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3603 - acc: 0.8711 - val_loss: 0.3135 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3358 - acc: 0.8660 - val_loss: 0.3267 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3293 - acc: 0.8660 - val_loss: 0.3412 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3212 - acc: 0.8660 - val_loss: 0.3508 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3121 - acc: 0.8660 - val_loss: 0.3525 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3020 - acc: 0.8763 - val_loss: 0.3496 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7003 - acc: 0.6082 - val_loss: 0.4809 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4481 - acc: 0.7990 - val_loss: 0.3859 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3846 - acc: 0.8402 - val_loss: 0.3502 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3649 - acc: 0.8402 - val_loss: 0.3400 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3507 - acc: 0.8402 - val_loss: 0.3400 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3410 - acc: 0.8402 - val_loss: 0.3413 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3342 - acc: 0.8402 - val_loss: 0.3420 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3288 - acc: 0.8660 - val_loss: 0.3367 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3215 - acc: 0.8711 - val_loss: 0.3342 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3145 - acc: 0.8763 - val_loss: 0.3305 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3053 - acc: 0.8814 - val_loss: 0.3201 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2984 - acc: 0.8814 - val_loss: 0.3160 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2911 - acc: 0.8866 - val_loss: 0.3198 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2848 - acc: 0.9021 - val_loss: 0.3188 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2862 - acc: 0.8866 - val_loss: 0.3247 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2846 - acc: 0.8814 - val_loss: 0.3339 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2844 - acc: 0.8814 - val_loss: 0.3437 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5575 - acc: 0.7320 - val_loss: 0.4062 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4138 - acc: 0.8093 - val_loss: 0.3910 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3801 - acc: 0.8247 - val_loss: 0.3891 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3658 - acc: 0.8402 - val_loss: 0.3901 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3559 - acc: 0.8454 - val_loss: 0.3959 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3413 - acc: 0.8557 - val_loss: 0.3955 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3255 - acc: 0.8763 - val_loss: 0.3858 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3104 - acc: 0.8711 - val_loss: 0.3817 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2957 - acc: 0.8866 - val_loss: 0.3963 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2896 - acc: 0.8866 - val_loss: 0.4251 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3000 - acc: 0.8763 - val_loss: 0.4367 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2905 - acc: 0.8763 - val_loss: 0.4155 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2830 - acc: 0.8814 - val_loss: 0.3897 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7194 - acc: 0.5130 - val_loss: 0.3843 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3983 - acc: 0.8446 - val_loss: 0.3514 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3654 - acc: 0.8601 - val_loss: 0.3683 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3581 - acc: 0.8601 - val_loss: 0.3764 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3465 - acc: 0.8601 - val_loss: 0.3866 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3177 - acc: 0.8653 - val_loss: 0.3908 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2921 - acc: 0.8860 - val_loss: 0.3917 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5916 - acc: 0.6580 - val_loss: 0.3594 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3961 - acc: 0.8290 - val_loss: 0.3427 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3797 - acc: 0.8290 - val_loss: 0.3485 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3640 - acc: 0.8446 - val_loss: 0.3565 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3368 - acc: 0.8653 - val_loss: 0.3765 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3294 - acc: 0.8653 - val_loss: 0.4009 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3272 - acc: 0.8601 - val_loss: 0.4063 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6020 - acc: 0.6649 - val_loss: 0.3895 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3746 - acc: 0.8299 - val_loss: 0.3633 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3392 - acc: 0.8608 - val_loss: 0.3600 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3317 - acc: 0.8660 - val_loss: 0.3525 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3308 - acc: 0.8608 - val_loss: 0.3603 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3213 - acc: 0.8660 - val_loss: 0.3765 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3186 - acc: 0.8660 - val_loss: 0.3933 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3083 - acc: 0.8660 - val_loss: 0.4032 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2910 - acc: 0.8711 - val_loss: 0.4077 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5806 - acc: 0.6753 - val_loss: 0.3593 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3649 - acc: 0.8402 - val_loss: 0.3333 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3422 - acc: 0.8505 - val_loss: 0.3243 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3362 - acc: 0.8608 - val_loss: 0.3333 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3350 - acc: 0.8505 - val_loss: 0.3495 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3224 - acc: 0.8454 - val_loss: 0.3708 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3100 - acc: 0.8608 - val_loss: 0.3853 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2999 - acc: 0.8454 - val_loss: 0.3799 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5736 - acc: 0.7165 - val_loss: 0.3828 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3996 - acc: 0.8402 - val_loss: 0.3971 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3683 - acc: 0.8505 - val_loss: 0.4145 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3470 - acc: 0.8557 - val_loss: 0.4016 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3391 - acc: 0.8763 - val_loss: 0.3917 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3233 - acc: 0.8763 - val_loss: 0.3804 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3049 - acc: 0.8660 - val_loss: 0.3765 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2864 - acc: 0.8814 - val_loss: 0.3910 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2808 - acc: 0.9124 - val_loss: 0.3989 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2656 - acc: 0.9072 - val_loss: 0.4001 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2590 - acc: 0.8969 - val_loss: 0.4094 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2516 - acc: 0.9072 - val_loss: 0.4136 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5441 - acc: 0.7047 - val_loss: 0.3383 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3637 - acc: 0.8446 - val_loss: 0.3139 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3677 - acc: 0.8187 - val_loss: 0.3142 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3626 - acc: 0.8290 - val_loss: 0.3215 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3531 - acc: 0.8342 - val_loss: 0.3134 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3222 - acc: 0.8549 - val_loss: 0.3156 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2915 - acc: 0.8601 - val_loss: 0.3249 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2679 - acc: 0.8808 - val_loss: 0.3200 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2516 - acc: 0.8964 - val_loss: 0.3041 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2621 - acc: 0.8808 - val_loss: 0.3114 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2670 - acc: 0.9016 - val_loss: 0.3274 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2630 - acc: 0.9119 - val_loss: 0.3347 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2516 - acc: 0.9016 - val_loss: 0.3378 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2355 - acc: 0.9067 - val_loss: 0.3413 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5952 - acc: 0.6632 - val_loss: 0.3640 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3809 - acc: 0.8290 - val_loss: 0.3832 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3647 - acc: 0.8446 - val_loss: 0.3744 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3516 - acc: 0.8394 - val_loss: 0.3649 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3317 - acc: 0.8394 - val_loss: 0.3673 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3040 - acc: 0.8446 - val_loss: 0.4058 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5276 - acc: 0.7268 - val_loss: 0.3213 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3417 - acc: 0.8660 - val_loss: 0.3514 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3466 - acc: 0.8814 - val_loss: 0.3751 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3130 - acc: 0.8711 - val_loss: 0.3817 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2921 - acc: 0.8814 - val_loss: 0.3691 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3014 - acc: 0.8608 - val_loss: 0.3479 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5425 - acc: 0.7216 - val_loss: 0.3032 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3789 - acc: 0.8196 - val_loss: 0.3250 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3615 - acc: 0.8505 - val_loss: 0.3579 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3460 - acc: 0.8608 - val_loss: 0.3766 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3318 - acc: 0.8608 - val_loss: 0.3794 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3105 - acc: 0.8660 - val_loss: 0.3604 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5745 - acc: 0.6598 - val_loss: 0.3698 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3719 - acc: 0.8299 - val_loss: 0.3985 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3665 - acc: 0.8505 - val_loss: 0.4164 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3349 - acc: 0.8763 - val_loss: 0.4320 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3102 - acc: 0.8866 - val_loss: 0.4327 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2865 - acc: 0.8918 - val_loss: 0.4011 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5493 - acc: 0.7098 - val_loss: 0.3957 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3665 - acc: 0.8394 - val_loss: 0.3921 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3369 - acc: 0.8497 - val_loss: 0.3498 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2953 - acc: 0.8808 - val_loss: 0.3018 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2738 - acc: 0.8964 - val_loss: 0.2952 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2611 - acc: 0.9171 - val_loss: 0.3089 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2419 - acc: 0.9171 - val_loss: 0.3247 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2282 - acc: 0.9223 - val_loss: 0.3378 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2211 - acc: 0.9119 - val_loss: 0.3473 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2540 - acc: 0.8756 - val_loss: 0.4020 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5717 - acc: 0.6528 - val_loss: 0.3357 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3785 - acc: 0.8290 - val_loss: 0.3498 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3879 - acc: 0.8394 - val_loss: 0.3584 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3887 - acc: 0.8187 - val_loss: 0.3721 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4017 - acc: 0.8135 - val_loss: 0.3811 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3692 - acc: 0.8342 - val_loss: 0.3841 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5684 - acc: 0.6598 - val_loss: 0.3188 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3510 - acc: 0.8557 - val_loss: 0.3446 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3150 - acc: 0.8763 - val_loss: 0.3622 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2777 - acc: 0.8763 - val_loss: 0.3864 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2553 - acc: 0.8866 - val_loss: 0.4190 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2656 - acc: 0.8814 - val_loss: 0.4290 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4876 - acc: 0.7732 - val_loss: 0.3980 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3730 - acc: 0.8557 - val_loss: 0.4547 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3550 - acc: 0.8711 - val_loss: 0.4838 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3388 - acc: 0.8454 - val_loss: 0.5356 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3473 - acc: 0.8299 - val_loss: 0.5954 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3776 - acc: 0.8299 - val_loss: 0.5693 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5116 - acc: 0.7629 - val_loss: 0.3524 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3769 - acc: 0.8454 - val_loss: 0.3625 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3160 - acc: 0.8608 - val_loss: 0.3994 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2716 - acc: 0.8866 - val_loss: 0.4057 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2512 - acc: 0.9021 - val_loss: 0.4270 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2482 - acc: 0.9124 - val_loss: 0.4782 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5228 - acc: 0.7202 - val_loss: 0.3711 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3840 - acc: 0.8394 - val_loss: 0.4128 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3295 - acc: 0.8601 - val_loss: 0.3731 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2758 - acc: 0.8860 - val_loss: 0.3374 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2549 - acc: 0.9016 - val_loss: 0.3947 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2792 - acc: 0.9016 - val_loss: 0.4368 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2993 - acc: 0.9067 - val_loss: 0.4337 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2696 - acc: 0.9119 - val_loss: 0.4058 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2205 - acc: 0.9326 - val_loss: 0.3916 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5082 - acc: 0.7047 - val_loss: 0.3689 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4110 - acc: 0.8497 - val_loss: 0.4400 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3935 - acc: 0.8446 - val_loss: 0.3863 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3495 - acc: 0.8601 - val_loss: 0.3506 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3063 - acc: 0.8601 - val_loss: 0.3377 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2683 - acc: 0.8964 - val_loss: 0.3691 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2408 - acc: 0.8912 - val_loss: 0.4895 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2620 - acc: 0.8912 - val_loss: 0.5186 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2409 - acc: 0.9067 - val_loss: 0.4922 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2251 - acc: 0.9119 - val_loss: 0.4633 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4844 - acc: 0.7526 - val_loss: 0.3507 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3802 - acc: 0.8608 - val_loss: 0.3651 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3229 - acc: 0.8660 - val_loss: 0.3574 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2768 - acc: 0.8763 - val_loss: 0.4191 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2758 - acc: 0.8763 - val_loss: 0.3980 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2369 - acc: 0.9021 - val_loss: 0.3682 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4755 - acc: 0.7423 - val_loss: 0.3924 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4193 - acc: 0.8402 - val_loss: 0.4267 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3514 - acc: 0.8866 - val_loss: 0.4085 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3081 - acc: 0.8763 - val_loss: 0.4387 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2998 - acc: 0.8814 - val_loss: 0.4156 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2777 - acc: 0.8866 - val_loss: 0.4224 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5132 - acc: 0.7320 - val_loss: 0.3940 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4047 - acc: 0.8505 - val_loss: 0.4672 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3721 - acc: 0.8505 - val_loss: 0.4671 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3105 - acc: 0.8814 - val_loss: 0.3891 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2600 - acc: 0.9227 - val_loss: 0.3460 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2863 - acc: 0.8814 - val_loss: 0.3890 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2903 - acc: 0.8969 - val_loss: 0.4561 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2901 - acc: 0.8711 - val_loss: 0.5479 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2817 - acc: 0.8814 - val_loss: 0.5387 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2283 - acc: 0.9072 - val_loss: 0.4723 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5205 - acc: 0.7513 - val_loss: 0.3948 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3886 - acc: 0.8446 - val_loss: 0.3793 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4016 - acc: 0.8238 - val_loss: 0.5183 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4897 - acc: 0.8031 - val_loss: 0.6107 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4778 - acc: 0.8135 - val_loss: 0.5630 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4803 - acc: 0.8187 - val_loss: 0.4769 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4087 - acc: 0.8394 - val_loss: 0.5178 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6548 - acc: 0.6632 - val_loss: 0.3604 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3806 - acc: 0.8238 - val_loss: 0.3704 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3465 - acc: 0.8601 - val_loss: 0.3902 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3032 - acc: 0.8705 - val_loss: 0.3140 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2828 - acc: 0.8497 - val_loss: 0.3873 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2542 - acc: 0.8756 - val_loss: 0.4970 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2637 - acc: 0.8964 - val_loss: 0.5392 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2515 - acc: 0.8964 - val_loss: 0.5132 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2357 - acc: 0.8964 - val_loss: 0.5345 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5661 - acc: 0.7010 - val_loss: 0.4193 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4206 - acc: 0.8351 - val_loss: 0.3680 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3369 - acc: 0.8557 - val_loss: 0.4323 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3856 - acc: 0.8041 - val_loss: 0.4287 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3659 - acc: 0.8196 - val_loss: 0.3974 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3411 - acc: 0.8402 - val_loss: 0.3778 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3124 - acc: 0.8557 - val_loss: 0.3599 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3161 - acc: 0.8557 - val_loss: 0.3813 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3188 - acc: 0.8608 - val_loss: 0.3797 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3047 - acc: 0.8763 - val_loss: 0.4090 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2962 - acc: 0.8763 - val_loss: 0.4746 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3009 - acc: 0.8814 - val_loss: 0.4620 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7167 - acc: 0.6392 - val_loss: 0.4467 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4634 - acc: 0.8144 - val_loss: 0.4241 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4125 - acc: 0.8351 - val_loss: 0.3802 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3728 - acc: 0.8454 - val_loss: 0.3976 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3484 - acc: 0.8763 - val_loss: 0.4978 - val_acc: 0.7869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3531 - acc: 0.8608 - val_loss: 0.5232 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3357 - acc: 0.8763 - val_loss: 0.5035 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3534 - acc: 0.8660 - val_loss: 0.4891 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7535 - acc: 0.6340 - val_loss: 0.3728 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4511 - acc: 0.8196 - val_loss: 0.3166 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3805 - acc: 0.8557 - val_loss: 0.4423 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3785 - acc: 0.8454 - val_loss: 0.5404 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3851 - acc: 0.8454 - val_loss: 0.4848 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3617 - acc: 0.8454 - val_loss: 0.4087 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3408 - acc: 0.8660 - val_loss: 0.4135 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4433 - acc: 0.8083 - val_loss: 0.4214 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3739 - acc: 0.8705 - val_loss: 0.4280 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3499 - acc: 0.8446 - val_loss: 0.3226 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2636 - acc: 0.8860 - val_loss: 0.4150 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2825 - acc: 0.9067 - val_loss: 0.4541 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2415 - acc: 0.9275 - val_loss: 0.4504 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2225 - acc: 0.9275 - val_loss: 0.5317 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2452 - acc: 0.9171 - val_loss: 0.7125 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6019 - acc: 0.6528 - val_loss: 0.4269 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5388 - acc: 0.7979 - val_loss: 0.6481 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5752 - acc: 0.7772 - val_loss: 0.4722 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4936 - acc: 0.7824 - val_loss: 0.3590 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4507 - acc: 0.7979 - val_loss: 0.3026 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3826 - acc: 0.8135 - val_loss: 0.3225 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3497 - acc: 0.8290 - val_loss: 0.4091 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3421 - acc: 0.8549 - val_loss: 0.4277 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3206 - acc: 0.8705 - val_loss: 0.3761 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2787 - acc: 0.8705 - val_loss: 0.3564 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5231 - acc: 0.7216 - val_loss: 0.4399 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4342 - acc: 0.8351 - val_loss: 0.3412 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3453 - acc: 0.8660 - val_loss: 0.3331 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3616 - acc: 0.8505 - val_loss: 0.4063 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3470 - acc: 0.8505 - val_loss: 0.4593 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3250 - acc: 0.8711 - val_loss: 0.5297 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2999 - acc: 0.8711 - val_loss: 0.5129 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2475 - acc: 0.8866 - val_loss: 0.4521 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6619 - acc: 0.6856 - val_loss: 0.3841 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4124 - acc: 0.8299 - val_loss: 0.4335 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3983 - acc: 0.7784 - val_loss: 0.3245 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3542 - acc: 0.8505 - val_loss: 0.3403 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3375 - acc: 0.8505 - val_loss: 0.4481 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3695 - acc: 0.8505 - val_loss: 0.4933 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3691 - acc: 0.8351 - val_loss: 0.4210 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3892 - acc: 0.8247 - val_loss: 0.3426 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6281 - acc: 0.6701 - val_loss: 0.6617 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4196 - acc: 0.8402 - val_loss: 0.5657 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3192 - acc: 0.8505 - val_loss: 0.5224 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2976 - acc: 0.8866 - val_loss: 0.6283 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2794 - acc: 0.8814 - val_loss: 0.5746 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2549 - acc: 0.8969 - val_loss: 0.5184 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2348 - acc: 0.8969 - val_loss: 0.7267 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1994 - acc: 0.9124 - val_loss: 0.8134 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1625 - acc: 0.9381 - val_loss: 0.9190 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1805 - acc: 0.9330 - val_loss: 1.1185 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1748 - acc: 0.9330 - val_loss: 0.9749 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5304 - acc: 0.7098 - val_loss: 0.3797 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4289 - acc: 0.8497 - val_loss: 0.4637 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3729 - acc: 0.8394 - val_loss: 0.5509 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4045 - acc: 0.8446 - val_loss: 0.5214 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3715 - acc: 0.8756 - val_loss: 0.5981 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5537 - acc: 0.8601 - val_loss: 0.7190 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5927 - acc: 0.7772 - val_loss: 0.4640 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3958 - acc: 0.8653 - val_loss: 0.3926 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4272 - acc: 0.8187 - val_loss: 0.6682 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4234 - acc: 0.8705 - val_loss: 0.8719 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4234 - acc: 0.8964 - val_loss: 0.6020 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3081 - acc: 0.8964 - val_loss: 0.4701 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2691 - acc: 0.9223 - val_loss: 0.5403 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5680 - acc: 0.6598 - val_loss: 0.3737 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4455 - acc: 0.8557 - val_loss: 0.5628 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3563 - acc: 0.8505 - val_loss: 0.5827 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3235 - acc: 0.8299 - val_loss: 0.6238 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2902 - acc: 0.8918 - val_loss: 0.6374 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2258 - acc: 0.9124 - val_loss: 0.5445 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6060 - acc: 0.7216 - val_loss: 0.4105 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4445 - acc: 0.8505 - val_loss: 0.7016 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4893 - acc: 0.8144 - val_loss: 0.5093 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4154 - acc: 0.8144 - val_loss: 0.6361 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3818 - acc: 0.8660 - val_loss: 0.7309 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3624 - acc: 0.8557 - val_loss: 0.6906 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5488 - acc: 0.6959 - val_loss: 0.6660 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6296 - acc: 0.7680 - val_loss: 0.6812 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5184 - acc: 0.7835 - val_loss: 0.5532 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4002 - acc: 0.8505 - val_loss: 0.6047 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3835 - acc: 0.8505 - val_loss: 0.4990 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3726 - acc: 0.8557 - val_loss: 0.5510 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4315 - acc: 0.8454 - val_loss: 0.8871 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4214 - acc: 0.8196 - val_loss: 0.9174 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4035 - acc: 0.8505 - val_loss: 0.7121 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3477 - acc: 0.8660 - val_loss: 0.5913 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8191 - acc: 0.6166 - val_loss: 0.4452 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3688 - acc: 0.8446 - val_loss: 0.4146 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4630 - acc: 0.8653 - val_loss: 0.6674 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2865 - acc: 0.9016 - val_loss: 0.5872 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3437 - acc: 0.8912 - val_loss: 1.0836 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3906 - acc: 0.8601 - val_loss: 0.8174 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4349 - acc: 0.8964 - val_loss: 0.7889 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5357 - acc: 0.8031 - val_loss: 0.5200 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7872 - acc: 0.7409 - val_loss: 1.0693 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6967 - acc: 0.8031 - val_loss: 0.4883 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6111 - acc: 0.8653 - val_loss: 0.5377 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6718 - acc: 0.8756 - val_loss: 0.9330 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6317 - acc: 0.8290 - val_loss: 1.2314 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5458 - acc: 0.8601 - val_loss: 0.9776 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2333 - acc: 0.9275 - val_loss: 0.7176 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6201 - acc: 0.6701 - val_loss: 0.4960 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4351 - acc: 0.8351 - val_loss: 0.5149 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5064 - acc: 0.8557 - val_loss: 0.6409 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3058 - acc: 0.8866 - val_loss: 0.4463 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3146 - acc: 0.8608 - val_loss: 0.9664 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4004 - acc: 0.8608 - val_loss: 0.9022 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2574 - acc: 0.9021 - val_loss: 0.8420 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2316 - acc: 0.8969 - val_loss: 0.7859 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2315 - acc: 0.8969 - val_loss: 0.7535 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6466 - acc: 0.7371 - val_loss: 0.6885 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5322 - acc: 0.8093 - val_loss: 0.9769 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5795 - acc: 0.7784 - val_loss: 0.4454 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4250 - acc: 0.8660 - val_loss: 0.4226 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3573 - acc: 0.8814 - val_loss: 0.4846 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2781 - acc: 0.8918 - val_loss: 0.7048 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2959 - acc: 0.8814 - val_loss: 0.7137 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3248 - acc: 0.8814 - val_loss: 0.6418 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2456 - acc: 0.9227 - val_loss: 0.6318 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6465 - acc: 0.6546 - val_loss: 0.6145 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0075 - acc: 0.6598 - val_loss: 0.5927 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6154 - acc: 0.8093 - val_loss: 0.6095 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5569 - acc: 0.8608 - val_loss: 0.7073 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6784 - acc: 0.7784 - val_loss: 0.7744 - val_acc: 0.7541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4428 - acc: 0.8402 - val_loss: 0.6960 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6744 - acc: 0.7835 - val_loss: 0.5855 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5380 - acc: 0.8093 - val_loss: 0.5021 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5047 - acc: 0.8299 - val_loss: 0.4574 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7227 - acc: 0.7474 - val_loss: 1.9713 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2422 - acc: 0.7371 - val_loss: 0.6524 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6622 - acc: 0.8144 - val_loss: 0.9085 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0735 - acc: 0.8351 - val_loss: 0.9731 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0572 - acc: 0.8247 - val_loss: 0.9146 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7566 - acc: 0.6839 - val_loss: 1.0118 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8358 - acc: 0.7720 - val_loss: 1.2856 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0698 - acc: 0.8653 - val_loss: 1.4438 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6033 - acc: 0.8808 - val_loss: 0.5429 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5632 - acc: 0.8290 - val_loss: 0.9011 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5332 - acc: 0.8808 - val_loss: 0.8193 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3376 - acc: 0.8653 - val_loss: 0.7044 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2633 - acc: 0.9016 - val_loss: 1.2417 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2574 - acc: 0.9067 - val_loss: 1.0252 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6759 - acc: 0.6321 - val_loss: 1.5686 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9292 - acc: 0.7927 - val_loss: 1.1202 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8296 - acc: 0.7565 - val_loss: 1.0881 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7414 - acc: 0.8497 - val_loss: 1.4063 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5547 - acc: 0.8705 - val_loss: 1.7068 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.5118 - acc: 0.6062 - val_loss: 2.0342 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.5478 - acc: 0.6684 - val_loss: 0.7161 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7210 - acc: 0.8549 - val_loss: 1.1302 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8553 - acc: 0.8497 - val_loss: 1.3146 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5867 - acc: 0.8964 - val_loss: 1.2542 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4757 - acc: 0.8912 - val_loss: 1.5725 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8020 - acc: 0.7979 - val_loss: 0.8982 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7028 - acc: 0.7784 - val_loss: 1.6098 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2352 - acc: 0.7062 - val_loss: 1.5601 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.3726 - acc: 0.8660 - val_loss: 1.8992 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0919 - acc: 0.8711 - val_loss: 1.6437 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6888 - acc: 0.8763 - val_loss: 1.8566 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4972 - acc: 0.7990 - val_loss: 1.6008 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9179 - acc: 0.8608 - val_loss: 1.5030 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4963 - acc: 0.8660 - val_loss: 1.3011 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5009 - acc: 0.9175 - val_loss: 1.1207 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3243 - acc: 0.9175 - val_loss: 0.9552 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2485 - acc: 0.9072 - val_loss: 1.0373 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1617 - acc: 0.9278 - val_loss: 1.1339 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1419 - acc: 0.9485 - val_loss: 1.2903 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0975 - acc: 0.9639 - val_loss: 1.4169 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0786 - acc: 0.9742 - val_loss: 1.4180 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6545 - acc: 0.6856 - val_loss: 0.6052 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0207 - acc: 0.7990 - val_loss: 1.2403 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9468 - acc: 0.7887 - val_loss: 1.1660 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2755 - acc: 0.7371 - val_loss: 1.2396 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4740 - acc: 0.7526 - val_loss: 0.6665 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1974 - acc: 0.8660 - val_loss: 2.0672 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6674 - acc: 0.7268 - val_loss: 1.2243 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0596 - acc: 0.7732 - val_loss: 1.5218 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8064 - acc: 0.8866 - val_loss: 1.2692 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6112 - acc: 0.8814 - val_loss: 0.9599 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4301 - acc: 0.8144 - val_loss: 0.5814 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4539 - acc: 0.8402 - val_loss: 1.1615 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4119 - acc: 0.8763 - val_loss: 0.7202 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3424 - acc: 0.9278 - val_loss: 0.6507 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3318 - acc: 0.9072 - val_loss: 0.6924 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2582 - acc: 0.9072 - val_loss: 0.7703 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0396 - acc: 0.5803 - val_loss: 13.3359 - val_acc: 0.2623\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 5.0535 - acc: 0.5803 - val_loss: 2.8193 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.5104 - acc: 0.8549 - val_loss: 2.6607 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0926 - acc: 0.8705 - val_loss: 1.6109 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1927 - acc: 0.8653 - val_loss: 2.4407 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8089 - acc: 0.8756 - val_loss: 2.9524 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5527 - acc: 0.8964 - val_loss: 3.2506 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4195 - acc: 0.9119 - val_loss: 3.6034 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3182 - acc: 0.9067 - val_loss: 2.3692 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0104 - acc: 0.6218 - val_loss: 3.5654 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8599 - acc: 0.7047 - val_loss: 2.3244 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0066 - acc: 0.8342 - val_loss: 1.2575 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1538 - acc: 0.8601 - val_loss: 1.1628 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7953 - acc: 0.8756 - val_loss: 1.1820 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5893 - acc: 0.8601 - val_loss: 1.2088 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5313 - acc: 0.8860 - val_loss: 1.8956 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3516 - acc: 0.9119 - val_loss: 1.3818 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2929 - acc: 0.9275 - val_loss: 1.2704 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9349 - acc: 0.7216 - val_loss: 3.7028 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.3460 - acc: 0.7526 - val_loss: 1.6923 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6159 - acc: 0.8454 - val_loss: 2.9694 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6509 - acc: 0.7835 - val_loss: 0.9139 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7332 - acc: 0.8247 - val_loss: 1.9677 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8318 - acc: 0.8093 - val_loss: 1.3648 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0440 - acc: 0.8454 - val_loss: 2.1837 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9285 - acc: 0.8660 - val_loss: 2.9730 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0536 - acc: 0.8557 - val_loss: 2.7351 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0240 - acc: 0.7577 - val_loss: 9.6022 - val_acc: 0.2459\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.7347 - acc: 0.5206 - val_loss: 1.4330 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4694 - acc: 0.8557 - val_loss: 2.0002 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8525 - acc: 0.8351 - val_loss: 1.6429 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2352 - acc: 0.8144 - val_loss: 1.3124 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7729 - acc: 0.8299 - val_loss: 1.8131 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6295 - acc: 0.8969 - val_loss: 2.5434 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3713 - acc: 0.9227 - val_loss: 2.5478 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7537 - acc: 0.8918 - val_loss: 2.6666 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3697 - acc: 0.8763 - val_loss: 2.7065 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.7356 - acc: 0.5361 - val_loss: 1.0463 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0133 - acc: 0.8351 - val_loss: 1.1659 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.0995 - acc: 0.8093 - val_loss: 0.6943 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.3160 - acc: 0.8196 - val_loss: 0.7605 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0385 - acc: 0.7990 - val_loss: 0.9237 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8421 - acc: 0.8608 - val_loss: 1.6869 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.5745 - acc: 0.8454 - val_loss: 3.3331 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.7041 - acc: 0.8505 - val_loss: 3.1100 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2834 - acc: 0.6269 - val_loss: 4.4944 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.2310 - acc: 0.8601 - val_loss: 3.8868 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9812 - acc: 0.8601 - val_loss: 2.5603 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2931 - acc: 0.7979 - val_loss: 2.0932 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8940 - acc: 0.7979 - val_loss: 3.0690 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.7843 - acc: 0.7979 - val_loss: 3.4671 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.3749 - acc: 0.8549 - val_loss: 2.6855 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2272 - acc: 0.8912 - val_loss: 2.4435 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7401 - acc: 0.9378 - val_loss: 2.5770 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.9815 - acc: 0.6684 - val_loss: 18.4810 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.0529 - acc: 0.5803 - val_loss: 9.1516 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.8685 - acc: 0.8497 - val_loss: 7.5173 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.0269 - acc: 0.8083 - val_loss: 5.2156 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.0734 - acc: 0.8290 - val_loss: 8.2939 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.7052 - acc: 0.8912 - val_loss: 9.1764 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.1466 - acc: 0.8860 - val_loss: 8.3668 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.4888 - acc: 0.8497 - val_loss: 7.5462 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.1561 - acc: 0.9171 - val_loss: 9.0095 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.2719 - acc: 0.7320 - val_loss: 9.0720 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.1402 - acc: 0.6907 - val_loss: 8.1634 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.4713 - acc: 0.8351 - val_loss: 6.9963 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.9122 - acc: 0.8299 - val_loss: 8.1429 - val_acc: 0.8197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.1957 - acc: 0.8608 - val_loss: 13.5937 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.5555 - acc: 0.8505 - val_loss: 12.4657 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.8725 - acc: 0.8402 - val_loss: 8.1109 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7367 - acc: 0.8196 - val_loss: 4.6168 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.9313 - acc: 0.7938 - val_loss: 2.5915 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.1364 - acc: 0.8351 - val_loss: 5.1730 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.1872 - acc: 0.8505 - val_loss: 5.7736 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.6291 - acc: 0.8557 - val_loss: 6.0582 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.3603 - acc: 0.8247 - val_loss: 4.9400 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.0344 - acc: 0.8557 - val_loss: 5.1230 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.5419 - acc: 0.6649 - val_loss: 3.6589 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.2063 - acc: 0.8351 - val_loss: 4.7125 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.1815 - acc: 0.7938 - val_loss: 1.5851 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6144 - acc: 0.7423 - val_loss: 1.0957 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4430 - acc: 0.8608 - val_loss: 2.5279 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6403 - acc: 0.8505 - val_loss: 2.0705 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1049 - acc: 0.8505 - val_loss: 0.9653 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1088 - acc: 0.8557 - val_loss: 1.3803 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5985 - acc: 0.8763 - val_loss: 1.6703 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2306 - acc: 0.9485 - val_loss: 2.3786 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7014 - acc: 0.8969 - val_loss: 2.3240 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4264 - acc: 0.9381 - val_loss: 1.9815 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.1478 - acc: 0.6186 - val_loss: 2.0626 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.6534 - acc: 0.8041 - val_loss: 2.6699 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.9190 - acc: 0.8299 - val_loss: 2.1553 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.1625 - acc: 0.8711 - val_loss: 1.6981 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.0715 - acc: 0.8299 - val_loss: 4.0368 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.3249 - acc: 0.8351 - val_loss: 3.0483 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.5743 - acc: 0.8454 - val_loss: 2.8843 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1334 - acc: 0.8763 - val_loss: 2.8699 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9573 - acc: 0.8711 - val_loss: 3.3912 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5169 - acc: 0.7565 - val_loss: 0.5748 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3981 - acc: 0.8549 - val_loss: 0.4209 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3707 - acc: 0.8342 - val_loss: 0.3555 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3440 - acc: 0.8446 - val_loss: 0.3665 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4648 - acc: 0.8290 - val_loss: 0.4923 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4226 - acc: 0.8290 - val_loss: 0.5993 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3422 - acc: 0.8601 - val_loss: 0.5171 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3897 - acc: 0.8912 - val_loss: 0.5306 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6572 - acc: 0.6528 - val_loss: 0.3992 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4217 - acc: 0.8497 - val_loss: 0.3840 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3654 - acc: 0.8549 - val_loss: 0.4275 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4014 - acc: 0.8187 - val_loss: 0.4171 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3739 - acc: 0.8497 - val_loss: 0.3328 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4495 - acc: 0.8705 - val_loss: 0.6423 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6658 - acc: 0.8705 - val_loss: 0.9685 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6182 - acc: 0.8653 - val_loss: 0.8028 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4371 - acc: 0.8394 - val_loss: 0.9584 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3319 - acc: 0.8756 - val_loss: 0.8863 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6026 - acc: 0.6186 - val_loss: 0.4541 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4497 - acc: 0.8454 - val_loss: 0.4812 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3523 - acc: 0.8505 - val_loss: 0.4770 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6247 - acc: 0.7216 - val_loss: 0.4033 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3701 - acc: 0.8505 - val_loss: 0.4776 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5046 - acc: 0.8608 - val_loss: 0.6493 - val_acc: 0.9180\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4543 - acc: 0.8763 - val_loss: 0.8814 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4608 - acc: 0.8557 - val_loss: 1.3059 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5918 - acc: 0.8505 - val_loss: 1.0471 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5650 - acc: 0.7320 - val_loss: 0.4334 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4228 - acc: 0.7887 - val_loss: 0.7312 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6370 - acc: 0.6598 - val_loss: 0.5960 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5100 - acc: 0.7938 - val_loss: 0.6306 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4523 - acc: 0.8144 - val_loss: 0.6792 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3807 - acc: 0.8505 - val_loss: 0.6985 - val_acc: 0.8197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6272 - acc: 0.6598 - val_loss: 0.4851 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4471 - acc: 0.8299 - val_loss: 0.4169 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4128 - acc: 0.8557 - val_loss: 0.6276 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3718 - acc: 0.8557 - val_loss: 0.3415 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4711 - acc: 0.7784 - val_loss: 0.3551 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3736 - acc: 0.8454 - val_loss: 0.4023 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3813 - acc: 0.8351 - val_loss: 0.4796 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3872 - acc: 0.8351 - val_loss: 0.4547 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3718 - acc: 0.8351 - val_loss: 0.4631 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6403 - acc: 0.6580 - val_loss: 0.8206 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6785 - acc: 0.7824 - val_loss: 0.4655 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6415 - acc: 0.8238 - val_loss: 0.8240 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8542 - acc: 0.6425 - val_loss: 0.5958 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6184 - acc: 0.7927 - val_loss: 0.7501 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5140 - acc: 0.8238 - val_loss: 0.6110 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3904 - acc: 0.8756 - val_loss: 0.5134 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6425 - acc: 0.6684 - val_loss: 0.4431 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4827 - acc: 0.8135 - val_loss: 0.7146 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3910 - acc: 0.8601 - val_loss: 0.2663 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4035 - acc: 0.8497 - val_loss: 0.9059 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6377 - acc: 0.8808 - val_loss: 0.6840 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5187 - acc: 0.8601 - val_loss: 0.4399 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4528 - acc: 0.8135 - val_loss: 0.9060 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3872 - acc: 0.8549 - val_loss: 0.5044 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5400 - acc: 0.7887 - val_loss: 0.4202 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5041 - acc: 0.8351 - val_loss: 1.2732 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4989 - acc: 0.8660 - val_loss: 0.7774 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4298 - acc: 0.8608 - val_loss: 0.8472 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5645 - acc: 0.8144 - val_loss: 1.1051 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6465 - acc: 0.8351 - val_loss: 1.0070 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5654 - acc: 0.7320 - val_loss: 0.3831 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5583 - acc: 0.8041 - val_loss: 0.4821 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5289 - acc: 0.8144 - val_loss: 0.3889 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4544 - acc: 0.8299 - val_loss: 0.3997 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3775 - acc: 0.8608 - val_loss: 0.8490 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6847 - acc: 0.7371 - val_loss: 1.4070 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6255 - acc: 0.7165 - val_loss: 0.9158 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5468 - acc: 0.8144 - val_loss: 0.8252 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6391 - acc: 0.8196 - val_loss: 1.2956 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6059 - acc: 0.8144 - val_loss: 0.8657 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3828 - acc: 0.8505 - val_loss: 0.5351 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3602 - acc: 0.8505 - val_loss: 0.8042 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3396 - acc: 0.8814 - val_loss: 0.8037 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2832 - acc: 0.8711 - val_loss: 0.5710 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4222 - acc: 0.8041 - val_loss: 0.8087 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4139 - acc: 0.8608 - val_loss: 1.1935 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7541 - acc: 0.7047 - val_loss: 2.9471 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6004 - acc: 0.6218 - val_loss: 0.4697 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1827 - acc: 0.7565 - val_loss: 0.8112 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1713 - acc: 0.8549 - val_loss: 1.4962 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.3119 - acc: 0.8653 - val_loss: 1.8616 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1762 - acc: 0.8342 - val_loss: 1.6173 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9537 - acc: 0.8394 - val_loss: 1.3047 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8769 - acc: 0.6943 - val_loss: 0.9967 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7168 - acc: 0.7824 - val_loss: 0.7834 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6146 - acc: 0.8290 - val_loss: 0.5742 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5440 - acc: 0.8497 - val_loss: 0.6973 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4555 - acc: 0.8342 - val_loss: 0.3979 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3047 - acc: 0.9067 - val_loss: 0.4166 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2361 - acc: 0.9119 - val_loss: 0.6150 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1744 - acc: 0.9223 - val_loss: 0.7071 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1551 - acc: 0.9430 - val_loss: 0.8857 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2104 - acc: 0.9223 - val_loss: 1.1205 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7558 - acc: 0.6804 - val_loss: 3.0139 - val_acc: 0.5738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6600 - acc: 0.6804 - val_loss: 1.5539 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8339 - acc: 0.8247 - val_loss: 1.8099 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6955 - acc: 0.8505 - val_loss: 1.9440 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6005 - acc: 0.8814 - val_loss: 1.9366 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4867 - acc: 0.9124 - val_loss: 1.7571 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3162 - acc: 0.8918 - val_loss: 1.4386 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2788 - acc: 0.8969 - val_loss: 1.0959 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2687 - acc: 0.8969 - val_loss: 1.1416 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2393 - acc: 0.9227 - val_loss: 1.4380 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1710 - acc: 0.9433 - val_loss: 1.4078 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0925 - acc: 0.9742 - val_loss: 1.3793 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0817 - acc: 0.9742 - val_loss: 1.4166 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8578 - acc: 0.7113 - val_loss: 2.4045 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4493 - acc: 0.7010 - val_loss: 1.5029 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6541 - acc: 0.8454 - val_loss: 2.1185 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.3734 - acc: 0.8763 - val_loss: 2.2623 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9746 - acc: 0.8196 - val_loss: 1.5520 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9284 - acc: 0.8454 - val_loss: 1.8509 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9533 - acc: 0.8247 - val_loss: 2.3030 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8530 - acc: 0.7268 - val_loss: 1.2696 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2172 - acc: 0.7216 - val_loss: 1.1046 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9980 - acc: 0.8557 - val_loss: 1.1872 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7456 - acc: 0.8351 - val_loss: 0.9238 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6727 - acc: 0.8247 - val_loss: 0.8487 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6352 - acc: 0.8454 - val_loss: 0.6325 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2922 - acc: 0.9021 - val_loss: 0.9575 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3693 - acc: 0.8608 - val_loss: 0.8312 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2583 - acc: 0.9278 - val_loss: 1.0717 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2095 - acc: 0.9021 - val_loss: 0.9510 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1564 - acc: 0.9433 - val_loss: 0.9240 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0106 - acc: 0.5959 - val_loss: 2.3502 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6907 - acc: 0.7668 - val_loss: 1.9793 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8526 - acc: 0.8497 - val_loss: 1.9037 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0725 - acc: 0.8653 - val_loss: 0.9377 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7716 - acc: 0.8497 - val_loss: 0.9268 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8273 - acc: 0.8912 - val_loss: 2.0574 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9678 - acc: 0.8705 - val_loss: 1.4218 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8215 - acc: 0.8497 - val_loss: 2.2902 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9261 - acc: 0.8187 - val_loss: 2.0386 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.7954 - acc: 0.7979 - val_loss: 3.5080 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.5322 - acc: 0.6839 - val_loss: 2.4280 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.3757 - acc: 0.7772 - val_loss: 5.1881 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0483 - acc: 0.7202 - val_loss: 2.9162 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1869 - acc: 0.8031 - val_loss: 3.1158 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0340 - acc: 0.8031 - val_loss: 3.2391 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.3844 - acc: 0.7358 - val_loss: 1.9002 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0180 - acc: 0.8290 - val_loss: 1.6144 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8126 - acc: 0.8549 - val_loss: 1.8303 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4773 - acc: 0.8860 - val_loss: 2.1227 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2936 - acc: 0.8860 - val_loss: 2.3578 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1222 - acc: 0.9326 - val_loss: 2.6695 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0809 - acc: 0.9585 - val_loss: 2.5476 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1597 - acc: 0.5773 - val_loss: 1.2817 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2364 - acc: 0.8093 - val_loss: 2.0244 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8229 - acc: 0.8299 - val_loss: 1.1121 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9528 - acc: 0.8247 - val_loss: 0.8963 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.5525 - acc: 0.8093 - val_loss: 1.4227 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6076 - acc: 0.8351 - val_loss: 2.0488 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1557 - acc: 0.8402 - val_loss: 1.2589 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.3935 - acc: 0.7423 - val_loss: 1.6834 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0695 - acc: 0.8093 - val_loss: 2.3476 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9476 - acc: 0.6031 - val_loss: 3.5076 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.3001 - acc: 0.7216 - val_loss: 1.5221 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.1069 - acc: 0.8144 - val_loss: 1.1154 - val_acc: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.2769 - acc: 0.7680 - val_loss: 3.0799 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.2980 - acc: 0.8144 - val_loss: 2.8440 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.4534 - acc: 0.8660 - val_loss: 3.1732 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.4768 - acc: 0.8093 - val_loss: 3.6649 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9313 - acc: 0.7990 - val_loss: 2.8477 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3716 - acc: 0.6082 - val_loss: 1.4603 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1564 - acc: 0.8144 - val_loss: 6.6857 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.5648 - acc: 0.7062 - val_loss: 3.3143 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8726 - acc: 0.7165 - val_loss: 2.1713 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2071 - acc: 0.8454 - val_loss: 1.9237 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9883 - acc: 0.8299 - val_loss: 2.5009 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.4903 - acc: 0.7254 - val_loss: 3.2202 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.1367 - acc: 0.8290 - val_loss: 3.5271 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.4105 - acc: 0.7927 - val_loss: 3.9349 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.1568 - acc: 0.7047 - val_loss: 4.0945 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.9616 - acc: 0.8187 - val_loss: 3.6929 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4934 - acc: 0.8549 - val_loss: 3.9957 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.7556 - acc: 0.7772 - val_loss: 6.9346 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.2676 - acc: 0.6943 - val_loss: 4.0894 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.6824 - acc: 0.8549 - val_loss: 3.4461 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.8151 - acc: 0.8031 - val_loss: 4.7134 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.9533 - acc: 0.7876 - val_loss: 3.9350 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.8593 - acc: 0.7927 - val_loss: 4.4475 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.1403 - acc: 0.8653 - val_loss: 5.2012 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4248 - acc: 0.8808 - val_loss: 3.8122 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.6590 - acc: 0.6495 - val_loss: 1.6655 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.5210 - acc: 0.7990 - val_loss: 2.1713 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.5710 - acc: 0.8196 - val_loss: 1.8109 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.5334 - acc: 0.8557 - val_loss: 3.1006 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1012 - acc: 0.8505 - val_loss: 3.4122 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9876 - acc: 0.9021 - val_loss: 4.3031 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.6804 - acc: 0.6598 - val_loss: 7.0225 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4422 - acc: 0.6753 - val_loss: 3.1715 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.6652 - acc: 0.7732 - val_loss: 3.7772 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9297 - acc: 0.8402 - val_loss: 4.2969 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0891 - acc: 0.8351 - val_loss: 1.9257 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9767 - acc: 0.8299 - val_loss: 2.2413 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4473 - acc: 0.8866 - val_loss: 3.4504 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7689 - acc: 0.8557 - val_loss: 2.2187 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2947 - acc: 0.9072 - val_loss: 2.1662 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3732 - acc: 0.9124 - val_loss: 2.0882 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.1497 - acc: 0.6186 - val_loss: 5.7473 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.1213 - acc: 0.7990 - val_loss: 4.4188 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.2552 - acc: 0.8402 - val_loss: 3.3631 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8557 - acc: 0.7835 - val_loss: 3.9583 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.3483 - acc: 0.8299 - val_loss: 3.4719 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1882 - acc: 0.8763 - val_loss: 1.8115 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7081 - acc: 0.8866 - val_loss: 2.5035 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3690 - acc: 0.9021 - val_loss: 3.0880 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4868 - acc: 0.8299 - val_loss: 5.2499 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.2330 - acc: 0.8763 - val_loss: 11.1207 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8215 - acc: 0.8918 - val_loss: 14.4251 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 7.3774 - acc: 0.5285 - val_loss: 4.9791 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.1202 - acc: 0.7927 - val_loss: 9.0265 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.4509 - acc: 0.7565 - val_loss: 3.2903 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.7176 - acc: 0.8187 - val_loss: 3.4065 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.6926 - acc: 0.8342 - val_loss: 7.6558 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.3625 - acc: 0.8238 - val_loss: 4.5515 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7754 - acc: 0.8705 - val_loss: 5.4279 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.2888 - acc: 0.7720 - val_loss: 25.0256 - val_acc: 0.7213\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 15.1343 - acc: 0.3834 - val_loss: 4.0711 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.2504 - acc: 0.8083 - val_loss: 16.2954 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 13.2056 - acc: 0.7772 - val_loss: 17.8514 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 11.5301 - acc: 0.7979 - val_loss: 19.0525 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.8969 - acc: 0.8238 - val_loss: 20.3783 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.5927 - acc: 0.8705 - val_loss: 17.3701 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 5.2612 - acc: 0.5412 - val_loss: 6.5004 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 5.8170 - acc: 0.8299 - val_loss: 2.8594 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.1809 - acc: 0.8144 - val_loss: 5.7658 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.0654 - acc: 0.8505 - val_loss: 6.9673 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.3225 - acc: 0.8454 - val_loss: 8.3099 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.4098 - acc: 0.8918 - val_loss: 5.6261 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.3241 - acc: 0.8814 - val_loss: 5.4922 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.6661 - acc: 0.4794 - val_loss: 5.4282 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.8493 - acc: 0.8247 - val_loss: 5.9445 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9.3445 - acc: 0.7990 - val_loss: 6.5083 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.0262 - acc: 0.7784 - val_loss: 5.4267 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.9880 - acc: 0.7732 - val_loss: 7.5614 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.2257 - acc: 0.8093 - val_loss: 9.7194 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.4423 - acc: 0.8093 - val_loss: 5.4021 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.5007 - acc: 0.8608 - val_loss: 4.9002 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.6438 - acc: 0.8402 - val_loss: 3.9314 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.4354 - acc: 0.8557 - val_loss: 6.7063 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8134 - acc: 0.8660 - val_loss: 4.8728 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.3151 - acc: 0.9021 - val_loss: 5.6227 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.5046 - acc: 0.9072 - val_loss: 10.0091 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.7498 - acc: 0.8814 - val_loss: 11.1557 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.3487 - acc: 0.6237 - val_loss: 16.7444 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.8596 - acc: 0.7526 - val_loss: 13.3583 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 11.4881 - acc: 0.8247 - val_loss: 14.8688 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.8884 - acc: 0.8144 - val_loss: 8.7212 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.0174 - acc: 0.7938 - val_loss: 11.9300 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.2245 - acc: 0.6598 - val_loss: 12.0221 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8941 - acc: 0.8196 - val_loss: 8.8006 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.1851 - acc: 0.8608 - val_loss: 9.2024 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.2871 - acc: 0.8866 - val_loss: 8.0006 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.4224 - acc: 0.8763 - val_loss: 6.2600 - val_acc: 0.9180\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2756 - acc: 0.9072 - val_loss: 5.6350 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4787 - acc: 0.9485 - val_loss: 5.6804 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4263 - acc: 0.9381 - val_loss: 5.4856 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2312 - acc: 0.9639 - val_loss: 6.1061 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2607 - acc: 0.9588 - val_loss: 5.1422 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2762 - acc: 0.9691 - val_loss: 10.3787 - val_acc: 0.7705\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.4241 - acc: 0.8608 - val_loss: 25.5785 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.0721 - acc: 0.8608 - val_loss: 23.6466 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.1378 - acc: 0.8814 - val_loss: 20.2490 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.5058 - acc: 0.8608 - val_loss: 17.6052 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.2029 - acc: 0.5648 - val_loss: 12.0289 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 13.8254 - acc: 0.8497 - val_loss: 17.3665 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 8.2940 - acc: 0.8497 - val_loss: 3.3037 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.6667 - acc: 0.8238 - val_loss: 25.7854 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.6401 - acc: 0.7565 - val_loss: 7.4021 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 8.2506 - acc: 0.8187 - val_loss: 7.4408 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.0445 - acc: 0.8964 - val_loss: 9.9962 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.8052 - acc: 0.8912 - val_loss: 5.9968 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.6887 - acc: 0.5959 - val_loss: 36.3569 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 19.2554 - acc: 0.6684 - val_loss: 5.3045 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.6650 - acc: 0.8083 - val_loss: 5.3043 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.3331 - acc: 0.8394 - val_loss: 7.7036 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.5440 - acc: 0.8705 - val_loss: 7.3892 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8782 - acc: 0.8238 - val_loss: 10.3099 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.2146 - acc: 0.7720 - val_loss: 11.7039 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.6286 - acc: 0.8549 - val_loss: 9.1865 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 15.2823 - acc: 0.5000 - val_loss: 15.7471 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 13.0708 - acc: 0.8454 - val_loss: 18.0790 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 11.6611 - acc: 0.8196 - val_loss: 10.9160 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.1916 - acc: 0.8144 - val_loss: 16.9336 - val_acc: 0.6393\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 5.8049 - acc: 0.8093 - val_loss: 15.7758 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.0937 - acc: 0.8763 - val_loss: 14.5079 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.7314 - acc: 0.8814 - val_loss: 19.0059 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.4463 - acc: 0.8041 - val_loss: 28.6939 - val_acc: 0.7213\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.6561 - acc: 0.6237 - val_loss: 6.9384 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 12.9484 - acc: 0.7320 - val_loss: 2.7531 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.4271 - acc: 0.7474 - val_loss: 5.0353 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.2431 - acc: 0.7784 - val_loss: 3.8455 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.1716 - acc: 0.8660 - val_loss: 2.8137 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.1273 - acc: 0.8144 - val_loss: 3.8778 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.8320 - acc: 0.8144 - val_loss: 3.5071 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9.7064 - acc: 0.6340 - val_loss: 14.9021 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 18.2431 - acc: 0.8505 - val_loss: 17.8953 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 15.9908 - acc: 0.8299 - val_loss: 26.1957 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 18.4315 - acc: 0.6443 - val_loss: 12.7713 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.1974 - acc: 0.7732 - val_loss: 12.3997 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.5631 - acc: 0.8454 - val_loss: 12.2816 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.8517 - acc: 0.8144 - val_loss: 5.9961 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.2002 - acc: 0.7990 - val_loss: 10.9595 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.8093 - acc: 0.8454 - val_loss: 10.3827 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.5391 - acc: 0.8351 - val_loss: 11.8744 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.2635 - acc: 0.8711 - val_loss: 11.7883 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.4846 - acc: 0.8969 - val_loss: 13.1933 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6987 - acc: 0.6943 - val_loss: 0.3943 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4050 - acc: 0.8187 - val_loss: 1.2128 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7964 - acc: 0.7409 - val_loss: 0.4304 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8432 - acc: 0.8497 - val_loss: 0.5500 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7597 - acc: 0.8342 - val_loss: 0.5399 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5053 - acc: 0.8446 - val_loss: 0.5018 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9237 - acc: 0.6736 - val_loss: 1.1241 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7313 - acc: 0.7979 - val_loss: 0.9088 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6077 - acc: 0.6684 - val_loss: 0.4966 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5202 - acc: 0.7565 - val_loss: 0.5254 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4325 - acc: 0.8290 - val_loss: 0.7368 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3776 - acc: 0.8290 - val_loss: 0.8775 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3734 - acc: 0.8446 - val_loss: 0.8463 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3811 - acc: 0.7513 - val_loss: 0.8285 - val_acc: 0.6885\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6422 - acc: 0.7010 - val_loss: 0.5304 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6922 - acc: 0.7216 - val_loss: 0.9156 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7862 - acc: 0.7577 - val_loss: 0.9267 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5468 - acc: 0.7577 - val_loss: 0.7573 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5090 - acc: 0.8299 - val_loss: 0.9552 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4407 - acc: 0.8557 - val_loss: 0.7011 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6596 - acc: 0.7062 - val_loss: 0.5530 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4733 - acc: 0.7990 - val_loss: 0.4770 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4760 - acc: 0.7938 - val_loss: 0.6131 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6349 - acc: 0.7938 - val_loss: 1.2122 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6249 - acc: 0.7990 - val_loss: 1.2306 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4339 - acc: 0.8144 - val_loss: 0.8224 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3357 - acc: 0.8454 - val_loss: 0.8879 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7305 - acc: 0.6237 - val_loss: 0.3855 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4655 - acc: 0.8196 - val_loss: 1.8556 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9737 - acc: 0.6649 - val_loss: 0.6194 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6146 - acc: 0.8557 - val_loss: 0.8067 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7588 - acc: 0.8402 - val_loss: 0.7926 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5790 - acc: 0.8608 - val_loss: 0.6919 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8841 - acc: 0.6218 - val_loss: 0.6585 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2751 - acc: 0.8446 - val_loss: 1.4030 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4361 - acc: 0.8290 - val_loss: 1.2086 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9881 - acc: 0.8290 - val_loss: 1.3431 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7972 - acc: 0.8394 - val_loss: 0.9475 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4602 - acc: 0.8497 - val_loss: 0.6404 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5331 - acc: 0.8446 - val_loss: 1.4101 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8138 - acc: 0.8290 - val_loss: 1.0396 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6548 - acc: 0.8653 - val_loss: 0.8981 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5189 - acc: 0.8808 - val_loss: 0.8355 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3429 - acc: 0.9067 - val_loss: 0.8257 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9082 - acc: 0.6995 - val_loss: 1.6048 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0120 - acc: 0.7098 - val_loss: 1.2205 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2230 - acc: 0.8497 - val_loss: 1.6409 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8250 - acc: 0.7927 - val_loss: 1.5172 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4849 - acc: 0.8238 - val_loss: 1.2957 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3840 - acc: 0.8601 - val_loss: 1.0896 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5048 - acc: 0.8083 - val_loss: 1.3716 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5278 - acc: 0.8394 - val_loss: 1.5092 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4540 - acc: 0.8653 - val_loss: 1.3518 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3321 - acc: 0.8756 - val_loss: 1.2350 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2403 - acc: 0.8860 - val_loss: 1.5078 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7155 - acc: 0.6598 - val_loss: 0.8791 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0824 - acc: 0.8557 - val_loss: 0.6740 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8117 - acc: 0.7938 - val_loss: 0.4887 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8261 - acc: 0.8351 - val_loss: 1.0400 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6620 - acc: 0.8505 - val_loss: 1.2409 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5630 - acc: 0.8505 - val_loss: 0.9014 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4491 - acc: 0.8505 - val_loss: 0.8599 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6135 - acc: 0.7216 - val_loss: 0.7940 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6832 - acc: 0.6701 - val_loss: 0.3687 - val_acc: 0.9344\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7305 - acc: 0.7887 - val_loss: 1.2005 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8883 - acc: 0.8144 - val_loss: 0.8626 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6601 - acc: 0.8454 - val_loss: 0.6119 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5889 - acc: 0.7887 - val_loss: 0.9801 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5830 - acc: 0.8402 - val_loss: 0.7710 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7124 - acc: 0.7062 - val_loss: 2.2298 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1643 - acc: 0.7835 - val_loss: 1.3186 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9091 - acc: 0.8299 - val_loss: 1.2857 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5225 - acc: 0.8196 - val_loss: 0.5538 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4757 - acc: 0.8660 - val_loss: 0.6422 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3489 - acc: 0.8866 - val_loss: 0.8659 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4149 - acc: 0.8402 - val_loss: 0.9360 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3681 - acc: 0.8505 - val_loss: 0.9102 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7752 - acc: 0.8351 - val_loss: 0.7063 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.2098 - acc: 0.6943 - val_loss: 1.7867 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9480 - acc: 0.7617 - val_loss: 0.8762 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0620 - acc: 0.8653 - val_loss: 0.3896 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7861 - acc: 0.8394 - val_loss: 0.9882 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4248 - acc: 0.8756 - val_loss: 0.5115 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7542 - acc: 0.8290 - val_loss: 1.6069 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1106 - acc: 0.8653 - val_loss: 1.8568 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7198 - acc: 0.8964 - val_loss: 1.4091 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.2086 - acc: 0.5751 - val_loss: 3.6164 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.7411 - acc: 0.7617 - val_loss: 1.6606 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4398 - acc: 0.8290 - val_loss: 0.7227 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6752 - acc: 0.8083 - val_loss: 0.7847 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6356 - acc: 0.8653 - val_loss: 0.7030 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4822 - acc: 0.8342 - val_loss: 0.6214 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4492 - acc: 0.8290 - val_loss: 1.5035 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5313 - acc: 0.8446 - val_loss: 1.5811 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6392 - acc: 0.8860 - val_loss: 1.5326 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5551 - acc: 0.8860 - val_loss: 1.9292 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5165 - acc: 0.8705 - val_loss: 1.9601 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.2071 - acc: 0.6082 - val_loss: 8.5936 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.1933 - acc: 0.4897 - val_loss: 2.1489 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1683 - acc: 0.8402 - val_loss: 1.0369 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6299 - acc: 0.8093 - val_loss: 2.6160 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4171 - acc: 0.8660 - val_loss: 2.0781 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8744 - acc: 0.8918 - val_loss: 1.5368 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7916 - acc: 0.8557 - val_loss: 3.6213 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1631 - acc: 0.8402 - val_loss: 3.2130 - val_acc: 0.8197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0412 - acc: 0.6649 - val_loss: 1.5192 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.7563 - acc: 0.8351 - val_loss: 1.6257 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9898 - acc: 0.8351 - val_loss: 0.8342 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6741 - acc: 0.7423 - val_loss: 0.4823 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5796 - acc: 0.8247 - val_loss: 1.8769 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8488 - acc: 0.8041 - val_loss: 1.2554 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8285 - acc: 0.8660 - val_loss: 1.4839 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3789 - acc: 0.9021 - val_loss: 1.6674 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3542 - acc: 0.8918 - val_loss: 1.1504 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1785 - acc: 0.6186 - val_loss: 6.6403 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.1614 - acc: 0.7320 - val_loss: 2.8069 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.2584 - acc: 0.7732 - val_loss: 3.3069 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4270 - acc: 0.8247 - val_loss: 2.8742 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7192 - acc: 0.8557 - val_loss: 2.0542 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6740 - acc: 0.8402 - val_loss: 1.4900 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5115 - acc: 0.8299 - val_loss: 1.5123 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3257 - acc: 0.8402 - val_loss: 1.6157 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2591 - acc: 0.8814 - val_loss: 1.5688 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2643 - acc: 0.8969 - val_loss: 1.8249 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2190 - acc: 0.8918 - val_loss: 1.2473 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2048 - acc: 0.8969 - val_loss: 1.1001 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1997 - acc: 0.9227 - val_loss: 1.3291 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1624 - acc: 0.8918 - val_loss: 1.4788 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1319 - acc: 0.9536 - val_loss: 1.9556 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1212 - acc: 0.9485 - val_loss: 2.1891 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1085 - acc: 0.9536 - val_loss: 2.1688 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.8984 - acc: 0.5751 - val_loss: 2.7138 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3573 - acc: 0.8187 - val_loss: 1.1049 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.1363 - acc: 0.8031 - val_loss: 2.0008 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8280 - acc: 0.8187 - val_loss: 2.0518 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.5932 - acc: 0.7979 - val_loss: 3.5369 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6206 - acc: 0.8031 - val_loss: 1.8105 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7924 - acc: 0.9016 - val_loss: 1.3197 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.9199 - acc: 0.5285 - val_loss: 4.4547 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.8519 - acc: 0.8187 - val_loss: 3.5727 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.7853 - acc: 0.8083 - val_loss: 7.7893 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.3172 - acc: 0.6321 - val_loss: 2.1366 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.0512 - acc: 0.7979 - val_loss: 3.7338 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.0042 - acc: 0.8290 - val_loss: 3.1063 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.1929 - acc: 0.7098 - val_loss: 4.2115 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.6963 - acc: 0.7358 - val_loss: 2.4625 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8747 - acc: 0.8238 - val_loss: 2.6175 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.8944 - acc: 0.7268 - val_loss: 12.3795 - val_acc: 0.2787\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.2241 - acc: 0.5361 - val_loss: 4.5198 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.0997 - acc: 0.8093 - val_loss: 6.0137 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.4891 - acc: 0.8144 - val_loss: 4.8909 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0433 - acc: 0.8351 - val_loss: 3.7813 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.3398 - acc: 0.8351 - val_loss: 4.1957 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4315 - acc: 0.8866 - val_loss: 2.7763 - val_acc: 0.9180\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1940 - acc: 0.8814 - val_loss: 4.4280 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.2587 - acc: 0.6649 - val_loss: 2.8820 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9084 - acc: 0.7990 - val_loss: 3.8116 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4147 - acc: 0.8866 - val_loss: 5.5289 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9577 - acc: 0.8814 - val_loss: 7.2438 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2762 - acc: 0.5876 - val_loss: 5.7227 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.3828 - acc: 0.8144 - val_loss: 3.4098 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0812 - acc: 0.8144 - val_loss: 4.6170 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.2308 - acc: 0.6701 - val_loss: 5.4596 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.6842 - acc: 0.7629 - val_loss: 2.9935 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9035 - acc: 0.8299 - val_loss: 2.1903 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4070 - acc: 0.8299 - val_loss: 2.3685 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.7718 - acc: 0.8196 - val_loss: 1.9684 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9065 - acc: 0.8608 - val_loss: 6.1646 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.9386 - acc: 0.8454 - val_loss: 6.9163 - val_acc: 0.8197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0831 - acc: 0.8866 - val_loss: 5.5372 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6866 - acc: 0.8711 - val_loss: 6.0041 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.9277 - acc: 0.8454 - val_loss: 5.3690 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.8031 - acc: 0.6186 - val_loss: 4.2787 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.7622 - acc: 0.8196 - val_loss: 7.3066 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.7831 - acc: 0.7938 - val_loss: 3.1378 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.1088 - acc: 0.8196 - val_loss: 2.4904 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.4353 - acc: 0.8196 - val_loss: 2.7374 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.2933 - acc: 0.8196 - val_loss: 1.4395 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.4398 - acc: 0.7216 - val_loss: 1.2021 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.8468 - acc: 0.8505 - val_loss: 3.3636 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.0561 - acc: 0.8299 - val_loss: 2.1812 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.3890 - acc: 0.7784 - val_loss: 4.3734 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.5872 - acc: 0.8711 - val_loss: 2.8723 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.3737 - acc: 0.8969 - val_loss: 6.4893 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 11.5525 - acc: 0.4663 - val_loss: 6.1825 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.4405 - acc: 0.8394 - val_loss: 10.0341 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.4791 - acc: 0.8705 - val_loss: 8.6135 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.9695 - acc: 0.7876 - val_loss: 11.3506 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0228 - acc: 0.8860 - val_loss: 12.9049 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.4124 - acc: 0.8860 - val_loss: 12.3934 - val_acc: 0.6721\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.2967 - acc: 0.6321 - val_loss: 27.9681 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 12.6623 - acc: 0.5803 - val_loss: 3.2206 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.3245 - acc: 0.8031 - val_loss: 5.5090 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.2759 - acc: 0.8290 - val_loss: 14.8120 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.1330 - acc: 0.8290 - val_loss: 15.0386 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.2029 - acc: 0.8342 - val_loss: 10.2855 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.6424 - acc: 0.8394 - val_loss: 7.4718 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 8.5982 - acc: 0.5361 - val_loss: 8.0069 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.2539 - acc: 0.8557 - val_loss: 12.2249 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.4969 - acc: 0.8505 - val_loss: 8.8457 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.9927 - acc: 0.8608 - val_loss: 6.5319 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6501 - acc: 0.8711 - val_loss: 6.2570 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6693 - acc: 0.8608 - val_loss: 7.8087 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6902 - acc: 0.9124 - val_loss: 6.4504 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6954 - acc: 0.9175 - val_loss: 9.0457 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.2908 - acc: 0.8299 - val_loss: 11.3844 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.0723 - acc: 0.8969 - val_loss: 5.4225 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.1186 - acc: 0.8814 - val_loss: 5.9759 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6587 - acc: 0.8918 - val_loss: 9.0852 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4514 - acc: 0.9175 - val_loss: 13.1618 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.3806 - acc: 0.9227 - val_loss: 14.0484 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0586 - acc: 0.9330 - val_loss: 13.2582 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.8670 - acc: 0.6546 - val_loss: 33.0566 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 17.7440 - acc: 0.5773 - val_loss: 4.4370 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7.9526 - acc: 0.7938 - val_loss: 3.7746 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.6636 - acc: 0.8144 - val_loss: 6.6572 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.4121 - acc: 0.8763 - val_loss: 8.1613 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.3313 - acc: 0.8402 - val_loss: 11.3646 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.3942 - acc: 0.8402 - val_loss: 13.3232 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.7843 - acc: 0.8454 - val_loss: 17.9032 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 7.6081 - acc: 0.5052 - val_loss: 3.8492 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.8960 - acc: 0.8454 - val_loss: 2.8681 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.6445 - acc: 0.7165 - val_loss: 5.8611 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5.9355 - acc: 0.8351 - val_loss: 12.0093 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.0239 - acc: 0.8557 - val_loss: 10.1807 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.7912 - acc: 0.8866 - val_loss: 7.4111 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.3447 - acc: 0.8814 - val_loss: 7.3611 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 10.7710 - acc: 0.6684 - val_loss: 20.1327 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 21.2980 - acc: 0.8394 - val_loss: 5.6004 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 14.2548 - acc: 0.7202 - val_loss: 6.0231 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 7.1746 - acc: 0.8808 - val_loss: 8.7280 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.4686 - acc: 0.8756 - val_loss: 9.0483 - val_acc: 0.8361\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 4.1687 - acc: 0.8031 - val_loss: 7.7734 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.4859 - acc: 0.8808 - val_loss: 6.8431 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 8.7256 - acc: 0.6166 - val_loss: 23.1645 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 17.5330 - acc: 0.7668 - val_loss: 6.7384 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 16.3521 - acc: 0.8135 - val_loss: 7.3596 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.8593 - acc: 0.8083 - val_loss: 7.5421 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6.7522 - acc: 0.8601 - val_loss: 8.7932 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.9410 - acc: 0.8653 - val_loss: 21.0575 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9.6194 - acc: 0.8135 - val_loss: 9.2149 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.3303 - acc: 0.6392 - val_loss: 56.0368 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 21.5316 - acc: 0.7165 - val_loss: 12.9211 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 20.8220 - acc: 0.8402 - val_loss: 13.8144 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 13.5699 - acc: 0.8918 - val_loss: 9.5024 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.8571 - acc: 0.8711 - val_loss: 11.1977 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 7.3050 - acc: 0.8299 - val_loss: 9.1381 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 4.1141 - acc: 0.8969 - val_loss: 12.8781 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 7.3877 - acc: 0.8608 - val_loss: 10.4379 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 6.4962 - acc: 0.8454 - val_loss: 8.9022 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.2625 - acc: 0.9072 - val_loss: 10.6564 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.2404 - acc: 0.9175 - val_loss: 8.4231 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.0065 - acc: 0.8918 - val_loss: 16.5603 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 19.9821 - acc: 0.7474 - val_loss: 53.5096 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 28.1567 - acc: 0.8299 - val_loss: 52.0677 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 18.9462 - acc: 0.8866 - val_loss: 50.4188 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 15.4751 - acc: 0.8454 - val_loss: 55.7991 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 20.8252 - acc: 0.5412 - val_loss: 14.3954 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 16.5793 - acc: 0.8093 - val_loss: 10.8982 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.3598 - acc: 0.8144 - val_loss: 23.4837 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 11.6154 - acc: 0.7010 - val_loss: 15.5919 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.0287 - acc: 0.8505 - val_loss: 21.4294 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.0571 - acc: 0.8660 - val_loss: 19.6007 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3.8627 - acc: 0.8866 - val_loss: 13.8237 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 12.8372 - acc: 0.5928 - val_loss: 105.8683 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 43.8261 - acc: 0.6804 - val_loss: 21.2553 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 19.9994 - acc: 0.8402 - val_loss: 25.7937 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 13.4579 - acc: 0.7732 - val_loss: 17.8486 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 11.9622 - acc: 0.8093 - val_loss: 12.8597 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 11.6509 - acc: 0.7887 - val_loss: 20.2151 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.8160 - acc: 0.8454 - val_loss: 34.7152 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 16.6556 - acc: 0.8247 - val_loss: 32.8886 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 17.4753 - acc: 0.8557 - val_loss: 31.0892 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.9199 - acc: 0.8608 - val_loss: 34.5291 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 24.8640 - acc: 0.4870 - val_loss: 28.3800 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 36.0367 - acc: 0.8083 - val_loss: 18.4606 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 36.5627 - acc: 0.8187 - val_loss: 50.1708 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 40.6984 - acc: 0.8083 - val_loss: 95.5476 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 43.5416 - acc: 0.8653 - val_loss: 112.1896 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 47.0958 - acc: 0.8756 - val_loss: 98.3814 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 30.7625 - acc: 0.8756 - val_loss: 79.6779 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 36.2462 - acc: 0.5337 - val_loss: 24.6474 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 25.5183 - acc: 0.8238 - val_loss: 42.6784 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 25.9609 - acc: 0.8342 - val_loss: 46.1802 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 19.6134 - acc: 0.7720 - val_loss: 38.4684 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 12.8044 - acc: 0.8756 - val_loss: 41.2424 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 10.8550 - acc: 0.8653 - val_loss: 28.6231 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.6755 - acc: 0.7732 - val_loss: 87.5276 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 49.1636 - acc: 0.6495 - val_loss: 45.8324 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 50.2104 - acc: 0.8041 - val_loss: 42.9021 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 36.2430 - acc: 0.8608 - val_loss: 24.9225 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 17.9597 - acc: 0.7990 - val_loss: 20.8925 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 20.3149 - acc: 0.7784 - val_loss: 38.4456 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 15.4929 - acc: 0.8351 - val_loss: 23.2003 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 16.6041 - acc: 0.8402 - val_loss: 24.4567 - val_acc: 0.8689\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 14.2181 - acc: 0.8763 - val_loss: 22.3582 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8.6864 - acc: 0.8711 - val_loss: 24.9323 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 25.3679 - acc: 0.4433 - val_loss: 25.3363 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 27.6815 - acc: 0.7835 - val_loss: 27.3292 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 31.2322 - acc: 0.7577 - val_loss: 48.0747 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 30.4254 - acc: 0.7423 - val_loss: 96.9348 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 122.6580 - acc: 0.6237 - val_loss: 66.9080 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 33.0415 - acc: 0.7990 - val_loss: 50.5326 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 15.0247 - acc: 0.6392 - val_loss: 28.2596 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 21.6503 - acc: 0.8247 - val_loss: 51.2173 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 26.9587 - acc: 0.7423 - val_loss: 28.1568 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 33.8051 - acc: 0.7165 - val_loss: 31.3738 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 15.2792 - acc: 0.8196 - val_loss: 41.7100 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 17.5416 - acc: 0.8402 - val_loss: 47.9986 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 35.2472 - acc: 0.8093 - val_loss: 55.7007 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 31.2873 - acc: 0.8247 - val_loss: 64.7019 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6440 - acc: 0.7150 - val_loss: 0.5104 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6440 - acc: 0.7150 - val_loss: 0.5104 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6440 - acc: 0.7150 - val_loss: 0.5104 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6440 - acc: 0.7150 - val_loss: 0.5104 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6440 - acc: 0.7150 - val_loss: 0.5104 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6440 - acc: 0.7150 - val_loss: 0.5104 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6440 - acc: 0.7150 - val_loss: 0.5104 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6440 - acc: 0.7150 - val_loss: 0.5104 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6440 - acc: 0.7150 - val_loss: 0.5104 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6440 - acc: 0.7150 - val_loss: 0.5104 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6439 - acc: 0.7150 - val_loss: 0.5103 - val_acc: 0.7541\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6439 - acc: 0.7150 - val_loss: 0.5103 - val_acc: 0.7541\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6439 - acc: 0.7150 - val_loss: 0.5103 - val_acc: 0.7541\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6439 - acc: 0.7150 - val_loss: 0.5103 - val_acc: 0.7541\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6439 - acc: 0.7150 - val_loss: 0.5103 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6439 - acc: 0.7150 - val_loss: 0.5103 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6439 - acc: 0.7150 - val_loss: 0.5103 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6439 - acc: 0.7150 - val_loss: 0.5103 - val_acc: 0.7541\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6439 - acc: 0.7150 - val_loss: 0.5103 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6439 - acc: 0.7150 - val_loss: 0.5103 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6220 - acc: 0.6632 - val_loss: 0.5991 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6220 - acc: 0.6632 - val_loss: 0.5991 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6220 - acc: 0.6632 - val_loss: 0.5991 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6220 - acc: 0.6632 - val_loss: 0.5991 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6219 - acc: 0.6632 - val_loss: 0.5991 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6219 - acc: 0.6632 - val_loss: 0.5991 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6219 - acc: 0.6632 - val_loss: 0.5991 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6219 - acc: 0.6632 - val_loss: 0.5991 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6219 - acc: 0.6632 - val_loss: 0.5991 - val_acc: 0.7049\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6219 - acc: 0.6632 - val_loss: 0.5991 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6219 - acc: 0.6632 - val_loss: 0.5991 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6219 - acc: 0.6632 - val_loss: 0.5991 - val_acc: 0.7049\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6219 - acc: 0.6632 - val_loss: 0.5991 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6219 - acc: 0.6632 - val_loss: 0.5991 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6219 - acc: 0.6632 - val_loss: 0.5990 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6219 - acc: 0.6632 - val_loss: 0.5990 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6208 - acc: 0.648 - 0s 5ms/step - loss: 0.6219 - acc: 0.6632 - val_loss: 0.5990 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6219 - acc: 0.6632 - val_loss: 0.5990 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6219 - acc: 0.6632 - val_loss: 0.5990 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6218 - acc: 0.6632 - val_loss: 0.5990 - val_acc: 0.7049\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.8452 - acc: 0.4021 - val_loss: 0.8075 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8452 - acc: 0.4021 - val_loss: 0.8075 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8452 - acc: 0.4021 - val_loss: 0.8075 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8452 - acc: 0.4021 - val_loss: 0.8075 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8451 - acc: 0.4021 - val_loss: 0.8075 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8451 - acc: 0.4021 - val_loss: 0.8075 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8451 - acc: 0.4021 - val_loss: 0.8075 - val_acc: 0.4590\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8451 - acc: 0.4021 - val_loss: 0.8075 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8451 - acc: 0.4021 - val_loss: 0.8075 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8451 - acc: 0.4021 - val_loss: 0.8074 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8451 - acc: 0.4021 - val_loss: 0.8074 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8451 - acc: 0.4021 - val_loss: 0.8074 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8451 - acc: 0.4021 - val_loss: 0.8074 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8451 - acc: 0.4021 - val_loss: 0.8074 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8450 - acc: 0.4021 - val_loss: 0.8074 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8450 - acc: 0.4021 - val_loss: 0.8074 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8450 - acc: 0.4021 - val_loss: 0.8074 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8450 - acc: 0.4021 - val_loss: 0.8074 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8450 - acc: 0.4021 - val_loss: 0.8073 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8450 - acc: 0.4021 - val_loss: 0.8073 - val_acc: 0.4590\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7772 - acc: 0.4845 - val_loss: 0.7332 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7772 - acc: 0.4845 - val_loss: 0.7332 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7772 - acc: 0.4845 - val_loss: 0.7332 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7772 - acc: 0.4845 - val_loss: 0.7331 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7772 - acc: 0.4845 - val_loss: 0.7331 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7772 - acc: 0.4845 - val_loss: 0.7331 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7772 - acc: 0.4845 - val_loss: 0.7331 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7772 - acc: 0.4845 - val_loss: 0.7331 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7771 - acc: 0.4845 - val_loss: 0.7331 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7771 - acc: 0.4845 - val_loss: 0.7331 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7771 - acc: 0.4845 - val_loss: 0.7331 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7771 - acc: 0.4845 - val_loss: 0.7331 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7771 - acc: 0.4845 - val_loss: 0.7331 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7771 - acc: 0.4845 - val_loss: 0.7331 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7771 - acc: 0.4845 - val_loss: 0.7330 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7771 - acc: 0.4845 - val_loss: 0.7330 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7771 - acc: 0.4845 - val_loss: 0.7330 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7771 - acc: 0.4845 - val_loss: 0.7330 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7770 - acc: 0.4845 - val_loss: 0.7330 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7770 - acc: 0.4845 - val_loss: 0.7330 - val_acc: 0.5246\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410631a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.2305 - acc: 0.4227 - val_loss: 1.2282 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2304 - acc: 0.4175 - val_loss: 1.2282 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2304 - acc: 0.4175 - val_loss: 1.2281 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2304 - acc: 0.4175 - val_loss: 1.2281 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2304 - acc: 0.4175 - val_loss: 1.2281 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2304 - acc: 0.4175 - val_loss: 1.2281 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2303 - acc: 0.4175 - val_loss: 1.2281 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2303 - acc: 0.4175 - val_loss: 1.2280 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2303 - acc: 0.4175 - val_loss: 1.2280 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2303 - acc: 0.4175 - val_loss: 1.2280 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2303 - acc: 0.4175 - val_loss: 1.2280 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2302 - acc: 0.4175 - val_loss: 1.2280 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2302 - acc: 0.4175 - val_loss: 1.2279 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2302 - acc: 0.4175 - val_loss: 1.2279 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2302 - acc: 0.4175 - val_loss: 1.2279 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2302 - acc: 0.4175 - val_loss: 1.2279 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2301 - acc: 0.4175 - val_loss: 1.2279 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2301 - acc: 0.4175 - val_loss: 1.2278 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2301 - acc: 0.4175 - val_loss: 1.2278 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2301 - acc: 0.4175 - val_loss: 1.2278 - val_acc: 0.4262\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4104de0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.8996 - acc: 0.4352 - val_loss: 0.9898 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8996 - acc: 0.4352 - val_loss: 0.9898 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8996 - acc: 0.4352 - val_loss: 0.9898 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8996 - acc: 0.4352 - val_loss: 0.9897 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8995 - acc: 0.4352 - val_loss: 0.9897 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8995 - acc: 0.4352 - val_loss: 0.9897 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8995 - acc: 0.4352 - val_loss: 0.9896 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8995 - acc: 0.4352 - val_loss: 0.9896 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8995 - acc: 0.4352 - val_loss: 0.9896 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8994 - acc: 0.4352 - val_loss: 0.9895 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8994 - acc: 0.4352 - val_loss: 0.9895 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8994 - acc: 0.4352 - val_loss: 0.9895 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8994 - acc: 0.4352 - val_loss: 0.9895 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8994 - acc: 0.4352 - val_loss: 0.9894 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8993 - acc: 0.4352 - val_loss: 0.9894 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8993 - acc: 0.4352 - val_loss: 0.9894 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8993 - acc: 0.4352 - val_loss: 0.9893 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8993 - acc: 0.4352 - val_loss: 0.9893 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8992 - acc: 0.4352 - val_loss: 0.9893 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8992 - acc: 0.4352 - val_loss: 0.9892 - val_acc: 0.4262\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4104ac0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.8194 - acc: 0.5026 - val_loss: 0.8572 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8194 - acc: 0.5026 - val_loss: 0.8572 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8194 - acc: 0.5026 - val_loss: 0.8571 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8194 - acc: 0.5026 - val_loss: 0.8571 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8193 - acc: 0.5026 - val_loss: 0.8571 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8193 - acc: 0.5026 - val_loss: 0.8571 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8193 - acc: 0.5026 - val_loss: 0.8571 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8193 - acc: 0.5026 - val_loss: 0.8570 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8192 - acc: 0.5026 - val_loss: 0.8570 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8192 - acc: 0.5026 - val_loss: 0.8570 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8192 - acc: 0.5026 - val_loss: 0.8570 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8192 - acc: 0.5026 - val_loss: 0.8570 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8192 - acc: 0.5026 - val_loss: 0.8569 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8191 - acc: 0.5026 - val_loss: 0.8569 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8191 - acc: 0.5026 - val_loss: 0.8569 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8191 - acc: 0.5026 - val_loss: 0.8569 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8191 - acc: 0.5026 - val_loss: 0.8569 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8191 - acc: 0.5026 - val_loss: 0.8568 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8190 - acc: 0.5026 - val_loss: 0.8568 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8190 - acc: 0.5026 - val_loss: 0.8568 - val_acc: 0.5246\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b864f8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8868 - acc: 0.4588 - val_loss: 0.9806 - val_acc: 0.3279\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8868 - acc: 0.4588 - val_loss: 0.9806 - val_acc: 0.3279\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8868 - acc: 0.4588 - val_loss: 0.9805 - val_acc: 0.3279\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8868 - acc: 0.4588 - val_loss: 0.9805 - val_acc: 0.3279\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8867 - acc: 0.4588 - val_loss: 0.9805 - val_acc: 0.3279\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8867 - acc: 0.4588 - val_loss: 0.9805 - val_acc: 0.3279\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8867 - acc: 0.4588 - val_loss: 0.9805 - val_acc: 0.3279\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8867 - acc: 0.4588 - val_loss: 0.9804 - val_acc: 0.3279\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8866 - acc: 0.4588 - val_loss: 0.9804 - val_acc: 0.3279\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8866 - acc: 0.4588 - val_loss: 0.9804 - val_acc: 0.3279\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8866 - acc: 0.4588 - val_loss: 0.9804 - val_acc: 0.3279\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8866 - acc: 0.4588 - val_loss: 0.9803 - val_acc: 0.3279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8866 - acc: 0.4588 - val_loss: 0.9803 - val_acc: 0.3279\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8865 - acc: 0.4588 - val_loss: 0.9803 - val_acc: 0.3279\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8865 - acc: 0.4588 - val_loss: 0.9803 - val_acc: 0.3279\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8865 - acc: 0.4588 - val_loss: 0.9803 - val_acc: 0.3279\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8865 - acc: 0.4588 - val_loss: 0.9802 - val_acc: 0.3279\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8865 - acc: 0.4588 - val_loss: 0.9802 - val_acc: 0.3279\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8864 - acc: 0.4588 - val_loss: 0.9802 - val_acc: 0.3279\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8864 - acc: 0.4588 - val_loss: 0.9802 - val_acc: 0.3279\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4747048b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6747 - acc: 0.6186 - val_loss: 0.7333 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6747 - acc: 0.6186 - val_loss: 0.7332 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6746 - acc: 0.6186 - val_loss: 0.7332 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6746 - acc: 0.6186 - val_loss: 0.7332 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6746 - acc: 0.6186 - val_loss: 0.7332 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6746 - acc: 0.6186 - val_loss: 0.7332 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6746 - acc: 0.6186 - val_loss: 0.7332 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6746 - acc: 0.6186 - val_loss: 0.7331 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6745 - acc: 0.6186 - val_loss: 0.7331 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6745 - acc: 0.6186 - val_loss: 0.7331 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6745 - acc: 0.6186 - val_loss: 0.7331 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6745 - acc: 0.6186 - val_loss: 0.7331 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6745 - acc: 0.6186 - val_loss: 0.7330 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6745 - acc: 0.6186 - val_loss: 0.7330 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6745 - acc: 0.6186 - val_loss: 0.7330 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6744 - acc: 0.6186 - val_loss: 0.7330 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6744 - acc: 0.6186 - val_loss: 0.7330 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6744 - acc: 0.6186 - val_loss: 0.7330 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6744 - acc: 0.6186 - val_loss: 0.7329 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6744 - acc: 0.6186 - val_loss: 0.7329 - val_acc: 0.5574\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4102cb0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6774 - acc: 0.6340 - val_loss: 0.7588 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6774 - acc: 0.6340 - val_loss: 0.7587 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6774 - acc: 0.6340 - val_loss: 0.7587 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6774 - acc: 0.6340 - val_loss: 0.7587 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6774 - acc: 0.6340 - val_loss: 0.7587 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6773 - acc: 0.6340 - val_loss: 0.7587 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6773 - acc: 0.6340 - val_loss: 0.7587 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6773 - acc: 0.6340 - val_loss: 0.7586 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6773 - acc: 0.6340 - val_loss: 0.7586 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6773 - acc: 0.6340 - val_loss: 0.7586 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6773 - acc: 0.6340 - val_loss: 0.7586 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6773 - acc: 0.6340 - val_loss: 0.7586 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6772 - acc: 0.6340 - val_loss: 0.7585 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6772 - acc: 0.6340 - val_loss: 0.7585 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6772 - acc: 0.6340 - val_loss: 0.7585 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6772 - acc: 0.6340 - val_loss: 0.7585 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6772 - acc: 0.6340 - val_loss: 0.7585 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6772 - acc: 0.6340 - val_loss: 0.7585 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6772 - acc: 0.6340 - val_loss: 0.7584 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6771 - acc: 0.6340 - val_loss: 0.7584 - val_acc: 0.5738\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410631430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7103 - acc: 0.5751 - val_loss: 0.7951 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7102 - acc: 0.5751 - val_loss: 0.7951 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7102 - acc: 0.5751 - val_loss: 0.7951 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7102 - acc: 0.5751 - val_loss: 0.7951 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7102 - acc: 0.5751 - val_loss: 0.7950 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7101 - acc: 0.5751 - val_loss: 0.7950 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7101 - acc: 0.5751 - val_loss: 0.7950 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7101 - acc: 0.5751 - val_loss: 0.7949 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7101 - acc: 0.5751 - val_loss: 0.7949 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7100 - acc: 0.5751 - val_loss: 0.7949 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7100 - acc: 0.5751 - val_loss: 0.7949 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7100 - acc: 0.5751 - val_loss: 0.7948 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7100 - acc: 0.5751 - val_loss: 0.7948 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7099 - acc: 0.5751 - val_loss: 0.7948 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7099 - acc: 0.5751 - val_loss: 0.7947 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7099 - acc: 0.5751 - val_loss: 0.7947 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7099 - acc: 0.5751 - val_loss: 0.7947 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7098 - acc: 0.5751 - val_loss: 0.7947 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7098 - acc: 0.5751 - val_loss: 0.7946 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7098 - acc: 0.5751 - val_loss: 0.7946 - val_acc: 0.4918\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc020940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.8060 - acc: 0.4301 - val_loss: 0.8401 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8060 - acc: 0.4301 - val_loss: 0.8401 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8060 - acc: 0.4301 - val_loss: 0.8401 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8059 - acc: 0.4301 - val_loss: 0.8400 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8059 - acc: 0.4301 - val_loss: 0.8400 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8059 - acc: 0.4301 - val_loss: 0.8400 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8058 - acc: 0.4301 - val_loss: 0.8399 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8058 - acc: 0.4301 - val_loss: 0.8399 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8058 - acc: 0.4301 - val_loss: 0.8399 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8057 - acc: 0.4301 - val_loss: 0.8398 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8057 - acc: 0.4301 - val_loss: 0.8398 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8057 - acc: 0.4301 - val_loss: 0.8398 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8056 - acc: 0.4301 - val_loss: 0.8397 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8056 - acc: 0.4301 - val_loss: 0.8397 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8056 - acc: 0.4301 - val_loss: 0.8397 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8055 - acc: 0.4301 - val_loss: 0.8396 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8055 - acc: 0.4301 - val_loss: 0.8396 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8055 - acc: 0.4301 - val_loss: 0.8396 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8054 - acc: 0.4301 - val_loss: 0.8395 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8054 - acc: 0.4301 - val_loss: 0.8395 - val_acc: 0.3934\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0ea4550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6003 - acc: 0.6959 - val_loss: 0.6076 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6002 - acc: 0.6959 - val_loss: 0.6076 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6002 - acc: 0.6959 - val_loss: 0.6076 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6002 - acc: 0.6959 - val_loss: 0.6076 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6002 - acc: 0.6959 - val_loss: 0.6075 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6002 - acc: 0.6959 - val_loss: 0.6075 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6001 - acc: 0.6959 - val_loss: 0.6075 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6001 - acc: 0.6959 - val_loss: 0.6075 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6001 - acc: 0.6959 - val_loss: 0.6074 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6001 - acc: 0.6959 - val_loss: 0.6074 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6001 - acc: 0.6959 - val_loss: 0.6074 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6000 - acc: 0.6959 - val_loss: 0.6074 - val_acc: 0.6721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6000 - acc: 0.6959 - val_loss: 0.6073 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6000 - acc: 0.6959 - val_loss: 0.6073 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6000 - acc: 0.6959 - val_loss: 0.6073 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5999 - acc: 0.6959 - val_loss: 0.6073 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5999 - acc: 0.6959 - val_loss: 0.6072 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5999 - acc: 0.6959 - val_loss: 0.6072 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5999 - acc: 0.6959 - val_loss: 0.6072 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5999 - acc: 0.6959 - val_loss: 0.6072 - val_acc: 0.6721\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4742ef0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7826 - acc: 0.4072 - val_loss: 0.7258 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7826 - acc: 0.4072 - val_loss: 0.7257 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7826 - acc: 0.4072 - val_loss: 0.7257 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7826 - acc: 0.4072 - val_loss: 0.7257 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7825 - acc: 0.4072 - val_loss: 0.7257 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7825 - acc: 0.4072 - val_loss: 0.7256 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7825 - acc: 0.4072 - val_loss: 0.7256 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7825 - acc: 0.4072 - val_loss: 0.7256 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7824 - acc: 0.4072 - val_loss: 0.7256 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7824 - acc: 0.4072 - val_loss: 0.7255 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7824 - acc: 0.4072 - val_loss: 0.7255 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7824 - acc: 0.4072 - val_loss: 0.7255 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7823 - acc: 0.4072 - val_loss: 0.7254 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7823 - acc: 0.4072 - val_loss: 0.7254 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7823 - acc: 0.4072 - val_loss: 0.7254 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7823 - acc: 0.4072 - val_loss: 0.7254 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7822 - acc: 0.4072 - val_loss: 0.7253 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7822 - acc: 0.4072 - val_loss: 0.7253 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7822 - acc: 0.4072 - val_loss: 0.7253 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7822 - acc: 0.4072 - val_loss: 0.7253 - val_acc: 0.5082\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e0d550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7905 - acc: 0.4794 - val_loss: 0.7343 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7905 - acc: 0.4794 - val_loss: 0.7342 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7905 - acc: 0.4794 - val_loss: 0.7342 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7904 - acc: 0.4794 - val_loss: 0.7342 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7904 - acc: 0.4794 - val_loss: 0.7342 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7904 - acc: 0.4794 - val_loss: 0.7341 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7904 - acc: 0.4794 - val_loss: 0.7341 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7903 - acc: 0.4794 - val_loss: 0.7341 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7903 - acc: 0.4794 - val_loss: 0.7340 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7903 - acc: 0.4794 - val_loss: 0.7340 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7903 - acc: 0.4794 - val_loss: 0.7340 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7902 - acc: 0.4794 - val_loss: 0.7340 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7902 - acc: 0.4794 - val_loss: 0.7339 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7902 - acc: 0.4794 - val_loss: 0.7339 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7902 - acc: 0.4794 - val_loss: 0.7339 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7901 - acc: 0.4794 - val_loss: 0.7339 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7901 - acc: 0.4794 - val_loss: 0.7338 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7901 - acc: 0.4794 - val_loss: 0.7338 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7900 - acc: 0.4794 - val_loss: 0.7338 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7900 - acc: 0.4794 - val_loss: 0.7338 - val_acc: 0.5246\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4582f1430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6859 - acc: 0.5596 - val_loss: 0.6420 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6859 - acc: 0.5596 - val_loss: 0.6419 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6859 - acc: 0.5596 - val_loss: 0.6419 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6858 - acc: 0.5596 - val_loss: 0.6418 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6858 - acc: 0.5596 - val_loss: 0.6418 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6858 - acc: 0.5596 - val_loss: 0.6418 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6857 - acc: 0.5596 - val_loss: 0.6417 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6857 - acc: 0.5596 - val_loss: 0.6417 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6856 - acc: 0.5596 - val_loss: 0.6417 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6856 - acc: 0.5596 - val_loss: 0.6416 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6856 - acc: 0.5596 - val_loss: 0.6416 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6855 - acc: 0.5596 - val_loss: 0.6415 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6855 - acc: 0.5596 - val_loss: 0.6415 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6855 - acc: 0.5596 - val_loss: 0.6415 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6854 - acc: 0.5596 - val_loss: 0.6414 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6854 - acc: 0.5596 - val_loss: 0.6414 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6853 - acc: 0.5596 - val_loss: 0.6414 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6853 - acc: 0.5596 - val_loss: 0.6413 - val_acc: 0.6066\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6853 - acc: 0.5596 - val_loss: 0.6413 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7084 - acc: 0.523 - 0s 5ms/step - loss: 0.6852 - acc: 0.5596 - val_loss: 0.6412 - val_acc: 0.6066\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41011bc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7463 - acc: 0.4456 - val_loss: 0.7511 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7463 - acc: 0.4456 - val_loss: 0.7511 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7463 - acc: 0.4456 - val_loss: 0.7510 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7462 - acc: 0.4456 - val_loss: 0.7510 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7462 - acc: 0.4508 - val_loss: 0.7510 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7462 - acc: 0.4508 - val_loss: 0.7509 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7461 - acc: 0.4508 - val_loss: 0.7509 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7461 - acc: 0.4508 - val_loss: 0.7508 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7461 - acc: 0.4508 - val_loss: 0.7508 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7460 - acc: 0.4508 - val_loss: 0.7508 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7460 - acc: 0.4508 - val_loss: 0.7507 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7460 - acc: 0.4560 - val_loss: 0.7507 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7459 - acc: 0.4560 - val_loss: 0.7506 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7459 - acc: 0.4560 - val_loss: 0.7506 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7459 - acc: 0.4560 - val_loss: 0.7506 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7458 - acc: 0.4560 - val_loss: 0.7505 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7458 - acc: 0.4560 - val_loss: 0.7505 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7458 - acc: 0.4560 - val_loss: 0.7505 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7457 - acc: 0.4560 - val_loss: 0.7504 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7457 - acc: 0.4560 - val_loss: 0.7504 - val_acc: 0.4754\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b43dde50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8076 - acc: 0.5515 - val_loss: 0.7558 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8075 - acc: 0.5515 - val_loss: 0.7558 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8075 - acc: 0.5515 - val_loss: 0.7557 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8074 - acc: 0.5515 - val_loss: 0.7557 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8074 - acc: 0.5515 - val_loss: 0.7556 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8074 - acc: 0.5515 - val_loss: 0.7556 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8073 - acc: 0.5515 - val_loss: 0.7555 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8073 - acc: 0.5515 - val_loss: 0.7555 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8072 - acc: 0.5515 - val_loss: 0.7554 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8072 - acc: 0.5515 - val_loss: 0.7554 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8072 - acc: 0.5515 - val_loss: 0.7553 - val_acc: 0.5574\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8071 - acc: 0.5515 - val_loss: 0.7553 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8071 - acc: 0.5515 - val_loss: 0.7552 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8070 - acc: 0.5515 - val_loss: 0.7552 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8070 - acc: 0.5515 - val_loss: 0.7551 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8070 - acc: 0.5515 - val_loss: 0.7551 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8069 - acc: 0.5515 - val_loss: 0.7551 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8069 - acc: 0.5515 - val_loss: 0.7550 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8068 - acc: 0.5515 - val_loss: 0.7550 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8068 - acc: 0.5515 - val_loss: 0.7549 - val_acc: 0.5574\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beca4c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7543 - acc: 0.4691 - val_loss: 0.7060 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7543 - acc: 0.4691 - val_loss: 0.7059 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7542 - acc: 0.4691 - val_loss: 0.7059 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7542 - acc: 0.4691 - val_loss: 0.7059 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7542 - acc: 0.4691 - val_loss: 0.7058 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7541 - acc: 0.4691 - val_loss: 0.7058 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7541 - acc: 0.4691 - val_loss: 0.7058 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7540 - acc: 0.4691 - val_loss: 0.7057 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7540 - acc: 0.4691 - val_loss: 0.7057 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7540 - acc: 0.4691 - val_loss: 0.7056 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7539 - acc: 0.4691 - val_loss: 0.7056 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7539 - acc: 0.4691 - val_loss: 0.7056 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7539 - acc: 0.4691 - val_loss: 0.7055 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7538 - acc: 0.4691 - val_loss: 0.7055 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7538 - acc: 0.4691 - val_loss: 0.7055 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7538 - acc: 0.4691 - val_loss: 0.7054 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7537 - acc: 0.4691 - val_loss: 0.7054 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7537 - acc: 0.4691 - val_loss: 0.7054 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7537 - acc: 0.4691 - val_loss: 0.7053 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7536 - acc: 0.4691 - val_loss: 0.7053 - val_acc: 0.5574\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b862c8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6682 - acc: 0.5722 - val_loss: 0.6450 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6682 - acc: 0.5722 - val_loss: 0.6450 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6682 - acc: 0.5773 - val_loss: 0.6450 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6681 - acc: 0.5773 - val_loss: 0.6449 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6681 - acc: 0.5773 - val_loss: 0.6449 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6681 - acc: 0.5773 - val_loss: 0.6449 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6681 - acc: 0.5773 - val_loss: 0.6448 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6680 - acc: 0.5722 - val_loss: 0.6448 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6680 - acc: 0.5722 - val_loss: 0.6448 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6680 - acc: 0.5722 - val_loss: 0.6447 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6679 - acc: 0.5722 - val_loss: 0.6447 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6679 - acc: 0.5722 - val_loss: 0.6447 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6679 - acc: 0.5722 - val_loss: 0.6447 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6679 - acc: 0.5722 - val_loss: 0.6446 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6678 - acc: 0.5722 - val_loss: 0.6446 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6678 - acc: 0.5722 - val_loss: 0.6446 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6678 - acc: 0.5722 - val_loss: 0.6445 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6677 - acc: 0.5722 - val_loss: 0.6445 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6677 - acc: 0.5722 - val_loss: 0.6445 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6677 - acc: 0.5722 - val_loss: 0.6444 - val_acc: 0.5902\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa42038c4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7231 - acc: 0.4922 - val_loss: 0.7361 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7231 - acc: 0.4922 - val_loss: 0.7361 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7230 - acc: 0.4922 - val_loss: 0.7360 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7230 - acc: 0.4922 - val_loss: 0.7360 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7229 - acc: 0.4922 - val_loss: 0.7359 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7229 - acc: 0.4922 - val_loss: 0.7359 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7228 - acc: 0.4922 - val_loss: 0.7358 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7228 - acc: 0.4922 - val_loss: 0.7357 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7227 - acc: 0.4922 - val_loss: 0.7357 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7227 - acc: 0.4922 - val_loss: 0.7356 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7226 - acc: 0.4922 - val_loss: 0.7356 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7226 - acc: 0.4922 - val_loss: 0.7355 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7225 - acc: 0.4922 - val_loss: 0.7355 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7225 - acc: 0.4922 - val_loss: 0.7354 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7224 - acc: 0.4922 - val_loss: 0.7354 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7224 - acc: 0.4922 - val_loss: 0.7353 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7223 - acc: 0.4922 - val_loss: 0.7352 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7223 - acc: 0.4922 - val_loss: 0.7352 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7222 - acc: 0.4922 - val_loss: 0.7351 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7222 - acc: 0.4922 - val_loss: 0.7351 - val_acc: 0.4918\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4103121f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7119 - acc: 0.4663 - val_loss: 0.7025 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7119 - acc: 0.4663 - val_loss: 0.7025 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7118 - acc: 0.4663 - val_loss: 0.7024 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7118 - acc: 0.4663 - val_loss: 0.7024 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7117 - acc: 0.4663 - val_loss: 0.7023 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7117 - acc: 0.4663 - val_loss: 0.7023 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7116 - acc: 0.4663 - val_loss: 0.7022 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7116 - acc: 0.4663 - val_loss: 0.7022 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7115 - acc: 0.4715 - val_loss: 0.7021 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7115 - acc: 0.4715 - val_loss: 0.7020 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7114 - acc: 0.4715 - val_loss: 0.7020 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7114 - acc: 0.4715 - val_loss: 0.7019 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7113 - acc: 0.4715 - val_loss: 0.7019 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7113 - acc: 0.4715 - val_loss: 0.7018 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7112 - acc: 0.4715 - val_loss: 0.7018 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7111 - acc: 0.4715 - val_loss: 0.7017 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7111 - acc: 0.4767 - val_loss: 0.7017 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7110 - acc: 0.4819 - val_loss: 0.7016 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7110 - acc: 0.4819 - val_loss: 0.7016 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7109 - acc: 0.4819 - val_loss: 0.7015 - val_acc: 0.5082\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410726af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7130 - acc: 0.5000 - val_loss: 0.6928 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7130 - acc: 0.5000 - val_loss: 0.6927 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7129 - acc: 0.5000 - val_loss: 0.6927 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7129 - acc: 0.5000 - val_loss: 0.6926 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7128 - acc: 0.5000 - val_loss: 0.6926 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7127 - acc: 0.5000 - val_loss: 0.6925 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7127 - acc: 0.5000 - val_loss: 0.6924 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7126 - acc: 0.5000 - val_loss: 0.6924 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7126 - acc: 0.5000 - val_loss: 0.6923 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7125 - acc: 0.5000 - val_loss: 0.6922 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7125 - acc: 0.5000 - val_loss: 0.6922 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7124 - acc: 0.5000 - val_loss: 0.6921 - val_acc: 0.5738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7124 - acc: 0.5000 - val_loss: 0.6920 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7123 - acc: 0.5000 - val_loss: 0.6920 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7122 - acc: 0.5052 - val_loss: 0.6919 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7122 - acc: 0.5052 - val_loss: 0.6919 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7121 - acc: 0.5052 - val_loss: 0.6918 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7121 - acc: 0.5052 - val_loss: 0.6917 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7120 - acc: 0.5052 - val_loss: 0.6917 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7120 - acc: 0.5052 - val_loss: 0.6916 - val_acc: 0.5738\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b869dca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 232ms/step - loss: 0.7328 - acc: 0.4588 - val_loss: 0.7391 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7327 - acc: 0.4588 - val_loss: 0.7390 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7327 - acc: 0.4588 - val_loss: 0.7390 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7326 - acc: 0.4588 - val_loss: 0.7389 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7326 - acc: 0.4588 - val_loss: 0.7388 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7325 - acc: 0.4588 - val_loss: 0.7388 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7325 - acc: 0.4588 - val_loss: 0.7387 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7324 - acc: 0.4588 - val_loss: 0.7387 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7323 - acc: 0.4639 - val_loss: 0.7386 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7323 - acc: 0.4639 - val_loss: 0.7385 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7322 - acc: 0.4639 - val_loss: 0.7385 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7322 - acc: 0.4639 - val_loss: 0.7384 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7321 - acc: 0.4639 - val_loss: 0.7384 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7321 - acc: 0.4639 - val_loss: 0.7383 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7320 - acc: 0.4639 - val_loss: 0.7382 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7320 - acc: 0.4639 - val_loss: 0.7382 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7319 - acc: 0.4639 - val_loss: 0.7381 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7319 - acc: 0.4639 - val_loss: 0.7381 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7318 - acc: 0.4639 - val_loss: 0.7380 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7318 - acc: 0.4639 - val_loss: 0.7379 - val_acc: 0.5082\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bed34f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6914 - acc: 0.5309 - val_loss: 0.6795 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6914 - acc: 0.5309 - val_loss: 0.6794 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6913 - acc: 0.5309 - val_loss: 0.6794 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6913 - acc: 0.5309 - val_loss: 0.6793 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6912 - acc: 0.5309 - val_loss: 0.6793 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6912 - acc: 0.5309 - val_loss: 0.6792 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6911 - acc: 0.5309 - val_loss: 0.6792 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6911 - acc: 0.5309 - val_loss: 0.6791 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6910 - acc: 0.5309 - val_loss: 0.6790 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6910 - acc: 0.5309 - val_loss: 0.6790 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6909 - acc: 0.5309 - val_loss: 0.6789 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6909 - acc: 0.5309 - val_loss: 0.6789 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6909 - acc: 0.5309 - val_loss: 0.6788 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6908 - acc: 0.5309 - val_loss: 0.6788 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6908 - acc: 0.5309 - val_loss: 0.6787 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6907 - acc: 0.5309 - val_loss: 0.6787 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6907 - acc: 0.5309 - val_loss: 0.6786 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6906 - acc: 0.5309 - val_loss: 0.6785 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6906 - acc: 0.5309 - val_loss: 0.6785 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6905 - acc: 0.5309 - val_loss: 0.6784 - val_acc: 0.5574\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b869db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7965 - acc: 0.3368 - val_loss: 0.7547 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7964 - acc: 0.3368 - val_loss: 0.7546 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7963 - acc: 0.3368 - val_loss: 0.7545 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7962 - acc: 0.3368 - val_loss: 0.7544 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7961 - acc: 0.3368 - val_loss: 0.7543 - val_acc: 0.3770\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7961 - acc: 0.3368 - val_loss: 0.7542 - val_acc: 0.3770\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7960 - acc: 0.3368 - val_loss: 0.7542 - val_acc: 0.3770\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7959 - acc: 0.3368 - val_loss: 0.7541 - val_acc: 0.3770\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7958 - acc: 0.3368 - val_loss: 0.7540 - val_acc: 0.3770\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7957 - acc: 0.3420 - val_loss: 0.7539 - val_acc: 0.3770\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7956 - acc: 0.3420 - val_loss: 0.7538 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7956 - acc: 0.3420 - val_loss: 0.7537 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7955 - acc: 0.3420 - val_loss: 0.7537 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7954 - acc: 0.3420 - val_loss: 0.7536 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7953 - acc: 0.3420 - val_loss: 0.7535 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7952 - acc: 0.3420 - val_loss: 0.7534 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7951 - acc: 0.3420 - val_loss: 0.7533 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7950 - acc: 0.3420 - val_loss: 0.7532 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7950 - acc: 0.3420 - val_loss: 0.7531 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7949 - acc: 0.3420 - val_loss: 0.7531 - val_acc: 0.3934\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beca43a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6620 - acc: 0.6269 - val_loss: 0.6593 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6619 - acc: 0.6269 - val_loss: 0.6592 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6619 - acc: 0.6269 - val_loss: 0.6591 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6618 - acc: 0.6269 - val_loss: 0.6591 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6617 - acc: 0.6269 - val_loss: 0.6590 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6617 - acc: 0.6269 - val_loss: 0.6589 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6616 - acc: 0.6269 - val_loss: 0.6588 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6615 - acc: 0.6269 - val_loss: 0.6588 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6615 - acc: 0.6269 - val_loss: 0.6587 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6614 - acc: 0.6269 - val_loss: 0.6586 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6613 - acc: 0.6269 - val_loss: 0.6585 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6613 - acc: 0.6269 - val_loss: 0.6585 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6612 - acc: 0.6269 - val_loss: 0.6584 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6611 - acc: 0.6269 - val_loss: 0.6583 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6611 - acc: 0.6269 - val_loss: 0.6583 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6610 - acc: 0.6269 - val_loss: 0.6582 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6609 - acc: 0.6269 - val_loss: 0.6581 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6609 - acc: 0.6269 - val_loss: 0.6580 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6608 - acc: 0.6269 - val_loss: 0.6580 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6607 - acc: 0.6269 - val_loss: 0.6579 - val_acc: 0.5738\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b43dd3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7882 - acc: 0.3144 - val_loss: 0.8154 - val_acc: 0.2459\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7881 - acc: 0.3144 - val_loss: 0.8153 - val_acc: 0.2459\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7881 - acc: 0.3144 - val_loss: 0.8152 - val_acc: 0.2459\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7880 - acc: 0.3144 - val_loss: 0.8151 - val_acc: 0.2459\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7879 - acc: 0.3144 - val_loss: 0.8150 - val_acc: 0.2459\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7878 - acc: 0.3144 - val_loss: 0.8149 - val_acc: 0.2459\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7877 - acc: 0.3144 - val_loss: 0.8148 - val_acc: 0.2459\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7876 - acc: 0.3144 - val_loss: 0.8147 - val_acc: 0.2459\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7876 - acc: 0.3144 - val_loss: 0.8146 - val_acc: 0.2459\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7875 - acc: 0.3144 - val_loss: 0.8145 - val_acc: 0.2459\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7874 - acc: 0.3144 - val_loss: 0.8144 - val_acc: 0.2459\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7873 - acc: 0.3144 - val_loss: 0.8144 - val_acc: 0.2459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7872 - acc: 0.3144 - val_loss: 0.8143 - val_acc: 0.2459\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7871 - acc: 0.3144 - val_loss: 0.8142 - val_acc: 0.2459\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7871 - acc: 0.3144 - val_loss: 0.8141 - val_acc: 0.2459\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7870 - acc: 0.3144 - val_loss: 0.8140 - val_acc: 0.2459\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7869 - acc: 0.3144 - val_loss: 0.8139 - val_acc: 0.2459\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7868 - acc: 0.3144 - val_loss: 0.8138 - val_acc: 0.2459\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7867 - acc: 0.3144 - val_loss: 0.8137 - val_acc: 0.2459\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7866 - acc: 0.3144 - val_loss: 0.8136 - val_acc: 0.2459\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bec57550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6899 - acc: 0.5876 - val_loss: 0.6852 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6898 - acc: 0.5876 - val_loss: 0.6851 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6897 - acc: 0.5876 - val_loss: 0.6850 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6897 - acc: 0.5876 - val_loss: 0.6849 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6896 - acc: 0.5876 - val_loss: 0.6849 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6895 - acc: 0.5876 - val_loss: 0.6848 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6894 - acc: 0.5876 - val_loss: 0.6847 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6894 - acc: 0.5876 - val_loss: 0.6846 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6893 - acc: 0.5876 - val_loss: 0.6846 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6892 - acc: 0.5876 - val_loss: 0.6845 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6892 - acc: 0.5876 - val_loss: 0.6844 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6891 - acc: 0.5876 - val_loss: 0.6843 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6890 - acc: 0.5876 - val_loss: 0.6843 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6890 - acc: 0.5876 - val_loss: 0.6842 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6889 - acc: 0.5876 - val_loss: 0.6841 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6888 - acc: 0.5876 - val_loss: 0.6840 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6888 - acc: 0.5876 - val_loss: 0.6840 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6887 - acc: 0.5876 - val_loss: 0.6839 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6886 - acc: 0.5876 - val_loss: 0.6838 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6886 - acc: 0.5876 - val_loss: 0.6837 - val_acc: 0.5902\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc1e9790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6939 - acc: 0.5722 - val_loss: 0.6958 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6938 - acc: 0.5722 - val_loss: 0.6957 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6937 - acc: 0.5722 - val_loss: 0.6956 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6936 - acc: 0.5722 - val_loss: 0.6955 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6936 - acc: 0.5722 - val_loss: 0.6955 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6935 - acc: 0.5722 - val_loss: 0.6954 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6934 - acc: 0.5722 - val_loss: 0.6953 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6934 - acc: 0.5722 - val_loss: 0.6952 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6933 - acc: 0.5722 - val_loss: 0.6952 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6932 - acc: 0.5722 - val_loss: 0.6951 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6931 - acc: 0.5722 - val_loss: 0.6950 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6931 - acc: 0.5722 - val_loss: 0.6949 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6930 - acc: 0.5722 - val_loss: 0.6949 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6929 - acc: 0.5722 - val_loss: 0.6948 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6929 - acc: 0.5722 - val_loss: 0.6947 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6928 - acc: 0.5722 - val_loss: 0.6946 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6927 - acc: 0.5722 - val_loss: 0.6946 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6926 - acc: 0.5722 - val_loss: 0.6945 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6926 - acc: 0.5722 - val_loss: 0.6944 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6925 - acc: 0.5722 - val_loss: 0.6943 - val_acc: 0.5410\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e0dc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6841 - acc: 0.5544 - val_loss: 0.6765 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6840 - acc: 0.5544 - val_loss: 0.6764 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6839 - acc: 0.5544 - val_loss: 0.6763 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6838 - acc: 0.5544 - val_loss: 0.6762 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6837 - acc: 0.5544 - val_loss: 0.6760 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6836 - acc: 0.5544 - val_loss: 0.6759 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6835 - acc: 0.5544 - val_loss: 0.6758 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6834 - acc: 0.5544 - val_loss: 0.6757 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6833 - acc: 0.5596 - val_loss: 0.6756 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6832 - acc: 0.5596 - val_loss: 0.6755 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6831 - acc: 0.5596 - val_loss: 0.6753 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6830 - acc: 0.5596 - val_loss: 0.6752 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6829 - acc: 0.5596 - val_loss: 0.6751 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6828 - acc: 0.5596 - val_loss: 0.6750 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6827 - acc: 0.5596 - val_loss: 0.6749 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6826 - acc: 0.5596 - val_loss: 0.6748 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6824 - acc: 0.5596 - val_loss: 0.6746 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6823 - acc: 0.5596 - val_loss: 0.6745 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6822 - acc: 0.5596 - val_loss: 0.6744 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6821 - acc: 0.5596 - val_loss: 0.6743 - val_acc: 0.6230\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4becf33a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6545 - acc: 0.6891 - val_loss: 0.6315 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6544 - acc: 0.6891 - val_loss: 0.6314 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6543 - acc: 0.6891 - val_loss: 0.6313 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6542 - acc: 0.6891 - val_loss: 0.6312 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6541 - acc: 0.6891 - val_loss: 0.6311 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6540 - acc: 0.6891 - val_loss: 0.6310 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6539 - acc: 0.6943 - val_loss: 0.6309 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6538 - acc: 0.6943 - val_loss: 0.6308 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6537 - acc: 0.6943 - val_loss: 0.6307 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6537 - acc: 0.6943 - val_loss: 0.6306 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6536 - acc: 0.6943 - val_loss: 0.6305 - val_acc: 0.7541\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6535 - acc: 0.6943 - val_loss: 0.6304 - val_acc: 0.7541\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6534 - acc: 0.6943 - val_loss: 0.6302 - val_acc: 0.7541\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6533 - acc: 0.6943 - val_loss: 0.6301 - val_acc: 0.7541\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6532 - acc: 0.6943 - val_loss: 0.6300 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6531 - acc: 0.6943 - val_loss: 0.6299 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6530 - acc: 0.6943 - val_loss: 0.6298 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6529 - acc: 0.6943 - val_loss: 0.6297 - val_acc: 0.7541\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6528 - acc: 0.6943 - val_loss: 0.6296 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6527 - acc: 0.6943 - val_loss: 0.6295 - val_acc: 0.7541\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc020550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7198 - acc: 0.4433 - val_loss: 0.7025 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7197 - acc: 0.4433 - val_loss: 0.7024 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7196 - acc: 0.4433 - val_loss: 0.7022 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7195 - acc: 0.4433 - val_loss: 0.7021 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7194 - acc: 0.4433 - val_loss: 0.7020 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7193 - acc: 0.4433 - val_loss: 0.7019 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7192 - acc: 0.4433 - val_loss: 0.7018 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7190 - acc: 0.4433 - val_loss: 0.7017 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7189 - acc: 0.4433 - val_loss: 0.7016 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7188 - acc: 0.4485 - val_loss: 0.7015 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7187 - acc: 0.4485 - val_loss: 0.7014 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7186 - acc: 0.4433 - val_loss: 0.7012 - val_acc: 0.4590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7185 - acc: 0.4433 - val_loss: 0.7011 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7184 - acc: 0.4433 - val_loss: 0.7010 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7183 - acc: 0.4433 - val_loss: 0.7009 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7182 - acc: 0.4433 - val_loss: 0.7008 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7181 - acc: 0.4433 - val_loss: 0.7007 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7180 - acc: 0.4433 - val_loss: 0.7006 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7178 - acc: 0.4433 - val_loss: 0.7005 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7177 - acc: 0.4485 - val_loss: 0.7004 - val_acc: 0.4590\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa474704700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7182 - acc: 0.4897 - val_loss: 0.7520 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7181 - acc: 0.4897 - val_loss: 0.7519 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7180 - acc: 0.4897 - val_loss: 0.7518 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7179 - acc: 0.4897 - val_loss: 0.7516 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7178 - acc: 0.4897 - val_loss: 0.7515 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7177 - acc: 0.4897 - val_loss: 0.7514 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7176 - acc: 0.4897 - val_loss: 0.7512 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7175 - acc: 0.4897 - val_loss: 0.7511 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7173 - acc: 0.4897 - val_loss: 0.7509 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7172 - acc: 0.4897 - val_loss: 0.7508 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7171 - acc: 0.4897 - val_loss: 0.7507 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7170 - acc: 0.4897 - val_loss: 0.7505 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7169 - acc: 0.4897 - val_loss: 0.7504 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7168 - acc: 0.4897 - val_loss: 0.7503 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7167 - acc: 0.4948 - val_loss: 0.7501 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7166 - acc: 0.4948 - val_loss: 0.7500 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7165 - acc: 0.4948 - val_loss: 0.7498 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7163 - acc: 0.4948 - val_loss: 0.7497 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7162 - acc: 0.4948 - val_loss: 0.7496 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7161 - acc: 0.4948 - val_loss: 0.7494 - val_acc: 0.4754\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b850ddc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6737 - acc: 0.5825 - val_loss: 0.7287 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6736 - acc: 0.5825 - val_loss: 0.7286 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6735 - acc: 0.5825 - val_loss: 0.7285 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6734 - acc: 0.5825 - val_loss: 0.7283 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6733 - acc: 0.5825 - val_loss: 0.7282 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6732 - acc: 0.5825 - val_loss: 0.7281 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6731 - acc: 0.5825 - val_loss: 0.7280 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6730 - acc: 0.5825 - val_loss: 0.7278 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6729 - acc: 0.5876 - val_loss: 0.7277 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6728 - acc: 0.5876 - val_loss: 0.7276 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6727 - acc: 0.5876 - val_loss: 0.7275 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6726 - acc: 0.5876 - val_loss: 0.7273 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6725 - acc: 0.5876 - val_loss: 0.7272 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6724 - acc: 0.5876 - val_loss: 0.7271 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6723 - acc: 0.5876 - val_loss: 0.7269 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6722 - acc: 0.5876 - val_loss: 0.7268 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6721 - acc: 0.5876 - val_loss: 0.7267 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6720 - acc: 0.5876 - val_loss: 0.7266 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6719 - acc: 0.5876 - val_loss: 0.7264 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6718 - acc: 0.5876 - val_loss: 0.7263 - val_acc: 0.4754\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa418647670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7959 - acc: 0.4922 - val_loss: 0.7813 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7958 - acc: 0.4974 - val_loss: 0.7813 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7958 - acc: 0.4974 - val_loss: 0.7813 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7958 - acc: 0.4974 - val_loss: 0.7812 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7958 - acc: 0.4974 - val_loss: 0.7812 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7958 - acc: 0.4974 - val_loss: 0.7812 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7958 - acc: 0.4974 - val_loss: 0.7812 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7958 - acc: 0.4974 - val_loss: 0.7812 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7958 - acc: 0.4974 - val_loss: 0.7812 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7958 - acc: 0.4974 - val_loss: 0.7812 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7958 - acc: 0.4974 - val_loss: 0.7812 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7958 - acc: 0.4974 - val_loss: 0.7812 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7958 - acc: 0.4974 - val_loss: 0.7812 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7958 - acc: 0.4974 - val_loss: 0.7812 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7957 - acc: 0.4974 - val_loss: 0.7812 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7957 - acc: 0.4974 - val_loss: 0.7812 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7957 - acc: 0.4974 - val_loss: 0.7811 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7957 - acc: 0.4974 - val_loss: 0.7811 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7957 - acc: 0.4974 - val_loss: 0.7811 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7957 - acc: 0.4974 - val_loss: 0.7811 - val_acc: 0.4918\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4202ac9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6534 - acc: 0.6788 - val_loss: 0.6489 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6534 - acc: 0.6736 - val_loss: 0.6489 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6534 - acc: 0.6736 - val_loss: 0.6489 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6534 - acc: 0.6736 - val_loss: 0.6489 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6534 - acc: 0.6736 - val_loss: 0.6489 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6534 - acc: 0.6736 - val_loss: 0.6489 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6534 - acc: 0.6736 - val_loss: 0.6488 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6534 - acc: 0.6736 - val_loss: 0.6488 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6534 - acc: 0.6736 - val_loss: 0.6488 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6534 - acc: 0.6736 - val_loss: 0.6488 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6534 - acc: 0.6736 - val_loss: 0.6488 - val_acc: 0.7213\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6534 - acc: 0.6736 - val_loss: 0.6488 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6534 - acc: 0.6736 - val_loss: 0.6488 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6533 - acc: 0.6736 - val_loss: 0.6488 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6533 - acc: 0.6736 - val_loss: 0.6488 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6533 - acc: 0.6736 - val_loss: 0.6488 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6533 - acc: 0.6736 - val_loss: 0.6487 - val_acc: 0.7213\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6533 - acc: 0.6736 - val_loss: 0.6487 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6533 - acc: 0.6736 - val_loss: 0.6487 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6533 - acc: 0.6736 - val_loss: 0.6487 - val_acc: 0.7213\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41023f040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.8265 - acc: 0.4536 - val_loss: 0.8301 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8265 - acc: 0.4536 - val_loss: 0.8301 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8265 - acc: 0.4536 - val_loss: 0.8300 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8265 - acc: 0.4536 - val_loss: 0.8300 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8265 - acc: 0.4536 - val_loss: 0.8300 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8264 - acc: 0.4536 - val_loss: 0.8300 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8264 - acc: 0.4536 - val_loss: 0.8300 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8264 - acc: 0.4536 - val_loss: 0.8300 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8264 - acc: 0.4536 - val_loss: 0.8300 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8264 - acc: 0.4536 - val_loss: 0.8300 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8264 - acc: 0.4536 - val_loss: 0.8300 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8264 - acc: 0.4536 - val_loss: 0.8299 - val_acc: 0.5246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8264 - acc: 0.4536 - val_loss: 0.8299 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8264 - acc: 0.4536 - val_loss: 0.8299 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8264 - acc: 0.4536 - val_loss: 0.8299 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8264 - acc: 0.4536 - val_loss: 0.8299 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8263 - acc: 0.4536 - val_loss: 0.8299 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8263 - acc: 0.4536 - val_loss: 0.8299 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8263 - acc: 0.4536 - val_loss: 0.8299 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8263 - acc: 0.4536 - val_loss: 0.8299 - val_acc: 0.5246\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa42003d940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0099 - acc: 0.3711 - val_loss: 1.0427 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.0099 - acc: 0.3711 - val_loss: 1.0427 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0098 - acc: 0.3711 - val_loss: 1.0427 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0098 - acc: 0.3711 - val_loss: 1.0427 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0098 - acc: 0.3711 - val_loss: 1.0427 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0098 - acc: 0.3711 - val_loss: 1.0426 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0098 - acc: 0.3711 - val_loss: 1.0426 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.0097 - acc: 0.3711 - val_loss: 1.0426 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0097 - acc: 0.3711 - val_loss: 1.0426 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0097 - acc: 0.3711 - val_loss: 1.0426 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0097 - acc: 0.3711 - val_loss: 1.0426 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0097 - acc: 0.3711 - val_loss: 1.0425 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0097 - acc: 0.3711 - val_loss: 1.0425 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0096 - acc: 0.3711 - val_loss: 1.0425 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0096 - acc: 0.3711 - val_loss: 1.0425 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0096 - acc: 0.3711 - val_loss: 1.0425 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0096 - acc: 0.3711 - val_loss: 1.0424 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0096 - acc: 0.3711 - val_loss: 1.0424 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0095 - acc: 0.3711 - val_loss: 1.0424 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0095 - acc: 0.3711 - val_loss: 1.0424 - val_acc: 0.4426\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa418145af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.8358 - acc: 0.4536 - val_loss: 0.8010 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8358 - acc: 0.4536 - val_loss: 0.8010 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8358 - acc: 0.4536 - val_loss: 0.8010 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8358 - acc: 0.4536 - val_loss: 0.8009 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8358 - acc: 0.4536 - val_loss: 0.8009 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8358 - acc: 0.4536 - val_loss: 0.8009 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8358 - acc: 0.4536 - val_loss: 0.8009 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8357 - acc: 0.4536 - val_loss: 0.8009 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8357 - acc: 0.4536 - val_loss: 0.8009 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8357 - acc: 0.4536 - val_loss: 0.8009 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8357 - acc: 0.4536 - val_loss: 0.8009 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8357 - acc: 0.4536 - val_loss: 0.8008 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8357 - acc: 0.4536 - val_loss: 0.8008 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8357 - acc: 0.4536 - val_loss: 0.8008 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8357 - acc: 0.4536 - val_loss: 0.8008 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8356 - acc: 0.4536 - val_loss: 0.8008 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8356 - acc: 0.4536 - val_loss: 0.8008 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8356 - acc: 0.4536 - val_loss: 0.8008 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8356 - acc: 0.4536 - val_loss: 0.8008 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8356 - acc: 0.4536 - val_loss: 0.8007 - val_acc: 0.4426\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b8640430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7992 - acc: 0.4249 - val_loss: 0.8165 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7992 - acc: 0.4249 - val_loss: 0.8165 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7992 - acc: 0.4249 - val_loss: 0.8165 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7991 - acc: 0.4249 - val_loss: 0.8165 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7991 - acc: 0.4249 - val_loss: 0.8165 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7991 - acc: 0.4249 - val_loss: 0.8164 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7991 - acc: 0.4249 - val_loss: 0.8164 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7991 - acc: 0.4249 - val_loss: 0.8164 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7991 - acc: 0.4249 - val_loss: 0.8164 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7990 - acc: 0.4249 - val_loss: 0.8164 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7990 - acc: 0.4249 - val_loss: 0.8163 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7990 - acc: 0.4249 - val_loss: 0.8163 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7990 - acc: 0.4249 - val_loss: 0.8163 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7990 - acc: 0.4249 - val_loss: 0.8163 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7990 - acc: 0.4249 - val_loss: 0.8163 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7989 - acc: 0.4249 - val_loss: 0.8163 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7989 - acc: 0.4249 - val_loss: 0.8162 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7989 - acc: 0.4249 - val_loss: 0.8162 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7989 - acc: 0.4249 - val_loss: 0.8162 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7989 - acc: 0.4249 - val_loss: 0.8162 - val_acc: 0.5738\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b8422820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6622 - acc: 0.5803 - val_loss: 0.7067 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6622 - acc: 0.5803 - val_loss: 0.7067 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6622 - acc: 0.5803 - val_loss: 0.7066 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6621 - acc: 0.5803 - val_loss: 0.7066 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6621 - acc: 0.5803 - val_loss: 0.7066 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6621 - acc: 0.5803 - val_loss: 0.7066 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6621 - acc: 0.5803 - val_loss: 0.7066 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6621 - acc: 0.5803 - val_loss: 0.7066 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6621 - acc: 0.5803 - val_loss: 0.7065 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6621 - acc: 0.5803 - val_loss: 0.7065 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6621 - acc: 0.5803 - val_loss: 0.7065 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6621 - acc: 0.5803 - val_loss: 0.7065 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6620 - acc: 0.5803 - val_loss: 0.7065 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6620 - acc: 0.5803 - val_loss: 0.7065 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6620 - acc: 0.5803 - val_loss: 0.7064 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6620 - acc: 0.5803 - val_loss: 0.7064 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6620 - acc: 0.5803 - val_loss: 0.7064 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6620 - acc: 0.5803 - val_loss: 0.7064 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6620 - acc: 0.5803 - val_loss: 0.7064 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6620 - acc: 0.5803 - val_loss: 0.7064 - val_acc: 0.4754\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41820aaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.8618 - acc: 0.4897 - val_loss: 0.8687 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8617 - acc: 0.4897 - val_loss: 0.8687 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8617 - acc: 0.4897 - val_loss: 0.8687 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8617 - acc: 0.4897 - val_loss: 0.8686 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8617 - acc: 0.4897 - val_loss: 0.8686 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8616 - acc: 0.4897 - val_loss: 0.8686 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8616 - acc: 0.4897 - val_loss: 0.8685 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8616 - acc: 0.4897 - val_loss: 0.8685 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8616 - acc: 0.4897 - val_loss: 0.8685 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8615 - acc: 0.4897 - val_loss: 0.8684 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8615 - acc: 0.4897 - val_loss: 0.8684 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8615 - acc: 0.4897 - val_loss: 0.8684 - val_acc: 0.5082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8615 - acc: 0.4897 - val_loss: 0.8684 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8614 - acc: 0.4897 - val_loss: 0.8683 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8614 - acc: 0.4897 - val_loss: 0.8683 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8614 - acc: 0.4897 - val_loss: 0.8683 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8614 - acc: 0.4897 - val_loss: 0.8682 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8613 - acc: 0.4897 - val_loss: 0.8682 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8613 - acc: 0.4897 - val_loss: 0.8682 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8613 - acc: 0.4897 - val_loss: 0.8681 - val_acc: 0.5082\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc2533a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8941 - acc: 0.5619 - val_loss: 0.8808 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8941 - acc: 0.5619 - val_loss: 0.8808 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8941 - acc: 0.5619 - val_loss: 0.8808 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8941 - acc: 0.5619 - val_loss: 0.8807 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8940 - acc: 0.5619 - val_loss: 0.8807 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8940 - acc: 0.5619 - val_loss: 0.8807 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8940 - acc: 0.5619 - val_loss: 0.8807 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8940 - acc: 0.5619 - val_loss: 0.8806 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8940 - acc: 0.5619 - val_loss: 0.8806 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8939 - acc: 0.5619 - val_loss: 0.8806 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8939 - acc: 0.5619 - val_loss: 0.8806 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8939 - acc: 0.5619 - val_loss: 0.8805 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8939 - acc: 0.5619 - val_loss: 0.8805 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8939 - acc: 0.5619 - val_loss: 0.8805 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8938 - acc: 0.5619 - val_loss: 0.8805 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8938 - acc: 0.5619 - val_loss: 0.8804 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8938 - acc: 0.5619 - val_loss: 0.8804 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8938 - acc: 0.5619 - val_loss: 0.8804 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8937 - acc: 0.5619 - val_loss: 0.8804 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8937 - acc: 0.5619 - val_loss: 0.8803 - val_acc: 0.5246\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc0203a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6527 - acc: 0.5825 - val_loss: 0.6250 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6526 - acc: 0.5825 - val_loss: 0.6250 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6526 - acc: 0.5825 - val_loss: 0.6250 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6526 - acc: 0.5825 - val_loss: 0.6249 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6526 - acc: 0.5825 - val_loss: 0.6249 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6526 - acc: 0.5825 - val_loss: 0.6249 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6526 - acc: 0.5825 - val_loss: 0.6249 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6526 - acc: 0.5825 - val_loss: 0.6249 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6525 - acc: 0.5825 - val_loss: 0.6249 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6525 - acc: 0.5825 - val_loss: 0.6249 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6525 - acc: 0.5825 - val_loss: 0.6248 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6525 - acc: 0.5825 - val_loss: 0.6248 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6525 - acc: 0.5825 - val_loss: 0.6248 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6525 - acc: 0.5825 - val_loss: 0.6248 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6525 - acc: 0.5825 - val_loss: 0.6248 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6525 - acc: 0.5825 - val_loss: 0.6248 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6524 - acc: 0.5825 - val_loss: 0.6248 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6524 - acc: 0.5825 - val_loss: 0.6248 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6524 - acc: 0.5825 - val_loss: 0.6247 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6524 - acc: 0.5825 - val_loss: 0.6247 - val_acc: 0.6230\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4becf3040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7360 - acc: 0.5440 - val_loss: 0.6747 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7360 - acc: 0.5440 - val_loss: 0.6747 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7360 - acc: 0.5440 - val_loss: 0.6747 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7359 - acc: 0.5440 - val_loss: 0.6746 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7359 - acc: 0.5440 - val_loss: 0.6746 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7359 - acc: 0.5440 - val_loss: 0.6746 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7359 - acc: 0.5440 - val_loss: 0.6746 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7358 - acc: 0.5440 - val_loss: 0.6745 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7358 - acc: 0.5440 - val_loss: 0.6745 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7358 - acc: 0.5440 - val_loss: 0.6745 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7358 - acc: 0.5440 - val_loss: 0.6745 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7357 - acc: 0.5440 - val_loss: 0.6744 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7357 - acc: 0.5440 - val_loss: 0.6744 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7357 - acc: 0.5440 - val_loss: 0.6744 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7357 - acc: 0.5440 - val_loss: 0.6744 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7356 - acc: 0.5440 - val_loss: 0.6743 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7356 - acc: 0.5440 - val_loss: 0.6743 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7356 - acc: 0.5492 - val_loss: 0.6743 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7356 - acc: 0.5492 - val_loss: 0.6743 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7356 - acc: 0.5492 - val_loss: 0.6742 - val_acc: 0.5738\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4742eff70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.8503 - acc: 0.3990 - val_loss: 0.8548 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8502 - acc: 0.3990 - val_loss: 0.8547 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8502 - acc: 0.3990 - val_loss: 0.8547 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8502 - acc: 0.3990 - val_loss: 0.8547 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8501 - acc: 0.3990 - val_loss: 0.8546 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8501 - acc: 0.3990 - val_loss: 0.8546 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8501 - acc: 0.3990 - val_loss: 0.8546 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8500 - acc: 0.3990 - val_loss: 0.8545 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8500 - acc: 0.3990 - val_loss: 0.8545 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8500 - acc: 0.3990 - val_loss: 0.8545 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8500 - acc: 0.3990 - val_loss: 0.8544 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8499 - acc: 0.3990 - val_loss: 0.8544 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8499 - acc: 0.3990 - val_loss: 0.8544 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8499 - acc: 0.3990 - val_loss: 0.8543 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8498 - acc: 0.3990 - val_loss: 0.8543 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8498 - acc: 0.3990 - val_loss: 0.8543 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8498 - acc: 0.3990 - val_loss: 0.8542 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8497 - acc: 0.3990 - val_loss: 0.8542 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8497 - acc: 0.3990 - val_loss: 0.8542 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8497 - acc: 0.3990 - val_loss: 0.8541 - val_acc: 0.3934\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc1e95e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.8258 - acc: 0.3557 - val_loss: 0.8266 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8258 - acc: 0.3557 - val_loss: 0.8266 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8258 - acc: 0.3557 - val_loss: 0.8265 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8257 - acc: 0.3557 - val_loss: 0.8265 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8257 - acc: 0.3557 - val_loss: 0.8265 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8257 - acc: 0.3557 - val_loss: 0.8264 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8256 - acc: 0.3557 - val_loss: 0.8264 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8256 - acc: 0.3557 - val_loss: 0.8264 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8255 - acc: 0.3557 - val_loss: 0.8263 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8255 - acc: 0.3557 - val_loss: 0.8263 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8255 - acc: 0.3557 - val_loss: 0.8263 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8254 - acc: 0.3557 - val_loss: 0.8262 - val_acc: 0.4262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8254 - acc: 0.3557 - val_loss: 0.8262 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8254 - acc: 0.3557 - val_loss: 0.8262 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8253 - acc: 0.3557 - val_loss: 0.8261 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8253 - acc: 0.3557 - val_loss: 0.8261 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8253 - acc: 0.3557 - val_loss: 0.8260 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8252 - acc: 0.3557 - val_loss: 0.8260 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8252 - acc: 0.3557 - val_loss: 0.8260 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8252 - acc: 0.3557 - val_loss: 0.8259 - val_acc: 0.4262\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac4944c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7167 - acc: 0.5515 - val_loss: 0.7508 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7167 - acc: 0.5515 - val_loss: 0.7507 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7166 - acc: 0.5515 - val_loss: 0.7507 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7166 - acc: 0.5515 - val_loss: 0.7507 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7166 - acc: 0.5515 - val_loss: 0.7506 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7166 - acc: 0.5515 - val_loss: 0.7506 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7165 - acc: 0.5515 - val_loss: 0.7506 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7165 - acc: 0.5515 - val_loss: 0.7506 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7165 - acc: 0.5515 - val_loss: 0.7505 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7165 - acc: 0.5515 - val_loss: 0.7505 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7164 - acc: 0.5515 - val_loss: 0.7505 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7164 - acc: 0.5515 - val_loss: 0.7504 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7164 - acc: 0.5515 - val_loss: 0.7504 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7164 - acc: 0.5515 - val_loss: 0.7504 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7164 - acc: 0.5515 - val_loss: 0.7504 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7163 - acc: 0.5515 - val_loss: 0.7503 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7163 - acc: 0.5515 - val_loss: 0.7503 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7163 - acc: 0.5515 - val_loss: 0.7503 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7163 - acc: 0.5515 - val_loss: 0.7502 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7162 - acc: 0.5515 - val_loss: 0.7502 - val_acc: 0.5410\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e28280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6820 - acc: 0.5876 - val_loss: 0.6765 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6819 - acc: 0.5876 - val_loss: 0.6765 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6819 - acc: 0.5876 - val_loss: 0.6764 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6819 - acc: 0.5876 - val_loss: 0.6764 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6819 - acc: 0.5876 - val_loss: 0.6764 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6818 - acc: 0.5876 - val_loss: 0.6764 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6818 - acc: 0.5876 - val_loss: 0.6764 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6818 - acc: 0.5876 - val_loss: 0.6763 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6818 - acc: 0.5876 - val_loss: 0.6763 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6818 - acc: 0.5876 - val_loss: 0.6763 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6817 - acc: 0.5876 - val_loss: 0.6763 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6817 - acc: 0.5876 - val_loss: 0.6762 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6817 - acc: 0.5876 - val_loss: 0.6762 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6817 - acc: 0.5876 - val_loss: 0.6762 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6816 - acc: 0.5876 - val_loss: 0.6762 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6816 - acc: 0.5876 - val_loss: 0.6762 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6816 - acc: 0.5876 - val_loss: 0.6761 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6816 - acc: 0.5876 - val_loss: 0.6761 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6816 - acc: 0.5876 - val_loss: 0.6761 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6815 - acc: 0.5876 - val_loss: 0.6761 - val_acc: 0.6230\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bed34e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7011 - acc: 0.5492 - val_loss: 0.6962 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7011 - acc: 0.5492 - val_loss: 0.6961 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7010 - acc: 0.5492 - val_loss: 0.6961 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7010 - acc: 0.5492 - val_loss: 0.6960 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7010 - acc: 0.5492 - val_loss: 0.6960 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7009 - acc: 0.5492 - val_loss: 0.6959 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7009 - acc: 0.5492 - val_loss: 0.6959 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7009 - acc: 0.5492 - val_loss: 0.6959 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7008 - acc: 0.5492 - val_loss: 0.6958 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7008 - acc: 0.5492 - val_loss: 0.6958 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7008 - acc: 0.5492 - val_loss: 0.6957 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7007 - acc: 0.5492 - val_loss: 0.6957 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7007 - acc: 0.5492 - val_loss: 0.6957 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7006 - acc: 0.5492 - val_loss: 0.6956 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7006 - acc: 0.5492 - val_loss: 0.6956 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7006 - acc: 0.5492 - val_loss: 0.6955 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7005 - acc: 0.5492 - val_loss: 0.6955 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7005 - acc: 0.5492 - val_loss: 0.6955 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7005 - acc: 0.5544 - val_loss: 0.6954 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7004 - acc: 0.5544 - val_loss: 0.6954 - val_acc: 0.5410\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1e3160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.8089 - acc: 0.4249 - val_loss: 0.7566 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8088 - acc: 0.4249 - val_loss: 0.7566 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8088 - acc: 0.4249 - val_loss: 0.7565 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8087 - acc: 0.4249 - val_loss: 0.7565 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8087 - acc: 0.4249 - val_loss: 0.7564 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8087 - acc: 0.4249 - val_loss: 0.7564 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8086 - acc: 0.4249 - val_loss: 0.7564 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8086 - acc: 0.4249 - val_loss: 0.7563 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8085 - acc: 0.4249 - val_loss: 0.7563 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8085 - acc: 0.4249 - val_loss: 0.7563 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8085 - acc: 0.4249 - val_loss: 0.7562 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8084 - acc: 0.4249 - val_loss: 0.7562 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8084 - acc: 0.4249 - val_loss: 0.7561 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8083 - acc: 0.4249 - val_loss: 0.7561 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8083 - acc: 0.4249 - val_loss: 0.7561 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8083 - acc: 0.4249 - val_loss: 0.7560 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8082 - acc: 0.4249 - val_loss: 0.7560 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8082 - acc: 0.4249 - val_loss: 0.7559 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8081 - acc: 0.4249 - val_loss: 0.7559 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8081 - acc: 0.4249 - val_loss: 0.7559 - val_acc: 0.4426\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4181450d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7872 - acc: 0.4948 - val_loss: 0.8351 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7872 - acc: 0.4948 - val_loss: 0.8350 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7871 - acc: 0.4948 - val_loss: 0.8350 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7871 - acc: 0.4948 - val_loss: 0.8349 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7870 - acc: 0.4948 - val_loss: 0.8349 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7870 - acc: 0.4948 - val_loss: 0.8348 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7869 - acc: 0.4948 - val_loss: 0.8348 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7869 - acc: 0.4948 - val_loss: 0.8347 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7869 - acc: 0.4948 - val_loss: 0.8347 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7868 - acc: 0.4948 - val_loss: 0.8346 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7868 - acc: 0.4948 - val_loss: 0.8345 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7867 - acc: 0.4948 - val_loss: 0.8345 - val_acc: 0.4426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7867 - acc: 0.4948 - val_loss: 0.8344 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7866 - acc: 0.4948 - val_loss: 0.8344 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7866 - acc: 0.4948 - val_loss: 0.8343 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7866 - acc: 0.4948 - val_loss: 0.8343 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7865 - acc: 0.4948 - val_loss: 0.8342 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7865 - acc: 0.4948 - val_loss: 0.8342 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7864 - acc: 0.4948 - val_loss: 0.8341 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7864 - acc: 0.4948 - val_loss: 0.8341 - val_acc: 0.4426\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b8308f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5865 - acc: 0.7062 - val_loss: 0.5476 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5865 - acc: 0.7062 - val_loss: 0.5475 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5865 - acc: 0.7062 - val_loss: 0.5475 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5865 - acc: 0.7062 - val_loss: 0.5475 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5864 - acc: 0.7062 - val_loss: 0.5474 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5864 - acc: 0.7062 - val_loss: 0.5474 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5864 - acc: 0.7062 - val_loss: 0.5474 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5864 - acc: 0.7062 - val_loss: 0.5474 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5863 - acc: 0.7062 - val_loss: 0.5473 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5863 - acc: 0.7062 - val_loss: 0.5473 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5863 - acc: 0.7062 - val_loss: 0.5473 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5863 - acc: 0.7062 - val_loss: 0.5473 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5862 - acc: 0.7062 - val_loss: 0.5472 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5862 - acc: 0.7062 - val_loss: 0.5472 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5862 - acc: 0.7062 - val_loss: 0.5472 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5862 - acc: 0.7062 - val_loss: 0.5472 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5861 - acc: 0.7062 - val_loss: 0.5471 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5861 - acc: 0.7062 - val_loss: 0.5471 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5861 - acc: 0.7062 - val_loss: 0.5471 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5860 - acc: 0.7062 - val_loss: 0.5471 - val_acc: 0.6721\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41862b820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6777 - acc: 0.5515 - val_loss: 0.6784 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6777 - acc: 0.5515 - val_loss: 0.6783 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6776 - acc: 0.5515 - val_loss: 0.6783 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6776 - acc: 0.5515 - val_loss: 0.6782 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6776 - acc: 0.5515 - val_loss: 0.6782 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6775 - acc: 0.5515 - val_loss: 0.6781 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6775 - acc: 0.5515 - val_loss: 0.6781 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6775 - acc: 0.5515 - val_loss: 0.6781 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6774 - acc: 0.5515 - val_loss: 0.6780 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6774 - acc: 0.5515 - val_loss: 0.6780 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6774 - acc: 0.5515 - val_loss: 0.6779 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6773 - acc: 0.5515 - val_loss: 0.6779 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6773 - acc: 0.5515 - val_loss: 0.6779 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6773 - acc: 0.5515 - val_loss: 0.6778 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6772 - acc: 0.5515 - val_loss: 0.6778 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6772 - acc: 0.5515 - val_loss: 0.6777 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6772 - acc: 0.5515 - val_loss: 0.6777 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6771 - acc: 0.5515 - val_loss: 0.6777 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6771 - acc: 0.5515 - val_loss: 0.6776 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6771 - acc: 0.5515 - val_loss: 0.6776 - val_acc: 0.5410\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4181c7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6804 - acc: 0.5751 - val_loss: 0.6676 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6803 - acc: 0.5751 - val_loss: 0.6675 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6803 - acc: 0.5751 - val_loss: 0.6674 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6802 - acc: 0.5751 - val_loss: 0.6674 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6802 - acc: 0.5751 - val_loss: 0.6673 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6801 - acc: 0.5751 - val_loss: 0.6673 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6801 - acc: 0.5751 - val_loss: 0.6672 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6800 - acc: 0.5751 - val_loss: 0.6671 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6800 - acc: 0.5751 - val_loss: 0.6671 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6799 - acc: 0.5751 - val_loss: 0.6670 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6799 - acc: 0.5751 - val_loss: 0.6670 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6798 - acc: 0.5751 - val_loss: 0.6669 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6797 - acc: 0.5751 - val_loss: 0.6669 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6797 - acc: 0.5751 - val_loss: 0.6668 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6796 - acc: 0.5751 - val_loss: 0.6667 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6796 - acc: 0.5751 - val_loss: 0.6667 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6795 - acc: 0.5751 - val_loss: 0.6666 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6795 - acc: 0.5751 - val_loss: 0.6666 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6794 - acc: 0.5751 - val_loss: 0.6665 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6794 - acc: 0.5751 - val_loss: 0.6664 - val_acc: 0.5902\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4100a53a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7386 - acc: 0.5751 - val_loss: 0.7856 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7386 - acc: 0.5751 - val_loss: 0.7855 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7385 - acc: 0.5751 - val_loss: 0.7854 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7385 - acc: 0.5751 - val_loss: 0.7854 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7384 - acc: 0.5751 - val_loss: 0.7853 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7384 - acc: 0.5751 - val_loss: 0.7852 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7383 - acc: 0.5751 - val_loss: 0.7852 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7383 - acc: 0.5751 - val_loss: 0.7851 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7382 - acc: 0.5751 - val_loss: 0.7850 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7382 - acc: 0.5751 - val_loss: 0.7850 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7381 - acc: 0.5751 - val_loss: 0.7849 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7381 - acc: 0.5751 - val_loss: 0.7848 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7380 - acc: 0.5751 - val_loss: 0.7848 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7380 - acc: 0.5751 - val_loss: 0.7847 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7379 - acc: 0.5751 - val_loss: 0.7846 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7379 - acc: 0.5751 - val_loss: 0.7846 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7378 - acc: 0.5751 - val_loss: 0.7845 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7378 - acc: 0.5751 - val_loss: 0.7844 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7377 - acc: 0.5751 - val_loss: 0.7844 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7377 - acc: 0.5751 - val_loss: 0.7843 - val_acc: 0.5410\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b85f2550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7234 - acc: 0.4794 - val_loss: 0.7513 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7234 - acc: 0.4794 - val_loss: 0.7512 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7233 - acc: 0.4794 - val_loss: 0.7512 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7233 - acc: 0.4794 - val_loss: 0.7511 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7232 - acc: 0.4794 - val_loss: 0.7510 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7231 - acc: 0.4794 - val_loss: 0.7510 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7231 - acc: 0.4794 - val_loss: 0.7509 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7230 - acc: 0.4794 - val_loss: 0.7508 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7230 - acc: 0.4794 - val_loss: 0.7507 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7229 - acc: 0.4794 - val_loss: 0.7507 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7228 - acc: 0.4794 - val_loss: 0.7506 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7228 - acc: 0.4794 - val_loss: 0.7505 - val_acc: 0.4426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7227 - acc: 0.4794 - val_loss: 0.7505 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7227 - acc: 0.4794 - val_loss: 0.7504 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7226 - acc: 0.4794 - val_loss: 0.7503 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7226 - acc: 0.4794 - val_loss: 0.7503 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7204 - acc: 0.476 - 0s 5ms/step - loss: 0.7225 - acc: 0.4794 - val_loss: 0.7502 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7224 - acc: 0.4794 - val_loss: 0.7501 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7224 - acc: 0.4794 - val_loss: 0.7501 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7223 - acc: 0.4794 - val_loss: 0.7500 - val_acc: 0.4426\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b82cc700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6793 - acc: 0.5567 - val_loss: 0.6290 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6792 - acc: 0.5567 - val_loss: 0.6290 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6792 - acc: 0.5567 - val_loss: 0.6289 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6791 - acc: 0.5567 - val_loss: 0.6289 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6791 - acc: 0.5567 - val_loss: 0.6288 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6790 - acc: 0.5567 - val_loss: 0.6288 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6790 - acc: 0.5567 - val_loss: 0.6287 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6789 - acc: 0.5567 - val_loss: 0.6287 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6789 - acc: 0.5567 - val_loss: 0.6286 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6788 - acc: 0.5567 - val_loss: 0.6286 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6788 - acc: 0.5567 - val_loss: 0.6285 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6787 - acc: 0.5567 - val_loss: 0.6285 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6787 - acc: 0.5567 - val_loss: 0.6284 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6786 - acc: 0.5567 - val_loss: 0.6284 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6786 - acc: 0.5567 - val_loss: 0.6283 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6785 - acc: 0.5567 - val_loss: 0.6283 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6785 - acc: 0.5567 - val_loss: 0.6282 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6784 - acc: 0.5567 - val_loss: 0.6282 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6784 - acc: 0.5567 - val_loss: 0.6281 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6783 - acc: 0.5567 - val_loss: 0.6281 - val_acc: 0.6230\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa47425b310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8328 - acc: 0.4536 - val_loss: 0.8110 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8328 - acc: 0.4536 - val_loss: 0.8110 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8327 - acc: 0.4536 - val_loss: 0.8109 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8327 - acc: 0.4536 - val_loss: 0.8108 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8326 - acc: 0.4536 - val_loss: 0.8108 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8325 - acc: 0.4536 - val_loss: 0.8107 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8325 - acc: 0.4536 - val_loss: 0.8107 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8324 - acc: 0.4536 - val_loss: 0.8106 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8324 - acc: 0.4536 - val_loss: 0.8106 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8323 - acc: 0.4536 - val_loss: 0.8105 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8322 - acc: 0.4536 - val_loss: 0.8104 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8322 - acc: 0.4536 - val_loss: 0.8104 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8321 - acc: 0.4536 - val_loss: 0.8103 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8321 - acc: 0.4536 - val_loss: 0.8103 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8320 - acc: 0.4536 - val_loss: 0.8102 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8319 - acc: 0.4536 - val_loss: 0.8102 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8319 - acc: 0.4536 - val_loss: 0.8101 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8318 - acc: 0.4536 - val_loss: 0.8101 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8318 - acc: 0.4536 - val_loss: 0.8100 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8317 - acc: 0.4536 - val_loss: 0.8099 - val_acc: 0.4754\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4100a5af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7453 - acc: 0.3316 - val_loss: 0.7423 - val_acc: 0.3443\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7452 - acc: 0.3368 - val_loss: 0.7422 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7451 - acc: 0.3368 - val_loss: 0.7421 - val_acc: 0.3443\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7450 - acc: 0.3368 - val_loss: 0.7420 - val_acc: 0.3443\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7449 - acc: 0.3368 - val_loss: 0.7420 - val_acc: 0.3443\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7449 - acc: 0.3368 - val_loss: 0.7419 - val_acc: 0.3443\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7448 - acc: 0.3368 - val_loss: 0.7418 - val_acc: 0.3443\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7447 - acc: 0.3368 - val_loss: 0.7417 - val_acc: 0.3443\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7446 - acc: 0.3368 - val_loss: 0.7416 - val_acc: 0.3443\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7445 - acc: 0.3368 - val_loss: 0.7415 - val_acc: 0.3443\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7445 - acc: 0.3368 - val_loss: 0.7414 - val_acc: 0.3443\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7444 - acc: 0.3368 - val_loss: 0.7414 - val_acc: 0.3443\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7443 - acc: 0.3368 - val_loss: 0.7413 - val_acc: 0.3443\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7442 - acc: 0.3368 - val_loss: 0.7412 - val_acc: 0.3443\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7441 - acc: 0.3368 - val_loss: 0.7411 - val_acc: 0.3443\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7440 - acc: 0.3368 - val_loss: 0.7410 - val_acc: 0.3443\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7440 - acc: 0.3368 - val_loss: 0.7409 - val_acc: 0.3443\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7439 - acc: 0.3368 - val_loss: 0.7408 - val_acc: 0.3443\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7438 - acc: 0.3368 - val_loss: 0.7408 - val_acc: 0.3443\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7437 - acc: 0.3420 - val_loss: 0.7407 - val_acc: 0.3443\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1e3550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6772 - acc: 0.5389 - val_loss: 0.6715 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6772 - acc: 0.5389 - val_loss: 0.6715 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6771 - acc: 0.5440 - val_loss: 0.6714 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6770 - acc: 0.5440 - val_loss: 0.6713 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6770 - acc: 0.5440 - val_loss: 0.6712 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6769 - acc: 0.5440 - val_loss: 0.6712 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6768 - acc: 0.5440 - val_loss: 0.6711 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6768 - acc: 0.5440 - val_loss: 0.6710 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6767 - acc: 0.5440 - val_loss: 0.6709 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6766 - acc: 0.5440 - val_loss: 0.6709 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6765 - acc: 0.5440 - val_loss: 0.6708 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6765 - acc: 0.5492 - val_loss: 0.6707 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6764 - acc: 0.5492 - val_loss: 0.6706 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6763 - acc: 0.5492 - val_loss: 0.6706 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6763 - acc: 0.5544 - val_loss: 0.6705 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6762 - acc: 0.5544 - val_loss: 0.6704 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6761 - acc: 0.5544 - val_loss: 0.6703 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6761 - acc: 0.5544 - val_loss: 0.6703 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6760 - acc: 0.5544 - val_loss: 0.6702 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6759 - acc: 0.5544 - val_loss: 0.6701 - val_acc: 0.5246\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beca4790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6779 - acc: 0.5876 - val_loss: 0.6917 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6778 - acc: 0.5876 - val_loss: 0.6916 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6777 - acc: 0.5876 - val_loss: 0.6916 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6777 - acc: 0.5876 - val_loss: 0.6915 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6776 - acc: 0.5876 - val_loss: 0.6914 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6775 - acc: 0.5876 - val_loss: 0.6913 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6774 - acc: 0.5876 - val_loss: 0.6912 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6774 - acc: 0.5876 - val_loss: 0.6911 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6773 - acc: 0.5876 - val_loss: 0.6910 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6772 - acc: 0.5876 - val_loss: 0.6910 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6771 - acc: 0.5876 - val_loss: 0.6909 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6771 - acc: 0.5876 - val_loss: 0.6908 - val_acc: 0.5082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6770 - acc: 0.5876 - val_loss: 0.6907 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6769 - acc: 0.5928 - val_loss: 0.6906 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6768 - acc: 0.5928 - val_loss: 0.6905 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6768 - acc: 0.5928 - val_loss: 0.6904 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6767 - acc: 0.5928 - val_loss: 0.6904 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6766 - acc: 0.5928 - val_loss: 0.6903 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6765 - acc: 0.5928 - val_loss: 0.6902 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6765 - acc: 0.5928 - val_loss: 0.6901 - val_acc: 0.5082\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4582f19d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5812 - acc: 0.7474 - val_loss: 0.5351 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5812 - acc: 0.7474 - val_loss: 0.5350 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5811 - acc: 0.7474 - val_loss: 0.5350 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5810 - acc: 0.7474 - val_loss: 0.5349 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5810 - acc: 0.7474 - val_loss: 0.5348 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5809 - acc: 0.7474 - val_loss: 0.5348 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5809 - acc: 0.7474 - val_loss: 0.5347 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5808 - acc: 0.7474 - val_loss: 0.5347 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5808 - acc: 0.7474 - val_loss: 0.5346 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5807 - acc: 0.7474 - val_loss: 0.5345 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5807 - acc: 0.7474 - val_loss: 0.5345 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5806 - acc: 0.7474 - val_loss: 0.5344 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5805 - acc: 0.7474 - val_loss: 0.5344 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5805 - acc: 0.7474 - val_loss: 0.5343 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5804 - acc: 0.7474 - val_loss: 0.5342 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5804 - acc: 0.7474 - val_loss: 0.5342 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5803 - acc: 0.7474 - val_loss: 0.5341 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5803 - acc: 0.7474 - val_loss: 0.5341 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5802 - acc: 0.7474 - val_loss: 0.5340 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5802 - acc: 0.7474 - val_loss: 0.5339 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4742ef040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6176 - acc: 0.7010 - val_loss: 0.6145 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6175 - acc: 0.7010 - val_loss: 0.6144 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6174 - acc: 0.7010 - val_loss: 0.6143 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6174 - acc: 0.7010 - val_loss: 0.6143 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6173 - acc: 0.7010 - val_loss: 0.6142 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6173 - acc: 0.7010 - val_loss: 0.6142 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6172 - acc: 0.7010 - val_loss: 0.6141 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6172 - acc: 0.7010 - val_loss: 0.6140 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6171 - acc: 0.7010 - val_loss: 0.6140 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6170 - acc: 0.7010 - val_loss: 0.6139 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6170 - acc: 0.7010 - val_loss: 0.6139 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6169 - acc: 0.7010 - val_loss: 0.6138 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6169 - acc: 0.7010 - val_loss: 0.6137 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6168 - acc: 0.7010 - val_loss: 0.6137 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6168 - acc: 0.7010 - val_loss: 0.6136 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6167 - acc: 0.7010 - val_loss: 0.6136 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6167 - acc: 0.7010 - val_loss: 0.6135 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6166 - acc: 0.7010 - val_loss: 0.6135 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6165 - acc: 0.7010 - val_loss: 0.6134 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6165 - acc: 0.7010 - val_loss: 0.6133 - val_acc: 0.6721\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e0df70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6889 - acc: 0.6010 - val_loss: 0.6644 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6888 - acc: 0.6010 - val_loss: 0.6643 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6887 - acc: 0.6010 - val_loss: 0.6642 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6886 - acc: 0.6010 - val_loss: 0.6641 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6885 - acc: 0.6010 - val_loss: 0.6640 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6884 - acc: 0.6010 - val_loss: 0.6639 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6883 - acc: 0.6010 - val_loss: 0.6638 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6882 - acc: 0.6010 - val_loss: 0.6637 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6881 - acc: 0.6010 - val_loss: 0.6636 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6880 - acc: 0.6010 - val_loss: 0.6635 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6879 - acc: 0.6010 - val_loss: 0.6634 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6878 - acc: 0.6010 - val_loss: 0.6633 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6877 - acc: 0.6010 - val_loss: 0.6632 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6876 - acc: 0.6010 - val_loss: 0.6631 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6875 - acc: 0.6010 - val_loss: 0.6630 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6874 - acc: 0.6062 - val_loss: 0.6629 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6873 - acc: 0.6062 - val_loss: 0.6628 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6872 - acc: 0.6062 - val_loss: 0.6627 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6871 - acc: 0.6062 - val_loss: 0.6626 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6870 - acc: 0.6062 - val_loss: 0.6625 - val_acc: 0.6230\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e71820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6976 - acc: 0.5130 - val_loss: 0.6940 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6975 - acc: 0.5130 - val_loss: 0.6939 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6974 - acc: 0.5181 - val_loss: 0.6938 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6973 - acc: 0.5181 - val_loss: 0.6937 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6972 - acc: 0.5181 - val_loss: 0.6936 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6971 - acc: 0.5181 - val_loss: 0.6935 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6970 - acc: 0.5181 - val_loss: 0.6933 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6969 - acc: 0.5233 - val_loss: 0.6932 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6968 - acc: 0.5233 - val_loss: 0.6931 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6967 - acc: 0.5285 - val_loss: 0.6930 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6966 - acc: 0.5285 - val_loss: 0.6929 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6965 - acc: 0.5285 - val_loss: 0.6928 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6963 - acc: 0.5285 - val_loss: 0.6927 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6962 - acc: 0.5285 - val_loss: 0.6926 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6961 - acc: 0.5285 - val_loss: 0.6924 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6960 - acc: 0.5285 - val_loss: 0.6923 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6959 - acc: 0.5285 - val_loss: 0.6922 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6958 - acc: 0.5285 - val_loss: 0.6921 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6957 - acc: 0.5285 - val_loss: 0.6920 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6956 - acc: 0.5285 - val_loss: 0.6919 - val_acc: 0.5902\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc0205e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6672 - acc: 0.6082 - val_loss: 0.6403 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6671 - acc: 0.6082 - val_loss: 0.6401 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6670 - acc: 0.6082 - val_loss: 0.6400 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6669 - acc: 0.6082 - val_loss: 0.6399 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6668 - acc: 0.6082 - val_loss: 0.6398 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6667 - acc: 0.6082 - val_loss: 0.6397 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6666 - acc: 0.6082 - val_loss: 0.6396 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6665 - acc: 0.6082 - val_loss: 0.6395 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6664 - acc: 0.6134 - val_loss: 0.6394 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6663 - acc: 0.6134 - val_loss: 0.6392 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6662 - acc: 0.6134 - val_loss: 0.6391 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6661 - acc: 0.6134 - val_loss: 0.6390 - val_acc: 0.6885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6660 - acc: 0.6134 - val_loss: 0.6389 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6659 - acc: 0.6134 - val_loss: 0.6388 - val_acc: 0.6885\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6658 - acc: 0.6134 - val_loss: 0.6387 - val_acc: 0.6885\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6657 - acc: 0.6134 - val_loss: 0.6386 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6656 - acc: 0.6134 - val_loss: 0.6385 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6655 - acc: 0.6134 - val_loss: 0.6384 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6654 - acc: 0.6134 - val_loss: 0.6383 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6653 - acc: 0.6134 - val_loss: 0.6382 - val_acc: 0.6885\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0ea4430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6808 - acc: 0.5309 - val_loss: 0.6780 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6807 - acc: 0.5309 - val_loss: 0.6779 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6806 - acc: 0.5309 - val_loss: 0.6778 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6805 - acc: 0.5309 - val_loss: 0.6777 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6804 - acc: 0.5309 - val_loss: 0.6776 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6803 - acc: 0.5361 - val_loss: 0.6774 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6802 - acc: 0.5361 - val_loss: 0.6773 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6801 - acc: 0.5361 - val_loss: 0.6772 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6800 - acc: 0.5361 - val_loss: 0.6771 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6799 - acc: 0.5361 - val_loss: 0.6770 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6798 - acc: 0.5361 - val_loss: 0.6769 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6797 - acc: 0.5361 - val_loss: 0.6768 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6796 - acc: 0.5361 - val_loss: 0.6767 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6795 - acc: 0.5361 - val_loss: 0.6766 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6794 - acc: 0.5361 - val_loss: 0.6765 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6793 - acc: 0.5361 - val_loss: 0.6764 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6792 - acc: 0.5361 - val_loss: 0.6762 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6791 - acc: 0.5361 - val_loss: 0.6761 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6790 - acc: 0.5361 - val_loss: 0.6760 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6789 - acc: 0.5361 - val_loss: 0.6759 - val_acc: 0.5246\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41068cc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7257 - acc: 0.4536 - val_loss: 0.7597 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7256 - acc: 0.4588 - val_loss: 0.7596 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7255 - acc: 0.4588 - val_loss: 0.7594 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7254 - acc: 0.4588 - val_loss: 0.7593 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7253 - acc: 0.4588 - val_loss: 0.7592 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7252 - acc: 0.4588 - val_loss: 0.7591 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7251 - acc: 0.4588 - val_loss: 0.7589 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7250 - acc: 0.4588 - val_loss: 0.7588 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7249 - acc: 0.4588 - val_loss: 0.7587 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7247 - acc: 0.4588 - val_loss: 0.7586 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7246 - acc: 0.4588 - val_loss: 0.7584 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7245 - acc: 0.4639 - val_loss: 0.7583 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7244 - acc: 0.4639 - val_loss: 0.7582 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7243 - acc: 0.4639 - val_loss: 0.7580 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7242 - acc: 0.4639 - val_loss: 0.7579 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7241 - acc: 0.4639 - val_loss: 0.7578 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7240 - acc: 0.4639 - val_loss: 0.7577 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7239 - acc: 0.4639 - val_loss: 0.7575 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7238 - acc: 0.4639 - val_loss: 0.7574 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7237 - acc: 0.4639 - val_loss: 0.7573 - val_acc: 0.4262\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa45874e3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.8362 - acc: 0.4145 - val_loss: 0.9322 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8350 - acc: 0.4145 - val_loss: 0.9309 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8338 - acc: 0.4197 - val_loss: 0.9296 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8326 - acc: 0.4197 - val_loss: 0.9283 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8314 - acc: 0.4197 - val_loss: 0.9271 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8304 - acc: 0.4197 - val_loss: 0.9259 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8291 - acc: 0.4197 - val_loss: 0.9246 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8280 - acc: 0.4197 - val_loss: 0.9234 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8269 - acc: 0.4197 - val_loss: 0.9222 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8258 - acc: 0.4197 - val_loss: 0.9210 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8246 - acc: 0.4301 - val_loss: 0.9197 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8235 - acc: 0.4352 - val_loss: 0.9185 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8224 - acc: 0.4352 - val_loss: 0.9172 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8213 - acc: 0.4352 - val_loss: 0.9159 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8202 - acc: 0.4404 - val_loss: 0.9147 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8190 - acc: 0.4404 - val_loss: 0.9134 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8179 - acc: 0.4404 - val_loss: 0.9122 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8168 - acc: 0.4404 - val_loss: 0.9109 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8157 - acc: 0.4404 - val_loss: 0.9097 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8145 - acc: 0.4404 - val_loss: 0.9085 - val_acc: 0.4098\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa418297700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7808 - acc: 0.5440 - val_loss: 0.7818 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7795 - acc: 0.5440 - val_loss: 0.7804 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7783 - acc: 0.5389 - val_loss: 0.7790 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7771 - acc: 0.5440 - val_loss: 0.7776 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7759 - acc: 0.5440 - val_loss: 0.7761 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7747 - acc: 0.5492 - val_loss: 0.7747 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7735 - acc: 0.5492 - val_loss: 0.7733 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7722 - acc: 0.5492 - val_loss: 0.7719 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7710 - acc: 0.5492 - val_loss: 0.7705 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7698 - acc: 0.5492 - val_loss: 0.7691 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7686 - acc: 0.5492 - val_loss: 0.7677 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7674 - acc: 0.5544 - val_loss: 0.7663 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7662 - acc: 0.5544 - val_loss: 0.7648 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7650 - acc: 0.5544 - val_loss: 0.7635 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7638 - acc: 0.5544 - val_loss: 0.7620 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7626 - acc: 0.5544 - val_loss: 0.7606 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7614 - acc: 0.5544 - val_loss: 0.7592 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7602 - acc: 0.5544 - val_loss: 0.7578 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7590 - acc: 0.5544 - val_loss: 0.7564 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7578 - acc: 0.5596 - val_loss: 0.7550 - val_acc: 0.5902\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4187c8040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6731 - acc: 0.5928 - val_loss: 0.6846 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6722 - acc: 0.5876 - val_loss: 0.6838 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6713 - acc: 0.5928 - val_loss: 0.6830 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6704 - acc: 0.5928 - val_loss: 0.6822 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6696 - acc: 0.5928 - val_loss: 0.6814 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6687 - acc: 0.5876 - val_loss: 0.6807 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6679 - acc: 0.5928 - val_loss: 0.6799 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6670 - acc: 0.5928 - val_loss: 0.6791 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6662 - acc: 0.5979 - val_loss: 0.6784 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6653 - acc: 0.5979 - val_loss: 0.6776 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6645 - acc: 0.5979 - val_loss: 0.6768 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6636 - acc: 0.5979 - val_loss: 0.6760 - val_acc: 0.5246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6628 - acc: 0.5979 - val_loss: 0.6753 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6619 - acc: 0.5979 - val_loss: 0.6745 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6611 - acc: 0.6031 - val_loss: 0.6737 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6602 - acc: 0.6031 - val_loss: 0.6730 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6594 - acc: 0.6031 - val_loss: 0.6722 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6585 - acc: 0.6134 - val_loss: 0.6715 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6577 - acc: 0.6134 - val_loss: 0.6707 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6569 - acc: 0.6134 - val_loss: 0.6699 - val_acc: 0.5246\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41818f430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7231 - acc: 0.5464 - val_loss: 0.7350 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7219 - acc: 0.5464 - val_loss: 0.7337 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7208 - acc: 0.5464 - val_loss: 0.7324 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7197 - acc: 0.5464 - val_loss: 0.7310 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7186 - acc: 0.5464 - val_loss: 0.7297 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7175 - acc: 0.5464 - val_loss: 0.7283 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7165 - acc: 0.5515 - val_loss: 0.7270 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7154 - acc: 0.5515 - val_loss: 0.7256 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7143 - acc: 0.5567 - val_loss: 0.7243 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7132 - acc: 0.5567 - val_loss: 0.7229 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7121 - acc: 0.5567 - val_loss: 0.7216 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7111 - acc: 0.5567 - val_loss: 0.7203 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7100 - acc: 0.5567 - val_loss: 0.7190 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7089 - acc: 0.5567 - val_loss: 0.7177 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7079 - acc: 0.5515 - val_loss: 0.7164 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7069 - acc: 0.5515 - val_loss: 0.7151 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7058 - acc: 0.5515 - val_loss: 0.7138 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7048 - acc: 0.5515 - val_loss: 0.7125 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7038 - acc: 0.5515 - val_loss: 0.7112 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7028 - acc: 0.5515 - val_loss: 0.7099 - val_acc: 0.5410\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4102e3430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6022 - acc: 0.7010 - val_loss: 0.5643 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6013 - acc: 0.7062 - val_loss: 0.5631 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6004 - acc: 0.7062 - val_loss: 0.5620 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5996 - acc: 0.7113 - val_loss: 0.5608 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5987 - acc: 0.7165 - val_loss: 0.5597 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5979 - acc: 0.7165 - val_loss: 0.5585 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5971 - acc: 0.7165 - val_loss: 0.5574 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5962 - acc: 0.7165 - val_loss: 0.5563 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5954 - acc: 0.7165 - val_loss: 0.5552 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5945 - acc: 0.7165 - val_loss: 0.5541 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5937 - acc: 0.7216 - val_loss: 0.5530 - val_acc: 0.7213\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5929 - acc: 0.7216 - val_loss: 0.5519 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5921 - acc: 0.7216 - val_loss: 0.5508 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5913 - acc: 0.7216 - val_loss: 0.5498 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5904 - acc: 0.7216 - val_loss: 0.5487 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5896 - acc: 0.7216 - val_loss: 0.5477 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5888 - acc: 0.7216 - val_loss: 0.5466 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5881 - acc: 0.7216 - val_loss: 0.5455 - val_acc: 0.7541\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5872 - acc: 0.7216 - val_loss: 0.5445 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5865 - acc: 0.7216 - val_loss: 0.5435 - val_acc: 0.7541\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41015b4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.8164 - acc: 0.5233 - val_loss: 0.8657 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8144 - acc: 0.5233 - val_loss: 0.8635 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8126 - acc: 0.5285 - val_loss: 0.8613 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8106 - acc: 0.5285 - val_loss: 0.8590 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8087 - acc: 0.5285 - val_loss: 0.8568 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8068 - acc: 0.5285 - val_loss: 0.8545 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8049 - acc: 0.5285 - val_loss: 0.8522 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8030 - acc: 0.5285 - val_loss: 0.8499 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8011 - acc: 0.5337 - val_loss: 0.8476 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7992 - acc: 0.5337 - val_loss: 0.8454 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7974 - acc: 0.5337 - val_loss: 0.8431 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7954 - acc: 0.5337 - val_loss: 0.8409 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7936 - acc: 0.5337 - val_loss: 0.8387 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7917 - acc: 0.5389 - val_loss: 0.8364 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7898 - acc: 0.5389 - val_loss: 0.8342 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7880 - acc: 0.5389 - val_loss: 0.8321 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7862 - acc: 0.5389 - val_loss: 0.8299 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7844 - acc: 0.5389 - val_loss: 0.8277 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7826 - acc: 0.5389 - val_loss: 0.8256 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7808 - acc: 0.5389 - val_loss: 0.8234 - val_acc: 0.5246\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b83785e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 236ms/step - loss: 0.6098 - acc: 0.6580 - val_loss: 0.5711 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6085 - acc: 0.6580 - val_loss: 0.5697 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6073 - acc: 0.6684 - val_loss: 0.5684 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6060 - acc: 0.6684 - val_loss: 0.5671 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6047 - acc: 0.6684 - val_loss: 0.5657 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6036 - acc: 0.6684 - val_loss: 0.5644 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6023 - acc: 0.6684 - val_loss: 0.5631 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6012 - acc: 0.6684 - val_loss: 0.5618 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6000 - acc: 0.6684 - val_loss: 0.5605 - val_acc: 0.7049\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5988 - acc: 0.6684 - val_loss: 0.5592 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5976 - acc: 0.6684 - val_loss: 0.5580 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5964 - acc: 0.6684 - val_loss: 0.5567 - val_acc: 0.7377\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5952 - acc: 0.6684 - val_loss: 0.5555 - val_acc: 0.7377\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5941 - acc: 0.6684 - val_loss: 0.5543 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5930 - acc: 0.6736 - val_loss: 0.5530 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5918 - acc: 0.6736 - val_loss: 0.5518 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5906 - acc: 0.6736 - val_loss: 0.5506 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5895 - acc: 0.6736 - val_loss: 0.5494 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5884 - acc: 0.6736 - val_loss: 0.5482 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5872 - acc: 0.6736 - val_loss: 0.5470 - val_acc: 0.7377\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4102e3e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8185 - acc: 0.5258 - val_loss: 0.9013 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8164 - acc: 0.5309 - val_loss: 0.8990 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8145 - acc: 0.5309 - val_loss: 0.8967 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8126 - acc: 0.5309 - val_loss: 0.8945 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8107 - acc: 0.5309 - val_loss: 0.8922 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8087 - acc: 0.5309 - val_loss: 0.8900 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8070 - acc: 0.5309 - val_loss: 0.8878 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8050 - acc: 0.5309 - val_loss: 0.8856 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8032 - acc: 0.5309 - val_loss: 0.8834 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8014 - acc: 0.5309 - val_loss: 0.8811 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7995 - acc: 0.5309 - val_loss: 0.8789 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7976 - acc: 0.5361 - val_loss: 0.8768 - val_acc: 0.4918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7958 - acc: 0.5361 - val_loss: 0.8746 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7940 - acc: 0.5361 - val_loss: 0.8724 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7921 - acc: 0.5464 - val_loss: 0.8703 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7904 - acc: 0.5464 - val_loss: 0.8681 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7886 - acc: 0.5464 - val_loss: 0.8660 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7868 - acc: 0.5464 - val_loss: 0.8639 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7850 - acc: 0.5515 - val_loss: 0.8618 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7832 - acc: 0.5515 - val_loss: 0.8597 - val_acc: 0.5246\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4582f10d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6622 - acc: 0.6598 - val_loss: 0.6468 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6611 - acc: 0.6598 - val_loss: 0.6457 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6600 - acc: 0.6598 - val_loss: 0.6445 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6590 - acc: 0.6598 - val_loss: 0.6434 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6580 - acc: 0.6598 - val_loss: 0.6424 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6569 - acc: 0.6598 - val_loss: 0.6413 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6559 - acc: 0.6598 - val_loss: 0.6402 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6549 - acc: 0.6598 - val_loss: 0.6392 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6539 - acc: 0.6598 - val_loss: 0.6381 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6529 - acc: 0.6546 - val_loss: 0.6371 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6519 - acc: 0.6546 - val_loss: 0.6361 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6509 - acc: 0.6598 - val_loss: 0.6350 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6500 - acc: 0.6649 - val_loss: 0.6340 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6490 - acc: 0.6649 - val_loss: 0.6329 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6480 - acc: 0.6649 - val_loss: 0.6319 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6471 - acc: 0.6649 - val_loss: 0.6309 - val_acc: 0.6557\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6461 - acc: 0.6649 - val_loss: 0.6299 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6452 - acc: 0.6649 - val_loss: 0.6289 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6442 - acc: 0.6701 - val_loss: 0.6279 - val_acc: 0.6557\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6433 - acc: 0.6701 - val_loss: 0.6269 - val_acc: 0.6557\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b8378c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7928 - acc: 0.5258 - val_loss: 0.7875 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7909 - acc: 0.5258 - val_loss: 0.7857 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7892 - acc: 0.5258 - val_loss: 0.7839 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7874 - acc: 0.5309 - val_loss: 0.7822 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7857 - acc: 0.5309 - val_loss: 0.7805 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7840 - acc: 0.5309 - val_loss: 0.7788 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7824 - acc: 0.5309 - val_loss: 0.7771 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7806 - acc: 0.5309 - val_loss: 0.7753 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7790 - acc: 0.5361 - val_loss: 0.7736 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7773 - acc: 0.5361 - val_loss: 0.7720 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7756 - acc: 0.5361 - val_loss: 0.7703 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7739 - acc: 0.5361 - val_loss: 0.7686 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7723 - acc: 0.5361 - val_loss: 0.7670 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7706 - acc: 0.5412 - val_loss: 0.7653 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7690 - acc: 0.5412 - val_loss: 0.7637 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7674 - acc: 0.5412 - val_loss: 0.7620 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7657 - acc: 0.5464 - val_loss: 0.7604 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7641 - acc: 0.5464 - val_loss: 0.7588 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7624 - acc: 0.5515 - val_loss: 0.7572 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7609 - acc: 0.5515 - val_loss: 0.7556 - val_acc: 0.5574\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b86fc670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.9826 - acc: 0.4819 - val_loss: 0.9906 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9795 - acc: 0.4819 - val_loss: 0.9868 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9763 - acc: 0.4819 - val_loss: 0.9830 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9732 - acc: 0.4819 - val_loss: 0.9792 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9701 - acc: 0.4819 - val_loss: 0.9754 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9670 - acc: 0.4819 - val_loss: 0.9716 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9640 - acc: 0.4819 - val_loss: 0.9679 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9609 - acc: 0.4819 - val_loss: 0.9642 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9579 - acc: 0.4819 - val_loss: 0.9606 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9548 - acc: 0.4819 - val_loss: 0.9570 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9518 - acc: 0.4819 - val_loss: 0.9534 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9488 - acc: 0.4819 - val_loss: 0.9499 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9459 - acc: 0.4819 - val_loss: 0.9463 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9428 - acc: 0.4819 - val_loss: 0.9428 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9399 - acc: 0.4819 - val_loss: 0.9393 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9370 - acc: 0.4819 - val_loss: 0.9358 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9340 - acc: 0.4819 - val_loss: 0.9323 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9310 - acc: 0.4922 - val_loss: 0.9289 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9282 - acc: 0.4922 - val_loss: 0.9254 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9253 - acc: 0.4922 - val_loss: 0.9220 - val_acc: 0.5082\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4103df670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.0179 - acc: 0.3990 - val_loss: 0.9341 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0140 - acc: 0.3990 - val_loss: 0.9310 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0103 - acc: 0.3990 - val_loss: 0.9278 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0066 - acc: 0.3990 - val_loss: 0.9246 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0029 - acc: 0.4041 - val_loss: 0.9215 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9991 - acc: 0.4041 - val_loss: 0.9183 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9955 - acc: 0.4041 - val_loss: 0.9152 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9919 - acc: 0.4093 - val_loss: 0.9120 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9883 - acc: 0.4093 - val_loss: 0.9088 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9846 - acc: 0.4093 - val_loss: 0.9057 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9810 - acc: 0.4093 - val_loss: 0.9026 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9774 - acc: 0.4093 - val_loss: 0.8995 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9740 - acc: 0.4093 - val_loss: 0.8964 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9703 - acc: 0.4093 - val_loss: 0.8934 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9669 - acc: 0.4145 - val_loss: 0.8904 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.9633 - acc: 0.4145 - val_loss: 0.8874 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9598 - acc: 0.4145 - val_loss: 0.8844 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9564 - acc: 0.4145 - val_loss: 0.8814 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9529 - acc: 0.4197 - val_loss: 0.8785 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9495 - acc: 0.4249 - val_loss: 0.8755 - val_acc: 0.4426\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0ea4f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5680 - acc: 0.7371 - val_loss: 0.5914 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5662 - acc: 0.7371 - val_loss: 0.5895 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5644 - acc: 0.7423 - val_loss: 0.5877 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5628 - acc: 0.7526 - val_loss: 0.5858 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5610 - acc: 0.7526 - val_loss: 0.5840 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5594 - acc: 0.7526 - val_loss: 0.5822 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5578 - acc: 0.7526 - val_loss: 0.5804 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5561 - acc: 0.7526 - val_loss: 0.5786 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5545 - acc: 0.7526 - val_loss: 0.5768 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5528 - acc: 0.7526 - val_loss: 0.5750 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5513 - acc: 0.7629 - val_loss: 0.5732 - val_acc: 0.7213\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5496 - acc: 0.7629 - val_loss: 0.5715 - val_acc: 0.7213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5481 - acc: 0.7680 - val_loss: 0.5697 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5465 - acc: 0.7680 - val_loss: 0.5680 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5449 - acc: 0.7680 - val_loss: 0.5663 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5434 - acc: 0.7680 - val_loss: 0.5646 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5418 - acc: 0.7680 - val_loss: 0.5629 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5403 - acc: 0.7680 - val_loss: 0.5612 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5388 - acc: 0.7680 - val_loss: 0.5595 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5373 - acc: 0.7680 - val_loss: 0.5578 - val_acc: 0.7377\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e71670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.9576 - acc: 0.4381 - val_loss: 0.9458 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9544 - acc: 0.4433 - val_loss: 0.9426 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9510 - acc: 0.4433 - val_loss: 0.9395 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9478 - acc: 0.4485 - val_loss: 0.9363 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9445 - acc: 0.4485 - val_loss: 0.9331 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9412 - acc: 0.4485 - val_loss: 0.9300 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9381 - acc: 0.4485 - val_loss: 0.9269 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9349 - acc: 0.4485 - val_loss: 0.9238 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9317 - acc: 0.4485 - val_loss: 0.9207 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9285 - acc: 0.4485 - val_loss: 0.9176 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9255 - acc: 0.4485 - val_loss: 0.9146 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9223 - acc: 0.4485 - val_loss: 0.9115 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9193 - acc: 0.4485 - val_loss: 0.9085 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9161 - acc: 0.4485 - val_loss: 0.9055 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9130 - acc: 0.4485 - val_loss: 0.9026 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9100 - acc: 0.4485 - val_loss: 0.8996 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9068 - acc: 0.4536 - val_loss: 0.8967 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9038 - acc: 0.4536 - val_loss: 0.8937 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9008 - acc: 0.4588 - val_loss: 0.8908 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8978 - acc: 0.4639 - val_loss: 0.8879 - val_acc: 0.4590\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1caee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7635 - acc: 0.4639 - val_loss: 0.7139 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7602 - acc: 0.4639 - val_loss: 0.7107 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7571 - acc: 0.4691 - val_loss: 0.7075 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7541 - acc: 0.4794 - val_loss: 0.7044 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7511 - acc: 0.4948 - val_loss: 0.7012 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7481 - acc: 0.4948 - val_loss: 0.6981 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7451 - acc: 0.4948 - val_loss: 0.6949 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7421 - acc: 0.4948 - val_loss: 0.6918 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7391 - acc: 0.5000 - val_loss: 0.6887 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7362 - acc: 0.5000 - val_loss: 0.6856 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7332 - acc: 0.5052 - val_loss: 0.6825 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7304 - acc: 0.5052 - val_loss: 0.6795 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7275 - acc: 0.5258 - val_loss: 0.6764 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7247 - acc: 0.5258 - val_loss: 0.6734 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7218 - acc: 0.5258 - val_loss: 0.6704 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7190 - acc: 0.5258 - val_loss: 0.6675 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7161 - acc: 0.5258 - val_loss: 0.6646 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7134 - acc: 0.5258 - val_loss: 0.6617 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7106 - acc: 0.5258 - val_loss: 0.6588 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7079 - acc: 0.5258 - val_loss: 0.6560 - val_acc: 0.5738\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac494ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6554 - acc: 0.6321 - val_loss: 0.6919 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6520 - acc: 0.6321 - val_loss: 0.6881 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6488 - acc: 0.6373 - val_loss: 0.6843 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6457 - acc: 0.6580 - val_loss: 0.6806 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6424 - acc: 0.6632 - val_loss: 0.6769 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6392 - acc: 0.6684 - val_loss: 0.6732 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6363 - acc: 0.6684 - val_loss: 0.6696 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6331 - acc: 0.6684 - val_loss: 0.6660 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6301 - acc: 0.6684 - val_loss: 0.6625 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6270 - acc: 0.6684 - val_loss: 0.6590 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6241 - acc: 0.6684 - val_loss: 0.6556 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6210 - acc: 0.6736 - val_loss: 0.6521 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6182 - acc: 0.6736 - val_loss: 0.6487 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6152 - acc: 0.6684 - val_loss: 0.6454 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6124 - acc: 0.6684 - val_loss: 0.6420 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6095 - acc: 0.6684 - val_loss: 0.6388 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6067 - acc: 0.6684 - val_loss: 0.6355 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6039 - acc: 0.6684 - val_loss: 0.6323 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6011 - acc: 0.6736 - val_loss: 0.6291 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5984 - acc: 0.6736 - val_loss: 0.6260 - val_acc: 0.6885\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e44040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7702 - acc: 0.4197 - val_loss: 0.8276 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7666 - acc: 0.4249 - val_loss: 0.8231 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7629 - acc: 0.4249 - val_loss: 0.8187 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7593 - acc: 0.4249 - val_loss: 0.8144 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7558 - acc: 0.4301 - val_loss: 0.8101 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7522 - acc: 0.4456 - val_loss: 0.8059 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7487 - acc: 0.4456 - val_loss: 0.8017 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7453 - acc: 0.4456 - val_loss: 0.7974 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7419 - acc: 0.4456 - val_loss: 0.7932 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7386 - acc: 0.4560 - val_loss: 0.7891 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7350 - acc: 0.4715 - val_loss: 0.7849 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7318 - acc: 0.4715 - val_loss: 0.7808 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7286 - acc: 0.4715 - val_loss: 0.7767 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7252 - acc: 0.4870 - val_loss: 0.7728 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7220 - acc: 0.5026 - val_loss: 0.7688 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7188 - acc: 0.5130 - val_loss: 0.7649 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7155 - acc: 0.5181 - val_loss: 0.7610 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7125 - acc: 0.5181 - val_loss: 0.7572 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7092 - acc: 0.5285 - val_loss: 0.7534 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7063 - acc: 0.5337 - val_loss: 0.7496 - val_acc: 0.4918\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1e3820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.9600 - acc: 0.2526 - val_loss: 0.9809 - val_acc: 0.2623\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9547 - acc: 0.2526 - val_loss: 0.9749 - val_acc: 0.2623\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9496 - acc: 0.2526 - val_loss: 0.9689 - val_acc: 0.2623\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9444 - acc: 0.2629 - val_loss: 0.9630 - val_acc: 0.2623\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9391 - acc: 0.2629 - val_loss: 0.9572 - val_acc: 0.2623\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9342 - acc: 0.2474 - val_loss: 0.9513 - val_acc: 0.2623\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9291 - acc: 0.2474 - val_loss: 0.9455 - val_acc: 0.2623\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9241 - acc: 0.2474 - val_loss: 0.9398 - val_acc: 0.2623\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9190 - acc: 0.2474 - val_loss: 0.9341 - val_acc: 0.2623\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9141 - acc: 0.2526 - val_loss: 0.9285 - val_acc: 0.2787\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9092 - acc: 0.2526 - val_loss: 0.9229 - val_acc: 0.2951\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9043 - acc: 0.2526 - val_loss: 0.9174 - val_acc: 0.2951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8995 - acc: 0.2577 - val_loss: 0.9119 - val_acc: 0.2951\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8947 - acc: 0.2629 - val_loss: 0.9064 - val_acc: 0.2951\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8899 - acc: 0.2629 - val_loss: 0.9011 - val_acc: 0.2951\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8852 - acc: 0.2629 - val_loss: 0.8958 - val_acc: 0.2951\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8804 - acc: 0.2680 - val_loss: 0.8905 - val_acc: 0.2951\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8758 - acc: 0.2680 - val_loss: 0.8852 - val_acc: 0.3115\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8713 - acc: 0.2680 - val_loss: 0.8800 - val_acc: 0.3443\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8666 - acc: 0.2680 - val_loss: 0.8748 - val_acc: 0.3443\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac18dee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7000 - acc: 0.5464 - val_loss: 0.6955 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6964 - acc: 0.5515 - val_loss: 0.6918 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6929 - acc: 0.5515 - val_loss: 0.6882 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6895 - acc: 0.5515 - val_loss: 0.6846 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6860 - acc: 0.5515 - val_loss: 0.6811 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6827 - acc: 0.5567 - val_loss: 0.6776 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6793 - acc: 0.5567 - val_loss: 0.6741 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6760 - acc: 0.5619 - val_loss: 0.6707 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6727 - acc: 0.5670 - val_loss: 0.6673 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6696 - acc: 0.5722 - val_loss: 0.6640 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6663 - acc: 0.5773 - val_loss: 0.6607 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6631 - acc: 0.5825 - val_loss: 0.6574 - val_acc: 0.6393\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6600 - acc: 0.5876 - val_loss: 0.6541 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6570 - acc: 0.5773 - val_loss: 0.6509 - val_acc: 0.6393\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6538 - acc: 0.5773 - val_loss: 0.6477 - val_acc: 0.6393\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6508 - acc: 0.5825 - val_loss: 0.6445 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6478 - acc: 0.5876 - val_loss: 0.6414 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6448 - acc: 0.5928 - val_loss: 0.6383 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6418 - acc: 0.5979 - val_loss: 0.6351 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6390 - acc: 0.6134 - val_loss: 0.6320 - val_acc: 0.6721\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41868f310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6570 - acc: 0.6340 - val_loss: 0.6615 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6537 - acc: 0.6495 - val_loss: 0.6577 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6504 - acc: 0.6546 - val_loss: 0.6541 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6474 - acc: 0.6495 - val_loss: 0.6505 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6441 - acc: 0.6546 - val_loss: 0.6470 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6411 - acc: 0.6598 - val_loss: 0.6434 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6381 - acc: 0.6546 - val_loss: 0.6400 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6349 - acc: 0.6598 - val_loss: 0.6365 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6319 - acc: 0.6598 - val_loss: 0.6331 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6290 - acc: 0.6598 - val_loss: 0.6297 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6260 - acc: 0.6753 - val_loss: 0.6264 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6230 - acc: 0.6753 - val_loss: 0.6231 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6201 - acc: 0.6753 - val_loss: 0.6198 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6172 - acc: 0.6753 - val_loss: 0.6166 - val_acc: 0.6885\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6144 - acc: 0.6804 - val_loss: 0.6134 - val_acc: 0.6885\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6116 - acc: 0.6804 - val_loss: 0.6103 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6088 - acc: 0.6856 - val_loss: 0.6072 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6060 - acc: 0.6856 - val_loss: 0.6042 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6033 - acc: 0.6856 - val_loss: 0.6012 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6006 - acc: 0.6907 - val_loss: 0.5982 - val_acc: 0.6885\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa418344700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7831 - acc: 0.4093 - val_loss: 0.7449 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7773 - acc: 0.4093 - val_loss: 0.7386 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7715 - acc: 0.4249 - val_loss: 0.7323 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7659 - acc: 0.4301 - val_loss: 0.7260 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7605 - acc: 0.4352 - val_loss: 0.7199 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7547 - acc: 0.4508 - val_loss: 0.7139 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7493 - acc: 0.4560 - val_loss: 0.7079 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7440 - acc: 0.4560 - val_loss: 0.7020 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7386 - acc: 0.4611 - val_loss: 0.6962 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7336 - acc: 0.4663 - val_loss: 0.6904 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7283 - acc: 0.4663 - val_loss: 0.6848 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7232 - acc: 0.4715 - val_loss: 0.6792 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7183 - acc: 0.4819 - val_loss: 0.6738 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7132 - acc: 0.4819 - val_loss: 0.6684 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7083 - acc: 0.4819 - val_loss: 0.6631 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7036 - acc: 0.5078 - val_loss: 0.6579 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6987 - acc: 0.5233 - val_loss: 0.6527 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6939 - acc: 0.5492 - val_loss: 0.6476 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6895 - acc: 0.5596 - val_loss: 0.6425 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6850 - acc: 0.5803 - val_loss: 0.6375 - val_acc: 0.5574\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4181d2160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7860 - acc: 0.4767 - val_loss: 0.7979 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7800 - acc: 0.4870 - val_loss: 0.7921 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7743 - acc: 0.4870 - val_loss: 0.7865 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7687 - acc: 0.4870 - val_loss: 0.7808 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7632 - acc: 0.4870 - val_loss: 0.7753 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7579 - acc: 0.4870 - val_loss: 0.7698 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7523 - acc: 0.4870 - val_loss: 0.7643 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7470 - acc: 0.4922 - val_loss: 0.7589 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7419 - acc: 0.4974 - val_loss: 0.7536 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7364 - acc: 0.5026 - val_loss: 0.7483 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7313 - acc: 0.5078 - val_loss: 0.7430 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7262 - acc: 0.5078 - val_loss: 0.7378 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7210 - acc: 0.5130 - val_loss: 0.7327 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7160 - acc: 0.5233 - val_loss: 0.7276 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7111 - acc: 0.5233 - val_loss: 0.7225 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7061 - acc: 0.5285 - val_loss: 0.7175 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7015 - acc: 0.5337 - val_loss: 0.7126 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6966 - acc: 0.5389 - val_loss: 0.7078 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6918 - acc: 0.5440 - val_loss: 0.7031 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6873 - acc: 0.5492 - val_loss: 0.6984 - val_acc: 0.5738\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41043f4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7566 - acc: 0.4536 - val_loss: 0.7178 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7507 - acc: 0.4588 - val_loss: 0.7116 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7447 - acc: 0.4742 - val_loss: 0.7055 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7388 - acc: 0.4794 - val_loss: 0.6995 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7333 - acc: 0.4897 - val_loss: 0.6935 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7276 - acc: 0.5052 - val_loss: 0.6875 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7222 - acc: 0.5052 - val_loss: 0.6816 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7167 - acc: 0.5155 - val_loss: 0.6759 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7113 - acc: 0.5258 - val_loss: 0.6702 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7059 - acc: 0.5361 - val_loss: 0.6646 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7010 - acc: 0.5412 - val_loss: 0.6590 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6957 - acc: 0.5464 - val_loss: 0.6536 - val_acc: 0.5574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6906 - acc: 0.5515 - val_loss: 0.6483 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6856 - acc: 0.5567 - val_loss: 0.6431 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6807 - acc: 0.5722 - val_loss: 0.6380 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6760 - acc: 0.5773 - val_loss: 0.6329 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6711 - acc: 0.5825 - val_loss: 0.6280 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6666 - acc: 0.5979 - val_loss: 0.6232 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6617 - acc: 0.6134 - val_loss: 0.6184 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6574 - acc: 0.6134 - val_loss: 0.6137 - val_acc: 0.6885\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b87648b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6535 - acc: 0.6649 - val_loss: 0.6402 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6481 - acc: 0.6753 - val_loss: 0.6344 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6433 - acc: 0.6856 - val_loss: 0.6287 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6383 - acc: 0.7062 - val_loss: 0.6231 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6333 - acc: 0.7113 - val_loss: 0.6176 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6286 - acc: 0.7268 - val_loss: 0.6122 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6237 - acc: 0.7423 - val_loss: 0.6068 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6192 - acc: 0.7526 - val_loss: 0.6016 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6146 - acc: 0.7577 - val_loss: 0.5965 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6101 - acc: 0.7577 - val_loss: 0.5915 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6056 - acc: 0.7732 - val_loss: 0.5866 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6014 - acc: 0.7784 - val_loss: 0.5817 - val_acc: 0.7541\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5971 - acc: 0.7784 - val_loss: 0.5770 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5929 - acc: 0.7784 - val_loss: 0.5724 - val_acc: 0.7705\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5888 - acc: 0.7784 - val_loss: 0.5679 - val_acc: 0.7705\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5849 - acc: 0.7784 - val_loss: 0.5635 - val_acc: 0.7705\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5808 - acc: 0.7835 - val_loss: 0.5592 - val_acc: 0.7705\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5768 - acc: 0.7887 - val_loss: 0.5549 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5733 - acc: 0.7990 - val_loss: 0.5507 - val_acc: 0.7869\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5694 - acc: 0.7990 - val_loss: 0.5466 - val_acc: 0.7869\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b82ba4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7263 - acc: 0.4639 - val_loss: 0.6607 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7209 - acc: 0.4742 - val_loss: 0.6555 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7155 - acc: 0.4948 - val_loss: 0.6505 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7101 - acc: 0.5103 - val_loss: 0.6455 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7051 - acc: 0.5361 - val_loss: 0.6405 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7000 - acc: 0.5412 - val_loss: 0.6356 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6950 - acc: 0.5670 - val_loss: 0.6307 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6899 - acc: 0.5773 - val_loss: 0.6260 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6848 - acc: 0.5979 - val_loss: 0.6213 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6801 - acc: 0.6134 - val_loss: 0.6166 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6752 - acc: 0.6186 - val_loss: 0.6121 - val_acc: 0.7541\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6706 - acc: 0.6289 - val_loss: 0.6076 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6659 - acc: 0.6340 - val_loss: 0.6032 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6613 - acc: 0.6546 - val_loss: 0.5988 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6566 - acc: 0.6495 - val_loss: 0.5946 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6524 - acc: 0.6546 - val_loss: 0.5903 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6479 - acc: 0.6649 - val_loss: 0.5862 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6437 - acc: 0.6701 - val_loss: 0.5822 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6393 - acc: 0.6753 - val_loss: 0.5782 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6351 - acc: 0.6804 - val_loss: 0.5743 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3947e4670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6956 - acc: 0.5492 - val_loss: 0.7009 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6876 - acc: 0.5648 - val_loss: 0.6929 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6800 - acc: 0.5907 - val_loss: 0.6851 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6726 - acc: 0.6010 - val_loss: 0.6774 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6651 - acc: 0.6010 - val_loss: 0.6699 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6579 - acc: 0.6218 - val_loss: 0.6625 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6507 - acc: 0.6321 - val_loss: 0.6553 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6439 - acc: 0.6425 - val_loss: 0.6481 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6369 - acc: 0.6632 - val_loss: 0.6411 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6303 - acc: 0.6684 - val_loss: 0.6343 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6235 - acc: 0.6736 - val_loss: 0.6275 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6173 - acc: 0.6788 - val_loss: 0.6208 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6108 - acc: 0.6995 - val_loss: 0.6143 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6049 - acc: 0.7047 - val_loss: 0.6079 - val_acc: 0.6393\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5986 - acc: 0.7202 - val_loss: 0.6017 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5927 - acc: 0.7358 - val_loss: 0.5956 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5869 - acc: 0.7461 - val_loss: 0.5897 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5812 - acc: 0.7565 - val_loss: 0.5839 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5759 - acc: 0.7617 - val_loss: 0.5782 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5702 - acc: 0.7617 - val_loss: 0.5727 - val_acc: 0.7541\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e0d670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.7259 - acc: 0.4404 - val_loss: 0.7091 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7179 - acc: 0.4560 - val_loss: 0.7002 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7106 - acc: 0.4870 - val_loss: 0.6914 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7028 - acc: 0.5389 - val_loss: 0.6829 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6958 - acc: 0.5389 - val_loss: 0.6744 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6886 - acc: 0.5440 - val_loss: 0.6662 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6816 - acc: 0.5544 - val_loss: 0.6582 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6747 - acc: 0.5596 - val_loss: 0.6504 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6680 - acc: 0.5803 - val_loss: 0.6428 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6612 - acc: 0.6062 - val_loss: 0.6353 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6548 - acc: 0.6166 - val_loss: 0.6280 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6484 - acc: 0.6218 - val_loss: 0.6207 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6424 - acc: 0.6321 - val_loss: 0.6136 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6360 - acc: 0.6373 - val_loss: 0.6068 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6300 - acc: 0.6477 - val_loss: 0.6000 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6240 - acc: 0.6477 - val_loss: 0.5935 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6183 - acc: 0.6632 - val_loss: 0.5870 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6128 - acc: 0.6736 - val_loss: 0.5806 - val_acc: 0.7541\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6071 - acc: 0.6943 - val_loss: 0.5745 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6018 - acc: 0.7047 - val_loss: 0.5685 - val_acc: 0.7705\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc313160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6845 - acc: 0.5464 - val_loss: 0.7231 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6767 - acc: 0.5670 - val_loss: 0.7145 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6694 - acc: 0.5773 - val_loss: 0.7062 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6620 - acc: 0.5979 - val_loss: 0.6981 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6548 - acc: 0.6134 - val_loss: 0.6902 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6478 - acc: 0.6186 - val_loss: 0.6824 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6409 - acc: 0.6392 - val_loss: 0.6748 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6343 - acc: 0.6392 - val_loss: 0.6672 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6276 - acc: 0.6495 - val_loss: 0.6598 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6215 - acc: 0.6546 - val_loss: 0.6525 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6150 - acc: 0.6907 - val_loss: 0.6455 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6088 - acc: 0.7320 - val_loss: 0.6386 - val_acc: 0.6721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6029 - acc: 0.7320 - val_loss: 0.6319 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5969 - acc: 0.7423 - val_loss: 0.6253 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5911 - acc: 0.7423 - val_loss: 0.6188 - val_acc: 0.6885\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5855 - acc: 0.7526 - val_loss: 0.6125 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5801 - acc: 0.7629 - val_loss: 0.6064 - val_acc: 0.7213\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5747 - acc: 0.7732 - val_loss: 0.6004 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5695 - acc: 0.7835 - val_loss: 0.5945 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5644 - acc: 0.7732 - val_loss: 0.5888 - val_acc: 0.7541\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b81a6940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.7516 - acc: 0.3402 - val_loss: 0.7499 - val_acc: 0.3443\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7436 - acc: 0.3814 - val_loss: 0.7413 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7356 - acc: 0.3969 - val_loss: 0.7329 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7281 - acc: 0.4072 - val_loss: 0.7246 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7205 - acc: 0.4381 - val_loss: 0.7165 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7132 - acc: 0.4691 - val_loss: 0.7085 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7057 - acc: 0.5000 - val_loss: 0.7007 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6988 - acc: 0.5206 - val_loss: 0.6929 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6919 - acc: 0.5412 - val_loss: 0.6854 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6848 - acc: 0.5515 - val_loss: 0.6780 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6784 - acc: 0.5619 - val_loss: 0.6708 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6715 - acc: 0.5825 - val_loss: 0.6639 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6651 - acc: 0.6186 - val_loss: 0.6569 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6590 - acc: 0.6237 - val_loss: 0.6502 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6528 - acc: 0.6392 - val_loss: 0.6436 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6468 - acc: 0.6495 - val_loss: 0.6372 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6408 - acc: 0.6649 - val_loss: 0.6309 - val_acc: 0.7213\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6351 - acc: 0.6804 - val_loss: 0.6248 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6293 - acc: 0.6907 - val_loss: 0.6188 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6239 - acc: 0.7062 - val_loss: 0.6129 - val_acc: 0.7213\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4202203a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6633 - acc: 0.6031 - val_loss: 0.6664 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6568 - acc: 0.5979 - val_loss: 0.6593 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6500 - acc: 0.6134 - val_loss: 0.6523 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6434 - acc: 0.6237 - val_loss: 0.6455 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6372 - acc: 0.6237 - val_loss: 0.6388 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6311 - acc: 0.6340 - val_loss: 0.6322 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6247 - acc: 0.6546 - val_loss: 0.6258 - val_acc: 0.6393\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6190 - acc: 0.6701 - val_loss: 0.6195 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6132 - acc: 0.6804 - val_loss: 0.6134 - val_acc: 0.7049\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6073 - acc: 0.6907 - val_loss: 0.6075 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6018 - acc: 0.7062 - val_loss: 0.6017 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5962 - acc: 0.7062 - val_loss: 0.5960 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5910 - acc: 0.7062 - val_loss: 0.5905 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5856 - acc: 0.7062 - val_loss: 0.5851 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5806 - acc: 0.7113 - val_loss: 0.5799 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5754 - acc: 0.7113 - val_loss: 0.5747 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5707 - acc: 0.7371 - val_loss: 0.5697 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5659 - acc: 0.7371 - val_loss: 0.5648 - val_acc: 0.7541\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5611 - acc: 0.7423 - val_loss: 0.5601 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5567 - acc: 0.7526 - val_loss: 0.5553 - val_acc: 0.7541\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac18d820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7704 - acc: 0.2539 - val_loss: 0.7538 - val_acc: 0.3279\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7582 - acc: 0.2591 - val_loss: 0.7417 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7470 - acc: 0.2953 - val_loss: 0.7299 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7360 - acc: 0.3368 - val_loss: 0.7183 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7252 - acc: 0.3731 - val_loss: 0.7070 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7147 - acc: 0.4508 - val_loss: 0.6961 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7046 - acc: 0.4974 - val_loss: 0.6854 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6942 - acc: 0.5233 - val_loss: 0.6751 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6848 - acc: 0.5544 - val_loss: 0.6650 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6752 - acc: 0.6062 - val_loss: 0.6551 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6658 - acc: 0.6269 - val_loss: 0.6456 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6570 - acc: 0.6373 - val_loss: 0.6363 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6480 - acc: 0.6528 - val_loss: 0.6274 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6395 - acc: 0.6632 - val_loss: 0.6187 - val_acc: 0.7705\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6310 - acc: 0.6943 - val_loss: 0.6102 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6232 - acc: 0.7047 - val_loss: 0.6018 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6153 - acc: 0.7150 - val_loss: 0.5938 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6076 - acc: 0.7358 - val_loss: 0.5859 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6004 - acc: 0.7565 - val_loss: 0.5783 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5928 - acc: 0.7668 - val_loss: 0.5710 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b43ddee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6898 - acc: 0.5803 - val_loss: 0.6883 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6793 - acc: 0.6114 - val_loss: 0.6768 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6690 - acc: 0.6321 - val_loss: 0.6657 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6591 - acc: 0.6321 - val_loss: 0.6549 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6495 - acc: 0.6425 - val_loss: 0.6444 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6402 - acc: 0.6528 - val_loss: 0.6341 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6313 - acc: 0.6839 - val_loss: 0.6240 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6223 - acc: 0.7202 - val_loss: 0.6143 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6138 - acc: 0.7513 - val_loss: 0.6048 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6055 - acc: 0.7720 - val_loss: 0.5956 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5976 - acc: 0.7876 - val_loss: 0.5867 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5895 - acc: 0.7876 - val_loss: 0.5781 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5822 - acc: 0.7927 - val_loss: 0.5698 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5747 - acc: 0.7979 - val_loss: 0.5617 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5677 - acc: 0.7979 - val_loss: 0.5539 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5605 - acc: 0.8083 - val_loss: 0.5464 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5540 - acc: 0.8238 - val_loss: 0.5390 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5476 - acc: 0.8238 - val_loss: 0.5318 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5413 - acc: 0.8290 - val_loss: 0.5249 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5354 - acc: 0.8290 - val_loss: 0.5183 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc1e9c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7229 - acc: 0.4742 - val_loss: 0.7075 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7118 - acc: 0.4845 - val_loss: 0.6952 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7004 - acc: 0.5155 - val_loss: 0.6831 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6896 - acc: 0.5515 - val_loss: 0.6714 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6788 - acc: 0.5825 - val_loss: 0.6603 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6691 - acc: 0.6031 - val_loss: 0.6493 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6587 - acc: 0.6237 - val_loss: 0.6388 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6491 - acc: 0.6546 - val_loss: 0.6286 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6397 - acc: 0.6701 - val_loss: 0.6186 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6307 - acc: 0.6856 - val_loss: 0.6089 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6216 - acc: 0.7010 - val_loss: 0.5996 - val_acc: 0.7541\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6131 - acc: 0.7062 - val_loss: 0.5905 - val_acc: 0.8033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6046 - acc: 0.7216 - val_loss: 0.5817 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5965 - acc: 0.7320 - val_loss: 0.5732 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5886 - acc: 0.7320 - val_loss: 0.5649 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5809 - acc: 0.7474 - val_loss: 0.5569 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5735 - acc: 0.7474 - val_loss: 0.5491 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5662 - acc: 0.7577 - val_loss: 0.5415 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5592 - acc: 0.7577 - val_loss: 0.5342 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5525 - acc: 0.7835 - val_loss: 0.5272 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc0200d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6910 - acc: 0.5670 - val_loss: 0.6778 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6810 - acc: 0.5825 - val_loss: 0.6663 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6714 - acc: 0.6134 - val_loss: 0.6552 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6621 - acc: 0.6546 - val_loss: 0.6445 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6530 - acc: 0.6701 - val_loss: 0.6341 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6443 - acc: 0.6804 - val_loss: 0.6240 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6358 - acc: 0.6804 - val_loss: 0.6142 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6273 - acc: 0.6856 - val_loss: 0.6046 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6192 - acc: 0.6907 - val_loss: 0.5953 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6112 - acc: 0.6959 - val_loss: 0.5862 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6036 - acc: 0.7268 - val_loss: 0.5775 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5958 - acc: 0.7423 - val_loss: 0.5691 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5888 - acc: 0.7474 - val_loss: 0.5609 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5814 - acc: 0.7320 - val_loss: 0.5530 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5747 - acc: 0.7320 - val_loss: 0.5453 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5680 - acc: 0.7577 - val_loss: 0.5379 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5619 - acc: 0.7680 - val_loss: 0.5307 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5555 - acc: 0.7784 - val_loss: 0.5238 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5494 - acc: 0.7835 - val_loss: 0.5172 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5436 - acc: 0.7835 - val_loss: 0.5109 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e719d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6743 - acc: 0.5258 - val_loss: 0.6716 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6633 - acc: 0.5979 - val_loss: 0.6594 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6528 - acc: 0.6289 - val_loss: 0.6477 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6424 - acc: 0.6495 - val_loss: 0.6363 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6326 - acc: 0.6907 - val_loss: 0.6251 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6227 - acc: 0.7165 - val_loss: 0.6144 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6136 - acc: 0.7423 - val_loss: 0.6040 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6047 - acc: 0.7526 - val_loss: 0.5940 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5958 - acc: 0.7732 - val_loss: 0.5844 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5874 - acc: 0.7887 - val_loss: 0.5750 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5791 - acc: 0.7835 - val_loss: 0.5660 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5714 - acc: 0.7887 - val_loss: 0.5574 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5637 - acc: 0.8041 - val_loss: 0.5490 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5563 - acc: 0.8041 - val_loss: 0.5410 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5493 - acc: 0.8041 - val_loss: 0.5333 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5425 - acc: 0.8196 - val_loss: 0.5259 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5359 - acc: 0.8196 - val_loss: 0.5188 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5295 - acc: 0.8299 - val_loss: 0.5119 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5235 - acc: 0.8299 - val_loss: 0.5054 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5173 - acc: 0.8402 - val_loss: 0.4990 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4becbb040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.9508 - acc: 0.4922 - val_loss: 1.0475 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9348 - acc: 0.4974 - val_loss: 1.0297 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9194 - acc: 0.4974 - val_loss: 1.0121 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9049 - acc: 0.4974 - val_loss: 0.9951 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8903 - acc: 0.4974 - val_loss: 0.9786 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8762 - acc: 0.4974 - val_loss: 0.9624 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8629 - acc: 0.5026 - val_loss: 0.9467 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8492 - acc: 0.5078 - val_loss: 0.9316 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8358 - acc: 0.5130 - val_loss: 0.9167 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8234 - acc: 0.5181 - val_loss: 0.9021 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8107 - acc: 0.5233 - val_loss: 0.8878 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7983 - acc: 0.5285 - val_loss: 0.8737 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7870 - acc: 0.5389 - val_loss: 0.8599 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7744 - acc: 0.5440 - val_loss: 0.8466 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7633 - acc: 0.5440 - val_loss: 0.8335 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7527 - acc: 0.5544 - val_loss: 0.8208 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7415 - acc: 0.5544 - val_loss: 0.8085 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7313 - acc: 0.5596 - val_loss: 0.7965 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7204 - acc: 0.5699 - val_loss: 0.7851 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7116 - acc: 0.5751 - val_loss: 0.7739 - val_acc: 0.5410\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b82ba160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.8654 - acc: 0.4767 - val_loss: 0.8042 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8487 - acc: 0.4870 - val_loss: 0.7889 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8339 - acc: 0.4922 - val_loss: 0.7742 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8185 - acc: 0.4922 - val_loss: 0.7598 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8039 - acc: 0.4974 - val_loss: 0.7458 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7901 - acc: 0.5026 - val_loss: 0.7327 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7759 - acc: 0.5078 - val_loss: 0.7200 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7622 - acc: 0.5233 - val_loss: 0.7077 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7495 - acc: 0.5389 - val_loss: 0.6957 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7365 - acc: 0.5440 - val_loss: 0.6839 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7237 - acc: 0.5440 - val_loss: 0.6724 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7121 - acc: 0.5596 - val_loss: 0.6613 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6998 - acc: 0.5699 - val_loss: 0.6506 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6887 - acc: 0.5907 - val_loss: 0.6400 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6778 - acc: 0.5959 - val_loss: 0.6300 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6671 - acc: 0.6166 - val_loss: 0.6205 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6564 - acc: 0.6321 - val_loss: 0.6112 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6467 - acc: 0.6321 - val_loss: 0.6022 - val_acc: 0.6393\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6375 - acc: 0.6321 - val_loss: 0.5934 - val_acc: 0.6393\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6283 - acc: 0.6321 - val_loss: 0.5851 - val_acc: 0.6557\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4105ad8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7811 - acc: 0.4330 - val_loss: 0.7932 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7694 - acc: 0.4381 - val_loss: 0.7809 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7590 - acc: 0.4433 - val_loss: 0.7688 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7485 - acc: 0.4485 - val_loss: 0.7573 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7386 - acc: 0.4485 - val_loss: 0.7461 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7290 - acc: 0.4485 - val_loss: 0.7353 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7192 - acc: 0.4485 - val_loss: 0.7248 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7105 - acc: 0.4691 - val_loss: 0.7146 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7019 - acc: 0.4691 - val_loss: 0.7049 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6934 - acc: 0.4742 - val_loss: 0.6955 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6853 - acc: 0.4845 - val_loss: 0.6864 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6777 - acc: 0.4897 - val_loss: 0.6776 - val_acc: 0.5082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6701 - acc: 0.4948 - val_loss: 0.6690 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6625 - acc: 0.5000 - val_loss: 0.6607 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6556 - acc: 0.5103 - val_loss: 0.6526 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6487 - acc: 0.5309 - val_loss: 0.6448 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6422 - acc: 0.5361 - val_loss: 0.6373 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6353 - acc: 0.5412 - val_loss: 0.6300 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6289 - acc: 0.5515 - val_loss: 0.6231 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6229 - acc: 0.5567 - val_loss: 0.6165 - val_acc: 0.6230\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41868b550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6486 - acc: 0.5876 - val_loss: 0.6180 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6411 - acc: 0.5876 - val_loss: 0.6100 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6336 - acc: 0.5979 - val_loss: 0.6022 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6262 - acc: 0.5979 - val_loss: 0.5946 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6195 - acc: 0.6082 - val_loss: 0.5871 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6127 - acc: 0.6237 - val_loss: 0.5798 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6062 - acc: 0.6340 - val_loss: 0.5728 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5996 - acc: 0.6495 - val_loss: 0.5659 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5933 - acc: 0.6546 - val_loss: 0.5590 - val_acc: 0.7049\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5873 - acc: 0.6649 - val_loss: 0.5524 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5813 - acc: 0.6649 - val_loss: 0.5460 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5756 - acc: 0.6649 - val_loss: 0.5398 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5700 - acc: 0.6649 - val_loss: 0.5336 - val_acc: 0.7541\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5648 - acc: 0.6649 - val_loss: 0.5276 - val_acc: 0.7705\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5598 - acc: 0.6753 - val_loss: 0.5219 - val_acc: 0.7705\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5544 - acc: 0.6856 - val_loss: 0.5164 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5497 - acc: 0.6907 - val_loss: 0.5111 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5446 - acc: 0.6959 - val_loss: 0.5059 - val_acc: 0.7869\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5401 - acc: 0.6959 - val_loss: 0.5007 - val_acc: 0.7869\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5355 - acc: 0.6959 - val_loss: 0.4955 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4482021f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6750 - acc: 0.6237 - val_loss: 0.6800 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6703 - acc: 0.6237 - val_loss: 0.6755 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6659 - acc: 0.6443 - val_loss: 0.6709 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6615 - acc: 0.6443 - val_loss: 0.6664 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6570 - acc: 0.6649 - val_loss: 0.6619 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6526 - acc: 0.6701 - val_loss: 0.6573 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6485 - acc: 0.6804 - val_loss: 0.6528 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6439 - acc: 0.6804 - val_loss: 0.6484 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6395 - acc: 0.6804 - val_loss: 0.6440 - val_acc: 0.7049\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6352 - acc: 0.6856 - val_loss: 0.6396 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6309 - acc: 0.6907 - val_loss: 0.6353 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6266 - acc: 0.6959 - val_loss: 0.6311 - val_acc: 0.7541\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6222 - acc: 0.7062 - val_loss: 0.6269 - val_acc: 0.7541\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6180 - acc: 0.7062 - val_loss: 0.6229 - val_acc: 0.7541\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6139 - acc: 0.7165 - val_loss: 0.6188 - val_acc: 0.7705\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6095 - acc: 0.7165 - val_loss: 0.6148 - val_acc: 0.7705\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6054 - acc: 0.7216 - val_loss: 0.6105 - val_acc: 0.7705\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6011 - acc: 0.7268 - val_loss: 0.6062 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5969 - acc: 0.7371 - val_loss: 0.6019 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5928 - acc: 0.7371 - val_loss: 0.5975 - val_acc: 0.7705\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410567820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6325 - acc: 0.6528 - val_loss: 0.6467 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6189 - acc: 0.6632 - val_loss: 0.6312 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6067 - acc: 0.6632 - val_loss: 0.6167 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5950 - acc: 0.6736 - val_loss: 0.6032 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5835 - acc: 0.6788 - val_loss: 0.5906 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5726 - acc: 0.6943 - val_loss: 0.5786 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5627 - acc: 0.7202 - val_loss: 0.5670 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5527 - acc: 0.7254 - val_loss: 0.5562 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5433 - acc: 0.7358 - val_loss: 0.5461 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5345 - acc: 0.7565 - val_loss: 0.5365 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5262 - acc: 0.7668 - val_loss: 0.5273 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5179 - acc: 0.7720 - val_loss: 0.5186 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5105 - acc: 0.7720 - val_loss: 0.5104 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5028 - acc: 0.7824 - val_loss: 0.5029 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4959 - acc: 0.7824 - val_loss: 0.4958 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4892 - acc: 0.7824 - val_loss: 0.4892 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4830 - acc: 0.7876 - val_loss: 0.4828 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4769 - acc: 0.7876 - val_loss: 0.4768 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4714 - acc: 0.7927 - val_loss: 0.4712 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4659 - acc: 0.7927 - val_loss: 0.4661 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410096ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7081 - acc: 0.5181 - val_loss: 0.6705 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6949 - acc: 0.5181 - val_loss: 0.6574 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6816 - acc: 0.5285 - val_loss: 0.6450 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6692 - acc: 0.5544 - val_loss: 0.6329 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6573 - acc: 0.5803 - val_loss: 0.6211 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6454 - acc: 0.6166 - val_loss: 0.6099 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6344 - acc: 0.6269 - val_loss: 0.5991 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6238 - acc: 0.6373 - val_loss: 0.5887 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6130 - acc: 0.6477 - val_loss: 0.5788 - val_acc: 0.7049\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6034 - acc: 0.6684 - val_loss: 0.5692 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5932 - acc: 0.6736 - val_loss: 0.5601 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5843 - acc: 0.6839 - val_loss: 0.5514 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5755 - acc: 0.6995 - val_loss: 0.5432 - val_acc: 0.7377\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5669 - acc: 0.7150 - val_loss: 0.5353 - val_acc: 0.7541\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5584 - acc: 0.7202 - val_loss: 0.5277 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5504 - acc: 0.7306 - val_loss: 0.5205 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5427 - acc: 0.7306 - val_loss: 0.5136 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5351 - acc: 0.7306 - val_loss: 0.5069 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5278 - acc: 0.7461 - val_loss: 0.5005 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5210 - acc: 0.7668 - val_loss: 0.4942 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b80b0310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.8070 - acc: 0.4845 - val_loss: 0.8884 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7893 - acc: 0.5052 - val_loss: 0.8671 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7722 - acc: 0.5103 - val_loss: 0.8466 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7560 - acc: 0.5155 - val_loss: 0.8270 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7401 - acc: 0.5258 - val_loss: 0.8081 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7251 - acc: 0.5412 - val_loss: 0.7899 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7106 - acc: 0.5464 - val_loss: 0.7723 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6960 - acc: 0.5722 - val_loss: 0.7553 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6827 - acc: 0.5825 - val_loss: 0.7387 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6691 - acc: 0.5928 - val_loss: 0.7227 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6566 - acc: 0.5979 - val_loss: 0.7073 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6442 - acc: 0.5979 - val_loss: 0.6925 - val_acc: 0.5902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6325 - acc: 0.6082 - val_loss: 0.6783 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6208 - acc: 0.6237 - val_loss: 0.6646 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6100 - acc: 0.6289 - val_loss: 0.6515 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5987 - acc: 0.6443 - val_loss: 0.6390 - val_acc: 0.6557\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5888 - acc: 0.6546 - val_loss: 0.6271 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5786 - acc: 0.6701 - val_loss: 0.6157 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5696 - acc: 0.6701 - val_loss: 0.6046 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5601 - acc: 0.6856 - val_loss: 0.5939 - val_acc: 0.6885\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b8133670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.7632 - acc: 0.5412 - val_loss: 0.7850 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7457 - acc: 0.5515 - val_loss: 0.7617 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7287 - acc: 0.5567 - val_loss: 0.7396 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7129 - acc: 0.5619 - val_loss: 0.7183 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6976 - acc: 0.5722 - val_loss: 0.6977 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6833 - acc: 0.5928 - val_loss: 0.6779 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6690 - acc: 0.6082 - val_loss: 0.6590 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6558 - acc: 0.6134 - val_loss: 0.6408 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6426 - acc: 0.6289 - val_loss: 0.6238 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6305 - acc: 0.6237 - val_loss: 0.6077 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6184 - acc: 0.6289 - val_loss: 0.5924 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6080 - acc: 0.6546 - val_loss: 0.5780 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5968 - acc: 0.6546 - val_loss: 0.5645 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5868 - acc: 0.6701 - val_loss: 0.5519 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5775 - acc: 0.6753 - val_loss: 0.5399 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5679 - acc: 0.6907 - val_loss: 0.5287 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5591 - acc: 0.7010 - val_loss: 0.5179 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5507 - acc: 0.7062 - val_loss: 0.5077 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5429 - acc: 0.7113 - val_loss: 0.4981 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5350 - acc: 0.7165 - val_loss: 0.4892 - val_acc: 0.7705\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c10084c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.8006 - acc: 0.4742 - val_loss: 0.7778 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7834 - acc: 0.4794 - val_loss: 0.7630 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7675 - acc: 0.4794 - val_loss: 0.7489 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7521 - acc: 0.4845 - val_loss: 0.7355 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7370 - acc: 0.5052 - val_loss: 0.7227 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7230 - acc: 0.5155 - val_loss: 0.7102 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7093 - acc: 0.5309 - val_loss: 0.6983 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6966 - acc: 0.5412 - val_loss: 0.6868 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6843 - acc: 0.5515 - val_loss: 0.6759 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6723 - acc: 0.5670 - val_loss: 0.6654 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6609 - acc: 0.5825 - val_loss: 0.6552 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6505 - acc: 0.5928 - val_loss: 0.6454 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6403 - acc: 0.6031 - val_loss: 0.6361 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6301 - acc: 0.6082 - val_loss: 0.6272 - val_acc: 0.6393\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6206 - acc: 0.6237 - val_loss: 0.6186 - val_acc: 0.6393\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6116 - acc: 0.6134 - val_loss: 0.6102 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6031 - acc: 0.6237 - val_loss: 0.6021 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5945 - acc: 0.6237 - val_loss: 0.5944 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5869 - acc: 0.6546 - val_loss: 0.5868 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5790 - acc: 0.6701 - val_loss: 0.5796 - val_acc: 0.6721\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4becf39d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8754 - acc: 0.4249 - val_loss: 0.9547 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8410 - acc: 0.4404 - val_loss: 0.9123 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8090 - acc: 0.4715 - val_loss: 0.8724 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7818 - acc: 0.5078 - val_loss: 0.8342 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7540 - acc: 0.5337 - val_loss: 0.7983 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7274 - acc: 0.5440 - val_loss: 0.7650 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7024 - acc: 0.5751 - val_loss: 0.7334 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6792 - acc: 0.5803 - val_loss: 0.7039 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6575 - acc: 0.6010 - val_loss: 0.6763 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6369 - acc: 0.6477 - val_loss: 0.6507 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6174 - acc: 0.6736 - val_loss: 0.6269 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6004 - acc: 0.6788 - val_loss: 0.6049 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5837 - acc: 0.7150 - val_loss: 0.5847 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5684 - acc: 0.7202 - val_loss: 0.5660 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5540 - acc: 0.7358 - val_loss: 0.5490 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5410 - acc: 0.7513 - val_loss: 0.5332 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5295 - acc: 0.7565 - val_loss: 0.5186 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5179 - acc: 0.7772 - val_loss: 0.5051 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5077 - acc: 0.7824 - val_loss: 0.4927 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4977 - acc: 0.7876 - val_loss: 0.4814 - val_acc: 0.7705\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc020790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.7111 - acc: 0.5803 - val_loss: 0.5696 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6879 - acc: 0.5907 - val_loss: 0.5526 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6658 - acc: 0.5959 - val_loss: 0.5371 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6460 - acc: 0.6114 - val_loss: 0.5226 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6253 - acc: 0.6218 - val_loss: 0.5093 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6094 - acc: 0.6580 - val_loss: 0.4968 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5919 - acc: 0.6632 - val_loss: 0.4853 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5760 - acc: 0.6684 - val_loss: 0.4746 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5620 - acc: 0.6839 - val_loss: 0.4647 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5481 - acc: 0.6891 - val_loss: 0.4557 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5349 - acc: 0.7098 - val_loss: 0.4473 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5226 - acc: 0.7513 - val_loss: 0.4394 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5115 - acc: 0.7565 - val_loss: 0.4320 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5008 - acc: 0.7668 - val_loss: 0.4251 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4913 - acc: 0.7824 - val_loss: 0.4186 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4824 - acc: 0.7927 - val_loss: 0.4126 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4732 - acc: 0.7979 - val_loss: 0.4070 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4651 - acc: 0.8031 - val_loss: 0.4017 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4577 - acc: 0.7979 - val_loss: 0.3967 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4498 - acc: 0.8135 - val_loss: 0.3921 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa474704940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.8504 - acc: 0.4021 - val_loss: 0.8777 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8162 - acc: 0.4381 - val_loss: 0.8433 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7847 - acc: 0.4536 - val_loss: 0.8112 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7547 - acc: 0.4845 - val_loss: 0.7812 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7270 - acc: 0.5155 - val_loss: 0.7528 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7007 - acc: 0.5515 - val_loss: 0.7263 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6753 - acc: 0.5619 - val_loss: 0.7018 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6519 - acc: 0.5979 - val_loss: 0.6789 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6294 - acc: 0.6237 - val_loss: 0.6575 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6096 - acc: 0.6289 - val_loss: 0.6376 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5904 - acc: 0.6546 - val_loss: 0.6193 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5729 - acc: 0.6753 - val_loss: 0.6026 - val_acc: 0.7049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5561 - acc: 0.7010 - val_loss: 0.5872 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5408 - acc: 0.7268 - val_loss: 0.5730 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5267 - acc: 0.7526 - val_loss: 0.5597 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5134 - acc: 0.7577 - val_loss: 0.5474 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5012 - acc: 0.7784 - val_loss: 0.5361 - val_acc: 0.7213\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4906 - acc: 0.7887 - val_loss: 0.5257 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4802 - acc: 0.7990 - val_loss: 0.5160 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4701 - acc: 0.8144 - val_loss: 0.5070 - val_acc: 0.7213\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc1e9700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0331 - acc: 0.2526 - val_loss: 1.0192 - val_acc: 0.1803\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9936 - acc: 0.2629 - val_loss: 0.9743 - val_acc: 0.2131\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9562 - acc: 0.2784 - val_loss: 0.9318 - val_acc: 0.2295\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9201 - acc: 0.3041 - val_loss: 0.8921 - val_acc: 0.2787\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8871 - acc: 0.3402 - val_loss: 0.8545 - val_acc: 0.3443\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8545 - acc: 0.3814 - val_loss: 0.8198 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8249 - acc: 0.4175 - val_loss: 0.7873 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7943 - acc: 0.4639 - val_loss: 0.7570 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7691 - acc: 0.4742 - val_loss: 0.7284 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7428 - acc: 0.5052 - val_loss: 0.7018 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7196 - acc: 0.5464 - val_loss: 0.6771 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6971 - acc: 0.5722 - val_loss: 0.6540 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6767 - acc: 0.6186 - val_loss: 0.6327 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6571 - acc: 0.6546 - val_loss: 0.6128 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6395 - acc: 0.6907 - val_loss: 0.5943 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6216 - acc: 0.7320 - val_loss: 0.5773 - val_acc: 0.7705\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6060 - acc: 0.7320 - val_loss: 0.5615 - val_acc: 0.7705\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5911 - acc: 0.7423 - val_loss: 0.5467 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5775 - acc: 0.7474 - val_loss: 0.5328 - val_acc: 0.7869\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5648 - acc: 0.7629 - val_loss: 0.5199 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beca4160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7893 - acc: 0.4330 - val_loss: 0.7883 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7638 - acc: 0.4691 - val_loss: 0.7638 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7418 - acc: 0.5206 - val_loss: 0.7407 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7199 - acc: 0.5464 - val_loss: 0.7185 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6990 - acc: 0.5722 - val_loss: 0.6971 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6803 - acc: 0.5825 - val_loss: 0.6768 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6621 - acc: 0.6031 - val_loss: 0.6574 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6447 - acc: 0.6134 - val_loss: 0.6390 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6287 - acc: 0.6186 - val_loss: 0.6219 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6128 - acc: 0.6443 - val_loss: 0.6059 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5983 - acc: 0.6701 - val_loss: 0.5907 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5848 - acc: 0.6856 - val_loss: 0.5765 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5720 - acc: 0.7010 - val_loss: 0.5630 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5592 - acc: 0.7165 - val_loss: 0.5504 - val_acc: 0.6885\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5473 - acc: 0.7165 - val_loss: 0.5386 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5366 - acc: 0.7268 - val_loss: 0.5276 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5260 - acc: 0.7320 - val_loss: 0.5171 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5160 - acc: 0.7423 - val_loss: 0.5072 - val_acc: 0.7869\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5067 - acc: 0.7629 - val_loss: 0.4978 - val_acc: 0.7869\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4980 - acc: 0.7680 - val_loss: 0.4888 - val_acc: 0.7869\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b4428a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7192 - acc: 0.5648 - val_loss: 0.6890 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6845 - acc: 0.5959 - val_loss: 0.6562 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6518 - acc: 0.6062 - val_loss: 0.6262 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6209 - acc: 0.6580 - val_loss: 0.5990 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5935 - acc: 0.6736 - val_loss: 0.5740 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5701 - acc: 0.6736 - val_loss: 0.5510 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5462 - acc: 0.7098 - val_loss: 0.5302 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5259 - acc: 0.7306 - val_loss: 0.5114 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5078 - acc: 0.7565 - val_loss: 0.4944 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4911 - acc: 0.7772 - val_loss: 0.4792 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4762 - acc: 0.7927 - val_loss: 0.4657 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4619 - acc: 0.7979 - val_loss: 0.4537 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4500 - acc: 0.8135 - val_loss: 0.4427 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4385 - acc: 0.8187 - val_loss: 0.4326 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4281 - acc: 0.8290 - val_loss: 0.4235 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4188 - acc: 0.8342 - val_loss: 0.4153 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4106 - acc: 0.8342 - val_loss: 0.4078 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4024 - acc: 0.8394 - val_loss: 0.4012 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3955 - acc: 0.8394 - val_loss: 0.3952 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3884 - acc: 0.8446 - val_loss: 0.3899 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bedf64c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.9137 - acc: 0.2746 - val_loss: 0.9517 - val_acc: 0.2623\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8676 - acc: 0.3212 - val_loss: 0.8990 - val_acc: 0.2787\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8292 - acc: 0.3575 - val_loss: 0.8494 - val_acc: 0.3443\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7908 - acc: 0.4197 - val_loss: 0.8036 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7547 - acc: 0.4663 - val_loss: 0.7615 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7223 - acc: 0.5078 - val_loss: 0.7229 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6921 - acc: 0.5648 - val_loss: 0.6875 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6649 - acc: 0.6010 - val_loss: 0.6551 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6377 - acc: 0.6373 - val_loss: 0.6259 - val_acc: 0.7049\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6145 - acc: 0.6684 - val_loss: 0.5991 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5922 - acc: 0.7047 - val_loss: 0.5749 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5721 - acc: 0.7306 - val_loss: 0.5528 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5544 - acc: 0.7358 - val_loss: 0.5329 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5385 - acc: 0.7358 - val_loss: 0.5150 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5232 - acc: 0.7513 - val_loss: 0.4990 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5094 - acc: 0.7513 - val_loss: 0.4847 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4970 - acc: 0.7617 - val_loss: 0.4719 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4854 - acc: 0.7668 - val_loss: 0.4604 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4760 - acc: 0.7824 - val_loss: 0.4499 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4657 - acc: 0.7927 - val_loss: 0.4407 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4204d8e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7581 - acc: 0.5052 - val_loss: 0.7303 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7192 - acc: 0.5722 - val_loss: 0.6961 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6845 - acc: 0.6031 - val_loss: 0.6640 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6515 - acc: 0.6546 - val_loss: 0.6339 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6219 - acc: 0.6804 - val_loss: 0.6063 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5936 - acc: 0.6959 - val_loss: 0.5811 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5682 - acc: 0.7423 - val_loss: 0.5581 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5452 - acc: 0.7474 - val_loss: 0.5370 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5234 - acc: 0.7577 - val_loss: 0.5176 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5044 - acc: 0.7938 - val_loss: 0.4998 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4862 - acc: 0.8093 - val_loss: 0.4838 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4700 - acc: 0.8351 - val_loss: 0.4693 - val_acc: 0.7869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4551 - acc: 0.8402 - val_loss: 0.4562 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4416 - acc: 0.8454 - val_loss: 0.4442 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4296 - acc: 0.8454 - val_loss: 0.4333 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4181 - acc: 0.8557 - val_loss: 0.4236 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4081 - acc: 0.8557 - val_loss: 0.4148 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3992 - acc: 0.8608 - val_loss: 0.4068 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3904 - acc: 0.8608 - val_loss: 0.3998 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3830 - acc: 0.8608 - val_loss: 0.3934 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac4944c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8164 - acc: 0.4588 - val_loss: 0.8066 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7731 - acc: 0.4794 - val_loss: 0.7542 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7329 - acc: 0.5258 - val_loss: 0.7068 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6965 - acc: 0.5670 - val_loss: 0.6632 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6633 - acc: 0.5928 - val_loss: 0.6229 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6316 - acc: 0.6649 - val_loss: 0.5864 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6035 - acc: 0.6907 - val_loss: 0.5537 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5787 - acc: 0.7216 - val_loss: 0.5245 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5542 - acc: 0.7423 - val_loss: 0.4991 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5340 - acc: 0.7680 - val_loss: 0.4764 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5146 - acc: 0.7938 - val_loss: 0.4564 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4976 - acc: 0.7990 - val_loss: 0.4388 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4830 - acc: 0.8093 - val_loss: 0.4230 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4695 - acc: 0.8041 - val_loss: 0.4093 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4570 - acc: 0.8144 - val_loss: 0.3972 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4469 - acc: 0.8144 - val_loss: 0.3866 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4362 - acc: 0.8144 - val_loss: 0.3774 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4279 - acc: 0.8144 - val_loss: 0.3693 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4198 - acc: 0.8196 - val_loss: 0.3622 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4130 - acc: 0.8196 - val_loss: 0.3560 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa420304e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7039 - acc: 0.4897 - val_loss: 0.6373 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6723 - acc: 0.5876 - val_loss: 0.6055 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6432 - acc: 0.6392 - val_loss: 0.5764 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6178 - acc: 0.6753 - val_loss: 0.5501 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5917 - acc: 0.7010 - val_loss: 0.5264 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5709 - acc: 0.7320 - val_loss: 0.5049 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5500 - acc: 0.7474 - val_loss: 0.4859 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5307 - acc: 0.7629 - val_loss: 0.4688 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5146 - acc: 0.7835 - val_loss: 0.4533 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4986 - acc: 0.7835 - val_loss: 0.4395 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4841 - acc: 0.8144 - val_loss: 0.4272 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4716 - acc: 0.8196 - val_loss: 0.4163 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4601 - acc: 0.8196 - val_loss: 0.4068 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4493 - acc: 0.8196 - val_loss: 0.3986 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4402 - acc: 0.8247 - val_loss: 0.3914 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4314 - acc: 0.8299 - val_loss: 0.3850 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4236 - acc: 0.8402 - val_loss: 0.3795 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4160 - acc: 0.8402 - val_loss: 0.3749 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4095 - acc: 0.8454 - val_loss: 0.3708 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4035 - acc: 0.8454 - val_loss: 0.3673 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41845c550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6063 - acc: 0.6891 - val_loss: 0.5086 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5634 - acc: 0.7358 - val_loss: 0.4726 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5264 - acc: 0.7720 - val_loss: 0.4424 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4948 - acc: 0.7824 - val_loss: 0.4171 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4681 - acc: 0.8187 - val_loss: 0.3961 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4445 - acc: 0.8394 - val_loss: 0.3794 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4265 - acc: 0.8446 - val_loss: 0.3656 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4099 - acc: 0.8446 - val_loss: 0.3545 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3963 - acc: 0.8446 - val_loss: 0.3457 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3840 - acc: 0.8497 - val_loss: 0.3384 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3742 - acc: 0.8497 - val_loss: 0.3323 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3651 - acc: 0.8549 - val_loss: 0.3274 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3572 - acc: 0.8549 - val_loss: 0.3231 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3500 - acc: 0.8549 - val_loss: 0.3197 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3436 - acc: 0.8601 - val_loss: 0.3168 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3377 - acc: 0.8601 - val_loss: 0.3143 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3323 - acc: 0.8653 - val_loss: 0.3127 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3276 - acc: 0.8653 - val_loss: 0.3110 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3224 - acc: 0.8705 - val_loss: 0.3091 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3179 - acc: 0.8756 - val_loss: 0.3076 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b862ae50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7803 - acc: 0.3782 - val_loss: 0.7009 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7253 - acc: 0.4508 - val_loss: 0.6487 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6738 - acc: 0.5544 - val_loss: 0.6026 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6297 - acc: 0.6477 - val_loss: 0.5625 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5907 - acc: 0.7254 - val_loss: 0.5280 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5562 - acc: 0.7617 - val_loss: 0.4980 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5261 - acc: 0.7876 - val_loss: 0.4728 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5011 - acc: 0.8031 - val_loss: 0.4514 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4791 - acc: 0.8135 - val_loss: 0.4335 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4597 - acc: 0.8187 - val_loss: 0.4184 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4435 - acc: 0.8238 - val_loss: 0.4060 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4298 - acc: 0.8290 - val_loss: 0.3959 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4174 - acc: 0.8342 - val_loss: 0.3872 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4073 - acc: 0.8342 - val_loss: 0.3795 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3983 - acc: 0.8394 - val_loss: 0.3730 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3901 - acc: 0.8342 - val_loss: 0.3676 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3828 - acc: 0.8342 - val_loss: 0.3630 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3764 - acc: 0.8394 - val_loss: 0.3593 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3705 - acc: 0.8342 - val_loss: 0.3563 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3654 - acc: 0.8342 - val_loss: 0.3539 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa418308040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6347 - acc: 0.7010 - val_loss: 0.6214 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5881 - acc: 0.7423 - val_loss: 0.5766 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5493 - acc: 0.7526 - val_loss: 0.5377 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5149 - acc: 0.7835 - val_loss: 0.5042 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4862 - acc: 0.7990 - val_loss: 0.4751 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4613 - acc: 0.8144 - val_loss: 0.4501 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4398 - acc: 0.8351 - val_loss: 0.4289 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4228 - acc: 0.8351 - val_loss: 0.4110 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4075 - acc: 0.8454 - val_loss: 0.3961 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3940 - acc: 0.8660 - val_loss: 0.3834 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3831 - acc: 0.8608 - val_loss: 0.3725 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3733 - acc: 0.8505 - val_loss: 0.3632 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3650 - acc: 0.8505 - val_loss: 0.3552 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3576 - acc: 0.8557 - val_loss: 0.3483 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3505 - acc: 0.8608 - val_loss: 0.3422 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3452 - acc: 0.8763 - val_loss: 0.3368 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3396 - acc: 0.8763 - val_loss: 0.3322 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3344 - acc: 0.8814 - val_loss: 0.3284 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3299 - acc: 0.8814 - val_loss: 0.3251 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3254 - acc: 0.8814 - val_loss: 0.3222 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b86ae9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6772 - acc: 0.5876 - val_loss: 0.5550 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6315 - acc: 0.6649 - val_loss: 0.5101 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5933 - acc: 0.7216 - val_loss: 0.4723 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5573 - acc: 0.7577 - val_loss: 0.4404 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5282 - acc: 0.7680 - val_loss: 0.4134 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5014 - acc: 0.7835 - val_loss: 0.3911 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4796 - acc: 0.7887 - val_loss: 0.3726 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4607 - acc: 0.7990 - val_loss: 0.3571 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4445 - acc: 0.8041 - val_loss: 0.3446 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4293 - acc: 0.8041 - val_loss: 0.3346 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4184 - acc: 0.8144 - val_loss: 0.3267 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4070 - acc: 0.8144 - val_loss: 0.3202 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3984 - acc: 0.8144 - val_loss: 0.3148 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3896 - acc: 0.8299 - val_loss: 0.3105 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3823 - acc: 0.8351 - val_loss: 0.3070 - val_acc: 0.9180\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3760 - acc: 0.8299 - val_loss: 0.3043 - val_acc: 0.9180\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3698 - acc: 0.8299 - val_loss: 0.3020 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3647 - acc: 0.8299 - val_loss: 0.3002 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3590 - acc: 0.8402 - val_loss: 0.2986 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3546 - acc: 0.8402 - val_loss: 0.2971 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b8424700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6942 - acc: 0.5670 - val_loss: 0.6739 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6458 - acc: 0.6804 - val_loss: 0.6240 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6030 - acc: 0.7165 - val_loss: 0.5814 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5656 - acc: 0.7474 - val_loss: 0.5446 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5352 - acc: 0.7680 - val_loss: 0.5131 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5084 - acc: 0.7784 - val_loss: 0.4862 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4871 - acc: 0.7835 - val_loss: 0.4642 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4667 - acc: 0.7938 - val_loss: 0.4459 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4506 - acc: 0.7990 - val_loss: 0.4307 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4371 - acc: 0.8093 - val_loss: 0.4181 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4250 - acc: 0.8351 - val_loss: 0.4080 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4150 - acc: 0.8299 - val_loss: 0.3994 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4061 - acc: 0.8299 - val_loss: 0.3924 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3986 - acc: 0.8299 - val_loss: 0.3865 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3909 - acc: 0.8299 - val_loss: 0.3815 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3851 - acc: 0.8299 - val_loss: 0.3774 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3793 - acc: 0.8299 - val_loss: 0.3736 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3737 - acc: 0.8247 - val_loss: 0.3703 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3687 - acc: 0.8299 - val_loss: 0.3673 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3638 - acc: 0.8351 - val_loss: 0.3652 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b83b79d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6232 - acc: 0.6943 - val_loss: 0.5355 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5661 - acc: 0.7668 - val_loss: 0.4871 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5194 - acc: 0.8238 - val_loss: 0.4476 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4814 - acc: 0.8290 - val_loss: 0.4153 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4488 - acc: 0.8290 - val_loss: 0.3897 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4242 - acc: 0.8394 - val_loss: 0.3693 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4048 - acc: 0.8342 - val_loss: 0.3535 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3883 - acc: 0.8342 - val_loss: 0.3420 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3751 - acc: 0.8446 - val_loss: 0.3336 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3636 - acc: 0.8549 - val_loss: 0.3270 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3536 - acc: 0.8549 - val_loss: 0.3215 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3458 - acc: 0.8601 - val_loss: 0.3175 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3393 - acc: 0.8601 - val_loss: 0.3148 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3329 - acc: 0.8601 - val_loss: 0.3126 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3267 - acc: 0.8653 - val_loss: 0.3105 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3210 - acc: 0.8653 - val_loss: 0.3087 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3161 - acc: 0.8705 - val_loss: 0.3068 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3109 - acc: 0.8653 - val_loss: 0.3051 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3064 - acc: 0.8705 - val_loss: 0.3036 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3020 - acc: 0.8653 - val_loss: 0.3021 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b82ce790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6595 - acc: 0.6166 - val_loss: 0.6056 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5980 - acc: 0.7306 - val_loss: 0.5455 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5489 - acc: 0.7720 - val_loss: 0.4969 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5088 - acc: 0.8135 - val_loss: 0.4585 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4754 - acc: 0.8290 - val_loss: 0.4282 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4492 - acc: 0.8187 - val_loss: 0.4041 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4281 - acc: 0.8290 - val_loss: 0.3850 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4102 - acc: 0.8290 - val_loss: 0.3698 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3971 - acc: 0.8238 - val_loss: 0.3580 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3851 - acc: 0.8342 - val_loss: 0.3490 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3756 - acc: 0.8394 - val_loss: 0.3417 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3667 - acc: 0.8446 - val_loss: 0.3357 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3595 - acc: 0.8446 - val_loss: 0.3308 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3530 - acc: 0.8446 - val_loss: 0.3271 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3472 - acc: 0.8497 - val_loss: 0.3239 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3412 - acc: 0.8497 - val_loss: 0.3213 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3362 - acc: 0.8601 - val_loss: 0.3191 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3307 - acc: 0.8653 - val_loss: 0.3171 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3259 - acc: 0.8653 - val_loss: 0.3152 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3212 - acc: 0.8653 - val_loss: 0.3140 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4becf3280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.7130 - acc: 0.5361 - val_loss: 0.6233 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6398 - acc: 0.6237 - val_loss: 0.5589 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5764 - acc: 0.7371 - val_loss: 0.5054 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5234 - acc: 0.8041 - val_loss: 0.4614 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4809 - acc: 0.8144 - val_loss: 0.4252 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4458 - acc: 0.8247 - val_loss: 0.3964 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4181 - acc: 0.8454 - val_loss: 0.3740 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3952 - acc: 0.8505 - val_loss: 0.3566 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3771 - acc: 0.8557 - val_loss: 0.3432 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3631 - acc: 0.8608 - val_loss: 0.3324 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3518 - acc: 0.8608 - val_loss: 0.3242 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3429 - acc: 0.8608 - val_loss: 0.3175 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3349 - acc: 0.8763 - val_loss: 0.3127 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3288 - acc: 0.8763 - val_loss: 0.3090 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3226 - acc: 0.8763 - val_loss: 0.3061 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3181 - acc: 0.8763 - val_loss: 0.3040 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3135 - acc: 0.8763 - val_loss: 0.3023 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3091 - acc: 0.8763 - val_loss: 0.3010 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3055 - acc: 0.8763 - val_loss: 0.3001 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3013 - acc: 0.8711 - val_loss: 0.3000 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac494160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.7667 - acc: 0.5206 - val_loss: 0.7098 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6900 - acc: 0.5361 - val_loss: 0.6262 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6248 - acc: 0.6031 - val_loss: 0.5576 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5725 - acc: 0.6959 - val_loss: 0.5025 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5268 - acc: 0.7526 - val_loss: 0.4590 - val_acc: 0.9344\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4920 - acc: 0.7835 - val_loss: 0.4251 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4631 - acc: 0.7887 - val_loss: 0.3991 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4392 - acc: 0.8144 - val_loss: 0.3795 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4208 - acc: 0.8196 - val_loss: 0.3648 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4068 - acc: 0.8196 - val_loss: 0.3538 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3946 - acc: 0.8299 - val_loss: 0.3458 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3837 - acc: 0.8299 - val_loss: 0.3402 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3754 - acc: 0.8402 - val_loss: 0.3360 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3678 - acc: 0.8402 - val_loss: 0.3328 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3614 - acc: 0.8454 - val_loss: 0.3305 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3552 - acc: 0.8505 - val_loss: 0.3287 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3507 - acc: 0.8505 - val_loss: 0.3273 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3454 - acc: 0.8557 - val_loss: 0.3261 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3409 - acc: 0.8660 - val_loss: 0.3253 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3369 - acc: 0.8660 - val_loss: 0.3250 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa47425b430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6610 - acc: 0.5928 - val_loss: 0.5807 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5986 - acc: 0.7577 - val_loss: 0.5235 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5466 - acc: 0.8144 - val_loss: 0.4782 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5030 - acc: 0.8144 - val_loss: 0.4430 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4704 - acc: 0.8299 - val_loss: 0.4154 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4407 - acc: 0.8505 - val_loss: 0.3945 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4202 - acc: 0.8557 - val_loss: 0.3786 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4019 - acc: 0.8505 - val_loss: 0.3670 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3889 - acc: 0.8608 - val_loss: 0.3590 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3764 - acc: 0.8660 - val_loss: 0.3533 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3662 - acc: 0.8660 - val_loss: 0.3494 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3581 - acc: 0.8608 - val_loss: 0.3467 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3511 - acc: 0.8557 - val_loss: 0.3447 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3442 - acc: 0.8608 - val_loss: 0.3429 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3389 - acc: 0.8660 - val_loss: 0.3414 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3338 - acc: 0.8711 - val_loss: 0.3406 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3285 - acc: 0.8711 - val_loss: 0.3402 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3242 - acc: 0.8711 - val_loss: 0.3393 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3194 - acc: 0.8711 - val_loss: 0.3386 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3153 - acc: 0.8711 - val_loss: 0.3379 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac18d0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6988 - acc: 0.5130 - val_loss: 0.6181 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6046 - acc: 0.7668 - val_loss: 0.5366 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5307 - acc: 0.8135 - val_loss: 0.4767 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4770 - acc: 0.8394 - val_loss: 0.4336 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4344 - acc: 0.8446 - val_loss: 0.4026 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4059 - acc: 0.8446 - val_loss: 0.3810 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3842 - acc: 0.8549 - val_loss: 0.3653 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3668 - acc: 0.8549 - val_loss: 0.3544 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3537 - acc: 0.8601 - val_loss: 0.3465 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3442 - acc: 0.8601 - val_loss: 0.3405 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3362 - acc: 0.8601 - val_loss: 0.3363 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3277 - acc: 0.8601 - val_loss: 0.3325 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3211 - acc: 0.8705 - val_loss: 0.3301 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3141 - acc: 0.8756 - val_loss: 0.3287 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3078 - acc: 0.8808 - val_loss: 0.3273 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3018 - acc: 0.8860 - val_loss: 0.3266 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2960 - acc: 0.8860 - val_loss: 0.3259 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2897 - acc: 0.8808 - val_loss: 0.3251 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2844 - acc: 0.8860 - val_loss: 0.3243 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2788 - acc: 0.8912 - val_loss: 0.3236 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beca41f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7064 - acc: 0.4508 - val_loss: 0.5959 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6070 - acc: 0.7254 - val_loss: 0.5144 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5311 - acc: 0.7979 - val_loss: 0.4536 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4747 - acc: 0.8446 - val_loss: 0.4087 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4342 - acc: 0.8601 - val_loss: 0.3775 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4047 - acc: 0.8653 - val_loss: 0.3553 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3832 - acc: 0.8601 - val_loss: 0.3401 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3675 - acc: 0.8549 - val_loss: 0.3300 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3561 - acc: 0.8653 - val_loss: 0.3237 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3463 - acc: 0.8653 - val_loss: 0.3202 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3397 - acc: 0.8601 - val_loss: 0.3180 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3322 - acc: 0.8601 - val_loss: 0.3171 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3265 - acc: 0.8601 - val_loss: 0.3173 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3201 - acc: 0.8601 - val_loss: 0.3181 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3144 - acc: 0.8653 - val_loss: 0.3182 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3078 - acc: 0.8653 - val_loss: 0.3181 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3021 - acc: 0.8653 - val_loss: 0.3177 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4742efca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6969 - acc: 0.5361 - val_loss: 0.6108 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5971 - acc: 0.7680 - val_loss: 0.5229 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5208 - acc: 0.8041 - val_loss: 0.4604 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4664 - acc: 0.8196 - val_loss: 0.4165 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4254 - acc: 0.8299 - val_loss: 0.3860 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3961 - acc: 0.8402 - val_loss: 0.3647 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3728 - acc: 0.8505 - val_loss: 0.3501 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3573 - acc: 0.8660 - val_loss: 0.3406 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3453 - acc: 0.8557 - val_loss: 0.3337 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3347 - acc: 0.8608 - val_loss: 0.3283 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3264 - acc: 0.8711 - val_loss: 0.3239 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3185 - acc: 0.8711 - val_loss: 0.3206 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3122 - acc: 0.8814 - val_loss: 0.3183 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3056 - acc: 0.8814 - val_loss: 0.3168 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2996 - acc: 0.8814 - val_loss: 0.3152 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2947 - acc: 0.8814 - val_loss: 0.3143 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2892 - acc: 0.8814 - val_loss: 0.3138 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2836 - acc: 0.8814 - val_loss: 0.3135 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2790 - acc: 0.8814 - val_loss: 0.3135 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2744 - acc: 0.8866 - val_loss: 0.3131 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa474704940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7597 - acc: 0.2990 - val_loss: 0.6583 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6461 - acc: 0.7062 - val_loss: 0.5590 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5648 - acc: 0.7835 - val_loss: 0.4834 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4994 - acc: 0.8196 - val_loss: 0.4287 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4532 - acc: 0.8196 - val_loss: 0.3903 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4204 - acc: 0.8247 - val_loss: 0.3637 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3960 - acc: 0.8351 - val_loss: 0.3458 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3764 - acc: 0.8351 - val_loss: 0.3346 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3642 - acc: 0.8299 - val_loss: 0.3279 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3535 - acc: 0.8351 - val_loss: 0.3240 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3461 - acc: 0.8454 - val_loss: 0.3217 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3397 - acc: 0.8505 - val_loss: 0.3209 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3353 - acc: 0.8557 - val_loss: 0.3208 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3303 - acc: 0.8660 - val_loss: 0.3211 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3257 - acc: 0.8660 - val_loss: 0.3223 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3209 - acc: 0.8660 - val_loss: 0.3235 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3161 - acc: 0.8711 - val_loss: 0.3250 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3114 - acc: 0.8763 - val_loss: 0.3265 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4582f1940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7219 - acc: 0.4175 - val_loss: 0.6361 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6173 - acc: 0.7784 - val_loss: 0.5475 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5440 - acc: 0.7938 - val_loss: 0.4816 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4854 - acc: 0.8247 - val_loss: 0.4342 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4447 - acc: 0.8299 - val_loss: 0.4005 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4154 - acc: 0.8454 - val_loss: 0.3767 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3933 - acc: 0.8454 - val_loss: 0.3607 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3776 - acc: 0.8505 - val_loss: 0.3503 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3659 - acc: 0.8454 - val_loss: 0.3441 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3557 - acc: 0.8454 - val_loss: 0.3408 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3470 - acc: 0.8557 - val_loss: 0.3392 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3391 - acc: 0.8557 - val_loss: 0.3389 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3327 - acc: 0.8608 - val_loss: 0.3391 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3260 - acc: 0.8608 - val_loss: 0.3395 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3194 - acc: 0.8608 - val_loss: 0.3401 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3140 - acc: 0.8711 - val_loss: 0.3407 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3078 - acc: 0.8711 - val_loss: 0.3412 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc364a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7110 - acc: 0.5596 - val_loss: 0.6310 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6167 - acc: 0.6788 - val_loss: 0.5551 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5449 - acc: 0.7617 - val_loss: 0.5024 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4945 - acc: 0.7927 - val_loss: 0.4626 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4512 - acc: 0.8031 - val_loss: 0.4323 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4211 - acc: 0.8342 - val_loss: 0.4093 - val_acc: 0.7869\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3922 - acc: 0.8290 - val_loss: 0.3911 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3710 - acc: 0.8394 - val_loss: 0.3769 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3538 - acc: 0.8497 - val_loss: 0.3657 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3416 - acc: 0.8497 - val_loss: 0.3565 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3300 - acc: 0.8601 - val_loss: 0.3497 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3214 - acc: 0.8705 - val_loss: 0.3444 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3151 - acc: 0.8808 - val_loss: 0.3406 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3080 - acc: 0.8860 - val_loss: 0.3381 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3021 - acc: 0.8912 - val_loss: 0.3356 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2963 - acc: 0.8912 - val_loss: 0.3333 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2907 - acc: 0.8912 - val_loss: 0.3323 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2860 - acc: 0.8964 - val_loss: 0.3326 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2822 - acc: 0.8964 - val_loss: 0.3335 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2790 - acc: 0.9016 - val_loss: 0.3351 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4740b0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0594 - acc: 0.5285 - val_loss: 1.0695 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8752 - acc: 0.5596 - val_loss: 0.8554 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7383 - acc: 0.6010 - val_loss: 0.6953 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6458 - acc: 0.6218 - val_loss: 0.5838 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5772 - acc: 0.6788 - val_loss: 0.5118 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5200 - acc: 0.7202 - val_loss: 0.4626 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4808 - acc: 0.7565 - val_loss: 0.4298 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4506 - acc: 0.7720 - val_loss: 0.4100 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4281 - acc: 0.7979 - val_loss: 0.3941 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4104 - acc: 0.8083 - val_loss: 0.3819 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3935 - acc: 0.8083 - val_loss: 0.3732 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3810 - acc: 0.8290 - val_loss: 0.3657 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3687 - acc: 0.8290 - val_loss: 0.3590 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3588 - acc: 0.8394 - val_loss: 0.3535 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3496 - acc: 0.8394 - val_loss: 0.3491 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3436 - acc: 0.8497 - val_loss: 0.3454 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3363 - acc: 0.8549 - val_loss: 0.3429 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3311 - acc: 0.8497 - val_loss: 0.3407 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3254 - acc: 0.8549 - val_loss: 0.3383 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3201 - acc: 0.8601 - val_loss: 0.3366 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4202dd310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.9404 - acc: 0.4742 - val_loss: 0.7639 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8062 - acc: 0.5103 - val_loss: 0.6662 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6846 - acc: 0.5722 - val_loss: 0.5882 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5951 - acc: 0.6701 - val_loss: 0.5283 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5250 - acc: 0.7423 - val_loss: 0.4854 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4757 - acc: 0.7680 - val_loss: 0.4535 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4423 - acc: 0.7835 - val_loss: 0.4299 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4142 - acc: 0.8041 - val_loss: 0.4113 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3937 - acc: 0.8041 - val_loss: 0.3959 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3783 - acc: 0.8144 - val_loss: 0.3856 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3676 - acc: 0.8196 - val_loss: 0.3794 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3589 - acc: 0.8299 - val_loss: 0.3751 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3521 - acc: 0.8454 - val_loss: 0.3708 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3468 - acc: 0.8505 - val_loss: 0.3673 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3409 - acc: 0.8608 - val_loss: 0.3647 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3361 - acc: 0.8608 - val_loss: 0.3625 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3310 - acc: 0.8711 - val_loss: 0.3602 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3260 - acc: 0.8711 - val_loss: 0.3585 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3216 - acc: 0.8711 - val_loss: 0.3571 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3173 - acc: 0.8660 - val_loss: 0.3560 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4740d75e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7629 - acc: 0.4948 - val_loss: 0.6039 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6190 - acc: 0.6598 - val_loss: 0.4779 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5227 - acc: 0.7629 - val_loss: 0.4022 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4567 - acc: 0.7990 - val_loss: 0.3623 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4145 - acc: 0.8093 - val_loss: 0.3385 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3927 - acc: 0.8299 - val_loss: 0.3255 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3767 - acc: 0.8351 - val_loss: 0.3188 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3648 - acc: 0.8351 - val_loss: 0.3159 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3576 - acc: 0.8402 - val_loss: 0.3157 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3520 - acc: 0.8454 - val_loss: 0.3167 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3465 - acc: 0.8505 - val_loss: 0.3185 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3408 - acc: 0.8660 - val_loss: 0.3211 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3361 - acc: 0.8660 - val_loss: 0.3239 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3304 - acc: 0.8711 - val_loss: 0.3269 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410277c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7581 - acc: 0.4742 - val_loss: 0.7469 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6885 - acc: 0.5412 - val_loss: 0.6719 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6309 - acc: 0.6340 - val_loss: 0.6115 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5831 - acc: 0.7113 - val_loss: 0.5596 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5408 - acc: 0.7784 - val_loss: 0.5177 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5056 - acc: 0.8093 - val_loss: 0.4835 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4723 - acc: 0.8351 - val_loss: 0.4561 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4455 - acc: 0.8247 - val_loss: 0.4363 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4238 - acc: 0.8247 - val_loss: 0.4212 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4042 - acc: 0.8299 - val_loss: 0.4112 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3896 - acc: 0.8351 - val_loss: 0.4050 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3757 - acc: 0.8402 - val_loss: 0.4024 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3651 - acc: 0.8402 - val_loss: 0.4008 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3561 - acc: 0.8454 - val_loss: 0.4006 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3468 - acc: 0.8454 - val_loss: 0.3998 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3392 - acc: 0.8505 - val_loss: 0.3989 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3333 - acc: 0.8608 - val_loss: 0.3985 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3263 - acc: 0.8608 - val_loss: 0.3968 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3211 - acc: 0.8660 - val_loss: 0.3941 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3159 - acc: 0.8711 - val_loss: 0.3913 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4104e9040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7551 - acc: 0.5803 - val_loss: 0.5798 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6065 - acc: 0.6839 - val_loss: 0.4688 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5173 - acc: 0.7409 - val_loss: 0.4054 - val_acc: 0.9180\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4554 - acc: 0.7927 - val_loss: 0.3711 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4165 - acc: 0.8135 - val_loss: 0.3516 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3905 - acc: 0.8342 - val_loss: 0.3421 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3719 - acc: 0.8342 - val_loss: 0.3367 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3567 - acc: 0.8394 - val_loss: 0.3319 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3450 - acc: 0.8394 - val_loss: 0.3278 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3344 - acc: 0.8653 - val_loss: 0.3224 - val_acc: 0.9016\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3245 - acc: 0.8756 - val_loss: 0.3172 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3163 - acc: 0.8756 - val_loss: 0.3130 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3076 - acc: 0.8705 - val_loss: 0.3094 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3012 - acc: 0.8705 - val_loss: 0.3054 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2933 - acc: 0.8808 - val_loss: 0.3030 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2859 - acc: 0.8860 - val_loss: 0.3011 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2800 - acc: 0.8964 - val_loss: 0.3003 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2731 - acc: 0.9016 - val_loss: 0.3006 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2680 - acc: 0.9067 - val_loss: 0.3023 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2634 - acc: 0.9067 - val_loss: 0.3054 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b824c280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0083 - acc: 0.4041 - val_loss: 0.8644 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8140 - acc: 0.5285 - val_loss: 0.7051 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6581 - acc: 0.6736 - val_loss: 0.5904 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5605 - acc: 0.7254 - val_loss: 0.5051 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4896 - acc: 0.7720 - val_loss: 0.4437 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4453 - acc: 0.8083 - val_loss: 0.3999 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4134 - acc: 0.8187 - val_loss: 0.3703 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3938 - acc: 0.8135 - val_loss: 0.3510 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3785 - acc: 0.8394 - val_loss: 0.3386 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3667 - acc: 0.8394 - val_loss: 0.3306 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3564 - acc: 0.8394 - val_loss: 0.3241 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3471 - acc: 0.8497 - val_loss: 0.3195 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3374 - acc: 0.8497 - val_loss: 0.3161 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3283 - acc: 0.8446 - val_loss: 0.3144 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3207 - acc: 0.8446 - val_loss: 0.3137 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3134 - acc: 0.8549 - val_loss: 0.3139 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3041 - acc: 0.8601 - val_loss: 0.3146 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2971 - acc: 0.8653 - val_loss: 0.3160 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2909 - acc: 0.8601 - val_loss: 0.3170 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2850 - acc: 0.8808 - val_loss: 0.3171 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4106f7c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6233 - acc: 0.6495 - val_loss: 0.4862 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5143 - acc: 0.7784 - val_loss: 0.4260 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4431 - acc: 0.8247 - val_loss: 0.3938 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3941 - acc: 0.8247 - val_loss: 0.3774 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3620 - acc: 0.8351 - val_loss: 0.3702 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3412 - acc: 0.8557 - val_loss: 0.3681 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3285 - acc: 0.8660 - val_loss: 0.3668 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3150 - acc: 0.8660 - val_loss: 0.3655 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3072 - acc: 0.8660 - val_loss: 0.3641 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2991 - acc: 0.8660 - val_loss: 0.3620 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2930 - acc: 0.8660 - val_loss: 0.3602 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2862 - acc: 0.8711 - val_loss: 0.3565 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2797 - acc: 0.8660 - val_loss: 0.3539 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2730 - acc: 0.8660 - val_loss: 0.3516 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2668 - acc: 0.8711 - val_loss: 0.3511 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2603 - acc: 0.8763 - val_loss: 0.3509 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2548 - acc: 0.8763 - val_loss: 0.3518 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2494 - acc: 0.8866 - val_loss: 0.3507 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2440 - acc: 0.8918 - val_loss: 0.3502 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2393 - acc: 0.8969 - val_loss: 0.3508 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b819cf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0274 - acc: 0.3866 - val_loss: 0.8617 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7791 - acc: 0.5052 - val_loss: 0.6863 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6180 - acc: 0.6701 - val_loss: 0.5699 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5090 - acc: 0.7887 - val_loss: 0.4895 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4379 - acc: 0.8402 - val_loss: 0.4380 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3988 - acc: 0.8402 - val_loss: 0.4044 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3705 - acc: 0.8454 - val_loss: 0.3846 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3572 - acc: 0.8402 - val_loss: 0.3735 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3475 - acc: 0.8351 - val_loss: 0.3676 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3408 - acc: 0.8351 - val_loss: 0.3643 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3371 - acc: 0.8402 - val_loss: 0.3628 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3334 - acc: 0.8402 - val_loss: 0.3609 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3291 - acc: 0.8454 - val_loss: 0.3595 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3240 - acc: 0.8505 - val_loss: 0.3593 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3184 - acc: 0.8608 - val_loss: 0.3589 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3121 - acc: 0.8608 - val_loss: 0.3572 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3057 - acc: 0.8608 - val_loss: 0.3550 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2997 - acc: 0.8608 - val_loss: 0.3542 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2933 - acc: 0.8608 - val_loss: 0.3546 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2874 - acc: 0.8660 - val_loss: 0.3550 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3945c0670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8268 - acc: 0.5567 - val_loss: 0.7062 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6841 - acc: 0.5979 - val_loss: 0.5780 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5909 - acc: 0.6907 - val_loss: 0.4901 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5196 - acc: 0.7474 - val_loss: 0.4309 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4700 - acc: 0.7887 - val_loss: 0.3917 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4337 - acc: 0.8196 - val_loss: 0.3676 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4089 - acc: 0.8196 - val_loss: 0.3550 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3873 - acc: 0.8247 - val_loss: 0.3493 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3733 - acc: 0.8454 - val_loss: 0.3470 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3603 - acc: 0.8454 - val_loss: 0.3471 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3528 - acc: 0.8454 - val_loss: 0.3481 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3444 - acc: 0.8557 - val_loss: 0.3499 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3372 - acc: 0.8763 - val_loss: 0.3498 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3308 - acc: 0.8763 - val_loss: 0.3485 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc2538b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.8804 - acc: 0.4352 - val_loss: 0.7192 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6398 - acc: 0.6425 - val_loss: 0.5554 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5155 - acc: 0.7565 - val_loss: 0.4572 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4390 - acc: 0.7876 - val_loss: 0.4006 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4025 - acc: 0.8238 - val_loss: 0.3684 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3766 - acc: 0.8342 - val_loss: 0.3522 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3612 - acc: 0.8290 - val_loss: 0.3454 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3511 - acc: 0.8446 - val_loss: 0.3449 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3405 - acc: 0.8549 - val_loss: 0.3471 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3277 - acc: 0.8549 - val_loss: 0.3500 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3172 - acc: 0.8601 - val_loss: 0.3520 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3063 - acc: 0.8756 - val_loss: 0.3523 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2986 - acc: 0.8756 - val_loss: 0.3517 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac18d940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6650 - acc: 0.6062 - val_loss: 0.4865 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5022 - acc: 0.7824 - val_loss: 0.3822 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4137 - acc: 0.8342 - val_loss: 0.3336 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3716 - acc: 0.8342 - val_loss: 0.3131 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3543 - acc: 0.8394 - val_loss: 0.3077 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3400 - acc: 0.8497 - val_loss: 0.3100 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3272 - acc: 0.8549 - val_loss: 0.3148 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3168 - acc: 0.8653 - val_loss: 0.3210 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3038 - acc: 0.8705 - val_loss: 0.3276 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2931 - acc: 0.8756 - val_loss: 0.3315 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0ea44c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6206 - acc: 0.6907 - val_loss: 0.4664 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4445 - acc: 0.8299 - val_loss: 0.3753 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3732 - acc: 0.8608 - val_loss: 0.3530 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3414 - acc: 0.8711 - val_loss: 0.3502 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3218 - acc: 0.8763 - val_loss: 0.3501 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3080 - acc: 0.8814 - val_loss: 0.3483 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2945 - acc: 0.8814 - val_loss: 0.3436 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2852 - acc: 0.8814 - val_loss: 0.3382 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2731 - acc: 0.8814 - val_loss: 0.3357 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2625 - acc: 0.8814 - val_loss: 0.3348 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2543 - acc: 0.8918 - val_loss: 0.3350 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2454 - acc: 0.8918 - val_loss: 0.3368 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2373 - acc: 0.8969 - val_loss: 0.3405 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2292 - acc: 0.9175 - val_loss: 0.3441 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2214 - acc: 0.9175 - val_loss: 0.3477 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4747043a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8237 - acc: 0.5619 - val_loss: 0.6497 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6195 - acc: 0.6649 - val_loss: 0.5041 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5007 - acc: 0.7474 - val_loss: 0.4121 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4304 - acc: 0.8041 - val_loss: 0.3594 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3937 - acc: 0.8299 - val_loss: 0.3338 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3761 - acc: 0.8454 - val_loss: 0.3227 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3689 - acc: 0.8402 - val_loss: 0.3196 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3607 - acc: 0.8454 - val_loss: 0.3196 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3514 - acc: 0.8402 - val_loss: 0.3229 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3406 - acc: 0.8454 - val_loss: 0.3260 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3277 - acc: 0.8557 - val_loss: 0.3311 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3172 - acc: 0.8557 - val_loss: 0.3374 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3072 - acc: 0.8711 - val_loss: 0.3420 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4747048b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7359 - acc: 0.6082 - val_loss: 0.4515 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5313 - acc: 0.7629 - val_loss: 0.3598 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4424 - acc: 0.8144 - val_loss: 0.3456 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4003 - acc: 0.8247 - val_loss: 0.3564 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3862 - acc: 0.8402 - val_loss: 0.3681 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3716 - acc: 0.8402 - val_loss: 0.3713 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3588 - acc: 0.8505 - val_loss: 0.3702 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3461 - acc: 0.8505 - val_loss: 0.3671 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beca4790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6565 - acc: 0.6425 - val_loss: 0.4004 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4261 - acc: 0.8135 - val_loss: 0.3555 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3574 - acc: 0.8238 - val_loss: 0.3637 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3372 - acc: 0.8497 - val_loss: 0.3792 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3244 - acc: 0.8653 - val_loss: 0.3851 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3103 - acc: 0.8653 - val_loss: 0.3846 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2950 - acc: 0.8808 - val_loss: 0.3787 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1e33a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.7692 - acc: 0.5285 - val_loss: 0.4761 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4862 - acc: 0.7876 - val_loss: 0.3606 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3946 - acc: 0.8290 - val_loss: 0.3301 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3600 - acc: 0.8394 - val_loss: 0.3255 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3492 - acc: 0.8601 - val_loss: 0.3254 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3413 - acc: 0.8601 - val_loss: 0.3299 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3311 - acc: 0.8705 - val_loss: 0.3339 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3169 - acc: 0.8705 - val_loss: 0.3375 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3023 - acc: 0.8808 - val_loss: 0.3405 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2840 - acc: 0.8808 - val_loss: 0.3434 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e0d8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6230 - acc: 0.6186 - val_loss: 0.4041 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4178 - acc: 0.8196 - val_loss: 0.3422 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3548 - acc: 0.8557 - val_loss: 0.3357 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3320 - acc: 0.8608 - val_loss: 0.3383 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3148 - acc: 0.8763 - val_loss: 0.3355 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2958 - acc: 0.8711 - val_loss: 0.3341 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2814 - acc: 0.8763 - val_loss: 0.3355 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2655 - acc: 0.8814 - val_loss: 0.3389 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2517 - acc: 0.8866 - val_loss: 0.3409 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2436 - acc: 0.8969 - val_loss: 0.3395 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2334 - acc: 0.9072 - val_loss: 0.3346 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bec57310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.8890 - acc: 0.3557 - val_loss: 0.5129 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5346 - acc: 0.7423 - val_loss: 0.3748 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4113 - acc: 0.8041 - val_loss: 0.3324 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3714 - acc: 0.8299 - val_loss: 0.3234 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3555 - acc: 0.8454 - val_loss: 0.3279 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3443 - acc: 0.8454 - val_loss: 0.3383 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3343 - acc: 0.8608 - val_loss: 0.3451 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3240 - acc: 0.8660 - val_loss: 0.3509 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3111 - acc: 0.8814 - val_loss: 0.3556 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4204d8550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7440 - acc: 0.5412 - val_loss: 0.5067 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4844 - acc: 0.7732 - val_loss: 0.3969 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3864 - acc: 0.8299 - val_loss: 0.3752 - val_acc: 0.8361\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3545 - acc: 0.8505 - val_loss: 0.3818 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3409 - acc: 0.8814 - val_loss: 0.3920 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3262 - acc: 0.8660 - val_loss: 0.3941 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3121 - acc: 0.8711 - val_loss: 0.3928 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2972 - acc: 0.8866 - val_loss: 0.3888 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa458412c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6148 - acc: 0.6477 - val_loss: 0.3776 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3975 - acc: 0.8290 - val_loss: 0.3325 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3496 - acc: 0.8601 - val_loss: 0.3378 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3235 - acc: 0.8653 - val_loss: 0.3467 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2985 - acc: 0.8912 - val_loss: 0.3514 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2751 - acc: 0.8964 - val_loss: 0.3572 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2609 - acc: 0.8964 - val_loss: 0.3571 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa42003d670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7318 - acc: 0.4974 - val_loss: 0.4018 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4263 - acc: 0.8238 - val_loss: 0.3483 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3542 - acc: 0.8497 - val_loss: 0.3517 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3354 - acc: 0.8653 - val_loss: 0.3594 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3178 - acc: 0.8756 - val_loss: 0.3558 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3017 - acc: 0.8756 - val_loss: 0.3485 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2795 - acc: 0.8912 - val_loss: 0.3409 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2615 - acc: 0.8912 - val_loss: 0.3343 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2461 - acc: 0.8860 - val_loss: 0.3284 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2309 - acc: 0.9119 - val_loss: 0.3304 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2228 - acc: 0.9223 - val_loss: 0.3377 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2116 - acc: 0.9223 - val_loss: 0.3520 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1992 - acc: 0.9223 - val_loss: 0.3689 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1886 - acc: 0.9378 - val_loss: 0.3874 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4744be9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6623 - acc: 0.6134 - val_loss: 0.4025 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3720 - acc: 0.8402 - val_loss: 0.3292 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3273 - acc: 0.8608 - val_loss: 0.3341 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3124 - acc: 0.8608 - val_loss: 0.3531 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3004 - acc: 0.8711 - val_loss: 0.3657 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2847 - acc: 0.8866 - val_loss: 0.3698 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2667 - acc: 0.8918 - val_loss: 0.3651 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b87ca040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.8054 - acc: 0.4588 - val_loss: 0.4096 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4286 - acc: 0.8041 - val_loss: 0.3467 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3671 - acc: 0.8144 - val_loss: 0.3608 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3609 - acc: 0.8299 - val_loss: 0.3707 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3515 - acc: 0.8351 - val_loss: 0.3733 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3350 - acc: 0.8402 - val_loss: 0.3697 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3130 - acc: 0.8557 - val_loss: 0.3683 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4105674c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6306 - acc: 0.5928 - val_loss: 0.3942 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4060 - acc: 0.8196 - val_loss: 0.3682 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3591 - acc: 0.8454 - val_loss: 0.3504 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3362 - acc: 0.8454 - val_loss: 0.3454 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3237 - acc: 0.8505 - val_loss: 0.3391 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3037 - acc: 0.8505 - val_loss: 0.3380 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2828 - acc: 0.8814 - val_loss: 0.3460 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2604 - acc: 0.8969 - val_loss: 0.3608 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2481 - acc: 0.9021 - val_loss: 0.3813 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2373 - acc: 0.9227 - val_loss: 0.3984 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2265 - acc: 0.9227 - val_loss: 0.4106 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b85704c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6220 - acc: 0.6218 - val_loss: 0.3451 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3585 - acc: 0.8394 - val_loss: 0.3403 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3370 - acc: 0.8497 - val_loss: 0.3506 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3121 - acc: 0.8653 - val_loss: 0.3570 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2808 - acc: 0.8808 - val_loss: 0.3442 - val_acc: 0.9180\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2582 - acc: 0.8912 - val_loss: 0.3376 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2396 - acc: 0.9171 - val_loss: 0.3354 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2216 - acc: 0.9223 - val_loss: 0.3437 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2095 - acc: 0.9378 - val_loss: 0.3553 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1953 - acc: 0.9430 - val_loss: 0.3723 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1829 - acc: 0.9534 - val_loss: 0.3898 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1706 - acc: 0.9534 - val_loss: 0.4015 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b85c7af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5707 - acc: 0.7202 - val_loss: 0.3358 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3814 - acc: 0.8446 - val_loss: 0.3544 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3577 - acc: 0.8601 - val_loss: 0.3735 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3348 - acc: 0.8653 - val_loss: 0.3770 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2970 - acc: 0.8756 - val_loss: 0.3684 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2645 - acc: 0.8964 - val_loss: 0.3619 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa39463eee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 0.6358 - acc: 0.6031 - val_loss: 0.3519 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3572 - acc: 0.8608 - val_loss: 0.3271 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3327 - acc: 0.8660 - val_loss: 0.3397 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3169 - acc: 0.8763 - val_loss: 0.3496 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2947 - acc: 0.8763 - val_loss: 0.3557 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2668 - acc: 0.8763 - val_loss: 0.3544 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2461 - acc: 0.8969 - val_loss: 0.3510 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b85709d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6000 - acc: 0.6031 - val_loss: 0.3333 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3788 - acc: 0.8247 - val_loss: 0.3455 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3560 - acc: 0.8557 - val_loss: 0.3737 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3352 - acc: 0.8608 - val_loss: 0.3782 - val_acc: 0.8525\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3071 - acc: 0.8918 - val_loss: 0.3785 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2802 - acc: 0.8969 - val_loss: 0.3721 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b4428940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7178 - acc: 0.5155 - val_loss: 0.3627 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3796 - acc: 0.8557 - val_loss: 0.3247 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3442 - acc: 0.8505 - val_loss: 0.3440 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3303 - acc: 0.8557 - val_loss: 0.3731 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3131 - acc: 0.8557 - val_loss: 0.3993 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2872 - acc: 0.8814 - val_loss: 0.4064 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2621 - acc: 0.9021 - val_loss: 0.3960 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b85700d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5546 - acc: 0.7461 - val_loss: 0.3403 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3699 - acc: 0.8446 - val_loss: 0.3743 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3297 - acc: 0.8705 - val_loss: 0.3511 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2769 - acc: 0.8964 - val_loss: 0.3405 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2413 - acc: 0.9067 - val_loss: 0.3486 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2277 - acc: 0.9067 - val_loss: 0.3710 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b85c7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6315 - acc: 0.6321 - val_loss: 0.3332 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3696 - acc: 0.8497 - val_loss: 0.3510 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3388 - acc: 0.8601 - val_loss: 0.3429 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2995 - acc: 0.8705 - val_loss: 0.3353 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2649 - acc: 0.8912 - val_loss: 0.3411 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2374 - acc: 0.9275 - val_loss: 0.3556 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e285e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6099 - acc: 0.6186 - val_loss: 0.3348 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3247 - acc: 0.8402 - val_loss: 0.3631 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3176 - acc: 0.8660 - val_loss: 0.3753 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2846 - acc: 0.8866 - val_loss: 0.3820 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2536 - acc: 0.8918 - val_loss: 0.3801 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2273 - acc: 0.9021 - val_loss: 0.3845 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e0dc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6097 - acc: 0.5825 - val_loss: 0.3250 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3735 - acc: 0.8093 - val_loss: 0.3536 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3727 - acc: 0.8351 - val_loss: 0.3649 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3435 - acc: 0.8608 - val_loss: 0.3769 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3046 - acc: 0.8711 - val_loss: 0.3660 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2692 - acc: 0.9021 - val_loss: 0.3560 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bedf6550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6268 - acc: 0.5722 - val_loss: 0.3294 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3552 - acc: 0.8505 - val_loss: 0.3459 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3551 - acc: 0.8402 - val_loss: 0.3629 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3247 - acc: 0.8505 - val_loss: 0.3655 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2803 - acc: 0.8763 - val_loss: 0.3856 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2476 - acc: 0.9124 - val_loss: 0.4051 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4742efca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.9125 - acc: 0.4922 - val_loss: 0.4039 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4574 - acc: 0.8083 - val_loss: 0.3945 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4048 - acc: 0.8549 - val_loss: 0.4161 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3524 - acc: 0.8601 - val_loss: 0.3909 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3194 - acc: 0.8653 - val_loss: 0.3592 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3060 - acc: 0.8756 - val_loss: 0.3548 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3003 - acc: 0.8808 - val_loss: 0.3628 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2868 - acc: 0.8912 - val_loss: 0.3929 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2715 - acc: 0.9171 - val_loss: 0.4176 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2583 - acc: 0.9119 - val_loss: 0.4064 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2403 - acc: 0.9171 - val_loss: 0.3720 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4becbb820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5804 - acc: 0.7150 - val_loss: 0.3520 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4345 - acc: 0.8238 - val_loss: 0.3450 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3693 - acc: 0.8446 - val_loss: 0.3283 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3356 - acc: 0.8497 - val_loss: 0.3235 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3210 - acc: 0.8497 - val_loss: 0.3231 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3043 - acc: 0.8601 - val_loss: 0.3564 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2852 - acc: 0.8497 - val_loss: 0.3693 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2754 - acc: 0.8601 - val_loss: 0.3736 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2639 - acc: 0.8756 - val_loss: 0.3919 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2482 - acc: 0.8808 - val_loss: 0.4266 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4becf3b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.9268 - acc: 0.5361 - val_loss: 0.5138 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4421 - acc: 0.7990 - val_loss: 0.3679 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3598 - acc: 0.8402 - val_loss: 0.3307 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3363 - acc: 0.8402 - val_loss: 0.3637 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3137 - acc: 0.8505 - val_loss: 0.4526 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2937 - acc: 0.8711 - val_loss: 0.5517 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2831 - acc: 0.8763 - val_loss: 0.6160 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2731 - acc: 0.8763 - val_loss: 0.6192 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa474704430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.7736 - acc: 0.5103 - val_loss: 0.3904 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4183 - acc: 0.8144 - val_loss: 0.3426 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3763 - acc: 0.8454 - val_loss: 0.3585 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3629 - acc: 0.8711 - val_loss: 0.3597 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3378 - acc: 0.8711 - val_loss: 0.3505 - val_acc: 0.8689\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3259 - acc: 0.8608 - val_loss: 0.3515 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3167 - acc: 0.8660 - val_loss: 0.3725 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa418297700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6621 - acc: 0.6392 - val_loss: 0.4213 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4364 - acc: 0.8093 - val_loss: 0.3596 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4066 - acc: 0.8247 - val_loss: 0.3771 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3812 - acc: 0.8402 - val_loss: 0.3461 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3462 - acc: 0.8660 - val_loss: 0.3227 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3233 - acc: 0.8711 - val_loss: 0.3193 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3144 - acc: 0.8763 - val_loss: 0.3112 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2995 - acc: 0.8866 - val_loss: 0.3057 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2861 - acc: 0.8918 - val_loss: 0.3253 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2688 - acc: 0.9072 - val_loss: 0.3632 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2523 - acc: 0.8969 - val_loss: 0.3948 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2371 - acc: 0.9021 - val_loss: 0.4130 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2204 - acc: 0.9227 - val_loss: 0.4302 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4740b0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7530 - acc: 0.6269 - val_loss: 0.3449 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3817 - acc: 0.8290 - val_loss: 0.4035 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3380 - acc: 0.8653 - val_loss: 0.4167 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3247 - acc: 0.8497 - val_loss: 0.3737 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2930 - acc: 0.8497 - val_loss: 0.3643 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2707 - acc: 0.8705 - val_loss: 0.3424 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2523 - acc: 0.9016 - val_loss: 0.3109 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2353 - acc: 0.9171 - val_loss: 0.3195 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2241 - acc: 0.9275 - val_loss: 0.3542 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2009 - acc: 0.9275 - val_loss: 0.3780 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1807 - acc: 0.9482 - val_loss: 0.4140 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1625 - acc: 0.9534 - val_loss: 0.4819 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa418344700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7035 - acc: 0.6788 - val_loss: 0.3039 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4238 - acc: 0.8290 - val_loss: 0.2960 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3805 - acc: 0.8290 - val_loss: 0.3069 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3104 - acc: 0.8756 - val_loss: 0.3865 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2852 - acc: 0.8964 - val_loss: 0.4137 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2756 - acc: 0.9119 - val_loss: 0.3950 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2533 - acc: 0.8964 - val_loss: 0.3720 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4181c7280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4919 - acc: 0.7629 - val_loss: 0.4237 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3718 - acc: 0.8763 - val_loss: 0.4938 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3059 - acc: 0.8866 - val_loss: 0.4957 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2693 - acc: 0.8711 - val_loss: 0.4093 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2492 - acc: 0.8814 - val_loss: 0.4325 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2219 - acc: 0.9124 - val_loss: 0.5101 - val_acc: 0.8689\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2175 - acc: 0.9072 - val_loss: 0.5224 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1877 - acc: 0.9278 - val_loss: 0.4966 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1696 - acc: 0.9381 - val_loss: 0.5248 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41014b1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7378 - acc: 0.5258 - val_loss: 0.3764 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3688 - acc: 0.8247 - val_loss: 0.3202 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4018 - acc: 0.8196 - val_loss: 0.3178 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3468 - acc: 0.8351 - val_loss: 0.4190 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3356 - acc: 0.8711 - val_loss: 0.4812 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3173 - acc: 0.8763 - val_loss: 0.3854 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2785 - acc: 0.8763 - val_loss: 0.3439 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2740 - acc: 0.8814 - val_loss: 0.3831 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b8667e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6920 - acc: 0.5722 - val_loss: 0.3192 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4671 - acc: 0.8093 - val_loss: 0.3427 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4006 - acc: 0.8402 - val_loss: 0.3624 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3169 - acc: 0.8711 - val_loss: 0.3889 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3180 - acc: 0.8608 - val_loss: 0.4189 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2980 - acc: 0.8608 - val_loss: 0.4668 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3944c18b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6502 - acc: 0.5959 - val_loss: 0.3620 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4817 - acc: 0.8187 - val_loss: 0.3863 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3414 - acc: 0.8549 - val_loss: 0.3820 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3327 - acc: 0.8549 - val_loss: 0.4030 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2683 - acc: 0.8756 - val_loss: 0.3898 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2512 - acc: 0.9016 - val_loss: 0.3794 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3945283a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 246ms/step - loss: 0.7429 - acc: 0.6166 - val_loss: 0.2979 - val_acc: 0.9180\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4282 - acc: 0.8187 - val_loss: 0.3331 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3396 - acc: 0.8601 - val_loss: 0.4304 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3016 - acc: 0.8808 - val_loss: 0.3928 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2891 - acc: 0.8808 - val_loss: 0.4192 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2366 - acc: 0.8964 - val_loss: 0.4665 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e71b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6832 - acc: 0.6443 - val_loss: 0.3360 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5104 - acc: 0.8247 - val_loss: 0.3871 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3674 - acc: 0.8660 - val_loss: 0.4484 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2980 - acc: 0.8454 - val_loss: 0.4972 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2974 - acc: 0.8814 - val_loss: 0.4791 - val_acc: 0.8197\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2605 - acc: 0.8918 - val_loss: 0.5407 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc1e9dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8274 - acc: 0.5515 - val_loss: 0.3112 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4757 - acc: 0.8093 - val_loss: 0.3564 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3910 - acc: 0.8454 - val_loss: 0.4400 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3611 - acc: 0.8402 - val_loss: 0.3678 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3189 - acc: 0.8402 - val_loss: 0.4000 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2848 - acc: 0.8608 - val_loss: 0.4621 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac4941f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6089 - acc: 0.6649 - val_loss: 0.5814 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5189 - acc: 0.8454 - val_loss: 0.4643 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3979 - acc: 0.8608 - val_loss: 0.4577 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3377 - acc: 0.8557 - val_loss: 0.3369 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3058 - acc: 0.8660 - val_loss: 0.3981 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2726 - acc: 0.8866 - val_loss: 0.5066 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2833 - acc: 0.8866 - val_loss: 0.4531 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2187 - acc: 0.9175 - val_loss: 0.4093 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2263 - acc: 0.8969 - val_loss: 0.4489 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b82ba040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6255 - acc: 0.6839 - val_loss: 0.6674 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4337 - acc: 0.8238 - val_loss: 0.5140 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4229 - acc: 0.8187 - val_loss: 0.3182 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3491 - acc: 0.8964 - val_loss: 0.5424 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3299 - acc: 0.8964 - val_loss: 0.7717 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3216 - acc: 0.9067 - val_loss: 0.7313 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2484 - acc: 0.9482 - val_loss: 0.6545 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2226 - acc: 0.9430 - val_loss: 0.6160 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc253940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5640 - acc: 0.7254 - val_loss: 0.4797 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6463 - acc: 0.8394 - val_loss: 0.3820 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3483 - acc: 0.8342 - val_loss: 0.4422 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3065 - acc: 0.8601 - val_loss: 0.6362 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3329 - acc: 0.8912 - val_loss: 0.7279 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3081 - acc: 0.8705 - val_loss: 0.6431 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2252 - acc: 0.9223 - val_loss: 0.6526 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4582f11f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6671 - acc: 0.6186 - val_loss: 0.6555 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5568 - acc: 0.8608 - val_loss: 0.3868 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4146 - acc: 0.8093 - val_loss: 0.3767 - val_acc: 0.8689\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2848 - acc: 0.8918 - val_loss: 0.5356 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3930 - acc: 0.8918 - val_loss: 0.6013 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3335 - acc: 0.8969 - val_loss: 0.5376 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2926 - acc: 0.8814 - val_loss: 0.5733 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2421 - acc: 0.9124 - val_loss: 0.6167 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa474704670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6975 - acc: 0.6289 - val_loss: 0.5492 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5629 - acc: 0.8351 - val_loss: 0.3627 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3812 - acc: 0.8247 - val_loss: 0.6237 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4503 - acc: 0.7629 - val_loss: 0.7408 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3493 - acc: 0.8763 - val_loss: 0.6604 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3672 - acc: 0.8711 - val_loss: 0.6074 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3490 - acc: 0.8814 - val_loss: 0.5593 - val_acc: 0.9180\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beb9f790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7181 - acc: 0.5412 - val_loss: 0.5442 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4902 - acc: 0.8093 - val_loss: 0.2916 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3688 - acc: 0.8454 - val_loss: 0.5037 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3782 - acc: 0.8866 - val_loss: 0.5858 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3021 - acc: 0.8814 - val_loss: 0.5123 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2474 - acc: 0.9124 - val_loss: 0.5880 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2296 - acc: 0.9175 - val_loss: 0.6422 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b43ddd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7281 - acc: 0.6269 - val_loss: 0.4536 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.1264 - acc: 0.6736 - val_loss: 0.5514 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4551 - acc: 0.8912 - val_loss: 1.3913 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.0135 - acc: 0.8756 - val_loss: 1.5570 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.9612 - acc: 0.8912 - val_loss: 1.3776 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7346 - acc: 0.9067 - val_loss: 1.1518 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e283a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6628 - acc: 0.6632 - val_loss: 1.0069 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6933 - acc: 0.8342 - val_loss: 1.9756 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.2526 - acc: 0.5855 - val_loss: 0.7070 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6365 - acc: 0.8705 - val_loss: 1.1397 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7443 - acc: 0.8912 - val_loss: 1.2391 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5745 - acc: 0.9016 - val_loss: 1.1778 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4081 - acc: 0.8964 - val_loss: 1.0627 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2880 - acc: 0.9067 - val_loss: 0.9253 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b4428dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6167 - acc: 0.6031 - val_loss: 0.3812 - val_acc: 0.8525\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7139 - acc: 0.8041 - val_loss: 0.9767 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7975 - acc: 0.7784 - val_loss: 1.1405 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6934 - acc: 0.8454 - val_loss: 1.1196 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5955 - acc: 0.8918 - val_loss: 0.9914 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4496 - acc: 0.8660 - val_loss: 0.9101 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa394331dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7296 - acc: 0.6546 - val_loss: 0.5238 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7631 - acc: 0.7320 - val_loss: 0.7820 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5488 - acc: 0.8144 - val_loss: 1.2076 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7624 - acc: 0.8557 - val_loss: 1.3624 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7275 - acc: 0.8814 - val_loss: 1.3638 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5805 - acc: 0.8505 - val_loss: 1.2597 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac6f6b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6295 - acc: 0.6753 - val_loss: 0.7017 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9787 - acc: 0.7216 - val_loss: 1.2345 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7096 - acc: 0.7990 - val_loss: 1.1632 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5036 - acc: 0.8969 - val_loss: 0.9167 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4461 - acc: 0.8711 - val_loss: 0.7198 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3009 - acc: 0.8866 - val_loss: 0.8595 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410400310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7702 - acc: 0.6269 - val_loss: 0.6091 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2586 - acc: 0.7306 - val_loss: 0.9991 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9850 - acc: 0.8394 - val_loss: 1.1223 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5357 - acc: 0.8083 - val_loss: 1.0003 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.1466 - acc: 0.8446 - val_loss: 1.2171 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7445 - acc: 0.8497 - val_loss: 0.8551 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b86b2af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.0067 - acc: 0.7098 - val_loss: 2.2956 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.2244 - acc: 0.6166 - val_loss: 1.6794 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.2543 - acc: 0.8187 - val_loss: 1.8884 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.4304 - acc: 0.8653 - val_loss: 1.6824 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.1662 - acc: 0.8808 - val_loss: 1.3135 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8422 - acc: 0.8756 - val_loss: 1.0220 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6033 - acc: 0.8912 - val_loss: 0.9708 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3961 - acc: 0.8705 - val_loss: 1.0825 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3618 - acc: 0.8756 - val_loss: 1.1507 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2420 - acc: 0.9275 - val_loss: 1.1876 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1815 - acc: 0.9534 - val_loss: 1.2802 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2040 - acc: 0.9326 - val_loss: 1.2354 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410400b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6712 - acc: 0.5567 - val_loss: 0.8395 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0222 - acc: 0.7577 - val_loss: 0.8334 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9919 - acc: 0.8608 - val_loss: 1.4700 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5157 - acc: 0.9021 - val_loss: 1.7171 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2704 - acc: 0.9021 - val_loss: 1.3992 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9281 - acc: 0.8454 - val_loss: 1.6060 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5436 - acc: 0.8711 - val_loss: 1.6482 - val_acc: 0.7869\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b809a5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6507 - acc: 0.7887 - val_loss: 0.6809 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.0965 - acc: 0.6598 - val_loss: 1.1659 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.0404 - acc: 0.8660 - val_loss: 2.5990 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.6199 - acc: 0.8660 - val_loss: 2.6471 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3737 - acc: 0.8763 - val_loss: 2.1909 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.9186 - acc: 0.8763 - val_loss: 1.7565 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3946f3820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8852 - acc: 0.5773 - val_loss: 1.2858 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.1766 - acc: 0.6598 - val_loss: 1.8228 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.3328 - acc: 0.8505 - val_loss: 2.2454 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.0901 - acc: 0.8454 - val_loss: 1.8833 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7299 - acc: 0.8041 - val_loss: 1.0363 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4164 - acc: 0.8814 - val_loss: 0.6594 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3777 - acc: 0.8299 - val_loss: 0.4350 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3331 - acc: 0.8247 - val_loss: 0.7797 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2244 - acc: 0.9175 - val_loss: 0.8727 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1907 - acc: 0.9330 - val_loss: 1.0375 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2223 - acc: 0.9278 - val_loss: 1.3192 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2214 - acc: 0.9227 - val_loss: 1.3020 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3944394c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6927 - acc: 0.6269 - val_loss: 5.1420 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.8963 - acc: 0.6373 - val_loss: 3.6790 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.1426 - acc: 0.8342 - val_loss: 4.8374 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.8863 - acc: 0.8601 - val_loss: 3.8190 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.3981 - acc: 0.9275 - val_loss: 3.7154 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.3265 - acc: 0.8756 - val_loss: 2.6512 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8249 - acc: 0.9016 - val_loss: 2.4538 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6297 - acc: 0.9119 - val_loss: 2.3260 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4671 - acc: 0.8964 - val_loss: 1.3094 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4414 - acc: 0.9067 - val_loss: 1.8757 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5463 - acc: 0.8860 - val_loss: 1.1668 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3164 - acc: 0.9534 - val_loss: 1.3930 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2321 - acc: 0.9585 - val_loss: 1.6326 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1780 - acc: 0.9585 - val_loss: 1.6882 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1252 - acc: 0.9689 - val_loss: 1.6082 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1190 - acc: 0.9637 - val_loss: 1.6141 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bec57040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1329 - acc: 0.6166 - val_loss: 7.0847 - val_acc: 0.2787\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.8319 - acc: 0.5181 - val_loss: 2.9130 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.7075 - acc: 0.8446 - val_loss: 4.3031 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.8030 - acc: 0.8342 - val_loss: 4.0766 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.8404 - acc: 0.8497 - val_loss: 3.6469 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.9493 - acc: 0.8860 - val_loss: 3.0862 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7284 - acc: 0.8549 - val_loss: 2.5706 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6502 - acc: 0.8290 - val_loss: 2.3559 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5528 - acc: 0.8394 - val_loss: 2.1528 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3325 - acc: 0.9016 - val_loss: 1.9969 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1613 - acc: 0.9223 - val_loss: 2.0204 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1822 - acc: 0.9326 - val_loss: 2.0717 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1341 - acc: 0.9378 - val_loss: 2.1562 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2307 - acc: 0.9275 - val_loss: 2.1354 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3175 - acc: 0.9637 - val_loss: 2.2912 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b4428b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.0154 - acc: 0.7320 - val_loss: 3.3722 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.0471 - acc: 0.6495 - val_loss: 3.6140 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.0624 - acc: 0.8557 - val_loss: 4.4594 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5180 - acc: 0.8402 - val_loss: 4.4888 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8623 - acc: 0.8763 - val_loss: 4.3202 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8105 - acc: 0.8351 - val_loss: 3.1189 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5676 - acc: 0.8402 - val_loss: 1.9657 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4804 - acc: 0.8866 - val_loss: 1.5873 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4007 - acc: 0.8814 - val_loss: 1.4072 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2690 - acc: 0.9330 - val_loss: 1.1459 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2514 - acc: 0.9330 - val_loss: 1.3881 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2183 - acc: 0.9124 - val_loss: 1.5965 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1274 - acc: 0.9691 - val_loss: 1.8979 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2133 - acc: 0.9485 - val_loss: 2.0760 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1310 - acc: 0.9433 - val_loss: 2.0692 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4204d8ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0392 - acc: 0.5979 - val_loss: 7.0171 - val_acc: 0.2787\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.8953 - acc: 0.5361 - val_loss: 5.0073 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.3635 - acc: 0.8144 - val_loss: 5.1877 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.1622 - acc: 0.8351 - val_loss: 4.1757 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9747 - acc: 0.8608 - val_loss: 2.5449 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0712 - acc: 0.8608 - val_loss: 1.5621 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7201 - acc: 0.8196 - val_loss: 1.3261 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5217 - acc: 0.8299 - val_loss: 1.2030 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5381 - acc: 0.8402 - val_loss: 1.1511 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1778 - acc: 0.9330 - val_loss: 1.3679 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2557 - acc: 0.9124 - val_loss: 1.2814 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2536 - acc: 0.9227 - val_loss: 1.2479 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1652 - acc: 0.9485 - val_loss: 1.3450 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0878 - acc: 0.9588 - val_loss: 1.4339 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc313820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1599 - acc: 0.6598 - val_loss: 8.2914 - val_acc: 0.1803\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.6399 - acc: 0.5155 - val_loss: 4.2021 - val_acc: 0.8525\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 3.0332 - acc: 0.8402 - val_loss: 4.9497 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.1546 - acc: 0.8608 - val_loss: 4.1790 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.1755 - acc: 0.8814 - val_loss: 3.4117 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.3590 - acc: 0.8814 - val_loss: 3.1485 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.3458 - acc: 0.8351 - val_loss: 3.2299 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.9326 - acc: 0.8454 - val_loss: 2.3204 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7044 - acc: 0.8402 - val_loss: 2.3238 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3835 - acc: 0.8866 - val_loss: 2.6520 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4369 - acc: 0.8969 - val_loss: 2.0000 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3733 - acc: 0.9072 - val_loss: 1.5068 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3232 - acc: 0.9072 - val_loss: 1.3614 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1917 - acc: 0.9433 - val_loss: 1.4845 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1536 - acc: 0.9433 - val_loss: 1.5483 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1086 - acc: 0.9485 - val_loss: 1.5055 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0537 - acc: 0.9794 - val_loss: 1.4860 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0909 - acc: 0.9691 - val_loss: 1.5925 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4204d8dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6120 - acc: 0.5959 - val_loss: 0.3524 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4156 - acc: 0.8446 - val_loss: 0.3028 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3529 - acc: 0.8394 - val_loss: 0.3464 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3193 - acc: 0.8446 - val_loss: 0.4691 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3324 - acc: 0.8549 - val_loss: 0.4043 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2918 - acc: 0.8653 - val_loss: 0.3510 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3019 - acc: 0.8549 - val_loss: 0.5036 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4582f18b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6713 - acc: 0.5544 - val_loss: 0.3995 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4550 - acc: 0.8290 - val_loss: 0.3336 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3746 - acc: 0.8342 - val_loss: 0.3358 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3597 - acc: 0.8497 - val_loss: 0.4979 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3732 - acc: 0.8394 - val_loss: 0.4283 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3231 - acc: 0.8601 - val_loss: 0.4040 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3045 - acc: 0.8601 - val_loss: 0.5209 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa474704700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7345 - acc: 0.4948 - val_loss: 0.3597 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3849 - acc: 0.8505 - val_loss: 0.4514 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3457 - acc: 0.8402 - val_loss: 0.3764 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3716 - acc: 0.8608 - val_loss: 0.4585 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2995 - acc: 0.8866 - val_loss: 0.4900 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2740 - acc: 0.9021 - val_loss: 0.3847 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410492040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6719 - acc: 0.6237 - val_loss: 0.5993 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5376 - acc: 0.8351 - val_loss: 0.4139 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4090 - acc: 0.8247 - val_loss: 0.4656 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4231 - acc: 0.8144 - val_loss: 0.4891 - val_acc: 0.8197\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3497 - acc: 0.8557 - val_loss: 0.6137 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3826 - acc: 0.8557 - val_loss: 0.6496 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3750 - acc: 0.8711 - val_loss: 0.6330 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc364c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7184 - acc: 0.5825 - val_loss: 0.2873 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4155 - acc: 0.8299 - val_loss: 0.5183 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5189 - acc: 0.7320 - val_loss: 0.4030 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3877 - acc: 0.8505 - val_loss: 0.4978 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3865 - acc: 0.8608 - val_loss: 0.4691 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3437 - acc: 0.8660 - val_loss: 0.4626 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc253160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6679 - acc: 0.6425 - val_loss: 0.3945 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4148 - acc: 0.8290 - val_loss: 0.5980 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4215 - acc: 0.8083 - val_loss: 0.3502 - val_acc: 0.9180\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3729 - acc: 0.8653 - val_loss: 0.4107 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3858 - acc: 0.8912 - val_loss: 0.3394 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3448 - acc: 0.8808 - val_loss: 0.3927 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2660 - acc: 0.8912 - val_loss: 0.6331 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3000 - acc: 0.9119 - val_loss: 0.7074 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2612 - acc: 0.9119 - val_loss: 0.6771 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2209 - acc: 0.9067 - val_loss: 0.7450 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3944393a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6145 - acc: 0.6580 - val_loss: 0.3463 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4530 - acc: 0.7824 - val_loss: 0.3533 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3653 - acc: 0.8446 - val_loss: 0.3162 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3278 - acc: 0.8601 - val_loss: 0.4869 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3059 - acc: 0.8549 - val_loss: 0.5044 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2648 - acc: 0.8808 - val_loss: 0.5479 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2477 - acc: 0.9171 - val_loss: 0.5734 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2294 - acc: 0.9119 - val_loss: 0.6538 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4582d4820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5557 - acc: 0.7526 - val_loss: 0.3671 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4518 - acc: 0.8505 - val_loss: 0.4940 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3601 - acc: 0.8454 - val_loss: 0.4729 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3465 - acc: 0.8351 - val_loss: 0.5371 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2871 - acc: 0.8814 - val_loss: 0.6266 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2822 - acc: 0.9021 - val_loss: 0.5434 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4587b8c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7712 - acc: 0.5103 - val_loss: 0.3521 - val_acc: 0.8689\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5203 - acc: 0.7474 - val_loss: 0.3790 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3690 - acc: 0.8505 - val_loss: 0.7376 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4528 - acc: 0.8608 - val_loss: 0.9413 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4358 - acc: 0.8608 - val_loss: 0.8881 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3397 - acc: 0.9021 - val_loss: 0.7507 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b87da8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6911 - acc: 0.5825 - val_loss: 0.5027 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5285 - acc: 0.7835 - val_loss: 0.4741 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3782 - acc: 0.8608 - val_loss: 0.7027 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4555 - acc: 0.8454 - val_loss: 0.7176 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3764 - acc: 0.8557 - val_loss: 0.4156 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3419 - acc: 0.8814 - val_loss: 0.3987 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3181 - acc: 0.8763 - val_loss: 0.6937 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3134 - acc: 0.8660 - val_loss: 0.6419 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2710 - acc: 0.8969 - val_loss: 0.5816 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2654 - acc: 0.8969 - val_loss: 0.7121 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2409 - acc: 0.9072 - val_loss: 0.8368 - val_acc: 0.7869\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4106e73a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.8853 - acc: 0.4560 - val_loss: 1.7589 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0583 - acc: 0.5907 - val_loss: 0.9388 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8268 - acc: 0.8601 - val_loss: 1.0740 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8653 - acc: 0.8653 - val_loss: 0.7424 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5835 - acc: 0.8653 - val_loss: 0.5658 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5818 - acc: 0.8342 - val_loss: 0.6909 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5199 - acc: 0.8031 - val_loss: 1.0650 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4379 - acc: 0.8549 - val_loss: 0.8306 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3367 - acc: 0.9067 - val_loss: 0.7440 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2869 - acc: 0.9171 - val_loss: 0.7069 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b8253a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7146 - acc: 0.5544 - val_loss: 0.6663 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8046 - acc: 0.7254 - val_loss: 0.7508 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6078 - acc: 0.8705 - val_loss: 0.8643 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4625 - acc: 0.8497 - val_loss: 0.5588 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3320 - acc: 0.8549 - val_loss: 0.5449 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3134 - acc: 0.8497 - val_loss: 0.5847 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2714 - acc: 0.8808 - val_loss: 0.6288 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2419 - acc: 0.8808 - val_loss: 0.5382 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1991 - acc: 0.8912 - val_loss: 0.5438 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1697 - acc: 0.9275 - val_loss: 0.5774 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1474 - acc: 0.9430 - val_loss: 0.6303 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1162 - acc: 0.9430 - val_loss: 0.7013 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0956 - acc: 0.9689 - val_loss: 0.7664 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3946513a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7410 - acc: 0.6649 - val_loss: 0.3716 - val_acc: 0.8852\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6098 - acc: 0.8041 - val_loss: 0.8347 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4007 - acc: 0.8299 - val_loss: 0.5501 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4057 - acc: 0.8608 - val_loss: 0.6806 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2946 - acc: 0.9021 - val_loss: 0.8610 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2769 - acc: 0.8969 - val_loss: 0.6150 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa394458790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7034 - acc: 0.6546 - val_loss: 0.3804 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0105 - acc: 0.6701 - val_loss: 0.6487 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6771 - acc: 0.8608 - val_loss: 1.5220 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.1749 - acc: 0.8402 - val_loss: 1.8285 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.1703 - acc: 0.8557 - val_loss: 1.5300 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8448 - acc: 0.8557 - val_loss: 1.1522 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa39420a160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.8086 - acc: 0.5103 - val_loss: 0.6625 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7761 - acc: 0.7680 - val_loss: 0.6313 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4737 - acc: 0.8351 - val_loss: 1.1552 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8013 - acc: 0.8557 - val_loss: 0.9480 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6376 - acc: 0.8505 - val_loss: 0.6633 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4716 - acc: 0.8557 - val_loss: 0.6272 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3075 - acc: 0.8814 - val_loss: 0.6443 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2773 - acc: 0.8711 - val_loss: 0.5536 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2375 - acc: 0.8918 - val_loss: 0.5909 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2210 - acc: 0.9175 - val_loss: 0.4724 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2261 - acc: 0.9072 - val_loss: 0.7679 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1896 - acc: 0.9381 - val_loss: 1.0373 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2002 - acc: 0.9175 - val_loss: 0.8290 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1615 - acc: 0.9381 - val_loss: 0.8434 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1219 - acc: 0.9588 - val_loss: 1.0046 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3940529d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8284 - acc: 0.7461 - val_loss: 0.5715 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4522 - acc: 0.6425 - val_loss: 0.9093 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6629 - acc: 0.8860 - val_loss: 2.3085 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.6329 - acc: 0.8860 - val_loss: 2.7553 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.6482 - acc: 0.8860 - val_loss: 2.5745 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.2871 - acc: 0.8964 - val_loss: 2.1757 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1cab80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6880 - acc: 0.6580 - val_loss: 1.1017 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.9736 - acc: 0.7824 - val_loss: 0.4582 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7031 - acc: 0.8135 - val_loss: 0.9648 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7989 - acc: 0.8031 - val_loss: 3.4076 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.7231 - acc: 0.6788 - val_loss: 1.3083 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8728 - acc: 0.8653 - val_loss: 1.8380 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8748 - acc: 0.8756 - val_loss: 1.7514 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa394420160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.8870 - acc: 0.6289 - val_loss: 2.8495 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.6060 - acc: 0.5515 - val_loss: 0.9396 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2470 - acc: 0.8608 - val_loss: 1.9435 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5240 - acc: 0.8557 - val_loss: 2.2359 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2578 - acc: 0.8557 - val_loss: 1.9224 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.9230 - acc: 0.8711 - val_loss: 1.6085 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6025 - acc: 0.8454 - val_loss: 1.5839 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410492310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.7845 - acc: 0.5928 - val_loss: 1.1239 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0838 - acc: 0.7732 - val_loss: 5.9056 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.8984 - acc: 0.6289 - val_loss: 1.3735 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8822 - acc: 0.8351 - val_loss: 2.1176 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.9951 - acc: 0.8351 - val_loss: 2.0327 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8041 - acc: 0.8660 - val_loss: 1.7809 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa394420a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7257 - acc: 0.6804 - val_loss: 2.6429 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.0196 - acc: 0.5825 - val_loss: 1.0514 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6381 - acc: 0.8454 - val_loss: 0.9945 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.7179 - acc: 0.8454 - val_loss: 0.7531 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.4453 - acc: 0.8351 - val_loss: 1.0978 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.9804 - acc: 0.8608 - val_loss: 1.0322 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6679 - acc: 0.8557 - val_loss: 0.9733 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5987 - acc: 0.8711 - val_loss: 0.8912 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4554 - acc: 0.8660 - val_loss: 0.8381 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41014b040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.9588 - acc: 0.5026 - val_loss: 2.4339 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.8206 - acc: 0.7358 - val_loss: 2.4480 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5136 - acc: 0.8601 - val_loss: 1.8877 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3744 - acc: 0.8342 - val_loss: 1.7128 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8287 - acc: 0.8756 - val_loss: 1.4612 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3643 - acc: 0.8446 - val_loss: 1.3444 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0586 - acc: 0.8446 - val_loss: 1.7399 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8090 - acc: 0.9067 - val_loss: 1.8225 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4692 - acc: 0.9171 - val_loss: 1.7907 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4379 - acc: 0.9016 - val_loss: 1.9710 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3116 - acc: 0.9067 - val_loss: 1.4746 - val_acc: 0.7705\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4582f1670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8450 - acc: 0.6839 - val_loss: 2.3938 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.4708 - acc: 0.6477 - val_loss: 1.5438 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2007 - acc: 0.8497 - val_loss: 5.2281 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.5916 - acc: 0.8601 - val_loss: 5.7628 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9798 - acc: 0.8135 - val_loss: 4.1770 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0009 - acc: 0.7979 - val_loss: 2.2270 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7236 - acc: 0.8653 - val_loss: 1.8379 - val_acc: 0.7869\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beca4670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0717 - acc: 0.6134 - val_loss: 7.9014 - val_acc: 0.2787\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7037 - acc: 0.4433 - val_loss: 3.0908 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.9323 - acc: 0.8763 - val_loss: 5.2684 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.0169 - acc: 0.8711 - val_loss: 5.9084 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3387 - acc: 0.8608 - val_loss: 5.8503 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4589 - acc: 0.8711 - val_loss: 5.5932 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9151 - acc: 0.8918 - val_loss: 5.5339 - val_acc: 0.7541\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e28550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8882 - acc: 0.6443 - val_loss: 8.1099 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7606 - acc: 0.5052 - val_loss: 4.7720 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2994 - acc: 0.8196 - val_loss: 5.1030 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.9995 - acc: 0.8402 - val_loss: 3.8739 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.1914 - acc: 0.8454 - val_loss: 2.4734 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8490 - acc: 0.8454 - val_loss: 1.6963 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.1540 - acc: 0.8351 - val_loss: 1.9083 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2620 - acc: 0.7835 - val_loss: 1.4051 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7205 - acc: 0.8608 - val_loss: 1.4043 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4746 - acc: 0.8814 - val_loss: 1.6936 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3744 - acc: 0.9175 - val_loss: 1.7485 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3506 - acc: 0.8969 - val_loss: 1.8400 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2830 - acc: 0.9124 - val_loss: 1.7212 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1752 - acc: 0.9588 - val_loss: 1.7620 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beca4af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.9212 - acc: 0.5309 - val_loss: 2.1102 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3670 - acc: 0.7371 - val_loss: 3.0658 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8665 - acc: 0.8454 - val_loss: 2.3614 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6630 - acc: 0.8505 - val_loss: 2.2585 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.3759 - acc: 0.8299 - val_loss: 1.8520 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7637 - acc: 0.8763 - val_loss: 1.8803 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7075 - acc: 0.8608 - val_loss: 2.0565 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7625 - acc: 0.8660 - val_loss: 1.7162 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5244 - acc: 0.8814 - val_loss: 1.4066 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4121 - acc: 0.8918 - val_loss: 0.8071 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3083 - acc: 0.8866 - val_loss: 0.8910 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2820 - acc: 0.8969 - val_loss: 1.1159 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1832 - acc: 0.9536 - val_loss: 1.5395 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1340 - acc: 0.9588 - val_loss: 1.8773 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1349 - acc: 0.9588 - val_loss: 1.9817 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b4428b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.2410 - acc: 0.5959 - val_loss: 25.6193 - val_acc: 0.2787\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.6293 - acc: 0.4974 - val_loss: 6.2780 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.5940 - acc: 0.8446 - val_loss: 8.8150 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.0472 - acc: 0.8497 - val_loss: 7.7705 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.4726 - acc: 0.8705 - val_loss: 6.9096 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.1885 - acc: 0.8342 - val_loss: 5.2664 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.6257 - acc: 0.8290 - val_loss: 4.0986 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2591 - acc: 0.8912 - val_loss: 4.0222 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8643 - acc: 0.8964 - val_loss: 3.6030 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5712 - acc: 0.9067 - val_loss: 3.6675 - val_acc: 0.8033\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6389 - acc: 0.8912 - val_loss: 3.2381 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4663 - acc: 0.9171 - val_loss: 2.7770 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5711 - acc: 0.9119 - val_loss: 2.6975 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2701 - acc: 0.9534 - val_loss: 2.9894 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1490 - acc: 0.9637 - val_loss: 3.1093 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2966 - acc: 0.9482 - val_loss: 2.8007 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2480 - acc: 0.9689 - val_loss: 2.5921 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1195 - acc: 0.9793 - val_loss: 2.5023 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1097 - acc: 0.9845 - val_loss: 2.5625 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0416 - acc: 0.9793 - val_loss: 2.5557 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa394052e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0639 - acc: 0.7047 - val_loss: 6.7213 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.8666 - acc: 0.7565 - val_loss: 5.3434 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.0985 - acc: 0.7668 - val_loss: 3.7656 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1249 - acc: 0.8290 - val_loss: 4.4923 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2555 - acc: 0.8187 - val_loss: 3.0531 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7012 - acc: 0.8705 - val_loss: 2.3310 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3487 - acc: 0.8187 - val_loss: 2.0151 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4981 - acc: 0.8705 - val_loss: 1.4923 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5797 - acc: 0.8756 - val_loss: 1.4284 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6282 - acc: 0.9067 - val_loss: 1.6506 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5980 - acc: 0.9016 - val_loss: 1.7878 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2455 - acc: 0.9378 - val_loss: 2.4867 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4440 - acc: 0.9119 - val_loss: 2.3467 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5038 - acc: 0.9430 - val_loss: 2.4356 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41873f310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.3316 - acc: 0.6340 - val_loss: 20.0844 - val_acc: 0.2459\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.6013 - acc: 0.4381 - val_loss: 7.5021 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.1359 - acc: 0.8660 - val_loss: 11.2107 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.1526 - acc: 0.8505 - val_loss: 11.7338 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9594 - acc: 0.8711 - val_loss: 10.3547 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.9010 - acc: 0.8505 - val_loss: 8.8623 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.0612 - acc: 0.8402 - val_loss: 5.8789 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7181 - acc: 0.8866 - val_loss: 4.4483 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2489 - acc: 0.9175 - val_loss: 4.1144 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0168 - acc: 0.9124 - val_loss: 4.6433 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8178 - acc: 0.8763 - val_loss: 4.7039 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5317 - acc: 0.9381 - val_loss: 4.9494 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4642 - acc: 0.9381 - val_loss: 5.9787 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3915 - acc: 0.9381 - val_loss: 5.7067 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b8335040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.3538 - acc: 0.5825 - val_loss: 24.8974 - val_acc: 0.1148\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.3746 - acc: 0.4330 - val_loss: 9.1803 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6915 - acc: 0.8299 - val_loss: 11.1249 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.6944 - acc: 0.8351 - val_loss: 9.5233 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9604 - acc: 0.8144 - val_loss: 6.7112 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.1269 - acc: 0.7835 - val_loss: 5.2350 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1837 - acc: 0.8247 - val_loss: 4.4034 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9946 - acc: 0.8247 - val_loss: 4.0919 - val_acc: 0.7869\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0586 - acc: 0.8454 - val_loss: 4.6421 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6079 - acc: 0.8918 - val_loss: 4.9248 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6481 - acc: 0.9072 - val_loss: 4.4415 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3773 - acc: 0.9381 - val_loss: 4.7351 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4891 - acc: 0.9175 - val_loss: 3.9713 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2404 - acc: 0.9588 - val_loss: 3.9424 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1735 - acc: 0.9588 - val_loss: 4.1063 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1539 - acc: 0.9536 - val_loss: 4.3191 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1131 - acc: 0.9588 - val_loss: 4.5166 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0518 - acc: 0.9845 - val_loss: 4.6854 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0635 - acc: 0.9742 - val_loss: 4.8027 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41048c280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.4534 - acc: 0.5825 - val_loss: 8.4860 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.1246 - acc: 0.6392 - val_loss: 3.2270 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9939 - acc: 0.8041 - val_loss: 5.5252 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.0943 - acc: 0.8402 - val_loss: 5.3841 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.3339 - acc: 0.8557 - val_loss: 2.3219 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4317 - acc: 0.8196 - val_loss: 2.5352 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7485 - acc: 0.7474 - val_loss: 2.4693 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.9031 - acc: 0.8505 - val_loss: 1.9205 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2889 - acc: 0.8505 - val_loss: 2.5087 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0548 - acc: 0.8814 - val_loss: 2.8597 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7549 - acc: 0.9124 - val_loss: 2.5305 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5442 - acc: 0.9175 - val_loss: 2.5624 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4127 - acc: 0.9021 - val_loss: 2.3306 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4107408b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.3491 - acc: 0.6528 - val_loss: 52.8760 - val_acc: 0.2295\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.4889 - acc: 0.4819 - val_loss: 11.5931 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.6957 - acc: 0.8290 - val_loss: 14.5078 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.9269 - acc: 0.8446 - val_loss: 10.0720 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.9615 - acc: 0.8964 - val_loss: 7.3381 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.5304 - acc: 0.8238 - val_loss: 10.2808 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.4282 - acc: 0.7668 - val_loss: 7.2114 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.7806 - acc: 0.8497 - val_loss: 5.4927 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8554 - acc: 0.8964 - val_loss: 4.5586 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9078 - acc: 0.8497 - val_loss: 3.6056 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3501 - acc: 0.8756 - val_loss: 2.9780 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9560 - acc: 0.9171 - val_loss: 3.1121 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6616 - acc: 0.9119 - val_loss: 3.8287 - val_acc: 0.7541\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4956 - acc: 0.9326 - val_loss: 4.2343 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3609 - acc: 0.9482 - val_loss: 2.6614 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4905 - acc: 0.9275 - val_loss: 3.0104 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2604 - acc: 0.9689 - val_loss: 3.8517 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4881 - acc: 0.9741 - val_loss: 4.5854 - val_acc: 0.7869\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3990 - acc: 0.9689 - val_loss: 4.2059 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3649 - acc: 0.9741 - val_loss: 4.1347 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b81024c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.7230 - acc: 0.6684 - val_loss: 35.8991 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.7434 - acc: 0.4974 - val_loss: 13.1769 - val_acc: 0.8689\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 10.5976 - acc: 0.8549 - val_loss: 17.5025 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9531 - acc: 0.8394 - val_loss: 12.4944 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.0632 - acc: 0.8653 - val_loss: 8.4455 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.6574 - acc: 0.8342 - val_loss: 9.9276 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.8845 - acc: 0.7358 - val_loss: 7.7359 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.4417 - acc: 0.8238 - val_loss: 7.4025 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5121 - acc: 0.8964 - val_loss: 7.0388 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5876 - acc: 0.8756 - val_loss: 5.9141 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.1468 - acc: 0.9119 - val_loss: 5.2905 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6981 - acc: 0.9016 - val_loss: 5.1417 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4772 - acc: 0.9171 - val_loss: 4.7333 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3445 - acc: 0.9223 - val_loss: 3.7327 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1478 - acc: 0.9637 - val_loss: 3.7367 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1197 - acc: 0.9637 - val_loss: 4.1392 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1270 - acc: 0.9637 - val_loss: 4.5038 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0215 - acc: 0.9896 - val_loss: 4.7420 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0529 - acc: 0.9793 - val_loss: 4.9965 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3942c43a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.2164 - acc: 0.5722 - val_loss: 8.9145 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.9516 - acc: 0.7320 - val_loss: 9.4783 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.4287 - acc: 0.8454 - val_loss: 5.6129 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.5436 - acc: 0.8557 - val_loss: 10.5549 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7269 - acc: 0.8711 - val_loss: 9.6719 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.7999 - acc: 0.8196 - val_loss: 7.9721 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.6607 - acc: 0.8041 - val_loss: 5.3301 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2917 - acc: 0.8505 - val_loss: 6.2664 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.8493 - acc: 0.8608 - val_loss: 5.8025 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.6082 - acc: 0.8814 - val_loss: 5.5611 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7430 - acc: 0.8660 - val_loss: 8.1088 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8487 - acc: 0.8969 - val_loss: 6.9534 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3787aeca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8648 - acc: 0.5979 - val_loss: 16.3012 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.8899 - acc: 0.6598 - val_loss: 12.4019 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.6446 - acc: 0.7990 - val_loss: 8.8440 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.6126 - acc: 0.8196 - val_loss: 5.4438 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7201 - acc: 0.7887 - val_loss: 3.7238 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.6444 - acc: 0.8299 - val_loss: 2.8224 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6292 - acc: 0.8814 - val_loss: 2.3588 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5537 - acc: 0.8918 - val_loss: 2.2525 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.9293 - acc: 0.8763 - val_loss: 3.2852 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.1872 - acc: 0.8814 - val_loss: 3.1955 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5771 - acc: 0.9124 - val_loss: 2.5127 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3907 - acc: 0.9381 - val_loss: 2.4952 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4216 - acc: 0.9278 - val_loss: 2.3943 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3941ef0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 239ms/step - loss: 2.0612 - acc: 0.5052 - val_loss: 71.3678 - val_acc: 0.2295\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 38.3612 - acc: 0.4227 - val_loss: 11.3250 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.8398 - acc: 0.8454 - val_loss: 15.5787 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.3728 - acc: 0.8505 - val_loss: 12.3705 - val_acc: 0.8689\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 10.7153 - acc: 0.8351 - val_loss: 11.4351 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.7865 - acc: 0.8247 - val_loss: 13.7866 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.8121 - acc: 0.7629 - val_loss: 14.5288 - val_acc: 0.7377\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0ea4a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6905 - acc: 0.6528 - val_loss: 0.3603 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4580 - acc: 0.8187 - val_loss: 0.4267 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3800 - acc: 0.8446 - val_loss: 0.3506 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3842 - acc: 0.8135 - val_loss: 0.3964 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3340 - acc: 0.8549 - val_loss: 0.6584 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3802 - acc: 0.8446 - val_loss: 0.6320 - val_acc: 0.9344\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3270 - acc: 0.8756 - val_loss: 0.4701 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3167 - acc: 0.8964 - val_loss: 0.3880 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa394069c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6812 - acc: 0.5596 - val_loss: 0.3784 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4637 - acc: 0.8083 - val_loss: 0.4641 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4570 - acc: 0.8031 - val_loss: 0.6868 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4581 - acc: 0.8394 - val_loss: 0.8522 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4462 - acc: 0.8342 - val_loss: 0.5941 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3663 - acc: 0.8446 - val_loss: 0.4894 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3941a7c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.7923 - acc: 0.5567 - val_loss: 0.4961 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4319 - acc: 0.8196 - val_loss: 0.2819 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3987 - acc: 0.8505 - val_loss: 0.4151 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3639 - acc: 0.8505 - val_loss: 0.4913 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3310 - acc: 0.8196 - val_loss: 0.4166 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2852 - acc: 0.8454 - val_loss: 0.4802 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2935 - acc: 0.8660 - val_loss: 0.5513 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa47425b280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6401 - acc: 0.6392 - val_loss: 0.3439 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4227 - acc: 0.8041 - val_loss: 0.5250 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4000 - acc: 0.7990 - val_loss: 0.3488 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4731 - acc: 0.8299 - val_loss: 0.4279 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4044 - acc: 0.8402 - val_loss: 0.5044 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3616 - acc: 0.8041 - val_loss: 0.4354 - val_acc: 0.7869\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bec57430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8241 - acc: 0.5103 - val_loss: 0.3514 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6079 - acc: 0.7732 - val_loss: 0.5120 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4189 - acc: 0.8299 - val_loss: 0.4226 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4307 - acc: 0.8402 - val_loss: 0.2918 - val_acc: 0.8852\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4113 - acc: 0.8144 - val_loss: 0.3461 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3401 - acc: 0.8608 - val_loss: 0.3828 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3589 - acc: 0.8557 - val_loss: 0.4303 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3210 - acc: 0.8711 - val_loss: 0.3915 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3519 - acc: 0.8402 - val_loss: 0.4642 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e0da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.3500 - acc: 0.5181 - val_loss: 1.7260 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7638 - acc: 0.7617 - val_loss: 0.5510 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6897 - acc: 0.8238 - val_loss: 0.4846 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6510 - acc: 0.7979 - val_loss: 0.4675 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5173 - acc: 0.8342 - val_loss: 0.6615 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3695 - acc: 0.8912 - val_loss: 0.7261 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4893 - acc: 0.8912 - val_loss: 0.7999 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4349 - acc: 0.8808 - val_loss: 0.8528 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3323 - acc: 0.8808 - val_loss: 0.8773 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1e33a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.1124 - acc: 0.5285 - val_loss: 0.3952 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5541 - acc: 0.8238 - val_loss: 0.4796 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3591 - acc: 0.8446 - val_loss: 0.8455 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4475 - acc: 0.8238 - val_loss: 0.7654 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5390 - acc: 0.8446 - val_loss: 0.5609 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3574 - acc: 0.8290 - val_loss: 1.1290 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa474704820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.8314 - acc: 0.6082 - val_loss: 0.8103 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5254 - acc: 0.7990 - val_loss: 0.3625 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4800 - acc: 0.7629 - val_loss: 0.3438 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4464 - acc: 0.8402 - val_loss: 0.4948 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4555 - acc: 0.8814 - val_loss: 0.7945 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3822 - acc: 0.8557 - val_loss: 1.0003 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3538 - acc: 0.8660 - val_loss: 0.5104 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3001 - acc: 0.8660 - val_loss: 0.4644 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4742ef280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.8418 - acc: 0.5309 - val_loss: 0.4476 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8689 - acc: 0.7165 - val_loss: 0.4952 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7012 - acc: 0.7577 - val_loss: 0.5663 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8663 - acc: 0.8144 - val_loss: 1.0782 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8471 - acc: 0.8299 - val_loss: 1.2064 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5977 - acc: 0.8402 - val_loss: 1.1057 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac494550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7589 - acc: 0.5619 - val_loss: 1.6291 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2487 - acc: 0.5464 - val_loss: 0.8018 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8811 - acc: 0.8402 - val_loss: 0.7990 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9135 - acc: 0.8402 - val_loss: 0.5457 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7187 - acc: 0.8505 - val_loss: 0.4566 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5396 - acc: 0.8505 - val_loss: 0.7208 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4772 - acc: 0.8557 - val_loss: 0.7117 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3910 - acc: 0.8505 - val_loss: 0.6288 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3204 - acc: 0.8454 - val_loss: 0.6892 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3261 - acc: 0.8557 - val_loss: 0.9509 - val_acc: 0.7869\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4becf3d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7388 - acc: 0.6010 - val_loss: 2.5621 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.5368 - acc: 0.6269 - val_loss: 2.1770 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2983 - acc: 0.8497 - val_loss: 2.8734 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.3891 - acc: 0.8290 - val_loss: 2.4608 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9116 - acc: 0.8653 - val_loss: 1.9887 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9426 - acc: 0.8756 - val_loss: 1.7507 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8647 - acc: 0.8860 - val_loss: 1.4808 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5993 - acc: 0.8756 - val_loss: 1.1702 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3741 - acc: 0.8964 - val_loss: 0.9166 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2709 - acc: 0.9067 - val_loss: 0.8823 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2662 - acc: 0.8964 - val_loss: 0.8467 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2245 - acc: 0.8964 - val_loss: 0.8033 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1483 - acc: 0.9378 - val_loss: 0.9508 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1910 - acc: 0.9430 - val_loss: 0.7975 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1057 - acc: 0.968 - 0s 6ms/step - loss: 0.1400 - acc: 0.9585 - val_loss: 0.8827 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1019 - acc: 0.9585 - val_loss: 1.0506 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0847 - acc: 0.9585 - val_loss: 1.0504 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0569 - acc: 0.9793 - val_loss: 0.9911 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0954 - acc: 0.9793 - val_loss: 1.0715 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4becbb550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6724 - acc: 0.6477 - val_loss: 6.3425 - val_acc: 0.3279\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3983 - acc: 0.6010 - val_loss: 1.9722 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9568 - acc: 0.8549 - val_loss: 2.4607 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8911 - acc: 0.8446 - val_loss: 1.8720 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2065 - acc: 0.8497 - val_loss: 1.3581 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7374 - acc: 0.8238 - val_loss: 1.4944 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6777 - acc: 0.7720 - val_loss: 1.1210 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4210 - acc: 0.8394 - val_loss: 0.9000 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3462 - acc: 0.8860 - val_loss: 0.8302 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4298 - acc: 0.8446 - val_loss: 1.0356 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3025 - acc: 0.8808 - val_loss: 1.0633 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2417 - acc: 0.9067 - val_loss: 0.8937 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2038 - acc: 0.9016 - val_loss: 0.7627 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1760 - acc: 0.9223 - val_loss: 0.7132 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1496 - acc: 0.9378 - val_loss: 0.8054 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1353 - acc: 0.9637 - val_loss: 0.8299 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1148 - acc: 0.9689 - val_loss: 0.6761 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1054 - acc: 0.9637 - val_loss: 0.6613 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0901 - acc: 0.9741 - val_loss: 0.7461 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0870 - acc: 0.9637 - val_loss: 0.7819 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3786b4af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0060 - acc: 0.4588 - val_loss: 4.9809 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.9393 - acc: 0.4948 - val_loss: 1.4873 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4003 - acc: 0.8557 - val_loss: 2.2954 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5769 - acc: 0.8402 - val_loss: 2.6276 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.2393 - acc: 0.8454 - val_loss: 2.5297 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7864 - acc: 0.8608 - val_loss: 2.3871 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5698 - acc: 0.8557 - val_loss: 2.3298 - val_acc: 0.7541\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1ca550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7054 - acc: 0.6753 - val_loss: 1.3777 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7326 - acc: 0.6392 - val_loss: 1.3290 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0928 - acc: 0.8247 - val_loss: 0.6849 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3799 - acc: 0.7680 - val_loss: 0.8807 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3626 - acc: 0.8144 - val_loss: 2.0159 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3669 - acc: 0.8402 - val_loss: 2.2308 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0039 - acc: 0.8454 - val_loss: 1.9743 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6058 - acc: 0.8402 - val_loss: 1.4151 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410740c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.8982 - acc: 0.6546 - val_loss: 1.0967 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.1033 - acc: 0.8196 - val_loss: 0.5506 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0903 - acc: 0.8196 - val_loss: 0.8365 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5066 - acc: 0.8402 - val_loss: 1.2680 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.1395 - acc: 0.6392 - val_loss: 1.6413 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9185 - acc: 0.8608 - val_loss: 2.6908 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.1881 - acc: 0.8660 - val_loss: 3.1084 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4101a5f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0265 - acc: 0.6839 - val_loss: 5.1702 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.5836 - acc: 0.5648 - val_loss: 2.4671 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.6795 - acc: 0.8497 - val_loss: 2.4534 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.8159 - acc: 0.8653 - val_loss: 1.4694 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3339 - acc: 0.8083 - val_loss: 1.6281 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5170 - acc: 0.8808 - val_loss: 1.7018 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0416 - acc: 0.8238 - val_loss: 1.1482 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7435 - acc: 0.8549 - val_loss: 1.2408 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6189 - acc: 0.8964 - val_loss: 1.1741 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3454 - acc: 0.9482 - val_loss: 1.1940 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3753 - acc: 0.8964 - val_loss: 1.1732 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3449 - acc: 0.8912 - val_loss: 1.5614 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b864ef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.8880 - acc: 0.6891 - val_loss: 6.0471 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.8805 - acc: 0.4819 - val_loss: 3.8385 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.8503 - acc: 0.8342 - val_loss: 4.1159 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.6017 - acc: 0.8394 - val_loss: 2.7538 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2524 - acc: 0.8446 - val_loss: 1.3819 - val_acc: 0.9344\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6272 - acc: 0.8083 - val_loss: 1.7409 - val_acc: 0.8361\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9260 - acc: 0.7927 - val_loss: 2.2715 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8857 - acc: 0.8031 - val_loss: 1.5125 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5487 - acc: 0.8653 - val_loss: 1.0375 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5662 - acc: 0.8653 - val_loss: 0.7057 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4443 - acc: 0.9171 - val_loss: 0.9791 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4219 - acc: 0.9275 - val_loss: 1.3160 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3460 - acc: 0.9378 - val_loss: 1.5283 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2764 - acc: 0.9223 - val_loss: 1.6120 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1809 - acc: 0.9430 - val_loss: 1.5379 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa39438b8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7800 - acc: 0.6031 - val_loss: 8.6333 - val_acc: 0.2787\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.0365 - acc: 0.5155 - val_loss: 4.0103 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0068 - acc: 0.8608 - val_loss: 5.0972 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.6515 - acc: 0.8711 - val_loss: 5.1128 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2200 - acc: 0.8660 - val_loss: 4.2473 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8963 - acc: 0.8557 - val_loss: 3.1723 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1608 - acc: 0.8144 - val_loss: 2.8728 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.2280 - acc: 0.8144 - val_loss: 2.2981 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6274 - acc: 0.8711 - val_loss: 2.2578 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6614 - acc: 0.8763 - val_loss: 2.2274 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4643 - acc: 0.8866 - val_loss: 1.7414 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3413 - acc: 0.9227 - val_loss: 1.5561 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3436 - acc: 0.9124 - val_loss: 2.3137 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2913 - acc: 0.9072 - val_loss: 2.6796 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2721 - acc: 0.9330 - val_loss: 3.0018 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2041 - acc: 0.9330 - val_loss: 3.0605 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1701 - acc: 0.9175 - val_loss: 3.1448 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa394332040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0115 - acc: 0.5361 - val_loss: 2.5827 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9892 - acc: 0.6959 - val_loss: 2.4793 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5025 - acc: 0.8660 - val_loss: 4.1707 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7843 - acc: 0.8557 - val_loss: 3.5913 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0133 - acc: 0.8402 - val_loss: 2.4885 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7263 - acc: 0.8608 - val_loss: 1.6307 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4797 - acc: 0.8351 - val_loss: 1.0368 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5719 - acc: 0.8814 - val_loss: 0.9981 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2940 - acc: 0.8918 - val_loss: 1.4661 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5117 - acc: 0.8557 - val_loss: 1.0225 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2412 - acc: 0.9381 - val_loss: 1.0566 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2240 - acc: 0.9124 - val_loss: 1.1671 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1926 - acc: 0.9227 - val_loss: 1.2737 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3785410d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1983 - acc: 0.6237 - val_loss: 9.2665 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.9106 - acc: 0.5206 - val_loss: 2.5665 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.1678 - acc: 0.8402 - val_loss: 2.3375 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.0901 - acc: 0.8505 - val_loss: 1.1796 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.5091 - acc: 0.8041 - val_loss: 1.1625 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.6345 - acc: 0.8299 - val_loss: 1.9387 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.1628 - acc: 0.8711 - val_loss: 1.5857 - val_acc: 0.8033\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.9123 - acc: 0.8866 - val_loss: 1.4754 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5941 - acc: 0.8660 - val_loss: 1.5702 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3293 - acc: 0.9072 - val_loss: 1.8733 - val_acc: 0.7705\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4582f1e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.0968 - acc: 0.5492 - val_loss: 40.2646 - val_acc: 0.2131\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 24.7841 - acc: 0.4249 - val_loss: 5.7685 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.6272 - acc: 0.8601 - val_loss: 8.9347 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.1541 - acc: 0.8601 - val_loss: 8.2258 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.9418 - acc: 0.8653 - val_loss: 5.6279 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.5967 - acc: 0.8446 - val_loss: 6.5669 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.3591 - acc: 0.8187 - val_loss: 8.2438 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.9351 - acc: 0.8446 - val_loss: 8.2214 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.5482 - acc: 0.8964 - val_loss: 7.5777 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.4057 - acc: 0.9067 - val_loss: 6.3728 - val_acc: 0.7541\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4582f1670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.3455 - acc: 0.5285 - val_loss: 4.3533 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.1234 - acc: 0.7358 - val_loss: 6.3723 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.0205 - acc: 0.8497 - val_loss: 5.3805 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.8498 - acc: 0.8342 - val_loss: 4.8416 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.7593 - acc: 0.8446 - val_loss: 5.6383 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5336 - acc: 0.8808 - val_loss: 6.3904 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc2f2d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1048 - acc: 0.5722 - val_loss: 9.2568 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.2637 - acc: 0.6237 - val_loss: 3.7210 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7653 - acc: 0.8247 - val_loss: 3.3811 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.2223 - acc: 0.8351 - val_loss: 5.0632 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.2238 - acc: 0.8557 - val_loss: 4.4470 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.3215 - acc: 0.8660 - val_loss: 3.7024 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2339 - acc: 0.8866 - val_loss: 4.3827 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7396 - acc: 0.8608 - val_loss: 3.7538 - val_acc: 0.7869\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc1e99d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.2313 - acc: 0.4948 - val_loss: 44.6354 - val_acc: 0.1803\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.0671 - acc: 0.4175 - val_loss: 7.6889 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.9116 - acc: 0.8196 - val_loss: 8.4341 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.2689 - acc: 0.8247 - val_loss: 6.7425 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1456 - acc: 0.8093 - val_loss: 4.0518 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.1526 - acc: 0.7680 - val_loss: 4.9271 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2784 - acc: 0.7835 - val_loss: 4.9815 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9131 - acc: 0.8660 - val_loss: 4.5306 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8203 - acc: 0.8814 - val_loss: 4.3886 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5934 - acc: 0.9227 - val_loss: 4.1617 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41014b550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.1347 - acc: 0.6546 - val_loss: 15.7192 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.0022 - acc: 0.5103 - val_loss: 10.9055 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7397 - acc: 0.8351 - val_loss: 11.3033 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.1090 - acc: 0.8505 - val_loss: 6.8854 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.8882 - acc: 0.8660 - val_loss: 4.3463 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.0703 - acc: 0.7990 - val_loss: 4.8233 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.6260 - acc: 0.8196 - val_loss: 4.9750 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.5332 - acc: 0.8454 - val_loss: 5.7046 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.8354 - acc: 0.8814 - val_loss: 6.7096 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.6821 - acc: 0.8814 - val_loss: 4.4423 - val_acc: 0.7705\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beca45e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.8014 - acc: 0.6114 - val_loss: 41.8637 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 33.6747 - acc: 0.4922 - val_loss: 9.0137 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9880 - acc: 0.8290 - val_loss: 16.3520 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3494 - acc: 0.8549 - val_loss: 10.8909 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.1948 - acc: 0.8756 - val_loss: 8.7604 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6860 - acc: 0.8238 - val_loss: 12.1931 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.8838 - acc: 0.8497 - val_loss: 13.1534 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.8303 - acc: 0.8860 - val_loss: 11.8894 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3352 - acc: 0.9119 - val_loss: 12.0129 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.0217 - acc: 0.9016 - val_loss: 11.7942 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1e3550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 4.5953 - acc: 0.5337 - val_loss: 11.4155 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.0104 - acc: 0.7772 - val_loss: 13.9450 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.1802 - acc: 0.8031 - val_loss: 11.1664 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.0878 - acc: 0.8446 - val_loss: 8.6114 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.8699 - acc: 0.8860 - val_loss: 7.1368 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.2413 - acc: 0.8705 - val_loss: 9.1101 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.0450 - acc: 0.8705 - val_loss: 11.1315 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.1949 - acc: 0.9016 - val_loss: 8.8012 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.1597 - acc: 0.8912 - val_loss: 8.3878 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4481 - acc: 0.9171 - val_loss: 9.7619 - val_acc: 0.7869\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e28280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.0684 - acc: 0.6649 - val_loss: 25.5125 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.1006 - acc: 0.5361 - val_loss: 13.2527 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7793 - acc: 0.8505 - val_loss: 14.5428 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.8948 - acc: 0.8505 - val_loss: 15.4870 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.4287 - acc: 0.8711 - val_loss: 10.6598 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7070 - acc: 0.8299 - val_loss: 9.7373 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.6345 - acc: 0.8608 - val_loss: 12.9527 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.6638 - acc: 0.9124 - val_loss: 12.9410 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8803 - acc: 0.9124 - val_loss: 14.3707 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9595 - acc: 0.8866 - val_loss: 14.6923 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8035 - acc: 0.9227 - val_loss: 14.6984 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e0ddc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.3626 - acc: 0.6031 - val_loss: 70.2655 - val_acc: 0.2623\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 44.1274 - acc: 0.4227 - val_loss: 11.3286 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.1732 - acc: 0.8093 - val_loss: 15.5640 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.4009 - acc: 0.8247 - val_loss: 12.8429 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.5866 - acc: 0.8351 - val_loss: 10.6727 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7232 - acc: 0.8196 - val_loss: 16.5647 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.5806 - acc: 0.7474 - val_loss: 17.7994 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.7273 - acc: 0.8093 - val_loss: 17.6819 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1604 - acc: 0.8608 - val_loss: 17.8363 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.0102 - acc: 0.8814 - val_loss: 16.4887 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e28ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.6093 - acc: 0.6856 - val_loss: 86.1019 - val_acc: 0.1967\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 44.9321 - acc: 0.4124 - val_loss: 11.9678 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.0225 - acc: 0.8608 - val_loss: 20.8423 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.7926 - acc: 0.8660 - val_loss: 20.8175 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.5220 - acc: 0.8454 - val_loss: 19.5550 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7769 - acc: 0.8196 - val_loss: 19.7040 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.5793 - acc: 0.8608 - val_loss: 18.7559 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa37852cee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3.1186 - acc: 0.8031 - val_loss: 120.8820 - val_acc: 0.2623\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 67.8116 - acc: 0.4922 - val_loss: 19.1884 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 21.3801 - acc: 0.8601 - val_loss: 34.9217 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.5062 - acc: 0.8549 - val_loss: 30.4991 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.5521 - acc: 0.8394 - val_loss: 21.9845 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.5486 - acc: 0.8031 - val_loss: 16.9310 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.8693 - acc: 0.7927 - val_loss: 13.6224 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.9889 - acc: 0.8860 - val_loss: 13.2547 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.8531 - acc: 0.9171 - val_loss: 12.9293 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.3375 - acc: 0.9119 - val_loss: 11.6198 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.2332 - acc: 0.8860 - val_loss: 10.5511 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.0782 - acc: 0.8653 - val_loss: 8.9114 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8542 - acc: 0.9430 - val_loss: 10.5578 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7879 - acc: 0.9326 - val_loss: 11.8313 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7100 - acc: 0.9482 - val_loss: 11.2778 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4080 - acc: 0.9482 - val_loss: 11.4736 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7523 - acc: 0.9534 - val_loss: 10.2018 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4483d0e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 9.2845 - acc: 0.4352 - val_loss: 33.3665 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.8071 - acc: 0.6218 - val_loss: 24.7069 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.0445 - acc: 0.8446 - val_loss: 21.6301 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 22.6750 - acc: 0.8290 - val_loss: 18.8827 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.5092 - acc: 0.8238 - val_loss: 22.8114 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.1935 - acc: 0.7824 - val_loss: 25.8018 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.6295 - acc: 0.8083 - val_loss: 21.5940 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.4754 - acc: 0.8549 - val_loss: 19.7166 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.3240 - acc: 0.9016 - val_loss: 15.3940 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.4943 - acc: 0.9119 - val_loss: 15.4929 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.6088 - acc: 0.9171 - val_loss: 18.1323 - val_acc: 0.8361\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 2.8786 - acc: 0.9067 - val_loss: 14.5666 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3415 - acc: 0.9378 - val_loss: 12.8913 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.2850 - acc: 0.9275 - val_loss: 15.4049 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3219 - acc: 0.9378 - val_loss: 19.7876 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0284 - acc: 0.9430 - val_loss: 22.9390 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.8108 - acc: 0.9378 - val_loss: 19.7708 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2643 - acc: 0.9741 - val_loss: 16.6064 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4183ab430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.9679 - acc: 0.5000 - val_loss: 39.5378 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 27.1734 - acc: 0.6289 - val_loss: 21.2289 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.1468 - acc: 0.8454 - val_loss: 10.6644 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.4795 - acc: 0.8299 - val_loss: 20.3438 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.0555 - acc: 0.7371 - val_loss: 16.0454 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1276 - acc: 0.8454 - val_loss: 20.2879 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.8917 - acc: 0.8660 - val_loss: 25.7899 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.6010 - acc: 0.8814 - val_loss: 28.8710 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b862a310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 3.5945 - acc: 0.4278 - val_loss: 78.8672 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 58.7525 - acc: 0.5876 - val_loss: 9.5523 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.1223 - acc: 0.7165 - val_loss: 24.3037 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.0680 - acc: 0.8196 - val_loss: 33.7916 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.6230 - acc: 0.8402 - val_loss: 22.6068 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.8794 - acc: 0.8505 - val_loss: 24.7580 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0890 - acc: 0.8247 - val_loss: 21.0776 - val_acc: 0.7541\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b845d3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.9718 - acc: 0.5928 - val_loss: 88.0593 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 47.9859 - acc: 0.6082 - val_loss: 25.6405 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.3688 - acc: 0.8454 - val_loss: 30.2243 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.2836 - acc: 0.8247 - val_loss: 26.8843 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.0287 - acc: 0.7577 - val_loss: 17.8633 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.9872 - acc: 0.7938 - val_loss: 18.3675 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.8150 - acc: 0.8351 - val_loss: 25.8031 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0349 - acc: 0.8557 - val_loss: 24.7592 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.6515 - acc: 0.9021 - val_loss: 23.2238 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.9562 - acc: 0.9175 - val_loss: 21.4070 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa394704ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7851 - acc: 0.4456 - val_loss: 0.7964 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7851 - acc: 0.4456 - val_loss: 0.7964 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7851 - acc: 0.4456 - val_loss: 0.7964 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7851 - acc: 0.4456 - val_loss: 0.7963 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7851 - acc: 0.4456 - val_loss: 0.7963 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7851 - acc: 0.4456 - val_loss: 0.7963 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7851 - acc: 0.4456 - val_loss: 0.7963 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7851 - acc: 0.4456 - val_loss: 0.7963 - val_acc: 0.4590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7851 - acc: 0.4456 - val_loss: 0.7963 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7851 - acc: 0.4456 - val_loss: 0.7963 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7850 - acc: 0.4456 - val_loss: 0.7963 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7850 - acc: 0.4456 - val_loss: 0.7963 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7850 - acc: 0.4456 - val_loss: 0.7963 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7850 - acc: 0.4456 - val_loss: 0.7963 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7850 - acc: 0.4456 - val_loss: 0.7963 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7850 - acc: 0.4456 - val_loss: 0.7962 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7850 - acc: 0.4456 - val_loss: 0.7962 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7850 - acc: 0.4456 - val_loss: 0.7962 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7850 - acc: 0.4456 - val_loss: 0.7962 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7850 - acc: 0.4456 - val_loss: 0.7962 - val_acc: 0.4590\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa39422e310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8529 - acc: 0.4663 - val_loss: 0.7839 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8529 - acc: 0.4715 - val_loss: 0.7839 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8529 - acc: 0.4715 - val_loss: 0.7839 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8529 - acc: 0.4715 - val_loss: 0.7839 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8529 - acc: 0.4715 - val_loss: 0.7839 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8529 - acc: 0.4715 - val_loss: 0.7839 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8529 - acc: 0.4715 - val_loss: 0.7839 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8529 - acc: 0.4715 - val_loss: 0.7839 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8529 - acc: 0.4715 - val_loss: 0.7839 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8529 - acc: 0.4715 - val_loss: 0.7839 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8529 - acc: 0.4715 - val_loss: 0.7838 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8529 - acc: 0.4715 - val_loss: 0.7838 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8528 - acc: 0.4715 - val_loss: 0.7838 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8528 - acc: 0.4715 - val_loss: 0.7838 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8528 - acc: 0.4715 - val_loss: 0.7838 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8528 - acc: 0.4715 - val_loss: 0.7838 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8528 - acc: 0.4715 - val_loss: 0.7838 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8528 - acc: 0.4715 - val_loss: 0.7838 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8528 - acc: 0.4715 - val_loss: 0.7838 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8528 - acc: 0.4715 - val_loss: 0.7838 - val_acc: 0.5246\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3940b83a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7627 - acc: 0.5103 - val_loss: 0.8374 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7627 - acc: 0.5206 - val_loss: 0.8374 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7627 - acc: 0.5206 - val_loss: 0.8374 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7627 - acc: 0.5206 - val_loss: 0.8374 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7627 - acc: 0.5206 - val_loss: 0.8374 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7627 - acc: 0.5206 - val_loss: 0.8374 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7627 - acc: 0.5206 - val_loss: 0.8374 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7626 - acc: 0.5206 - val_loss: 0.8374 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7626 - acc: 0.5206 - val_loss: 0.8374 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7626 - acc: 0.5206 - val_loss: 0.8374 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7626 - acc: 0.5206 - val_loss: 0.8374 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7626 - acc: 0.5206 - val_loss: 0.8374 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7626 - acc: 0.5206 - val_loss: 0.8374 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7626 - acc: 0.5206 - val_loss: 0.8373 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7626 - acc: 0.5206 - val_loss: 0.8373 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7626 - acc: 0.5206 - val_loss: 0.8373 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7626 - acc: 0.5206 - val_loss: 0.8373 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7626 - acc: 0.5206 - val_loss: 0.8373 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7626 - acc: 0.5206 - val_loss: 0.8373 - val_acc: 0.4754\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7626 - acc: 0.5206 - val_loss: 0.8373 - val_acc: 0.4754\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3784ad0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6853 - acc: 0.5979 - val_loss: 0.8216 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6853 - acc: 0.5979 - val_loss: 0.8216 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6853 - acc: 0.5979 - val_loss: 0.8216 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6853 - acc: 0.5979 - val_loss: 0.8216 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6853 - acc: 0.5979 - val_loss: 0.8216 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6853 - acc: 0.5979 - val_loss: 0.8215 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6853 - acc: 0.5979 - val_loss: 0.8215 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6853 - acc: 0.5979 - val_loss: 0.8215 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6853 - acc: 0.5979 - val_loss: 0.8215 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6852 - acc: 0.5979 - val_loss: 0.8215 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6852 - acc: 0.5979 - val_loss: 0.8215 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6852 - acc: 0.5979 - val_loss: 0.8215 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6852 - acc: 0.5979 - val_loss: 0.8215 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6852 - acc: 0.5979 - val_loss: 0.8215 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6852 - acc: 0.5979 - val_loss: 0.8215 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6852 - acc: 0.5979 - val_loss: 0.8215 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6852 - acc: 0.5979 - val_loss: 0.8215 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6852 - acc: 0.5979 - val_loss: 0.8214 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6852 - acc: 0.5979 - val_loss: 0.8214 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6852 - acc: 0.5979 - val_loss: 0.8214 - val_acc: 0.4590\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3785ea4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9615 - acc: 0.4124 - val_loss: 0.9522 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9615 - acc: 0.4124 - val_loss: 0.9522 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9615 - acc: 0.4124 - val_loss: 0.9522 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9614 - acc: 0.4124 - val_loss: 0.9522 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9614 - acc: 0.4124 - val_loss: 0.9521 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9614 - acc: 0.4124 - val_loss: 0.9521 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9614 - acc: 0.4124 - val_loss: 0.9521 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9614 - acc: 0.4124 - val_loss: 0.9521 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9614 - acc: 0.4124 - val_loss: 0.9521 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9614 - acc: 0.4124 - val_loss: 0.9521 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9614 - acc: 0.4124 - val_loss: 0.9521 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9614 - acc: 0.4124 - val_loss: 0.9521 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9613 - acc: 0.4124 - val_loss: 0.9521 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9613 - acc: 0.4124 - val_loss: 0.9521 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9613 - acc: 0.4124 - val_loss: 0.9520 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9613 - acc: 0.4124 - val_loss: 0.9520 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9613 - acc: 0.4124 - val_loss: 0.9520 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9613 - acc: 0.4124 - val_loss: 0.9520 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9613 - acc: 0.4124 - val_loss: 0.9520 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9613 - acc: 0.4124 - val_loss: 0.9520 - val_acc: 0.4098\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc2f7e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8951 - acc: 0.5078 - val_loss: 0.9836 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8951 - acc: 0.5078 - val_loss: 0.9836 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8951 - acc: 0.5078 - val_loss: 0.9836 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8951 - acc: 0.5078 - val_loss: 0.9836 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8951 - acc: 0.5078 - val_loss: 0.9835 - val_acc: 0.4918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8950 - acc: 0.5078 - val_loss: 0.9835 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8950 - acc: 0.5078 - val_loss: 0.9835 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8950 - acc: 0.5078 - val_loss: 0.9835 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8950 - acc: 0.5078 - val_loss: 0.9835 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8950 - acc: 0.5078 - val_loss: 0.9835 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8950 - acc: 0.5078 - val_loss: 0.9835 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8950 - acc: 0.5078 - val_loss: 0.9834 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8950 - acc: 0.5078 - val_loss: 0.9834 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8949 - acc: 0.5078 - val_loss: 0.9834 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8949 - acc: 0.5078 - val_loss: 0.9834 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8949 - acc: 0.5078 - val_loss: 0.9834 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8949 - acc: 0.5078 - val_loss: 0.9834 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8949 - acc: 0.5078 - val_loss: 0.9834 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8949 - acc: 0.5078 - val_loss: 0.9834 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8949 - acc: 0.5078 - val_loss: 0.9833 - val_acc: 0.4918\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e71e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9842 - acc: 0.3886 - val_loss: 0.9654 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9842 - acc: 0.3886 - val_loss: 0.9654 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9841 - acc: 0.3886 - val_loss: 0.9654 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9841 - acc: 0.3886 - val_loss: 0.9654 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9841 - acc: 0.3886 - val_loss: 0.9654 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9841 - acc: 0.3886 - val_loss: 0.9654 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9841 - acc: 0.3886 - val_loss: 0.9654 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9841 - acc: 0.3886 - val_loss: 0.9654 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9841 - acc: 0.3886 - val_loss: 0.9653 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9841 - acc: 0.3886 - val_loss: 0.9653 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9840 - acc: 0.3886 - val_loss: 0.9653 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9840 - acc: 0.3886 - val_loss: 0.9653 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9840 - acc: 0.3886 - val_loss: 0.9653 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9840 - acc: 0.3886 - val_loss: 0.9653 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9840 - acc: 0.3886 - val_loss: 0.9653 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9840 - acc: 0.3886 - val_loss: 0.9652 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9840 - acc: 0.3886 - val_loss: 0.9652 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9840 - acc: 0.3886 - val_loss: 0.9652 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9839 - acc: 0.3886 - val_loss: 0.9652 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9839 - acc: 0.3886 - val_loss: 0.9652 - val_acc: 0.4098\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b4428dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8618 - acc: 0.4381 - val_loss: 0.9076 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8618 - acc: 0.4381 - val_loss: 0.9076 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8618 - acc: 0.4381 - val_loss: 0.9076 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8618 - acc: 0.4381 - val_loss: 0.9075 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8618 - acc: 0.4381 - val_loss: 0.9075 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8618 - acc: 0.4381 - val_loss: 0.9075 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8617 - acc: 0.4381 - val_loss: 0.9075 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8617 - acc: 0.4381 - val_loss: 0.9075 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8617 - acc: 0.4381 - val_loss: 0.9075 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8617 - acc: 0.4381 - val_loss: 0.9075 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8617 - acc: 0.4381 - val_loss: 0.9074 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8617 - acc: 0.4381 - val_loss: 0.9074 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8617 - acc: 0.4381 - val_loss: 0.9074 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8617 - acc: 0.4381 - val_loss: 0.9074 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8616 - acc: 0.4381 - val_loss: 0.9074 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8616 - acc: 0.4381 - val_loss: 0.9074 - val_acc: 0.4098\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8616 - acc: 0.4381 - val_loss: 0.9074 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8616 - acc: 0.4381 - val_loss: 0.9073 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8616 - acc: 0.4381 - val_loss: 0.9073 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8616 - acc: 0.4381 - val_loss: 0.9073 - val_acc: 0.4098\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e0dc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0100 - acc: 0.3763 - val_loss: 1.0885 - val_acc: 0.3443\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0100 - acc: 0.3763 - val_loss: 1.0885 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0099 - acc: 0.3763 - val_loss: 1.0885 - val_acc: 0.3443\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0099 - acc: 0.3763 - val_loss: 1.0885 - val_acc: 0.3443\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0099 - acc: 0.3763 - val_loss: 1.0885 - val_acc: 0.3443\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0099 - acc: 0.3763 - val_loss: 1.0885 - val_acc: 0.3443\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0099 - acc: 0.3763 - val_loss: 1.0884 - val_acc: 0.3443\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0099 - acc: 0.3763 - val_loss: 1.0884 - val_acc: 0.3443\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0099 - acc: 0.3763 - val_loss: 1.0884 - val_acc: 0.3443\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0099 - acc: 0.3763 - val_loss: 1.0884 - val_acc: 0.3443\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0099 - acc: 0.3763 - val_loss: 1.0884 - val_acc: 0.3443\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0098 - acc: 0.3763 - val_loss: 1.0884 - val_acc: 0.3443\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0098 - acc: 0.3763 - val_loss: 1.0884 - val_acc: 0.3443\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0098 - acc: 0.3763 - val_loss: 1.0884 - val_acc: 0.3443\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0098 - acc: 0.3763 - val_loss: 1.0884 - val_acc: 0.3443\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0098 - acc: 0.3763 - val_loss: 1.0883 - val_acc: 0.3443\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0098 - acc: 0.3763 - val_loss: 1.0883 - val_acc: 0.3443\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0098 - acc: 0.3763 - val_loss: 1.0883 - val_acc: 0.3443\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0098 - acc: 0.3763 - val_loss: 1.0883 - val_acc: 0.3443\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0098 - acc: 0.3763 - val_loss: 1.0883 - val_acc: 0.3443\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac18d550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7505 - acc: 0.5515 - val_loss: 0.7379 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7505 - acc: 0.5515 - val_loss: 0.7379 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7505 - acc: 0.5515 - val_loss: 0.7379 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7505 - acc: 0.5515 - val_loss: 0.7379 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7505 - acc: 0.5515 - val_loss: 0.7378 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7504 - acc: 0.5515 - val_loss: 0.7378 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7504 - acc: 0.5515 - val_loss: 0.7378 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7504 - acc: 0.5515 - val_loss: 0.7378 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7504 - acc: 0.5515 - val_loss: 0.7378 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7504 - acc: 0.5515 - val_loss: 0.7378 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7504 - acc: 0.5515 - val_loss: 0.7378 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7504 - acc: 0.5515 - val_loss: 0.7378 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7504 - acc: 0.5515 - val_loss: 0.7378 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7504 - acc: 0.5515 - val_loss: 0.7378 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7504 - acc: 0.5515 - val_loss: 0.7378 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7504 - acc: 0.5515 - val_loss: 0.7377 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7504 - acc: 0.5515 - val_loss: 0.7377 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7503 - acc: 0.5515 - val_loss: 0.7377 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7503 - acc: 0.5515 - val_loss: 0.7377 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7503 - acc: 0.5515 - val_loss: 0.7377 - val_acc: 0.5410\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc1e99d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7792 - acc: 0.5337 - val_loss: 0.8309 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7792 - acc: 0.5337 - val_loss: 0.8309 - val_acc: 0.5738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7792 - acc: 0.5337 - val_loss: 0.8309 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7792 - acc: 0.5337 - val_loss: 0.8309 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7792 - acc: 0.5337 - val_loss: 0.8309 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7791 - acc: 0.5337 - val_loss: 0.8308 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7791 - acc: 0.5337 - val_loss: 0.8308 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7791 - acc: 0.5337 - val_loss: 0.8308 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7791 - acc: 0.5337 - val_loss: 0.8308 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7791 - acc: 0.5337 - val_loss: 0.8308 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7791 - acc: 0.5337 - val_loss: 0.8307 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7790 - acc: 0.5337 - val_loss: 0.8307 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7790 - acc: 0.5337 - val_loss: 0.8307 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7790 - acc: 0.5337 - val_loss: 0.8307 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7790 - acc: 0.5337 - val_loss: 0.8307 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7790 - acc: 0.5337 - val_loss: 0.8306 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7790 - acc: 0.5337 - val_loss: 0.8306 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7789 - acc: 0.5337 - val_loss: 0.8306 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7789 - acc: 0.5337 - val_loss: 0.8306 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7789 - acc: 0.5337 - val_loss: 0.8305 - val_acc: 0.5738\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4742ef8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2618 - acc: 0.3627 - val_loss: 1.2792 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2617 - acc: 0.3627 - val_loss: 1.2792 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2617 - acc: 0.3627 - val_loss: 1.2792 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2617 - acc: 0.3627 - val_loss: 1.2791 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2617 - acc: 0.3627 - val_loss: 1.2791 - val_acc: 0.3770\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2617 - acc: 0.3627 - val_loss: 1.2791 - val_acc: 0.3770\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2616 - acc: 0.3627 - val_loss: 1.2791 - val_acc: 0.3770\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2616 - acc: 0.3627 - val_loss: 1.2790 - val_acc: 0.3770\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2616 - acc: 0.3627 - val_loss: 1.2790 - val_acc: 0.3770\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2616 - acc: 0.3627 - val_loss: 1.2790 - val_acc: 0.3770\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2615 - acc: 0.3627 - val_loss: 1.2790 - val_acc: 0.3770\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2615 - acc: 0.3627 - val_loss: 1.2789 - val_acc: 0.3770\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2615 - acc: 0.3627 - val_loss: 1.2789 - val_acc: 0.3770\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2615 - acc: 0.3627 - val_loss: 1.2789 - val_acc: 0.3770\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2615 - acc: 0.3627 - val_loss: 1.2789 - val_acc: 0.3770\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2614 - acc: 0.3627 - val_loss: 1.2789 - val_acc: 0.3770\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2614 - acc: 0.3627 - val_loss: 1.2788 - val_acc: 0.3770\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2614 - acc: 0.3627 - val_loss: 1.2788 - val_acc: 0.3770\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2614 - acc: 0.3627 - val_loss: 1.2788 - val_acc: 0.3770\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2613 - acc: 0.3627 - val_loss: 1.2788 - val_acc: 0.3770\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac494e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6400 - acc: 0.6443 - val_loss: 0.6790 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6400 - acc: 0.6443 - val_loss: 0.6789 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6399 - acc: 0.6443 - val_loss: 0.6789 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6399 - acc: 0.6443 - val_loss: 0.6789 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6399 - acc: 0.6443 - val_loss: 0.6789 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6399 - acc: 0.6443 - val_loss: 0.6789 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6399 - acc: 0.6443 - val_loss: 0.6789 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6399 - acc: 0.6443 - val_loss: 0.6789 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6399 - acc: 0.6443 - val_loss: 0.6789 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6399 - acc: 0.6443 - val_loss: 0.6788 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6399 - acc: 0.6443 - val_loss: 0.6788 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6398 - acc: 0.6443 - val_loss: 0.6788 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6398 - acc: 0.6443 - val_loss: 0.6788 - val_acc: 0.5738\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6398 - acc: 0.6443 - val_loss: 0.6788 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6398 - acc: 0.6443 - val_loss: 0.6788 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6398 - acc: 0.6443 - val_loss: 0.6788 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6398 - acc: 0.6443 - val_loss: 0.6788 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6398 - acc: 0.6443 - val_loss: 0.6788 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6398 - acc: 0.6443 - val_loss: 0.6787 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6398 - acc: 0.6443 - val_loss: 0.6787 - val_acc: 0.5738\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4becf3ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8372 - acc: 0.3814 - val_loss: 0.9355 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8371 - acc: 0.3814 - val_loss: 0.9355 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8371 - acc: 0.3814 - val_loss: 0.9355 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8371 - acc: 0.3814 - val_loss: 0.9355 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8371 - acc: 0.3814 - val_loss: 0.9355 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8371 - acc: 0.3814 - val_loss: 0.9354 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8371 - acc: 0.3814 - val_loss: 0.9354 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8370 - acc: 0.3814 - val_loss: 0.9354 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8370 - acc: 0.3814 - val_loss: 0.9354 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8370 - acc: 0.3814 - val_loss: 0.9354 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8370 - acc: 0.3814 - val_loss: 0.9353 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8370 - acc: 0.3814 - val_loss: 0.9353 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8370 - acc: 0.3814 - val_loss: 0.9353 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8370 - acc: 0.3814 - val_loss: 0.9353 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8369 - acc: 0.3814 - val_loss: 0.9353 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8369 - acc: 0.3814 - val_loss: 0.9352 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8369 - acc: 0.3814 - val_loss: 0.9352 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8369 - acc: 0.3814 - val_loss: 0.9352 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8369 - acc: 0.3814 - val_loss: 0.9352 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8369 - acc: 0.3814 - val_loss: 0.9352 - val_acc: 0.4098\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bec57430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6732 - acc: 0.5722 - val_loss: 0.6789 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6732 - acc: 0.5722 - val_loss: 0.6788 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6732 - acc: 0.5722 - val_loss: 0.6788 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6732 - acc: 0.5722 - val_loss: 0.6788 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6732 - acc: 0.5722 - val_loss: 0.6788 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6731 - acc: 0.5722 - val_loss: 0.6788 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6731 - acc: 0.5722 - val_loss: 0.6788 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6731 - acc: 0.5722 - val_loss: 0.6788 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6731 - acc: 0.5722 - val_loss: 0.6788 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6731 - acc: 0.5722 - val_loss: 0.6788 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6731 - acc: 0.5722 - val_loss: 0.6787 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6731 - acc: 0.5722 - val_loss: 0.6787 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6731 - acc: 0.5722 - val_loss: 0.6787 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6731 - acc: 0.5722 - val_loss: 0.6787 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6731 - acc: 0.5722 - val_loss: 0.6787 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6731 - acc: 0.5722 - val_loss: 0.6787 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6730 - acc: 0.5722 - val_loss: 0.6787 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6730 - acc: 0.5722 - val_loss: 0.6787 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6730 - acc: 0.5722 - val_loss: 0.6787 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6730 - acc: 0.5722 - val_loss: 0.6786 - val_acc: 0.6230\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3787b24c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6905 - acc: 0.5648 - val_loss: 0.6610 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6905 - acc: 0.5648 - val_loss: 0.6610 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6905 - acc: 0.5648 - val_loss: 0.6610 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6905 - acc: 0.5648 - val_loss: 0.6610 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6905 - acc: 0.5648 - val_loss: 0.6609 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6904 - acc: 0.5648 - val_loss: 0.6609 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6904 - acc: 0.5648 - val_loss: 0.6609 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6904 - acc: 0.5648 - val_loss: 0.6609 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6904 - acc: 0.5648 - val_loss: 0.6609 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6904 - acc: 0.5648 - val_loss: 0.6608 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6904 - acc: 0.5648 - val_loss: 0.6608 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6903 - acc: 0.5648 - val_loss: 0.6608 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6903 - acc: 0.5648 - val_loss: 0.6608 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6903 - acc: 0.5648 - val_loss: 0.6607 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6903 - acc: 0.5648 - val_loss: 0.6607 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6903 - acc: 0.5648 - val_loss: 0.6607 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6902 - acc: 0.5648 - val_loss: 0.6607 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6902 - acc: 0.5648 - val_loss: 0.6607 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6902 - acc: 0.5648 - val_loss: 0.6606 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6902 - acc: 0.5648 - val_loss: 0.6606 - val_acc: 0.6230\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4204441f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9249 - acc: 0.4508 - val_loss: 0.9064 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9249 - acc: 0.4508 - val_loss: 0.9064 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9249 - acc: 0.4508 - val_loss: 0.9063 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9249 - acc: 0.4508 - val_loss: 0.9063 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9248 - acc: 0.4508 - val_loss: 0.9063 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9248 - acc: 0.4508 - val_loss: 0.9063 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9248 - acc: 0.4508 - val_loss: 0.9063 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9248 - acc: 0.4508 - val_loss: 0.9062 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9248 - acc: 0.4508 - val_loss: 0.9062 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9247 - acc: 0.4508 - val_loss: 0.9062 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9247 - acc: 0.4508 - val_loss: 0.9062 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9247 - acc: 0.4508 - val_loss: 0.9061 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9247 - acc: 0.4508 - val_loss: 0.9061 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9246 - acc: 0.4508 - val_loss: 0.9061 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9246 - acc: 0.4508 - val_loss: 0.9061 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9246 - acc: 0.4508 - val_loss: 0.9061 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9246 - acc: 0.4508 - val_loss: 0.9060 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9245 - acc: 0.4508 - val_loss: 0.9060 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9245 - acc: 0.4508 - val_loss: 0.9060 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9245 - acc: 0.4508 - val_loss: 0.9060 - val_acc: 0.4918\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4482608b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7586 - acc: 0.4330 - val_loss: 0.7571 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7585 - acc: 0.4330 - val_loss: 0.7571 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7585 - acc: 0.4330 - val_loss: 0.7571 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7585 - acc: 0.4330 - val_loss: 0.7570 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7585 - acc: 0.4330 - val_loss: 0.7570 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7585 - acc: 0.4330 - val_loss: 0.7570 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7585 - acc: 0.4330 - val_loss: 0.7570 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7584 - acc: 0.4330 - val_loss: 0.7570 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7584 - acc: 0.4330 - val_loss: 0.7569 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7584 - acc: 0.4330 - val_loss: 0.7569 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7584 - acc: 0.4330 - val_loss: 0.7569 - val_acc: 0.4590\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7584 - acc: 0.4330 - val_loss: 0.7569 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7584 - acc: 0.4330 - val_loss: 0.7569 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7583 - acc: 0.4330 - val_loss: 0.7568 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7583 - acc: 0.4330 - val_loss: 0.7568 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7583 - acc: 0.4330 - val_loss: 0.7568 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7583 - acc: 0.4330 - val_loss: 0.7568 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7583 - acc: 0.4330 - val_loss: 0.7568 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7582 - acc: 0.4330 - val_loss: 0.7567 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7582 - acc: 0.4330 - val_loss: 0.7567 - val_acc: 0.4590\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa420444af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6487 - acc: 0.6340 - val_loss: 0.5984 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6487 - acc: 0.6340 - val_loss: 0.5984 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6487 - acc: 0.6340 - val_loss: 0.5984 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6487 - acc: 0.6340 - val_loss: 0.5984 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6487 - acc: 0.6340 - val_loss: 0.5984 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6487 - acc: 0.6340 - val_loss: 0.5984 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6487 - acc: 0.6340 - val_loss: 0.5983 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6486 - acc: 0.6340 - val_loss: 0.5983 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6486 - acc: 0.6340 - val_loss: 0.5983 - val_acc: 0.7049\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6486 - acc: 0.6340 - val_loss: 0.5983 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6486 - acc: 0.6340 - val_loss: 0.5983 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6486 - acc: 0.6340 - val_loss: 0.5983 - val_acc: 0.7049\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6486 - acc: 0.6340 - val_loss: 0.5982 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6485 - acc: 0.6340 - val_loss: 0.5982 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6485 - acc: 0.6340 - val_loss: 0.5982 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6485 - acc: 0.6340 - val_loss: 0.5982 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6485 - acc: 0.6340 - val_loss: 0.5982 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6485 - acc: 0.6340 - val_loss: 0.5982 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6485 - acc: 0.6340 - val_loss: 0.5981 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6484 - acc: 0.6340 - val_loss: 0.5981 - val_acc: 0.7049\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410127280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6603 - acc: 0.5876 - val_loss: 0.7000 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6603 - acc: 0.5876 - val_loss: 0.7000 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6603 - acc: 0.5876 - val_loss: 0.7000 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6603 - acc: 0.5876 - val_loss: 0.6999 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6602 - acc: 0.5876 - val_loss: 0.6999 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6602 - acc: 0.5876 - val_loss: 0.6999 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6602 - acc: 0.5876 - val_loss: 0.6999 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6602 - acc: 0.5876 - val_loss: 0.6999 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6602 - acc: 0.5876 - val_loss: 0.6998 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6602 - acc: 0.5876 - val_loss: 0.6998 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6601 - acc: 0.5876 - val_loss: 0.6998 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6601 - acc: 0.5876 - val_loss: 0.6998 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6601 - acc: 0.5876 - val_loss: 0.6998 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6601 - acc: 0.5876 - val_loss: 0.6998 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6601 - acc: 0.5876 - val_loss: 0.6997 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6601 - acc: 0.5876 - val_loss: 0.6997 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6600 - acc: 0.5876 - val_loss: 0.6997 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6600 - acc: 0.5876 - val_loss: 0.6997 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6600 - acc: 0.5876 - val_loss: 0.6997 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6600 - acc: 0.5876 - val_loss: 0.6996 - val_acc: 0.5902\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa39458b310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8613 - acc: 0.4093 - val_loss: 0.8443 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8613 - acc: 0.4093 - val_loss: 0.8443 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8613 - acc: 0.4093 - val_loss: 0.8442 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8612 - acc: 0.4093 - val_loss: 0.8442 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8612 - acc: 0.4093 - val_loss: 0.8442 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8612 - acc: 0.4093 - val_loss: 0.8441 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8611 - acc: 0.4093 - val_loss: 0.8441 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8611 - acc: 0.4093 - val_loss: 0.8441 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8611 - acc: 0.4093 - val_loss: 0.8440 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8610 - acc: 0.4093 - val_loss: 0.8440 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8610 - acc: 0.4093 - val_loss: 0.8440 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8610 - acc: 0.4093 - val_loss: 0.8439 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8609 - acc: 0.4093 - val_loss: 0.8439 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8609 - acc: 0.4093 - val_loss: 0.8439 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8609 - acc: 0.4093 - val_loss: 0.8438 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8608 - acc: 0.4093 - val_loss: 0.8438 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8608 - acc: 0.4093 - val_loss: 0.8438 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8608 - acc: 0.4093 - val_loss: 0.8437 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8607 - acc: 0.4093 - val_loss: 0.8437 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8607 - acc: 0.4093 - val_loss: 0.8437 - val_acc: 0.4098\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3785ba8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7195 - acc: 0.5285 - val_loss: 0.7561 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7195 - acc: 0.5285 - val_loss: 0.7560 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7195 - acc: 0.5285 - val_loss: 0.7560 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7194 - acc: 0.5285 - val_loss: 0.7560 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7194 - acc: 0.5285 - val_loss: 0.7559 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7194 - acc: 0.5285 - val_loss: 0.7559 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7193 - acc: 0.5285 - val_loss: 0.7559 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7193 - acc: 0.5285 - val_loss: 0.7558 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7193 - acc: 0.5285 - val_loss: 0.7558 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7193 - acc: 0.5285 - val_loss: 0.7558 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7192 - acc: 0.5285 - val_loss: 0.7557 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7192 - acc: 0.5285 - val_loss: 0.7557 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7192 - acc: 0.5285 - val_loss: 0.7557 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7192 - acc: 0.5285 - val_loss: 0.7556 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7191 - acc: 0.5285 - val_loss: 0.7556 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7191 - acc: 0.5285 - val_loss: 0.7556 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7191 - acc: 0.5285 - val_loss: 0.7555 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7190 - acc: 0.5285 - val_loss: 0.7555 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7190 - acc: 0.5285 - val_loss: 0.7555 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7190 - acc: 0.5285 - val_loss: 0.7554 - val_acc: 0.4426\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa37876a280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6008 - acc: 0.7268 - val_loss: 0.6130 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6007 - acc: 0.7268 - val_loss: 0.6130 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6007 - acc: 0.7268 - val_loss: 0.6130 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6007 - acc: 0.7268 - val_loss: 0.6129 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6007 - acc: 0.7268 - val_loss: 0.6129 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6007 - acc: 0.7320 - val_loss: 0.6129 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6006 - acc: 0.7320 - val_loss: 0.6129 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6006 - acc: 0.7320 - val_loss: 0.6128 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6006 - acc: 0.7320 - val_loss: 0.6128 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6006 - acc: 0.7320 - val_loss: 0.6128 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6005 - acc: 0.7320 - val_loss: 0.6127 - val_acc: 0.6557\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6005 - acc: 0.7320 - val_loss: 0.6127 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6005 - acc: 0.7320 - val_loss: 0.6127 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6005 - acc: 0.7320 - val_loss: 0.6127 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6005 - acc: 0.7320 - val_loss: 0.6126 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6004 - acc: 0.7320 - val_loss: 0.6126 - val_acc: 0.6557\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6004 - acc: 0.7320 - val_loss: 0.6126 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6004 - acc: 0.7320 - val_loss: 0.6126 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6004 - acc: 0.7320 - val_loss: 0.6125 - val_acc: 0.6557\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6004 - acc: 0.7320 - val_loss: 0.6125 - val_acc: 0.6557\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3783e83a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.8093 - acc: 0.3041 - val_loss: 0.8712 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8092 - acc: 0.3041 - val_loss: 0.8711 - val_acc: 0.3115\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8092 - acc: 0.3041 - val_loss: 0.8711 - val_acc: 0.3115\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8092 - acc: 0.3041 - val_loss: 0.8710 - val_acc: 0.3115\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8091 - acc: 0.3041 - val_loss: 0.8710 - val_acc: 0.3115\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8091 - acc: 0.3041 - val_loss: 0.8709 - val_acc: 0.3115\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8090 - acc: 0.3041 - val_loss: 0.8709 - val_acc: 0.3115\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8090 - acc: 0.3041 - val_loss: 0.8708 - val_acc: 0.3115\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8090 - acc: 0.3041 - val_loss: 0.8708 - val_acc: 0.3115\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8089 - acc: 0.3041 - val_loss: 0.8708 - val_acc: 0.3115\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8089 - acc: 0.3041 - val_loss: 0.8707 - val_acc: 0.3115\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8089 - acc: 0.3041 - val_loss: 0.8707 - val_acc: 0.3115\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8088 - acc: 0.3041 - val_loss: 0.8706 - val_acc: 0.3115\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8088 - acc: 0.3041 - val_loss: 0.8706 - val_acc: 0.3115\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8088 - acc: 0.3041 - val_loss: 0.8705 - val_acc: 0.3115\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8087 - acc: 0.3041 - val_loss: 0.8705 - val_acc: 0.3115\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8087 - acc: 0.3041 - val_loss: 0.8704 - val_acc: 0.3115\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8087 - acc: 0.3041 - val_loss: 0.8704 - val_acc: 0.3115\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8086 - acc: 0.3041 - val_loss: 0.8703 - val_acc: 0.3115\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8086 - acc: 0.3041 - val_loss: 0.8703 - val_acc: 0.3115\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3943feee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7128 - acc: 0.4948 - val_loss: 0.7389 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7128 - acc: 0.4948 - val_loss: 0.7389 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7128 - acc: 0.4948 - val_loss: 0.7388 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7128 - acc: 0.4948 - val_loss: 0.7388 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7127 - acc: 0.4948 - val_loss: 0.7388 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7127 - acc: 0.4948 - val_loss: 0.7387 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7127 - acc: 0.4948 - val_loss: 0.7387 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7127 - acc: 0.4948 - val_loss: 0.7387 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7126 - acc: 0.4948 - val_loss: 0.7386 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7126 - acc: 0.4948 - val_loss: 0.7386 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7126 - acc: 0.4948 - val_loss: 0.7386 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7125 - acc: 0.4948 - val_loss: 0.7385 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7125 - acc: 0.4948 - val_loss: 0.7385 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7125 - acc: 0.4948 - val_loss: 0.7384 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7125 - acc: 0.4948 - val_loss: 0.7384 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7124 - acc: 0.4948 - val_loss: 0.7384 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7124 - acc: 0.4948 - val_loss: 0.7383 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7124 - acc: 0.4948 - val_loss: 0.7383 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7123 - acc: 0.4948 - val_loss: 0.7383 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7123 - acc: 0.4948 - val_loss: 0.7382 - val_acc: 0.4426\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beb9fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7262 - acc: 0.4560 - val_loss: 0.7268 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7262 - acc: 0.4560 - val_loss: 0.7268 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7261 - acc: 0.4560 - val_loss: 0.7267 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7261 - acc: 0.4560 - val_loss: 0.7267 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7260 - acc: 0.4560 - val_loss: 0.7266 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7260 - acc: 0.4611 - val_loss: 0.7266 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7260 - acc: 0.4611 - val_loss: 0.7265 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7259 - acc: 0.4611 - val_loss: 0.7265 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7259 - acc: 0.4611 - val_loss: 0.7265 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7258 - acc: 0.4611 - val_loss: 0.7264 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7258 - acc: 0.4611 - val_loss: 0.7264 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7258 - acc: 0.4611 - val_loss: 0.7263 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7257 - acc: 0.4611 - val_loss: 0.7263 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7257 - acc: 0.4611 - val_loss: 0.7262 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7256 - acc: 0.4611 - val_loss: 0.7262 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7256 - acc: 0.4611 - val_loss: 0.7261 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7255 - acc: 0.4611 - val_loss: 0.7261 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7255 - acc: 0.4611 - val_loss: 0.7260 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7255 - acc: 0.4611 - val_loss: 0.7260 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7254 - acc: 0.4611 - val_loss: 0.7260 - val_acc: 0.3934\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beb9f820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7946 - acc: 0.3109 - val_loss: 0.8400 - val_acc: 0.2295\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7946 - acc: 0.3109 - val_loss: 0.8399 - val_acc: 0.2295\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7945 - acc: 0.3109 - val_loss: 0.8399 - val_acc: 0.2295\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7945 - acc: 0.3109 - val_loss: 0.8398 - val_acc: 0.2295\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7944 - acc: 0.3109 - val_loss: 0.8398 - val_acc: 0.2295\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7944 - acc: 0.3109 - val_loss: 0.8397 - val_acc: 0.2295\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7943 - acc: 0.3109 - val_loss: 0.8396 - val_acc: 0.2295\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7943 - acc: 0.3109 - val_loss: 0.8396 - val_acc: 0.2295\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7942 - acc: 0.3109 - val_loss: 0.8395 - val_acc: 0.2295\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7942 - acc: 0.3109 - val_loss: 0.8395 - val_acc: 0.2295\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7941 - acc: 0.3109 - val_loss: 0.8394 - val_acc: 0.2295\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7941 - acc: 0.3109 - val_loss: 0.8393 - val_acc: 0.2295\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7940 - acc: 0.3109 - val_loss: 0.8393 - val_acc: 0.2295\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7940 - acc: 0.3161 - val_loss: 0.8392 - val_acc: 0.2295\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7940 - acc: 0.3161 - val_loss: 0.8392 - val_acc: 0.2295\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7939 - acc: 0.3161 - val_loss: 0.8391 - val_acc: 0.2295\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7939 - acc: 0.3161 - val_loss: 0.8391 - val_acc: 0.2295\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7938 - acc: 0.3212 - val_loss: 0.8390 - val_acc: 0.2295\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7938 - acc: 0.3212 - val_loss: 0.8389 - val_acc: 0.2295\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7937 - acc: 0.3212 - val_loss: 0.8389 - val_acc: 0.2295\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bec57280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7819 - acc: 0.5361 - val_loss: 0.8330 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7819 - acc: 0.5361 - val_loss: 0.8329 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7818 - acc: 0.5361 - val_loss: 0.8329 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7818 - acc: 0.5361 - val_loss: 0.8328 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7818 - acc: 0.5361 - val_loss: 0.8327 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7817 - acc: 0.5361 - val_loss: 0.8327 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7817 - acc: 0.5361 - val_loss: 0.8326 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7816 - acc: 0.5361 - val_loss: 0.8326 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7816 - acc: 0.5361 - val_loss: 0.8325 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7815 - acc: 0.5361 - val_loss: 0.8324 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7815 - acc: 0.5361 - val_loss: 0.8324 - val_acc: 0.5082\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7814 - acc: 0.5361 - val_loss: 0.8323 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7814 - acc: 0.5361 - val_loss: 0.8322 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7813 - acc: 0.5361 - val_loss: 0.8322 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7813 - acc: 0.5361 - val_loss: 0.8321 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7812 - acc: 0.5361 - val_loss: 0.8321 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7812 - acc: 0.5361 - val_loss: 0.8320 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7811 - acc: 0.5361 - val_loss: 0.8319 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7811 - acc: 0.5361 - val_loss: 0.8319 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7810 - acc: 0.5361 - val_loss: 0.8318 - val_acc: 0.5082\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410492e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6997 - acc: 0.5258 - val_loss: 0.7120 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6997 - acc: 0.5258 - val_loss: 0.7120 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6996 - acc: 0.5258 - val_loss: 0.7119 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6996 - acc: 0.5258 - val_loss: 0.7119 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6995 - acc: 0.5258 - val_loss: 0.7118 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6995 - acc: 0.5258 - val_loss: 0.7118 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6995 - acc: 0.5258 - val_loss: 0.7117 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6994 - acc: 0.5258 - val_loss: 0.7117 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6994 - acc: 0.5258 - val_loss: 0.7116 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6993 - acc: 0.5258 - val_loss: 0.7116 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6993 - acc: 0.5258 - val_loss: 0.7115 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6993 - acc: 0.5258 - val_loss: 0.7115 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6992 - acc: 0.5258 - val_loss: 0.7115 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6992 - acc: 0.5258 - val_loss: 0.7114 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6991 - acc: 0.5258 - val_loss: 0.7114 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6991 - acc: 0.5258 - val_loss: 0.7113 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6991 - acc: 0.5258 - val_loss: 0.7113 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6990 - acc: 0.5258 - val_loss: 0.7112 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6990 - acc: 0.5258 - val_loss: 0.7112 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6989 - acc: 0.5258 - val_loss: 0.7111 - val_acc: 0.4918\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41014b940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7435 - acc: 0.4021 - val_loss: 0.7480 - val_acc: 0.3443\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7435 - acc: 0.4021 - val_loss: 0.7480 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7435 - acc: 0.4021 - val_loss: 0.7479 - val_acc: 0.3443\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7434 - acc: 0.4021 - val_loss: 0.7479 - val_acc: 0.3443\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7434 - acc: 0.4021 - val_loss: 0.7479 - val_acc: 0.3443\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7433 - acc: 0.4021 - val_loss: 0.7478 - val_acc: 0.3443\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7433 - acc: 0.4021 - val_loss: 0.7478 - val_acc: 0.3443\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7433 - acc: 0.4021 - val_loss: 0.7477 - val_acc: 0.3443\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7432 - acc: 0.4021 - val_loss: 0.7477 - val_acc: 0.3443\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7432 - acc: 0.4021 - val_loss: 0.7476 - val_acc: 0.3443\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7431 - acc: 0.4021 - val_loss: 0.7476 - val_acc: 0.3443\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7431 - acc: 0.4021 - val_loss: 0.7475 - val_acc: 0.3443\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7431 - acc: 0.4021 - val_loss: 0.7475 - val_acc: 0.3443\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7430 - acc: 0.4021 - val_loss: 0.7474 - val_acc: 0.3443\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7430 - acc: 0.4021 - val_loss: 0.7474 - val_acc: 0.3443\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7429 - acc: 0.4021 - val_loss: 0.7473 - val_acc: 0.3443\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7429 - acc: 0.4021 - val_loss: 0.7473 - val_acc: 0.3443\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7429 - acc: 0.4021 - val_loss: 0.7473 - val_acc: 0.3443\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7428 - acc: 0.4021 - val_loss: 0.7472 - val_acc: 0.3443\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7428 - acc: 0.4021 - val_loss: 0.7472 - val_acc: 0.3607\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4742ef1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7417 - acc: 0.4404 - val_loss: 0.7608 - val_acc: 0.3443\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7417 - acc: 0.4404 - val_loss: 0.7608 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7416 - acc: 0.4404 - val_loss: 0.7607 - val_acc: 0.3443\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7416 - acc: 0.4404 - val_loss: 0.7606 - val_acc: 0.3443\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7415 - acc: 0.4404 - val_loss: 0.7606 - val_acc: 0.3443\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7415 - acc: 0.4404 - val_loss: 0.7605 - val_acc: 0.3607\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7414 - acc: 0.4404 - val_loss: 0.7604 - val_acc: 0.3607\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7413 - acc: 0.4404 - val_loss: 0.7604 - val_acc: 0.3607\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7413 - acc: 0.4404 - val_loss: 0.7603 - val_acc: 0.3607\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7412 - acc: 0.4404 - val_loss: 0.7602 - val_acc: 0.3607\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7412 - acc: 0.4404 - val_loss: 0.7602 - val_acc: 0.3607\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7411 - acc: 0.4404 - val_loss: 0.7601 - val_acc: 0.3607\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7410 - acc: 0.4404 - val_loss: 0.7600 - val_acc: 0.3607\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7410 - acc: 0.4404 - val_loss: 0.7600 - val_acc: 0.3607\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7409 - acc: 0.4404 - val_loss: 0.7599 - val_acc: 0.3607\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7409 - acc: 0.4404 - val_loss: 0.7598 - val_acc: 0.3607\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7408 - acc: 0.4404 - val_loss: 0.7598 - val_acc: 0.3607\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7407 - acc: 0.4404 - val_loss: 0.7597 - val_acc: 0.3607\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7407 - acc: 0.4404 - val_loss: 0.7597 - val_acc: 0.3607\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7406 - acc: 0.4404 - val_loss: 0.7596 - val_acc: 0.3607\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc3133a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7118 - acc: 0.4404 - val_loss: 0.6896 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7117 - acc: 0.4404 - val_loss: 0.6896 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7117 - acc: 0.4404 - val_loss: 0.6895 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7116 - acc: 0.4404 - val_loss: 0.6894 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7115 - acc: 0.4404 - val_loss: 0.6894 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7115 - acc: 0.4404 - val_loss: 0.6893 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7114 - acc: 0.4404 - val_loss: 0.6893 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7114 - acc: 0.4404 - val_loss: 0.6892 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7113 - acc: 0.4404 - val_loss: 0.6892 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7113 - acc: 0.4404 - val_loss: 0.6891 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7112 - acc: 0.4404 - val_loss: 0.6891 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7112 - acc: 0.4404 - val_loss: 0.6890 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7111 - acc: 0.4404 - val_loss: 0.6889 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7111 - acc: 0.4404 - val_loss: 0.6889 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7110 - acc: 0.4404 - val_loss: 0.6888 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7109 - acc: 0.4404 - val_loss: 0.6888 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7109 - acc: 0.4404 - val_loss: 0.6887 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7108 - acc: 0.4404 - val_loss: 0.6887 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7108 - acc: 0.4404 - val_loss: 0.6886 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7107 - acc: 0.4404 - val_loss: 0.6886 - val_acc: 0.5246\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1e3160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6458 - acc: 0.6959 - val_loss: 0.6252 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6458 - acc: 0.7010 - val_loss: 0.6252 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6457 - acc: 0.7010 - val_loss: 0.6251 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6456 - acc: 0.7010 - val_loss: 0.6251 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6456 - acc: 0.7010 - val_loss: 0.6250 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6455 - acc: 0.7010 - val_loss: 0.6249 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6455 - acc: 0.7010 - val_loss: 0.6249 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6454 - acc: 0.7010 - val_loss: 0.6248 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6454 - acc: 0.7010 - val_loss: 0.6248 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6453 - acc: 0.7010 - val_loss: 0.6247 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6453 - acc: 0.7062 - val_loss: 0.6246 - val_acc: 0.7377\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6452 - acc: 0.7062 - val_loss: 0.6246 - val_acc: 0.7377\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6452 - acc: 0.7062 - val_loss: 0.6245 - val_acc: 0.7377\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6451 - acc: 0.7062 - val_loss: 0.6245 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6451 - acc: 0.7062 - val_loss: 0.6244 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6450 - acc: 0.7062 - val_loss: 0.6244 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6450 - acc: 0.7062 - val_loss: 0.6243 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6449 - acc: 0.7062 - val_loss: 0.6242 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6449 - acc: 0.7062 - val_loss: 0.6242 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6448 - acc: 0.7062 - val_loss: 0.6241 - val_acc: 0.7377\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b4428040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7195 - acc: 0.4072 - val_loss: 0.6915 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7194 - acc: 0.4072 - val_loss: 0.6914 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7194 - acc: 0.4072 - val_loss: 0.6914 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7193 - acc: 0.4175 - val_loss: 0.6913 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7193 - acc: 0.4175 - val_loss: 0.6913 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7192 - acc: 0.4175 - val_loss: 0.6912 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7192 - acc: 0.4175 - val_loss: 0.6911 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7191 - acc: 0.4175 - val_loss: 0.6911 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7190 - acc: 0.4175 - val_loss: 0.6910 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7190 - acc: 0.4175 - val_loss: 0.6909 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7189 - acc: 0.4175 - val_loss: 0.6909 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7189 - acc: 0.4175 - val_loss: 0.6908 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7188 - acc: 0.4175 - val_loss: 0.6907 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7187 - acc: 0.4175 - val_loss: 0.6907 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7187 - acc: 0.4175 - val_loss: 0.6906 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7186 - acc: 0.4175 - val_loss: 0.6905 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7186 - acc: 0.4175 - val_loss: 0.6905 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7185 - acc: 0.4175 - val_loss: 0.6904 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7184 - acc: 0.4175 - val_loss: 0.6904 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7184 - acc: 0.4175 - val_loss: 0.6903 - val_acc: 0.4590\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1e34c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6842 - acc: 0.6186 - val_loss: 0.6774 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6842 - acc: 0.6186 - val_loss: 0.6774 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6841 - acc: 0.6186 - val_loss: 0.6773 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6841 - acc: 0.6186 - val_loss: 0.6773 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6840 - acc: 0.6186 - val_loss: 0.6772 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6840 - acc: 0.6186 - val_loss: 0.6771 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6839 - acc: 0.6186 - val_loss: 0.6771 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6839 - acc: 0.6186 - val_loss: 0.6770 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6838 - acc: 0.6186 - val_loss: 0.6770 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6838 - acc: 0.6186 - val_loss: 0.6769 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6837 - acc: 0.6186 - val_loss: 0.6769 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6837 - acc: 0.6186 - val_loss: 0.6768 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6836 - acc: 0.6186 - val_loss: 0.6767 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6835 - acc: 0.6186 - val_loss: 0.6767 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6835 - acc: 0.6186 - val_loss: 0.6766 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6834 - acc: 0.6186 - val_loss: 0.6766 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6834 - acc: 0.6186 - val_loss: 0.6765 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6833 - acc: 0.6186 - val_loss: 0.6764 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6833 - acc: 0.6186 - val_loss: 0.6764 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6832 - acc: 0.6186 - val_loss: 0.6763 - val_acc: 0.6230\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa378317820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7090 - acc: 0.5130 - val_loss: 0.7768 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7090 - acc: 0.5130 - val_loss: 0.7768 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7090 - acc: 0.5130 - val_loss: 0.7768 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7090 - acc: 0.5130 - val_loss: 0.7768 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7090 - acc: 0.5130 - val_loss: 0.7768 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7090 - acc: 0.5130 - val_loss: 0.7768 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7090 - acc: 0.5130 - val_loss: 0.7768 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7090 - acc: 0.5130 - val_loss: 0.7767 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7090 - acc: 0.5130 - val_loss: 0.7767 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7090 - acc: 0.5130 - val_loss: 0.7767 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7090 - acc: 0.5130 - val_loss: 0.7767 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7090 - acc: 0.5130 - val_loss: 0.7767 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7090 - acc: 0.5130 - val_loss: 0.7767 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7090 - acc: 0.5130 - val_loss: 0.7767 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7090 - acc: 0.5130 - val_loss: 0.7767 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7089 - acc: 0.5130 - val_loss: 0.7767 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7089 - acc: 0.5130 - val_loss: 0.7767 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7089 - acc: 0.5130 - val_loss: 0.7767 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7089 - acc: 0.5130 - val_loss: 0.7767 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7089 - acc: 0.5130 - val_loss: 0.7767 - val_acc: 0.4590\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41873fb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7150 - acc: 0.6477 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7150 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7150 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7150 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7150 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7149 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7149 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7149 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7149 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7149 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7149 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7149 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7149 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7149 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7149 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7149 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7149 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7149 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7149 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7149 - acc: 0.6528 - val_loss: 0.7359 - val_acc: 0.6557\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4184f6790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7222 - acc: 0.5670 - val_loss: 0.7882 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7222 - acc: 0.5670 - val_loss: 0.7882 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7221 - acc: 0.5670 - val_loss: 0.7882 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7221 - acc: 0.5670 - val_loss: 0.7881 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7221 - acc: 0.5670 - val_loss: 0.7881 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7221 - acc: 0.5670 - val_loss: 0.7881 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7221 - acc: 0.5670 - val_loss: 0.7881 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7221 - acc: 0.5670 - val_loss: 0.7881 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7221 - acc: 0.5670 - val_loss: 0.7881 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7221 - acc: 0.5670 - val_loss: 0.7881 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7221 - acc: 0.5670 - val_loss: 0.7881 - val_acc: 0.5738\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7221 - acc: 0.5670 - val_loss: 0.7880 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7221 - acc: 0.5670 - val_loss: 0.7880 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7220 - acc: 0.5670 - val_loss: 0.7880 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7220 - acc: 0.5670 - val_loss: 0.7880 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7220 - acc: 0.5670 - val_loss: 0.7880 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7220 - acc: 0.5670 - val_loss: 0.7880 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7220 - acc: 0.5670 - val_loss: 0.7880 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7220 - acc: 0.5670 - val_loss: 0.7880 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7220 - acc: 0.5670 - val_loss: 0.7880 - val_acc: 0.5738\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3946503a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7439 - acc: 0.5361 - val_loss: 0.7255 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7439 - acc: 0.5361 - val_loss: 0.7255 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7439 - acc: 0.5361 - val_loss: 0.7255 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7439 - acc: 0.5361 - val_loss: 0.7255 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7439 - acc: 0.5361 - val_loss: 0.7255 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7439 - acc: 0.5361 - val_loss: 0.7255 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7439 - acc: 0.5361 - val_loss: 0.7255 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7439 - acc: 0.5361 - val_loss: 0.7255 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7439 - acc: 0.5361 - val_loss: 0.7255 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7439 - acc: 0.5361 - val_loss: 0.7255 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7439 - acc: 0.5361 - val_loss: 0.7255 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7439 - acc: 0.5361 - val_loss: 0.7255 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7439 - acc: 0.5361 - val_loss: 0.7255 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7439 - acc: 0.5361 - val_loss: 0.7255 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7439 - acc: 0.5361 - val_loss: 0.7255 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7439 - acc: 0.5361 - val_loss: 0.7254 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7438 - acc: 0.5361 - val_loss: 0.7254 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7438 - acc: 0.5361 - val_loss: 0.7254 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7438 - acc: 0.5361 - val_loss: 0.7254 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7438 - acc: 0.5361 - val_loss: 0.7254 - val_acc: 0.5246\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b87ca4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8395 - acc: 0.5103 - val_loss: 0.8754 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8395 - acc: 0.5103 - val_loss: 0.8754 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8395 - acc: 0.5103 - val_loss: 0.8754 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8395 - acc: 0.5103 - val_loss: 0.8754 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8395 - acc: 0.5103 - val_loss: 0.8753 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8394 - acc: 0.5103 - val_loss: 0.8753 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8394 - acc: 0.5103 - val_loss: 0.8753 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8394 - acc: 0.5103 - val_loss: 0.8753 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8394 - acc: 0.5103 - val_loss: 0.8753 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8394 - acc: 0.5103 - val_loss: 0.8753 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8394 - acc: 0.5103 - val_loss: 0.8753 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8394 - acc: 0.5103 - val_loss: 0.8753 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8394 - acc: 0.5103 - val_loss: 0.8753 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8394 - acc: 0.5103 - val_loss: 0.8753 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8394 - acc: 0.5103 - val_loss: 0.8753 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8394 - acc: 0.5103 - val_loss: 0.8753 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8394 - acc: 0.5103 - val_loss: 0.8753 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8394 - acc: 0.5103 - val_loss: 0.8753 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8394 - acc: 0.5103 - val_loss: 0.8752 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8394 - acc: 0.5103 - val_loss: 0.8752 - val_acc: 0.4262\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3943ffe50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6515 - acc: 0.6373 - val_loss: 0.7071 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6515 - acc: 0.6373 - val_loss: 0.7071 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6515 - acc: 0.6373 - val_loss: 0.7071 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6515 - acc: 0.6373 - val_loss: 0.7070 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6515 - acc: 0.6373 - val_loss: 0.7070 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6515 - acc: 0.6373 - val_loss: 0.7070 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6515 - acc: 0.6373 - val_loss: 0.7070 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6515 - acc: 0.6373 - val_loss: 0.7070 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6515 - acc: 0.6373 - val_loss: 0.7070 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6514 - acc: 0.6373 - val_loss: 0.7070 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6514 - acc: 0.6373 - val_loss: 0.7070 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6514 - acc: 0.6373 - val_loss: 0.7070 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6514 - acc: 0.6373 - val_loss: 0.7070 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6514 - acc: 0.6373 - val_loss: 0.7069 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6514 - acc: 0.6373 - val_loss: 0.7069 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6514 - acc: 0.6373 - val_loss: 0.7069 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6514 - acc: 0.6373 - val_loss: 0.7069 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6514 - acc: 0.6373 - val_loss: 0.7069 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6514 - acc: 0.6373 - val_loss: 0.7069 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6514 - acc: 0.6373 - val_loss: 0.7069 - val_acc: 0.6230\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3945eb820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8427 - acc: 0.4404 - val_loss: 0.8682 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8427 - acc: 0.4404 - val_loss: 0.8682 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8427 - acc: 0.4404 - val_loss: 0.8682 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8427 - acc: 0.4404 - val_loss: 0.8682 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8427 - acc: 0.4404 - val_loss: 0.8682 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8427 - acc: 0.4404 - val_loss: 0.8682 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8427 - acc: 0.4404 - val_loss: 0.8682 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8427 - acc: 0.4404 - val_loss: 0.8681 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8427 - acc: 0.4404 - val_loss: 0.8681 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8426 - acc: 0.4404 - val_loss: 0.8681 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8426 - acc: 0.4404 - val_loss: 0.8681 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8426 - acc: 0.4404 - val_loss: 0.8681 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8426 - acc: 0.4404 - val_loss: 0.8681 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8426 - acc: 0.4404 - val_loss: 0.8681 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8426 - acc: 0.4404 - val_loss: 0.8681 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8426 - acc: 0.4404 - val_loss: 0.8681 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8426 - acc: 0.4404 - val_loss: 0.8681 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8426 - acc: 0.4404 - val_loss: 0.8680 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8425 - acc: 0.4404 - val_loss: 0.8680 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8425 - acc: 0.4404 - val_loss: 0.8680 - val_acc: 0.4754\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3944adca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8455 - acc: 0.4433 - val_loss: 0.8023 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8454 - acc: 0.4433 - val_loss: 0.8023 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8454 - acc: 0.4433 - val_loss: 0.8023 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8454 - acc: 0.4433 - val_loss: 0.8023 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8454 - acc: 0.4433 - val_loss: 0.8023 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8454 - acc: 0.4433 - val_loss: 0.8023 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8454 - acc: 0.4433 - val_loss: 0.8022 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8454 - acc: 0.4433 - val_loss: 0.8022 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8454 - acc: 0.4433 - val_loss: 0.8022 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8454 - acc: 0.4433 - val_loss: 0.8022 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8453 - acc: 0.4433 - val_loss: 0.8022 - val_acc: 0.4754\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8453 - acc: 0.4433 - val_loss: 0.8022 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8453 - acc: 0.4433 - val_loss: 0.8022 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8453 - acc: 0.4433 - val_loss: 0.8022 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8453 - acc: 0.4433 - val_loss: 0.8022 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8453 - acc: 0.4433 - val_loss: 0.8021 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8453 - acc: 0.4433 - val_loss: 0.8021 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8453 - acc: 0.4433 - val_loss: 0.8021 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8453 - acc: 0.4433 - val_loss: 0.8021 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8452 - acc: 0.4433 - val_loss: 0.8021 - val_acc: 0.4754\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3941250d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7447 - acc: 0.5619 - val_loss: 0.8140 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7447 - acc: 0.5619 - val_loss: 0.8140 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7447 - acc: 0.5619 - val_loss: 0.8140 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7447 - acc: 0.5619 - val_loss: 0.8140 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7447 - acc: 0.5619 - val_loss: 0.8140 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7447 - acc: 0.5619 - val_loss: 0.8140 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7447 - acc: 0.5619 - val_loss: 0.8140 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7447 - acc: 0.5619 - val_loss: 0.8140 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7447 - acc: 0.5619 - val_loss: 0.8139 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7447 - acc: 0.5619 - val_loss: 0.8139 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7446 - acc: 0.5619 - val_loss: 0.8139 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7446 - acc: 0.5619 - val_loss: 0.8139 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7446 - acc: 0.5619 - val_loss: 0.8139 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7446 - acc: 0.5619 - val_loss: 0.8139 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7446 - acc: 0.5619 - val_loss: 0.8139 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7446 - acc: 0.5619 - val_loss: 0.8138 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7446 - acc: 0.5619 - val_loss: 0.8138 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7446 - acc: 0.5619 - val_loss: 0.8138 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7446 - acc: 0.5619 - val_loss: 0.8138 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7446 - acc: 0.5619 - val_loss: 0.8138 - val_acc: 0.5410\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3781b7430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7894 - acc: 0.5412 - val_loss: 0.7969 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7894 - acc: 0.5412 - val_loss: 0.7969 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7894 - acc: 0.5412 - val_loss: 0.7969 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7894 - acc: 0.5412 - val_loss: 0.7969 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7894 - acc: 0.5412 - val_loss: 0.7969 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7894 - acc: 0.5412 - val_loss: 0.7969 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7894 - acc: 0.5412 - val_loss: 0.7969 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7894 - acc: 0.5412 - val_loss: 0.7969 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7894 - acc: 0.5412 - val_loss: 0.7968 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7893 - acc: 0.5412 - val_loss: 0.7968 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7893 - acc: 0.5412 - val_loss: 0.7968 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7893 - acc: 0.5412 - val_loss: 0.7968 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7893 - acc: 0.5412 - val_loss: 0.7968 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7893 - acc: 0.5412 - val_loss: 0.7968 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7893 - acc: 0.5412 - val_loss: 0.7968 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7893 - acc: 0.5412 - val_loss: 0.7968 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7893 - acc: 0.5412 - val_loss: 0.7967 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7893 - acc: 0.5412 - val_loss: 0.7967 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7892 - acc: 0.5412 - val_loss: 0.7967 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7892 - acc: 0.5412 - val_loss: 0.7967 - val_acc: 0.5574\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc3135e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7590 - acc: 0.4767 - val_loss: 0.8193 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7590 - acc: 0.4767 - val_loss: 0.8193 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7590 - acc: 0.4767 - val_loss: 0.8193 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7589 - acc: 0.4767 - val_loss: 0.8193 - val_acc: 0.3607\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7589 - acc: 0.4767 - val_loss: 0.8193 - val_acc: 0.3607\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7589 - acc: 0.4767 - val_loss: 0.8193 - val_acc: 0.3607\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7589 - acc: 0.4767 - val_loss: 0.8192 - val_acc: 0.3607\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7589 - acc: 0.4767 - val_loss: 0.8192 - val_acc: 0.3607\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7589 - acc: 0.4767 - val_loss: 0.8192 - val_acc: 0.3607\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7589 - acc: 0.4767 - val_loss: 0.8192 - val_acc: 0.3607\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7589 - acc: 0.4767 - val_loss: 0.8192 - val_acc: 0.3607\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7588 - acc: 0.4767 - val_loss: 0.8192 - val_acc: 0.3770\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7588 - acc: 0.4767 - val_loss: 0.8191 - val_acc: 0.3770\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7588 - acc: 0.4767 - val_loss: 0.8191 - val_acc: 0.3770\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7588 - acc: 0.4767 - val_loss: 0.8191 - val_acc: 0.3770\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7588 - acc: 0.4767 - val_loss: 0.8191 - val_acc: 0.3770\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7588 - acc: 0.4767 - val_loss: 0.8191 - val_acc: 0.3770\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7588 - acc: 0.4767 - val_loss: 0.8191 - val_acc: 0.3770\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7588 - acc: 0.4767 - val_loss: 0.8191 - val_acc: 0.3770\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7587 - acc: 0.4767 - val_loss: 0.8190 - val_acc: 0.3770\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bed34ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9128 - acc: 0.3679 - val_loss: 1.0394 - val_acc: 0.3279\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9128 - acc: 0.3679 - val_loss: 1.0394 - val_acc: 0.3279\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9128 - acc: 0.3679 - val_loss: 1.0394 - val_acc: 0.3279\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9128 - acc: 0.3679 - val_loss: 1.0393 - val_acc: 0.3279\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9127 - acc: 0.3679 - val_loss: 1.0393 - val_acc: 0.3279\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9127 - acc: 0.3679 - val_loss: 1.0393 - val_acc: 0.3279\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9127 - acc: 0.3679 - val_loss: 1.0393 - val_acc: 0.3279\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9127 - acc: 0.3679 - val_loss: 1.0392 - val_acc: 0.3279\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9127 - acc: 0.3679 - val_loss: 1.0392 - val_acc: 0.3279\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9126 - acc: 0.3679 - val_loss: 1.0392 - val_acc: 0.3279\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9126 - acc: 0.3679 - val_loss: 1.0392 - val_acc: 0.3279\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9126 - acc: 0.3679 - val_loss: 1.0391 - val_acc: 0.3279\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9126 - acc: 0.3679 - val_loss: 1.0391 - val_acc: 0.3279\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9126 - acc: 0.3679 - val_loss: 1.0391 - val_acc: 0.3279\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9126 - acc: 0.3679 - val_loss: 1.0391 - val_acc: 0.3279\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9125 - acc: 0.3679 - val_loss: 1.0391 - val_acc: 0.3279\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9125 - acc: 0.3679 - val_loss: 1.0390 - val_acc: 0.3279\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9125 - acc: 0.3679 - val_loss: 1.0390 - val_acc: 0.3279\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9125 - acc: 0.3679 - val_loss: 1.0390 - val_acc: 0.3279\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9125 - acc: 0.3679 - val_loss: 1.0390 - val_acc: 0.3279\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0ea4700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6547 - acc: 0.6237 - val_loss: 0.6316 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6547 - acc: 0.6237 - val_loss: 0.6316 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6547 - acc: 0.6237 - val_loss: 0.6316 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6547 - acc: 0.6237 - val_loss: 0.6316 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6546 - acc: 0.6237 - val_loss: 0.6316 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6546 - acc: 0.6237 - val_loss: 0.6316 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6546 - acc: 0.6237 - val_loss: 0.6316 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6546 - acc: 0.6237 - val_loss: 0.6315 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6546 - acc: 0.6237 - val_loss: 0.6315 - val_acc: 0.7049\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6546 - acc: 0.6237 - val_loss: 0.6315 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6546 - acc: 0.6237 - val_loss: 0.6315 - val_acc: 0.7049\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6546 - acc: 0.6237 - val_loss: 0.6315 - val_acc: 0.7049\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6545 - acc: 0.6237 - val_loss: 0.6315 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6545 - acc: 0.6237 - val_loss: 0.6315 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6545 - acc: 0.6237 - val_loss: 0.6315 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6545 - acc: 0.6237 - val_loss: 0.6314 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6545 - acc: 0.6237 - val_loss: 0.6314 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6545 - acc: 0.6237 - val_loss: 0.6314 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6545 - acc: 0.6237 - val_loss: 0.6314 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6544 - acc: 0.6237 - val_loss: 0.6314 - val_acc: 0.7049\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e0d0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8293 - acc: 0.5515 - val_loss: 0.8069 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8292 - acc: 0.5515 - val_loss: 0.8069 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8292 - acc: 0.5515 - val_loss: 0.8069 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8292 - acc: 0.5515 - val_loss: 0.8068 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8292 - acc: 0.5515 - val_loss: 0.8068 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8292 - acc: 0.5515 - val_loss: 0.8068 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8292 - acc: 0.5515 - val_loss: 0.8068 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8292 - acc: 0.5515 - val_loss: 0.8068 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8291 - acc: 0.5515 - val_loss: 0.8068 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8291 - acc: 0.5515 - val_loss: 0.8067 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8291 - acc: 0.5515 - val_loss: 0.8067 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8291 - acc: 0.5515 - val_loss: 0.8067 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8291 - acc: 0.5515 - val_loss: 0.8067 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8291 - acc: 0.5515 - val_loss: 0.8067 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8291 - acc: 0.5515 - val_loss: 0.8067 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8290 - acc: 0.5515 - val_loss: 0.8066 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8290 - acc: 0.5515 - val_loss: 0.8066 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8290 - acc: 0.5515 - val_loss: 0.8066 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8290 - acc: 0.5515 - val_loss: 0.8066 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8290 - acc: 0.5515 - val_loss: 0.8066 - val_acc: 0.5246\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac18d4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9309 - acc: 0.4278 - val_loss: 1.0169 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9308 - acc: 0.4278 - val_loss: 1.0169 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9308 - acc: 0.4278 - val_loss: 1.0168 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9308 - acc: 0.4278 - val_loss: 1.0168 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9308 - acc: 0.4278 - val_loss: 1.0168 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9308 - acc: 0.4278 - val_loss: 1.0168 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9307 - acc: 0.4278 - val_loss: 1.0167 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9307 - acc: 0.4278 - val_loss: 1.0167 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9307 - acc: 0.4278 - val_loss: 1.0167 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9307 - acc: 0.4278 - val_loss: 1.0167 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9307 - acc: 0.4278 - val_loss: 1.0166 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9307 - acc: 0.4278 - val_loss: 1.0166 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9306 - acc: 0.4278 - val_loss: 1.0166 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9306 - acc: 0.4278 - val_loss: 1.0166 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9306 - acc: 0.4278 - val_loss: 1.0165 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9306 - acc: 0.4278 - val_loss: 1.0165 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9306 - acc: 0.4278 - val_loss: 1.0165 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9306 - acc: 0.4278 - val_loss: 1.0165 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9305 - acc: 0.4278 - val_loss: 1.0164 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9305 - acc: 0.4278 - val_loss: 1.0164 - val_acc: 0.4426\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1e38b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7463 - acc: 0.4508 - val_loss: 0.7803 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7463 - acc: 0.4508 - val_loss: 0.7803 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7463 - acc: 0.4508 - val_loss: 0.7803 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7463 - acc: 0.4508 - val_loss: 0.7803 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7463 - acc: 0.4508 - val_loss: 0.7802 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7462 - acc: 0.4508 - val_loss: 0.7802 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7462 - acc: 0.4508 - val_loss: 0.7802 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7462 - acc: 0.4508 - val_loss: 0.7802 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7462 - acc: 0.4508 - val_loss: 0.7801 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7461 - acc: 0.4508 - val_loss: 0.7801 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7461 - acc: 0.4508 - val_loss: 0.7801 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7461 - acc: 0.4508 - val_loss: 0.7801 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7461 - acc: 0.4508 - val_loss: 0.7800 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7461 - acc: 0.4508 - val_loss: 0.7800 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7460 - acc: 0.4508 - val_loss: 0.7800 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7460 - acc: 0.4508 - val_loss: 0.7800 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7460 - acc: 0.4508 - val_loss: 0.7799 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7460 - acc: 0.4508 - val_loss: 0.7799 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7459 - acc: 0.4508 - val_loss: 0.7799 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7459 - acc: 0.4508 - val_loss: 0.7799 - val_acc: 0.4098\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa474704700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7353 - acc: 0.4560 - val_loss: 0.7996 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7353 - acc: 0.4560 - val_loss: 0.7996 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7353 - acc: 0.4560 - val_loss: 0.7996 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7353 - acc: 0.4560 - val_loss: 0.7996 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7352 - acc: 0.4560 - val_loss: 0.7995 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7352 - acc: 0.4560 - val_loss: 0.7995 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7352 - acc: 0.4560 - val_loss: 0.7995 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7352 - acc: 0.4560 - val_loss: 0.7995 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7352 - acc: 0.4560 - val_loss: 0.7994 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7351 - acc: 0.4560 - val_loss: 0.7994 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7351 - acc: 0.4560 - val_loss: 0.7994 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7351 - acc: 0.4560 - val_loss: 0.7993 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7351 - acc: 0.4560 - val_loss: 0.7993 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7351 - acc: 0.4560 - val_loss: 0.7993 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7350 - acc: 0.4560 - val_loss: 0.7993 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7350 - acc: 0.4560 - val_loss: 0.7992 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7350 - acc: 0.4560 - val_loss: 0.7992 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7350 - acc: 0.4560 - val_loss: 0.7992 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7350 - acc: 0.4560 - val_loss: 0.7992 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7350 - acc: 0.4560 - val_loss: 0.7991 - val_acc: 0.4098\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4becf30d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6966 - acc: 0.5464 - val_loss: 0.6669 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6966 - acc: 0.5464 - val_loss: 0.6669 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6966 - acc: 0.5464 - val_loss: 0.6668 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6966 - acc: 0.5464 - val_loss: 0.6668 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6966 - acc: 0.5464 - val_loss: 0.6668 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6966 - acc: 0.5464 - val_loss: 0.6668 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6965 - acc: 0.5464 - val_loss: 0.6668 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6965 - acc: 0.5464 - val_loss: 0.6667 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6965 - acc: 0.5464 - val_loss: 0.6667 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6965 - acc: 0.5464 - val_loss: 0.6667 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6965 - acc: 0.5464 - val_loss: 0.6667 - val_acc: 0.5574\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6964 - acc: 0.5464 - val_loss: 0.6667 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6964 - acc: 0.5464 - val_loss: 0.6666 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6964 - acc: 0.5464 - val_loss: 0.6666 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6964 - acc: 0.5464 - val_loss: 0.6666 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6964 - acc: 0.5464 - val_loss: 0.6666 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6963 - acc: 0.5464 - val_loss: 0.6666 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6963 - acc: 0.5464 - val_loss: 0.6665 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6963 - acc: 0.5464 - val_loss: 0.6665 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6963 - acc: 0.5464 - val_loss: 0.6665 - val_acc: 0.5574\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4204d8700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8669 - acc: 0.3402 - val_loss: 0.8744 - val_acc: 0.2951\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8669 - acc: 0.3402 - val_loss: 0.8743 - val_acc: 0.2951\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8669 - acc: 0.3402 - val_loss: 0.8743 - val_acc: 0.2951\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8669 - acc: 0.3402 - val_loss: 0.8743 - val_acc: 0.2951\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8668 - acc: 0.3402 - val_loss: 0.8743 - val_acc: 0.2951\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8668 - acc: 0.3402 - val_loss: 0.8742 - val_acc: 0.2951\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8668 - acc: 0.3402 - val_loss: 0.8742 - val_acc: 0.2951\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8668 - acc: 0.3402 - val_loss: 0.8742 - val_acc: 0.2951\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8667 - acc: 0.3402 - val_loss: 0.8742 - val_acc: 0.2951\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8667 - acc: 0.3402 - val_loss: 0.8741 - val_acc: 0.2951\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8667 - acc: 0.3402 - val_loss: 0.8741 - val_acc: 0.2951\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8667 - acc: 0.3402 - val_loss: 0.8741 - val_acc: 0.2951\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8666 - acc: 0.3402 - val_loss: 0.8741 - val_acc: 0.2951\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8666 - acc: 0.3402 - val_loss: 0.8740 - val_acc: 0.2951\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8666 - acc: 0.3402 - val_loss: 0.8740 - val_acc: 0.2951\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8666 - acc: 0.3402 - val_loss: 0.8740 - val_acc: 0.2951\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8665 - acc: 0.3402 - val_loss: 0.8739 - val_acc: 0.2951\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8665 - acc: 0.3402 - val_loss: 0.8739 - val_acc: 0.2951\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8665 - acc: 0.3402 - val_loss: 0.8739 - val_acc: 0.2951\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8665 - acc: 0.3402 - val_loss: 0.8739 - val_acc: 0.2951\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3787ae310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7366 - acc: 0.5309 - val_loss: 0.6458 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7366 - acc: 0.5309 - val_loss: 0.6458 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7366 - acc: 0.5309 - val_loss: 0.6458 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7365 - acc: 0.5309 - val_loss: 0.6458 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7365 - acc: 0.5309 - val_loss: 0.6457 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7365 - acc: 0.5309 - val_loss: 0.6457 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7365 - acc: 0.5309 - val_loss: 0.6457 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7365 - acc: 0.5309 - val_loss: 0.6457 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7365 - acc: 0.5309 - val_loss: 0.6457 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7364 - acc: 0.5309 - val_loss: 0.6456 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7364 - acc: 0.5309 - val_loss: 0.6456 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7364 - acc: 0.5309 - val_loss: 0.6456 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7364 - acc: 0.5309 - val_loss: 0.6456 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7364 - acc: 0.5309 - val_loss: 0.6456 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7363 - acc: 0.5309 - val_loss: 0.6455 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7363 - acc: 0.5309 - val_loss: 0.6455 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7363 - acc: 0.5309 - val_loss: 0.6455 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7363 - acc: 0.5309 - val_loss: 0.6455 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7363 - acc: 0.5309 - val_loss: 0.6455 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7363 - acc: 0.5309 - val_loss: 0.6454 - val_acc: 0.5902\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3786f8790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7709 - acc: 0.5130 - val_loss: 0.8057 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7709 - acc: 0.5130 - val_loss: 0.8057 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7708 - acc: 0.5130 - val_loss: 0.8056 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7708 - acc: 0.5130 - val_loss: 0.8056 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7708 - acc: 0.5130 - val_loss: 0.8056 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7707 - acc: 0.5130 - val_loss: 0.8055 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7707 - acc: 0.5130 - val_loss: 0.8055 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7707 - acc: 0.5130 - val_loss: 0.8055 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7706 - acc: 0.5130 - val_loss: 0.8054 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7706 - acc: 0.5130 - val_loss: 0.8054 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7706 - acc: 0.5130 - val_loss: 0.8054 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7706 - acc: 0.5130 - val_loss: 0.8053 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7705 - acc: 0.5130 - val_loss: 0.8053 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7705 - acc: 0.5130 - val_loss: 0.8053 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7705 - acc: 0.5130 - val_loss: 0.8052 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7704 - acc: 0.5130 - val_loss: 0.8052 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7704 - acc: 0.5130 - val_loss: 0.8052 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7704 - acc: 0.5130 - val_loss: 0.8051 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7703 - acc: 0.5130 - val_loss: 0.8051 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7703 - acc: 0.5130 - val_loss: 0.8051 - val_acc: 0.4262\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4201bf1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7229 - acc: 0.5078 - val_loss: 0.6869 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7229 - acc: 0.5078 - val_loss: 0.6869 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7229 - acc: 0.5078 - val_loss: 0.6868 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7229 - acc: 0.5078 - val_loss: 0.6868 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7228 - acc: 0.5078 - val_loss: 0.6868 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7228 - acc: 0.5078 - val_loss: 0.6867 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7228 - acc: 0.5078 - val_loss: 0.6867 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7227 - acc: 0.5078 - val_loss: 0.6867 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7227 - acc: 0.5078 - val_loss: 0.6866 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7227 - acc: 0.5078 - val_loss: 0.6866 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7226 - acc: 0.5078 - val_loss: 0.6866 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7226 - acc: 0.5078 - val_loss: 0.6866 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7226 - acc: 0.5078 - val_loss: 0.6865 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7226 - acc: 0.5078 - val_loss: 0.6865 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7225 - acc: 0.5078 - val_loss: 0.6865 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7225 - acc: 0.5078 - val_loss: 0.6864 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7225 - acc: 0.5078 - val_loss: 0.6864 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7224 - acc: 0.5078 - val_loss: 0.6864 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7224 - acc: 0.5078 - val_loss: 0.6863 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7224 - acc: 0.5078 - val_loss: 0.6863 - val_acc: 0.5902\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4481e2a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8324 - acc: 0.3454 - val_loss: 0.8315 - val_acc: 0.3443\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8323 - acc: 0.3454 - val_loss: 0.8315 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8323 - acc: 0.3454 - val_loss: 0.8314 - val_acc: 0.3443\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8323 - acc: 0.3454 - val_loss: 0.8314 - val_acc: 0.3443\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8322 - acc: 0.3454 - val_loss: 0.8313 - val_acc: 0.3443\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8322 - acc: 0.3454 - val_loss: 0.8313 - val_acc: 0.3443\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8322 - acc: 0.3454 - val_loss: 0.8313 - val_acc: 0.3443\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8321 - acc: 0.3454 - val_loss: 0.8312 - val_acc: 0.3443\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8321 - acc: 0.3454 - val_loss: 0.8312 - val_acc: 0.3443\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8321 - acc: 0.3454 - val_loss: 0.8312 - val_acc: 0.3443\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8320 - acc: 0.3454 - val_loss: 0.8311 - val_acc: 0.3443\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8320 - acc: 0.3454 - val_loss: 0.8311 - val_acc: 0.3443\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8319 - acc: 0.3454 - val_loss: 0.8310 - val_acc: 0.3443\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8319 - acc: 0.3454 - val_loss: 0.8310 - val_acc: 0.3443\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8319 - acc: 0.3454 - val_loss: 0.8310 - val_acc: 0.3443\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8318 - acc: 0.3454 - val_loss: 0.8309 - val_acc: 0.3443\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8318 - acc: 0.3454 - val_loss: 0.8309 - val_acc: 0.3443\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8318 - acc: 0.3454 - val_loss: 0.8309 - val_acc: 0.3443\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8317 - acc: 0.3454 - val_loss: 0.8308 - val_acc: 0.3443\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8317 - acc: 0.3454 - val_loss: 0.8308 - val_acc: 0.3443\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4201bfa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7148 - acc: 0.4536 - val_loss: 0.7030 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7148 - acc: 0.4536 - val_loss: 0.7030 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7148 - acc: 0.4536 - val_loss: 0.7029 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7147 - acc: 0.4536 - val_loss: 0.7029 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7147 - acc: 0.4536 - val_loss: 0.7029 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7147 - acc: 0.4536 - val_loss: 0.7029 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7147 - acc: 0.4536 - val_loss: 0.7028 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7146 - acc: 0.4536 - val_loss: 0.7028 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7146 - acc: 0.4536 - val_loss: 0.7028 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7146 - acc: 0.4536 - val_loss: 0.7028 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7146 - acc: 0.4536 - val_loss: 0.7027 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7145 - acc: 0.4536 - val_loss: 0.7027 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7145 - acc: 0.4536 - val_loss: 0.7027 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7145 - acc: 0.4536 - val_loss: 0.7026 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7145 - acc: 0.4536 - val_loss: 0.7026 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7144 - acc: 0.4536 - val_loss: 0.7026 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7144 - acc: 0.4536 - val_loss: 0.7026 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7144 - acc: 0.4536 - val_loss: 0.7025 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7143 - acc: 0.4536 - val_loss: 0.7025 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7143 - acc: 0.4536 - val_loss: 0.7025 - val_acc: 0.5574\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b84ad280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8160 - acc: 0.3351 - val_loss: 0.8200 - val_acc: 0.3279\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8160 - acc: 0.3351 - val_loss: 0.8200 - val_acc: 0.3279\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8160 - acc: 0.3351 - val_loss: 0.8199 - val_acc: 0.3279\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8160 - acc: 0.3351 - val_loss: 0.8199 - val_acc: 0.3279\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8159 - acc: 0.3351 - val_loss: 0.8199 - val_acc: 0.3279\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8159 - acc: 0.3351 - val_loss: 0.8198 - val_acc: 0.3279\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8159 - acc: 0.3351 - val_loss: 0.8198 - val_acc: 0.3279\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8158 - acc: 0.3351 - val_loss: 0.8198 - val_acc: 0.3279\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8158 - acc: 0.3351 - val_loss: 0.8197 - val_acc: 0.3279\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8158 - acc: 0.3351 - val_loss: 0.8197 - val_acc: 0.3279\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8157 - acc: 0.3351 - val_loss: 0.8197 - val_acc: 0.3279\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8157 - acc: 0.3351 - val_loss: 0.8196 - val_acc: 0.3279\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8157 - acc: 0.3351 - val_loss: 0.8196 - val_acc: 0.3279\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8156 - acc: 0.3351 - val_loss: 0.8196 - val_acc: 0.3279\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8156 - acc: 0.3351 - val_loss: 0.8195 - val_acc: 0.3279\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8156 - acc: 0.3351 - val_loss: 0.8195 - val_acc: 0.3279\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8156 - acc: 0.3351 - val_loss: 0.8195 - val_acc: 0.3279\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8155 - acc: 0.3351 - val_loss: 0.8194 - val_acc: 0.3279\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8155 - acc: 0.3351 - val_loss: 0.8194 - val_acc: 0.3279\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8155 - acc: 0.3402 - val_loss: 0.8194 - val_acc: 0.3279\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b80c68b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7039 - acc: 0.5699 - val_loss: 0.6662 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7038 - acc: 0.5699 - val_loss: 0.6662 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7038 - acc: 0.5699 - val_loss: 0.6661 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7038 - acc: 0.5699 - val_loss: 0.6661 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7037 - acc: 0.5699 - val_loss: 0.6660 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7037 - acc: 0.5699 - val_loss: 0.6660 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7036 - acc: 0.5699 - val_loss: 0.6660 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7036 - acc: 0.5699 - val_loss: 0.6659 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7036 - acc: 0.5699 - val_loss: 0.6659 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7035 - acc: 0.5699 - val_loss: 0.6658 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7035 - acc: 0.5699 - val_loss: 0.6658 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7034 - acc: 0.5699 - val_loss: 0.6658 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7034 - acc: 0.5699 - val_loss: 0.6657 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7034 - acc: 0.5699 - val_loss: 0.6657 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7033 - acc: 0.5699 - val_loss: 0.6656 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7033 - acc: 0.5699 - val_loss: 0.6656 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7032 - acc: 0.5699 - val_loss: 0.6655 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7032 - acc: 0.5699 - val_loss: 0.6655 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7032 - acc: 0.5699 - val_loss: 0.6655 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7031 - acc: 0.5699 - val_loss: 0.6654 - val_acc: 0.6721\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3945cb8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8054 - acc: 0.3523 - val_loss: 0.8003 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8054 - acc: 0.3523 - val_loss: 0.8003 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8054 - acc: 0.3523 - val_loss: 0.8002 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8053 - acc: 0.3523 - val_loss: 0.8002 - val_acc: 0.3607\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8053 - acc: 0.3523 - val_loss: 0.8001 - val_acc: 0.3607\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8052 - acc: 0.3523 - val_loss: 0.8001 - val_acc: 0.3607\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8052 - acc: 0.3523 - val_loss: 0.8001 - val_acc: 0.3607\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8051 - acc: 0.3523 - val_loss: 0.8000 - val_acc: 0.3607\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8051 - acc: 0.3523 - val_loss: 0.8000 - val_acc: 0.3607\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8050 - acc: 0.3523 - val_loss: 0.7999 - val_acc: 0.3607\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8050 - acc: 0.3523 - val_loss: 0.7999 - val_acc: 0.3607\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8049 - acc: 0.3523 - val_loss: 0.7998 - val_acc: 0.3607\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8049 - acc: 0.3523 - val_loss: 0.7998 - val_acc: 0.3607\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8049 - acc: 0.3523 - val_loss: 0.7997 - val_acc: 0.3607\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8048 - acc: 0.3523 - val_loss: 0.7997 - val_acc: 0.3607\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8048 - acc: 0.3523 - val_loss: 0.7996 - val_acc: 0.3607\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8047 - acc: 0.3523 - val_loss: 0.7996 - val_acc: 0.3607\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8047 - acc: 0.3523 - val_loss: 0.7995 - val_acc: 0.3607\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8046 - acc: 0.3523 - val_loss: 0.7995 - val_acc: 0.3607\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8046 - acc: 0.3523 - val_loss: 0.7994 - val_acc: 0.3607\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa378657280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7074 - acc: 0.4433 - val_loss: 0.7581 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7073 - acc: 0.4433 - val_loss: 0.7581 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7073 - acc: 0.4433 - val_loss: 0.7580 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7072 - acc: 0.4433 - val_loss: 0.7580 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7072 - acc: 0.4433 - val_loss: 0.7579 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7071 - acc: 0.4433 - val_loss: 0.7579 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7071 - acc: 0.4433 - val_loss: 0.7578 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7071 - acc: 0.4433 - val_loss: 0.7578 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7070 - acc: 0.4433 - val_loss: 0.7577 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7070 - acc: 0.4433 - val_loss: 0.7577 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7069 - acc: 0.4433 - val_loss: 0.7576 - val_acc: 0.4098\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7069 - acc: 0.4433 - val_loss: 0.7576 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7068 - acc: 0.4433 - val_loss: 0.7575 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7068 - acc: 0.4433 - val_loss: 0.7575 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7068 - acc: 0.4433 - val_loss: 0.7574 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7067 - acc: 0.4433 - val_loss: 0.7574 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7067 - acc: 0.4433 - val_loss: 0.7573 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7066 - acc: 0.4433 - val_loss: 0.7573 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7066 - acc: 0.4433 - val_loss: 0.7572 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7065 - acc: 0.4433 - val_loss: 0.7572 - val_acc: 0.4098\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3782803a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7974 - acc: 0.2629 - val_loss: 0.7583 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7973 - acc: 0.2629 - val_loss: 0.7582 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7973 - acc: 0.2629 - val_loss: 0.7582 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7972 - acc: 0.2629 - val_loss: 0.7581 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7972 - acc: 0.2629 - val_loss: 0.7581 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7971 - acc: 0.2629 - val_loss: 0.7580 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7971 - acc: 0.2629 - val_loss: 0.7580 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7970 - acc: 0.2629 - val_loss: 0.7579 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7970 - acc: 0.2629 - val_loss: 0.7579 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7970 - acc: 0.2629 - val_loss: 0.7579 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7969 - acc: 0.2629 - val_loss: 0.7578 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7969 - acc: 0.2629 - val_loss: 0.7578 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7968 - acc: 0.2629 - val_loss: 0.7577 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7968 - acc: 0.2629 - val_loss: 0.7577 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7967 - acc: 0.2629 - val_loss: 0.7576 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7967 - acc: 0.2629 - val_loss: 0.7576 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7966 - acc: 0.2629 - val_loss: 0.7575 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7966 - acc: 0.2629 - val_loss: 0.7575 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7966 - acc: 0.2629 - val_loss: 0.7574 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7965 - acc: 0.2629 - val_loss: 0.7574 - val_acc: 0.3934\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa378312430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7591 - acc: 0.3918 - val_loss: 0.7676 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7591 - acc: 0.3918 - val_loss: 0.7676 - val_acc: 0.3115\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7590 - acc: 0.3918 - val_loss: 0.7675 - val_acc: 0.3115\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7590 - acc: 0.3918 - val_loss: 0.7675 - val_acc: 0.3115\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7589 - acc: 0.3918 - val_loss: 0.7674 - val_acc: 0.3115\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7589 - acc: 0.3918 - val_loss: 0.7674 - val_acc: 0.3115\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7588 - acc: 0.3918 - val_loss: 0.7673 - val_acc: 0.3115\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7588 - acc: 0.3918 - val_loss: 0.7673 - val_acc: 0.3115\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7587 - acc: 0.3918 - val_loss: 0.7672 - val_acc: 0.3115\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7587 - acc: 0.3918 - val_loss: 0.7672 - val_acc: 0.3279\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7587 - acc: 0.3918 - val_loss: 0.7671 - val_acc: 0.3279\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7586 - acc: 0.3918 - val_loss: 0.7671 - val_acc: 0.3279\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7586 - acc: 0.3918 - val_loss: 0.7670 - val_acc: 0.3279\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7585 - acc: 0.3918 - val_loss: 0.7670 - val_acc: 0.3279\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7585 - acc: 0.3918 - val_loss: 0.7669 - val_acc: 0.3279\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7584 - acc: 0.3918 - val_loss: 0.7669 - val_acc: 0.3279\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7584 - acc: 0.3918 - val_loss: 0.7668 - val_acc: 0.3279\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7583 - acc: 0.3918 - val_loss: 0.7668 - val_acc: 0.3279\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7583 - acc: 0.3918 - val_loss: 0.7667 - val_acc: 0.3279\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7583 - acc: 0.3918 - val_loss: 0.7667 - val_acc: 0.3279\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bec571f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6946 - acc: 0.5389 - val_loss: 0.7176 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6945 - acc: 0.5389 - val_loss: 0.7175 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6945 - acc: 0.5389 - val_loss: 0.7175 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6944 - acc: 0.5389 - val_loss: 0.7174 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6944 - acc: 0.5389 - val_loss: 0.7173 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6943 - acc: 0.5389 - val_loss: 0.7173 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6942 - acc: 0.5389 - val_loss: 0.7172 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6942 - acc: 0.5389 - val_loss: 0.7172 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6941 - acc: 0.5389 - val_loss: 0.7171 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6941 - acc: 0.5389 - val_loss: 0.7170 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6940 - acc: 0.5389 - val_loss: 0.7170 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6940 - acc: 0.5389 - val_loss: 0.7169 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6939 - acc: 0.5389 - val_loss: 0.7168 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6939 - acc: 0.5389 - val_loss: 0.7168 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6938 - acc: 0.5389 - val_loss: 0.7167 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6938 - acc: 0.5389 - val_loss: 0.7166 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6937 - acc: 0.5389 - val_loss: 0.7166 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6936 - acc: 0.5389 - val_loss: 0.7165 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6936 - acc: 0.5389 - val_loss: 0.7164 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6935 - acc: 0.5389 - val_loss: 0.7164 - val_acc: 0.5410\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bec57a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8245 - acc: 0.3627 - val_loss: 0.8379 - val_acc: 0.3279\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8244 - acc: 0.3627 - val_loss: 0.8378 - val_acc: 0.3279\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8244 - acc: 0.3627 - val_loss: 0.8377 - val_acc: 0.3279\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8243 - acc: 0.3627 - val_loss: 0.8377 - val_acc: 0.3279\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8242 - acc: 0.3627 - val_loss: 0.8376 - val_acc: 0.3279\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8242 - acc: 0.3627 - val_loss: 0.8375 - val_acc: 0.3279\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8241 - acc: 0.3627 - val_loss: 0.8374 - val_acc: 0.3279\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8240 - acc: 0.3627 - val_loss: 0.8374 - val_acc: 0.3279\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8240 - acc: 0.3627 - val_loss: 0.8373 - val_acc: 0.3279\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8239 - acc: 0.3627 - val_loss: 0.8372 - val_acc: 0.3279\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8238 - acc: 0.3627 - val_loss: 0.8372 - val_acc: 0.3279\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8238 - acc: 0.3627 - val_loss: 0.8371 - val_acc: 0.3279\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8237 - acc: 0.3627 - val_loss: 0.8370 - val_acc: 0.3279\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8236 - acc: 0.3627 - val_loss: 0.8369 - val_acc: 0.3279\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8236 - acc: 0.3627 - val_loss: 0.8369 - val_acc: 0.3279\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8235 - acc: 0.3627 - val_loss: 0.8368 - val_acc: 0.3279\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8234 - acc: 0.3627 - val_loss: 0.8367 - val_acc: 0.3279\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8234 - acc: 0.3627 - val_loss: 0.8367 - val_acc: 0.3279\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8233 - acc: 0.3627 - val_loss: 0.8366 - val_acc: 0.3279\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8232 - acc: 0.3627 - val_loss: 0.8365 - val_acc: 0.3279\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc364af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7182 - acc: 0.4845 - val_loss: 0.7250 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7181 - acc: 0.4845 - val_loss: 0.7250 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7181 - acc: 0.4845 - val_loss: 0.7249 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7180 - acc: 0.4845 - val_loss: 0.7248 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7180 - acc: 0.4845 - val_loss: 0.7247 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7179 - acc: 0.4845 - val_loss: 0.7247 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7178 - acc: 0.4845 - val_loss: 0.7246 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7178 - acc: 0.4845 - val_loss: 0.7245 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7177 - acc: 0.4845 - val_loss: 0.7244 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7176 - acc: 0.4845 - val_loss: 0.7244 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7176 - acc: 0.4845 - val_loss: 0.7243 - val_acc: 0.5082\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7175 - acc: 0.4845 - val_loss: 0.7242 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7174 - acc: 0.4845 - val_loss: 0.7242 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7174 - acc: 0.4845 - val_loss: 0.7241 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7173 - acc: 0.4845 - val_loss: 0.7240 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7173 - acc: 0.4845 - val_loss: 0.7239 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7172 - acc: 0.4897 - val_loss: 0.7239 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7171 - acc: 0.4897 - val_loss: 0.7238 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7171 - acc: 0.4897 - val_loss: 0.7237 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7170 - acc: 0.4897 - val_loss: 0.7236 - val_acc: 0.5082\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4204d8b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7124 - acc: 0.4948 - val_loss: 0.7388 - val_acc: 0.3279\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7124 - acc: 0.4948 - val_loss: 0.7387 - val_acc: 0.3279\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7123 - acc: 0.4948 - val_loss: 0.7386 - val_acc: 0.3279\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7122 - acc: 0.4948 - val_loss: 0.7385 - val_acc: 0.3279\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7122 - acc: 0.4948 - val_loss: 0.7385 - val_acc: 0.3279\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7121 - acc: 0.4948 - val_loss: 0.7384 - val_acc: 0.3279\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7121 - acc: 0.4948 - val_loss: 0.7383 - val_acc: 0.3279\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7120 - acc: 0.4948 - val_loss: 0.7383 - val_acc: 0.3279\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7120 - acc: 0.4948 - val_loss: 0.7382 - val_acc: 0.3279\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7119 - acc: 0.4948 - val_loss: 0.7381 - val_acc: 0.3279\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7118 - acc: 0.4948 - val_loss: 0.7381 - val_acc: 0.3279\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7118 - acc: 0.4897 - val_loss: 0.7380 - val_acc: 0.3279\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7117 - acc: 0.4897 - val_loss: 0.7379 - val_acc: 0.3279\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7117 - acc: 0.4897 - val_loss: 0.7379 - val_acc: 0.3279\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7116 - acc: 0.4897 - val_loss: 0.7378 - val_acc: 0.3279\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7115 - acc: 0.4897 - val_loss: 0.7377 - val_acc: 0.3279\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7115 - acc: 0.4948 - val_loss: 0.7377 - val_acc: 0.3443\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7114 - acc: 0.4948 - val_loss: 0.7376 - val_acc: 0.3443\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7114 - acc: 0.4948 - val_loss: 0.7375 - val_acc: 0.3443\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7113 - acc: 0.4948 - val_loss: 0.7375 - val_acc: 0.3443\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4becf31f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6518 - acc: 0.6546 - val_loss: 0.6437 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6518 - acc: 0.6546 - val_loss: 0.6436 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6517 - acc: 0.6598 - val_loss: 0.6436 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6517 - acc: 0.6598 - val_loss: 0.6435 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6516 - acc: 0.6598 - val_loss: 0.6435 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6516 - acc: 0.6598 - val_loss: 0.6434 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6515 - acc: 0.6598 - val_loss: 0.6434 - val_acc: 0.6393\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6515 - acc: 0.6598 - val_loss: 0.6433 - val_acc: 0.6393\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6514 - acc: 0.6598 - val_loss: 0.6433 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6514 - acc: 0.6598 - val_loss: 0.6432 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6513 - acc: 0.6598 - val_loss: 0.6432 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6513 - acc: 0.6598 - val_loss: 0.6431 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6512 - acc: 0.6598 - val_loss: 0.6431 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6512 - acc: 0.6598 - val_loss: 0.6430 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6511 - acc: 0.6598 - val_loss: 0.6429 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6511 - acc: 0.6598 - val_loss: 0.6429 - val_acc: 0.6557\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6510 - acc: 0.6598 - val_loss: 0.6428 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6510 - acc: 0.6598 - val_loss: 0.6428 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6509 - acc: 0.6598 - val_loss: 0.6427 - val_acc: 0.6557\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6509 - acc: 0.6598 - val_loss: 0.6427 - val_acc: 0.6557\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc1e9ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8333 - acc: 0.3886 - val_loss: 0.8639 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8327 - acc: 0.3886 - val_loss: 0.8633 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8321 - acc: 0.3886 - val_loss: 0.8627 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8316 - acc: 0.3886 - val_loss: 0.8621 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8310 - acc: 0.3886 - val_loss: 0.8615 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8304 - acc: 0.3886 - val_loss: 0.8609 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8298 - acc: 0.3886 - val_loss: 0.8603 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8292 - acc: 0.3886 - val_loss: 0.8597 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8286 - acc: 0.3886 - val_loss: 0.8591 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8281 - acc: 0.3886 - val_loss: 0.8585 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8275 - acc: 0.3886 - val_loss: 0.8579 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8269 - acc: 0.3886 - val_loss: 0.8573 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8263 - acc: 0.3886 - val_loss: 0.8567 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8257 - acc: 0.3886 - val_loss: 0.8561 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8252 - acc: 0.3886 - val_loss: 0.8555 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8246 - acc: 0.3886 - val_loss: 0.8549 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8240 - acc: 0.3886 - val_loss: 0.8544 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8234 - acc: 0.3886 - val_loss: 0.8538 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8229 - acc: 0.3886 - val_loss: 0.8532 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8223 - acc: 0.3886 - val_loss: 0.8526 - val_acc: 0.4098\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4747048b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6643 - acc: 0.6528 - val_loss: 0.6981 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6637 - acc: 0.6528 - val_loss: 0.6974 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6631 - acc: 0.6580 - val_loss: 0.6967 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6625 - acc: 0.6580 - val_loss: 0.6961 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6618 - acc: 0.6684 - val_loss: 0.6954 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6612 - acc: 0.6684 - val_loss: 0.6947 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6606 - acc: 0.6684 - val_loss: 0.6940 - val_acc: 0.6393\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6600 - acc: 0.6684 - val_loss: 0.6933 - val_acc: 0.6393\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6593 - acc: 0.6684 - val_loss: 0.6926 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6587 - acc: 0.6684 - val_loss: 0.6919 - val_acc: 0.6393\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6581 - acc: 0.6684 - val_loss: 0.6912 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6575 - acc: 0.6684 - val_loss: 0.6906 - val_acc: 0.6393\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6569 - acc: 0.6684 - val_loss: 0.6899 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6563 - acc: 0.6684 - val_loss: 0.6892 - val_acc: 0.6393\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6557 - acc: 0.6684 - val_loss: 0.6885 - val_acc: 0.6393\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6551 - acc: 0.6684 - val_loss: 0.6878 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6544 - acc: 0.6684 - val_loss: 0.6872 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6538 - acc: 0.6736 - val_loss: 0.6865 - val_acc: 0.6393\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6532 - acc: 0.6839 - val_loss: 0.6858 - val_acc: 0.6393\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6526 - acc: 0.6839 - val_loss: 0.6851 - val_acc: 0.6393\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e28940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6460 - acc: 0.6340 - val_loss: 0.6744 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6455 - acc: 0.6340 - val_loss: 0.6739 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6450 - acc: 0.6340 - val_loss: 0.6734 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6445 - acc: 0.6340 - val_loss: 0.6728 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6440 - acc: 0.6340 - val_loss: 0.6723 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6434 - acc: 0.6340 - val_loss: 0.6718 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6429 - acc: 0.6340 - val_loss: 0.6713 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6424 - acc: 0.6340 - val_loss: 0.6707 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6419 - acc: 0.6340 - val_loss: 0.6702 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6414 - acc: 0.6392 - val_loss: 0.6697 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6409 - acc: 0.6392 - val_loss: 0.6692 - val_acc: 0.6393\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6404 - acc: 0.6392 - val_loss: 0.6687 - val_acc: 0.6393\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6399 - acc: 0.6392 - val_loss: 0.6681 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6394 - acc: 0.6392 - val_loss: 0.6676 - val_acc: 0.6393\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6389 - acc: 0.6392 - val_loss: 0.6671 - val_acc: 0.6393\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6384 - acc: 0.6392 - val_loss: 0.6666 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6379 - acc: 0.6392 - val_loss: 0.6661 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6375 - acc: 0.6392 - val_loss: 0.6656 - val_acc: 0.6393\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6370 - acc: 0.6443 - val_loss: 0.6651 - val_acc: 0.6393\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6365 - acc: 0.6443 - val_loss: 0.6646 - val_acc: 0.6393\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beca4d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8328 - acc: 0.5258 - val_loss: 0.7506 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8320 - acc: 0.5309 - val_loss: 0.7498 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8312 - acc: 0.5309 - val_loss: 0.7489 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8304 - acc: 0.5309 - val_loss: 0.7481 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8296 - acc: 0.5309 - val_loss: 0.7472 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8289 - acc: 0.5309 - val_loss: 0.7464 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8281 - acc: 0.5309 - val_loss: 0.7455 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8273 - acc: 0.5309 - val_loss: 0.7447 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8265 - acc: 0.5309 - val_loss: 0.7438 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8258 - acc: 0.5309 - val_loss: 0.7430 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8250 - acc: 0.5258 - val_loss: 0.7422 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8242 - acc: 0.5258 - val_loss: 0.7413 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8234 - acc: 0.5258 - val_loss: 0.7405 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8227 - acc: 0.5258 - val_loss: 0.7397 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8219 - acc: 0.5258 - val_loss: 0.7388 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8211 - acc: 0.5309 - val_loss: 0.7380 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8204 - acc: 0.5309 - val_loss: 0.7372 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8196 - acc: 0.5309 - val_loss: 0.7363 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8188 - acc: 0.5309 - val_loss: 0.7355 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8181 - acc: 0.5309 - val_loss: 0.7347 - val_acc: 0.5902\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1e3550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7348 - acc: 0.5670 - val_loss: 0.7736 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7343 - acc: 0.5670 - val_loss: 0.7729 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7338 - acc: 0.5670 - val_loss: 0.7722 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7333 - acc: 0.5670 - val_loss: 0.7715 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7328 - acc: 0.5670 - val_loss: 0.7708 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7323 - acc: 0.5670 - val_loss: 0.7702 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7317 - acc: 0.5670 - val_loss: 0.7695 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7312 - acc: 0.5670 - val_loss: 0.7688 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7307 - acc: 0.5670 - val_loss: 0.7681 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7302 - acc: 0.5670 - val_loss: 0.7674 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7297 - acc: 0.5670 - val_loss: 0.7667 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7292 - acc: 0.5670 - val_loss: 0.7660 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7287 - acc: 0.5670 - val_loss: 0.7653 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7282 - acc: 0.5670 - val_loss: 0.7647 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7276 - acc: 0.5670 - val_loss: 0.7640 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7271 - acc: 0.5670 - val_loss: 0.7633 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7266 - acc: 0.5722 - val_loss: 0.7626 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7261 - acc: 0.5722 - val_loss: 0.7619 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7256 - acc: 0.5722 - val_loss: 0.7613 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7251 - acc: 0.5722 - val_loss: 0.7606 - val_acc: 0.5738\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3547acdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6594 - acc: 0.6062 - val_loss: 0.6036 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6587 - acc: 0.6062 - val_loss: 0.6030 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6581 - acc: 0.6062 - val_loss: 0.6024 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6575 - acc: 0.6062 - val_loss: 0.6018 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6569 - acc: 0.6062 - val_loss: 0.6012 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6563 - acc: 0.6062 - val_loss: 0.6006 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6557 - acc: 0.6062 - val_loss: 0.6000 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6550 - acc: 0.6062 - val_loss: 0.5994 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6544 - acc: 0.6114 - val_loss: 0.5988 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6538 - acc: 0.6114 - val_loss: 0.5982 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6532 - acc: 0.6114 - val_loss: 0.5976 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6526 - acc: 0.6114 - val_loss: 0.5970 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6520 - acc: 0.6114 - val_loss: 0.5965 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6514 - acc: 0.6114 - val_loss: 0.5959 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6508 - acc: 0.6114 - val_loss: 0.5953 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6502 - acc: 0.6114 - val_loss: 0.5947 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6496 - acc: 0.6114 - val_loss: 0.5942 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6490 - acc: 0.6114 - val_loss: 0.5936 - val_acc: 0.6066\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6484 - acc: 0.6114 - val_loss: 0.5930 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6478 - acc: 0.6114 - val_loss: 0.5924 - val_acc: 0.6066\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4480774c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8327 - acc: 0.4145 - val_loss: 0.8851 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8317 - acc: 0.4197 - val_loss: 0.8838 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8306 - acc: 0.4197 - val_loss: 0.8826 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8296 - acc: 0.4249 - val_loss: 0.8814 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8286 - acc: 0.4301 - val_loss: 0.8802 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8276 - acc: 0.4352 - val_loss: 0.8790 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8266 - acc: 0.4352 - val_loss: 0.8778 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8256 - acc: 0.4404 - val_loss: 0.8765 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8245 - acc: 0.4456 - val_loss: 0.8753 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8235 - acc: 0.4456 - val_loss: 0.8741 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8225 - acc: 0.4456 - val_loss: 0.8729 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8215 - acc: 0.4456 - val_loss: 0.8718 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8205 - acc: 0.4456 - val_loss: 0.8706 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8195 - acc: 0.4456 - val_loss: 0.8694 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8185 - acc: 0.4456 - val_loss: 0.8682 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8175 - acc: 0.4456 - val_loss: 0.8670 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8165 - acc: 0.4508 - val_loss: 0.8658 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8155 - acc: 0.4508 - val_loss: 0.8646 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8145 - acc: 0.4508 - val_loss: 0.8634 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8135 - acc: 0.4560 - val_loss: 0.8622 - val_acc: 0.4098\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa418063040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.0172 - acc: 0.3351 - val_loss: 1.0012 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0157 - acc: 0.3351 - val_loss: 0.9994 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0141 - acc: 0.3351 - val_loss: 0.9975 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0126 - acc: 0.3351 - val_loss: 0.9957 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0111 - acc: 0.3351 - val_loss: 0.9939 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0095 - acc: 0.3402 - val_loss: 0.9921 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0080 - acc: 0.3402 - val_loss: 0.9903 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0065 - acc: 0.3402 - val_loss: 0.9885 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0049 - acc: 0.3402 - val_loss: 0.9867 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0034 - acc: 0.3402 - val_loss: 0.9849 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0019 - acc: 0.3402 - val_loss: 0.9832 - val_acc: 0.4426\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0004 - acc: 0.3454 - val_loss: 0.9814 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9989 - acc: 0.3454 - val_loss: 0.9796 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9974 - acc: 0.3454 - val_loss: 0.9779 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9958 - acc: 0.3454 - val_loss: 0.9761 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9943 - acc: 0.3454 - val_loss: 0.9744 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9928 - acc: 0.3454 - val_loss: 0.9726 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9913 - acc: 0.3454 - val_loss: 0.9709 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9898 - acc: 0.3505 - val_loss: 0.9692 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9883 - acc: 0.3557 - val_loss: 0.9674 - val_acc: 0.4426\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa420544a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7757 - acc: 0.4742 - val_loss: 0.7961 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7747 - acc: 0.4742 - val_loss: 0.7949 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7738 - acc: 0.4742 - val_loss: 0.7937 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7728 - acc: 0.4742 - val_loss: 0.7926 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7718 - acc: 0.4742 - val_loss: 0.7914 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7709 - acc: 0.4742 - val_loss: 0.7902 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7699 - acc: 0.4845 - val_loss: 0.7890 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7690 - acc: 0.4845 - val_loss: 0.7878 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7681 - acc: 0.4845 - val_loss: 0.7867 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7671 - acc: 0.4845 - val_loss: 0.7855 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7662 - acc: 0.4845 - val_loss: 0.7843 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7652 - acc: 0.4845 - val_loss: 0.7832 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7643 - acc: 0.4845 - val_loss: 0.7820 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7634 - acc: 0.4845 - val_loss: 0.7808 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7624 - acc: 0.4845 - val_loss: 0.7797 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7615 - acc: 0.4845 - val_loss: 0.7785 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7606 - acc: 0.4845 - val_loss: 0.7774 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7596 - acc: 0.4845 - val_loss: 0.7762 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7587 - acc: 0.4845 - val_loss: 0.7751 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7578 - acc: 0.4845 - val_loss: 0.7739 - val_acc: 0.4590\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa418303940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9817 - acc: 0.4072 - val_loss: 0.8954 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9804 - acc: 0.4072 - val_loss: 0.8941 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9792 - acc: 0.4072 - val_loss: 0.8929 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9779 - acc: 0.4072 - val_loss: 0.8916 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9766 - acc: 0.4072 - val_loss: 0.8904 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9753 - acc: 0.4072 - val_loss: 0.8891 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9740 - acc: 0.4072 - val_loss: 0.8879 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9728 - acc: 0.4072 - val_loss: 0.8866 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9715 - acc: 0.4072 - val_loss: 0.8854 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9702 - acc: 0.4072 - val_loss: 0.8841 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9689 - acc: 0.4072 - val_loss: 0.8829 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9677 - acc: 0.4072 - val_loss: 0.8817 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9664 - acc: 0.4072 - val_loss: 0.8804 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9651 - acc: 0.4072 - val_loss: 0.8792 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9638 - acc: 0.4072 - val_loss: 0.8780 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9626 - acc: 0.4072 - val_loss: 0.8768 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9613 - acc: 0.4072 - val_loss: 0.8756 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9600 - acc: 0.4072 - val_loss: 0.8743 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9588 - acc: 0.4072 - val_loss: 0.8731 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9575 - acc: 0.4072 - val_loss: 0.8719 - val_acc: 0.4754\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa39446d280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7574 - acc: 0.4715 - val_loss: 0.7527 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7562 - acc: 0.4819 - val_loss: 0.7513 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7549 - acc: 0.4819 - val_loss: 0.7498 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7536 - acc: 0.4922 - val_loss: 0.7484 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7524 - acc: 0.5026 - val_loss: 0.7470 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7511 - acc: 0.5078 - val_loss: 0.7455 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7498 - acc: 0.5078 - val_loss: 0.7441 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7486 - acc: 0.5130 - val_loss: 0.7427 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7473 - acc: 0.5130 - val_loss: 0.7413 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7461 - acc: 0.5130 - val_loss: 0.7399 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7448 - acc: 0.5130 - val_loss: 0.7385 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7436 - acc: 0.5130 - val_loss: 0.7371 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7424 - acc: 0.5130 - val_loss: 0.7357 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7411 - acc: 0.5233 - val_loss: 0.7343 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7399 - acc: 0.5233 - val_loss: 0.7329 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7387 - acc: 0.5233 - val_loss: 0.7316 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7375 - acc: 0.5285 - val_loss: 0.7302 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7363 - acc: 0.5285 - val_loss: 0.7288 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7351 - acc: 0.5389 - val_loss: 0.7275 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7339 - acc: 0.5337 - val_loss: 0.7261 - val_acc: 0.5410\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3945dde50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8348 - acc: 0.3886 - val_loss: 0.8165 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8332 - acc: 0.3886 - val_loss: 0.8150 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8317 - acc: 0.3886 - val_loss: 0.8135 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8302 - acc: 0.3886 - val_loss: 0.8120 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8287 - acc: 0.3886 - val_loss: 0.8105 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8271 - acc: 0.3886 - val_loss: 0.8090 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8256 - acc: 0.3886 - val_loss: 0.8074 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8241 - acc: 0.3886 - val_loss: 0.8059 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8226 - acc: 0.3886 - val_loss: 0.8044 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8211 - acc: 0.3938 - val_loss: 0.8029 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8196 - acc: 0.3990 - val_loss: 0.8015 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8181 - acc: 0.3990 - val_loss: 0.8000 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8166 - acc: 0.3990 - val_loss: 0.7985 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8151 - acc: 0.3990 - val_loss: 0.7970 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8136 - acc: 0.4041 - val_loss: 0.7955 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8121 - acc: 0.4041 - val_loss: 0.7941 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8106 - acc: 0.4041 - val_loss: 0.7926 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8091 - acc: 0.4093 - val_loss: 0.7911 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8076 - acc: 0.4145 - val_loss: 0.7896 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8062 - acc: 0.4145 - val_loss: 0.7882 - val_acc: 0.4590\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3940d2b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8327 - acc: 0.4948 - val_loss: 0.8050 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8311 - acc: 0.4948 - val_loss: 0.8034 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8295 - acc: 0.4948 - val_loss: 0.8017 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8279 - acc: 0.4948 - val_loss: 0.8001 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8263 - acc: 0.4948 - val_loss: 0.7985 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8247 - acc: 0.5000 - val_loss: 0.7969 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8231 - acc: 0.5000 - val_loss: 0.7953 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8215 - acc: 0.5000 - val_loss: 0.7937 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8199 - acc: 0.5052 - val_loss: 0.7921 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8183 - acc: 0.5052 - val_loss: 0.7905 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8168 - acc: 0.5103 - val_loss: 0.7889 - val_acc: 0.5082\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8152 - acc: 0.5103 - val_loss: 0.7873 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8136 - acc: 0.5103 - val_loss: 0.7857 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8121 - acc: 0.5052 - val_loss: 0.7841 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8105 - acc: 0.5155 - val_loss: 0.7825 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8090 - acc: 0.5155 - val_loss: 0.7809 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8074 - acc: 0.5155 - val_loss: 0.7794 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8059 - acc: 0.5155 - val_loss: 0.7778 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8044 - acc: 0.5155 - val_loss: 0.7762 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8029 - acc: 0.5155 - val_loss: 0.7746 - val_acc: 0.5410\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa37810e940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6946 - acc: 0.5928 - val_loss: 0.6782 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6933 - acc: 0.5928 - val_loss: 0.6767 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6921 - acc: 0.5928 - val_loss: 0.6753 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6909 - acc: 0.5928 - val_loss: 0.6738 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6896 - acc: 0.5979 - val_loss: 0.6724 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6884 - acc: 0.5979 - val_loss: 0.6709 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6872 - acc: 0.5979 - val_loss: 0.6695 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6859 - acc: 0.5979 - val_loss: 0.6681 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6847 - acc: 0.5979 - val_loss: 0.6666 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6835 - acc: 0.5928 - val_loss: 0.6652 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6823 - acc: 0.5928 - val_loss: 0.6638 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6811 - acc: 0.5928 - val_loss: 0.6624 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6799 - acc: 0.5928 - val_loss: 0.6610 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6787 - acc: 0.5928 - val_loss: 0.6596 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6775 - acc: 0.5979 - val_loss: 0.6583 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6763 - acc: 0.5979 - val_loss: 0.6569 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6751 - acc: 0.5979 - val_loss: 0.6555 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6739 - acc: 0.6031 - val_loss: 0.6541 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6727 - acc: 0.6031 - val_loss: 0.6528 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6715 - acc: 0.6031 - val_loss: 0.6514 - val_acc: 0.6066\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa37867eca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7361 - acc: 0.5206 - val_loss: 0.6896 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7349 - acc: 0.5206 - val_loss: 0.6884 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.7337 - acc: 0.5206 - val_loss: 0.6873 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7326 - acc: 0.5206 - val_loss: 0.6861 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7314 - acc: 0.5206 - val_loss: 0.6850 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7302 - acc: 0.5258 - val_loss: 0.6838 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7291 - acc: 0.5258 - val_loss: 0.6827 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7279 - acc: 0.5258 - val_loss: 0.6815 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7268 - acc: 0.5258 - val_loss: 0.6804 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7256 - acc: 0.5309 - val_loss: 0.6793 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7245 - acc: 0.5309 - val_loss: 0.6781 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7233 - acc: 0.5361 - val_loss: 0.6770 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7222 - acc: 0.5361 - val_loss: 0.6759 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7210 - acc: 0.5361 - val_loss: 0.6747 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7199 - acc: 0.5361 - val_loss: 0.6736 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7188 - acc: 0.5361 - val_loss: 0.6725 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7176 - acc: 0.5361 - val_loss: 0.6714 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7165 - acc: 0.5361 - val_loss: 0.6703 - val_acc: 0.6066\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7154 - acc: 0.5361 - val_loss: 0.6691 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7142 - acc: 0.5361 - val_loss: 0.6680 - val_acc: 0.6066\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc3138b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6922 - acc: 0.5751 - val_loss: 0.6151 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6905 - acc: 0.5803 - val_loss: 0.6136 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6888 - acc: 0.5803 - val_loss: 0.6122 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6871 - acc: 0.5803 - val_loss: 0.6108 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6854 - acc: 0.5803 - val_loss: 0.6094 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6838 - acc: 0.5855 - val_loss: 0.6080 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6821 - acc: 0.5907 - val_loss: 0.6066 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6804 - acc: 0.5907 - val_loss: 0.6052 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6788 - acc: 0.6010 - val_loss: 0.6038 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6771 - acc: 0.6010 - val_loss: 0.6024 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6755 - acc: 0.6010 - val_loss: 0.6010 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6738 - acc: 0.6010 - val_loss: 0.5996 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6722 - acc: 0.6010 - val_loss: 0.5983 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6706 - acc: 0.6010 - val_loss: 0.5969 - val_acc: 0.6885\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6689 - acc: 0.6010 - val_loss: 0.5955 - val_acc: 0.6885\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6673 - acc: 0.5959 - val_loss: 0.5942 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6657 - acc: 0.5959 - val_loss: 0.5929 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6641 - acc: 0.5959 - val_loss: 0.5915 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6626 - acc: 0.6010 - val_loss: 0.5902 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6610 - acc: 0.6010 - val_loss: 0.5889 - val_acc: 0.6885\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41014b430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8286 - acc: 0.3782 - val_loss: 0.8483 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8264 - acc: 0.3782 - val_loss: 0.8460 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8241 - acc: 0.3782 - val_loss: 0.8438 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8219 - acc: 0.3782 - val_loss: 0.8416 - val_acc: 0.3607\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8198 - acc: 0.3782 - val_loss: 0.8394 - val_acc: 0.3607\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8176 - acc: 0.3782 - val_loss: 0.8371 - val_acc: 0.3607\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8154 - acc: 0.3782 - val_loss: 0.8349 - val_acc: 0.3607\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8132 - acc: 0.3834 - val_loss: 0.8327 - val_acc: 0.3607\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8111 - acc: 0.3834 - val_loss: 0.8305 - val_acc: 0.3607\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8089 - acc: 0.3834 - val_loss: 0.8283 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8068 - acc: 0.3834 - val_loss: 0.8261 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8046 - acc: 0.3834 - val_loss: 0.8240 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8025 - acc: 0.3938 - val_loss: 0.8218 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8003 - acc: 0.3938 - val_loss: 0.8196 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7982 - acc: 0.3990 - val_loss: 0.8175 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7961 - acc: 0.3990 - val_loss: 0.8153 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7940 - acc: 0.3990 - val_loss: 0.8132 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7919 - acc: 0.3990 - val_loss: 0.8111 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7898 - acc: 0.3990 - val_loss: 0.8090 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7877 - acc: 0.4093 - val_loss: 0.8069 - val_acc: 0.4262\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1cab80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7630 - acc: 0.5258 - val_loss: 0.7503 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7609 - acc: 0.5258 - val_loss: 0.7481 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7588 - acc: 0.5206 - val_loss: 0.7458 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7567 - acc: 0.5206 - val_loss: 0.7435 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7546 - acc: 0.5258 - val_loss: 0.7413 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7525 - acc: 0.5258 - val_loss: 0.7390 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7505 - acc: 0.5258 - val_loss: 0.7368 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7484 - acc: 0.5258 - val_loss: 0.7346 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7463 - acc: 0.5258 - val_loss: 0.7323 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7443 - acc: 0.5258 - val_loss: 0.7301 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7422 - acc: 0.5258 - val_loss: 0.7279 - val_acc: 0.5082\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7402 - acc: 0.5309 - val_loss: 0.7257 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7381 - acc: 0.5309 - val_loss: 0.7235 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7361 - acc: 0.5309 - val_loss: 0.7213 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7341 - acc: 0.5309 - val_loss: 0.7192 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7321 - acc: 0.5309 - val_loss: 0.7170 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7301 - acc: 0.5309 - val_loss: 0.7148 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7281 - acc: 0.5361 - val_loss: 0.7127 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7261 - acc: 0.5361 - val_loss: 0.7105 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7241 - acc: 0.5361 - val_loss: 0.7084 - val_acc: 0.5246\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa378646940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7496 - acc: 0.4691 - val_loss: 0.7848 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7476 - acc: 0.4742 - val_loss: 0.7825 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7457 - acc: 0.4742 - val_loss: 0.7801 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7438 - acc: 0.4742 - val_loss: 0.7778 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7419 - acc: 0.4742 - val_loss: 0.7755 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7400 - acc: 0.4794 - val_loss: 0.7732 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7381 - acc: 0.4794 - val_loss: 0.7709 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7362 - acc: 0.4897 - val_loss: 0.7686 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7343 - acc: 0.5000 - val_loss: 0.7663 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7324 - acc: 0.5000 - val_loss: 0.7640 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7305 - acc: 0.5000 - val_loss: 0.7617 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7287 - acc: 0.5000 - val_loss: 0.7594 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7268 - acc: 0.5052 - val_loss: 0.7572 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7250 - acc: 0.5052 - val_loss: 0.7549 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7231 - acc: 0.5052 - val_loss: 0.7527 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7213 - acc: 0.5052 - val_loss: 0.7505 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7195 - acc: 0.5103 - val_loss: 0.7483 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7176 - acc: 0.5206 - val_loss: 0.7461 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7158 - acc: 0.5155 - val_loss: 0.7439 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7140 - acc: 0.5155 - val_loss: 0.7417 - val_acc: 0.5246\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beca48b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5330 - acc: 0.7526 - val_loss: 0.5481 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5317 - acc: 0.7526 - val_loss: 0.5467 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5305 - acc: 0.7577 - val_loss: 0.5452 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5292 - acc: 0.7577 - val_loss: 0.5438 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5279 - acc: 0.7577 - val_loss: 0.5424 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5267 - acc: 0.7577 - val_loss: 0.5410 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5254 - acc: 0.7680 - val_loss: 0.5396 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5242 - acc: 0.7680 - val_loss: 0.5382 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5230 - acc: 0.7680 - val_loss: 0.5368 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5217 - acc: 0.7680 - val_loss: 0.5354 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5205 - acc: 0.7629 - val_loss: 0.5341 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5193 - acc: 0.7629 - val_loss: 0.5327 - val_acc: 0.7377\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5181 - acc: 0.7629 - val_loss: 0.5314 - val_acc: 0.7377\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5169 - acc: 0.7629 - val_loss: 0.5300 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5157 - acc: 0.7629 - val_loss: 0.5287 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5145 - acc: 0.7629 - val_loss: 0.5274 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5133 - acc: 0.7629 - val_loss: 0.5260 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5121 - acc: 0.7680 - val_loss: 0.5247 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5110 - acc: 0.7680 - val_loss: 0.5234 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5098 - acc: 0.7680 - val_loss: 0.5221 - val_acc: 0.7377\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa47425b940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6788 - acc: 0.6062 - val_loss: 0.6794 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6762 - acc: 0.6114 - val_loss: 0.6766 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6736 - acc: 0.6269 - val_loss: 0.6739 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6710 - acc: 0.6425 - val_loss: 0.6712 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6685 - acc: 0.6425 - val_loss: 0.6685 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6659 - acc: 0.6425 - val_loss: 0.6658 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6634 - acc: 0.6425 - val_loss: 0.6631 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6609 - acc: 0.6425 - val_loss: 0.6605 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6584 - acc: 0.6477 - val_loss: 0.6578 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6559 - acc: 0.6528 - val_loss: 0.6552 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6534 - acc: 0.6580 - val_loss: 0.6526 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6509 - acc: 0.6632 - val_loss: 0.6500 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6485 - acc: 0.6684 - val_loss: 0.6474 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6461 - acc: 0.6736 - val_loss: 0.6449 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6437 - acc: 0.6736 - val_loss: 0.6424 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6413 - acc: 0.6839 - val_loss: 0.6399 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6389 - acc: 0.6891 - val_loss: 0.6374 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6365 - acc: 0.6943 - val_loss: 0.6349 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6342 - acc: 0.7047 - val_loss: 0.6324 - val_acc: 0.6557\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6319 - acc: 0.7047 - val_loss: 0.6300 - val_acc: 0.6721\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1e3e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7503 - acc: 0.3627 - val_loss: 0.7985 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7473 - acc: 0.3627 - val_loss: 0.7945 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7444 - acc: 0.3731 - val_loss: 0.7906 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7414 - acc: 0.3834 - val_loss: 0.7867 - val_acc: 0.3607\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7384 - acc: 0.3938 - val_loss: 0.7828 - val_acc: 0.3607\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7355 - acc: 0.3938 - val_loss: 0.7789 - val_acc: 0.3607\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7326 - acc: 0.3938 - val_loss: 0.7751 - val_acc: 0.3607\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7297 - acc: 0.3938 - val_loss: 0.7713 - val_acc: 0.3607\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7268 - acc: 0.3990 - val_loss: 0.7675 - val_acc: 0.3443\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7239 - acc: 0.4197 - val_loss: 0.7637 - val_acc: 0.3607\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7211 - acc: 0.4249 - val_loss: 0.7600 - val_acc: 0.3607\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7182 - acc: 0.4301 - val_loss: 0.7562 - val_acc: 0.3607\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7154 - acc: 0.4352 - val_loss: 0.7525 - val_acc: 0.3770\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7126 - acc: 0.4404 - val_loss: 0.7489 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7098 - acc: 0.4508 - val_loss: 0.7452 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7071 - acc: 0.4560 - val_loss: 0.7415 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7043 - acc: 0.4715 - val_loss: 0.7379 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7016 - acc: 0.4767 - val_loss: 0.7343 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6989 - acc: 0.4819 - val_loss: 0.7308 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6962 - acc: 0.4819 - val_loss: 0.7272 - val_acc: 0.4262\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa474704280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7625 - acc: 0.4742 - val_loss: 0.7214 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7594 - acc: 0.4691 - val_loss: 0.7183 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7563 - acc: 0.4691 - val_loss: 0.7152 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7532 - acc: 0.4742 - val_loss: 0.7121 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7502 - acc: 0.4794 - val_loss: 0.7091 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7471 - acc: 0.4794 - val_loss: 0.7061 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7441 - acc: 0.4845 - val_loss: 0.7030 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7411 - acc: 0.4897 - val_loss: 0.7001 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7381 - acc: 0.4845 - val_loss: 0.6971 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7351 - acc: 0.4845 - val_loss: 0.6941 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7321 - acc: 0.4948 - val_loss: 0.6912 - val_acc: 0.4918\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7292 - acc: 0.5000 - val_loss: 0.6883 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7262 - acc: 0.5000 - val_loss: 0.6854 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7233 - acc: 0.5052 - val_loss: 0.6825 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7204 - acc: 0.5052 - val_loss: 0.6797 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7175 - acc: 0.5052 - val_loss: 0.6768 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7147 - acc: 0.5103 - val_loss: 0.6740 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7118 - acc: 0.5155 - val_loss: 0.6712 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7090 - acc: 0.5309 - val_loss: 0.6684 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7062 - acc: 0.5361 - val_loss: 0.6657 - val_acc: 0.5246\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc1e9940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7055 - acc: 0.5155 - val_loss: 0.7335 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7027 - acc: 0.5206 - val_loss: 0.7301 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7000 - acc: 0.5258 - val_loss: 0.7267 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6972 - acc: 0.5412 - val_loss: 0.7233 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6945 - acc: 0.5567 - val_loss: 0.7200 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6918 - acc: 0.5567 - val_loss: 0.7167 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6891 - acc: 0.5619 - val_loss: 0.7134 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6865 - acc: 0.5722 - val_loss: 0.7101 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6838 - acc: 0.5928 - val_loss: 0.7069 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6812 - acc: 0.5979 - val_loss: 0.7036 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6786 - acc: 0.6031 - val_loss: 0.7004 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6760 - acc: 0.6031 - val_loss: 0.6973 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6734 - acc: 0.6186 - val_loss: 0.6941 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6186 - val_loss: 0.6910 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6683 - acc: 0.6186 - val_loss: 0.6879 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6658 - acc: 0.6289 - val_loss: 0.6848 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6633 - acc: 0.6495 - val_loss: 0.6817 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6608 - acc: 0.6495 - val_loss: 0.6787 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6583 - acc: 0.6546 - val_loss: 0.6757 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6559 - acc: 0.6495 - val_loss: 0.6727 - val_acc: 0.5738\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4582f1940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6475 - acc: 0.6082 - val_loss: 0.6415 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6450 - acc: 0.6082 - val_loss: 0.6384 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6426 - acc: 0.6082 - val_loss: 0.6353 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6401 - acc: 0.6082 - val_loss: 0.6323 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6377 - acc: 0.6186 - val_loss: 0.6292 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6353 - acc: 0.6237 - val_loss: 0.6262 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6329 - acc: 0.6289 - val_loss: 0.6232 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6305 - acc: 0.6340 - val_loss: 0.6202 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6282 - acc: 0.6340 - val_loss: 0.6173 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6258 - acc: 0.6443 - val_loss: 0.6143 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6235 - acc: 0.6443 - val_loss: 0.6114 - val_acc: 0.7213\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6211 - acc: 0.6392 - val_loss: 0.6086 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6188 - acc: 0.6443 - val_loss: 0.6057 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6165 - acc: 0.6443 - val_loss: 0.6029 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6143 - acc: 0.6443 - val_loss: 0.6001 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6120 - acc: 0.6443 - val_loss: 0.5973 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6098 - acc: 0.6443 - val_loss: 0.5946 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6075 - acc: 0.6546 - val_loss: 0.5919 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6053 - acc: 0.6598 - val_loss: 0.5892 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6031 - acc: 0.6649 - val_loss: 0.5866 - val_acc: 0.7377\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac494430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7535 - acc: 0.4249 - val_loss: 0.7303 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7492 - acc: 0.4249 - val_loss: 0.7259 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7449 - acc: 0.4404 - val_loss: 0.7216 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7406 - acc: 0.4404 - val_loss: 0.7172 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7364 - acc: 0.4456 - val_loss: 0.7129 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7322 - acc: 0.4560 - val_loss: 0.7087 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7280 - acc: 0.4767 - val_loss: 0.7045 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7239 - acc: 0.4819 - val_loss: 0.7003 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7198 - acc: 0.4870 - val_loss: 0.6962 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7158 - acc: 0.4870 - val_loss: 0.6921 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7118 - acc: 0.5130 - val_loss: 0.6880 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7078 - acc: 0.5181 - val_loss: 0.6840 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7038 - acc: 0.5233 - val_loss: 0.6800 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6999 - acc: 0.5337 - val_loss: 0.6760 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6960 - acc: 0.5389 - val_loss: 0.6721 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6922 - acc: 0.5492 - val_loss: 0.6683 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6884 - acc: 0.5544 - val_loss: 0.6645 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6846 - acc: 0.5751 - val_loss: 0.6607 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6809 - acc: 0.5803 - val_loss: 0.6570 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6772 - acc: 0.5855 - val_loss: 0.6533 - val_acc: 0.6066\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410492af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7558 - acc: 0.4974 - val_loss: 0.7273 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7517 - acc: 0.4974 - val_loss: 0.7233 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7476 - acc: 0.4974 - val_loss: 0.7193 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7435 - acc: 0.4974 - val_loss: 0.7154 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7395 - acc: 0.4974 - val_loss: 0.7114 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7355 - acc: 0.5026 - val_loss: 0.7075 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7315 - acc: 0.5130 - val_loss: 0.7037 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7276 - acc: 0.5181 - val_loss: 0.6998 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7237 - acc: 0.5181 - val_loss: 0.6960 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7198 - acc: 0.5233 - val_loss: 0.6922 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7160 - acc: 0.5285 - val_loss: 0.6885 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7121 - acc: 0.5492 - val_loss: 0.6847 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7084 - acc: 0.5544 - val_loss: 0.6811 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7046 - acc: 0.5596 - val_loss: 0.6774 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7009 - acc: 0.5648 - val_loss: 0.6738 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6972 - acc: 0.5648 - val_loss: 0.6702 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6935 - acc: 0.5648 - val_loss: 0.6666 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6899 - acc: 0.5648 - val_loss: 0.6631 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6863 - acc: 0.5803 - val_loss: 0.6596 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6827 - acc: 0.5855 - val_loss: 0.6561 - val_acc: 0.5902\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b86be040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6734 - acc: 0.5825 - val_loss: 0.6550 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6695 - acc: 0.5928 - val_loss: 0.6508 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6657 - acc: 0.5928 - val_loss: 0.6467 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6619 - acc: 0.6134 - val_loss: 0.6426 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6581 - acc: 0.6186 - val_loss: 0.6385 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6543 - acc: 0.6237 - val_loss: 0.6345 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6506 - acc: 0.6289 - val_loss: 0.6305 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6469 - acc: 0.6443 - val_loss: 0.6266 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6432 - acc: 0.6495 - val_loss: 0.6227 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6396 - acc: 0.6495 - val_loss: 0.6188 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6360 - acc: 0.6598 - val_loss: 0.6150 - val_acc: 0.7049\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6324 - acc: 0.6701 - val_loss: 0.6112 - val_acc: 0.7049\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6289 - acc: 0.6753 - val_loss: 0.6075 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6254 - acc: 0.6907 - val_loss: 0.6038 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6220 - acc: 0.6907 - val_loss: 0.6001 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6185 - acc: 0.6856 - val_loss: 0.5965 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6152 - acc: 0.6907 - val_loss: 0.5929 - val_acc: 0.7213\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6118 - acc: 0.7010 - val_loss: 0.5894 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6085 - acc: 0.7062 - val_loss: 0.5859 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6052 - acc: 0.7268 - val_loss: 0.5824 - val_acc: 0.7541\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b81dbd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6621 - acc: 0.6237 - val_loss: 0.6584 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6584 - acc: 0.6443 - val_loss: 0.6538 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6546 - acc: 0.6495 - val_loss: 0.6492 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6509 - acc: 0.6546 - val_loss: 0.6447 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6472 - acc: 0.6649 - val_loss: 0.6402 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6436 - acc: 0.6804 - val_loss: 0.6357 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6400 - acc: 0.6856 - val_loss: 0.6313 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6364 - acc: 0.6959 - val_loss: 0.6270 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6329 - acc: 0.7010 - val_loss: 0.6227 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6294 - acc: 0.7010 - val_loss: 0.6185 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6259 - acc: 0.7216 - val_loss: 0.6143 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6225 - acc: 0.7320 - val_loss: 0.6101 - val_acc: 0.7377\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6191 - acc: 0.7268 - val_loss: 0.6061 - val_acc: 0.7541\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6157 - acc: 0.7320 - val_loss: 0.6020 - val_acc: 0.7541\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6124 - acc: 0.7268 - val_loss: 0.5981 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6092 - acc: 0.7268 - val_loss: 0.5941 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6059 - acc: 0.7320 - val_loss: 0.5903 - val_acc: 0.7705\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6027 - acc: 0.7371 - val_loss: 0.5865 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5996 - acc: 0.7423 - val_loss: 0.5827 - val_acc: 0.7869\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5965 - acc: 0.7526 - val_loss: 0.5790 - val_acc: 0.7869\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b83b0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7187 - acc: 0.5773 - val_loss: 0.6804 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7146 - acc: 0.5876 - val_loss: 0.6757 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7105 - acc: 0.5928 - val_loss: 0.6710 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7064 - acc: 0.6134 - val_loss: 0.6664 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7024 - acc: 0.6186 - val_loss: 0.6618 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6984 - acc: 0.6392 - val_loss: 0.6573 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6945 - acc: 0.6443 - val_loss: 0.6528 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6905 - acc: 0.6443 - val_loss: 0.6483 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6866 - acc: 0.6546 - val_loss: 0.6439 - val_acc: 0.7049\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6828 - acc: 0.6546 - val_loss: 0.6396 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6789 - acc: 0.6701 - val_loss: 0.6353 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6752 - acc: 0.6701 - val_loss: 0.6310 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6714 - acc: 0.6856 - val_loss: 0.6268 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6677 - acc: 0.6959 - val_loss: 0.6227 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6640 - acc: 0.6959 - val_loss: 0.6186 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6604 - acc: 0.6959 - val_loss: 0.6145 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6567 - acc: 0.7010 - val_loss: 0.6105 - val_acc: 0.7213\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6532 - acc: 0.7010 - val_loss: 0.6066 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6496 - acc: 0.7113 - val_loss: 0.6027 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6461 - acc: 0.7165 - val_loss: 0.5988 - val_acc: 0.7049\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa394698f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7184 - acc: 0.5026 - val_loss: 0.6953 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7128 - acc: 0.5078 - val_loss: 0.6897 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7073 - acc: 0.5130 - val_loss: 0.6841 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7019 - acc: 0.5285 - val_loss: 0.6787 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6966 - acc: 0.5337 - val_loss: 0.6732 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6913 - acc: 0.5389 - val_loss: 0.6679 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6860 - acc: 0.5440 - val_loss: 0.6626 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6809 - acc: 0.5492 - val_loss: 0.6574 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6757 - acc: 0.5544 - val_loss: 0.6522 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6707 - acc: 0.5596 - val_loss: 0.6471 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6657 - acc: 0.5751 - val_loss: 0.6421 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6608 - acc: 0.5855 - val_loss: 0.6371 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6559 - acc: 0.5959 - val_loss: 0.6323 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6511 - acc: 0.6062 - val_loss: 0.6274 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6463 - acc: 0.6010 - val_loss: 0.6227 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6417 - acc: 0.6166 - val_loss: 0.6180 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6370 - acc: 0.6218 - val_loss: 0.6133 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6325 - acc: 0.6321 - val_loss: 0.6088 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6280 - acc: 0.6528 - val_loss: 0.6043 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6235 - acc: 0.6736 - val_loss: 0.5999 - val_acc: 0.7213\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa394735e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7169 - acc: 0.5181 - val_loss: 0.7168 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7111 - acc: 0.5337 - val_loss: 0.7102 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7055 - acc: 0.5440 - val_loss: 0.7037 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6999 - acc: 0.5544 - val_loss: 0.6973 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6944 - acc: 0.5596 - val_loss: 0.6910 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6889 - acc: 0.5803 - val_loss: 0.6848 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6835 - acc: 0.5907 - val_loss: 0.6786 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6782 - acc: 0.6010 - val_loss: 0.6725 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6729 - acc: 0.6062 - val_loss: 0.6665 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6677 - acc: 0.6218 - val_loss: 0.6606 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6625 - acc: 0.6218 - val_loss: 0.6548 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6575 - acc: 0.6166 - val_loss: 0.6490 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6525 - acc: 0.6218 - val_loss: 0.6434 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6475 - acc: 0.6373 - val_loss: 0.6378 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6427 - acc: 0.6477 - val_loss: 0.6323 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6378 - acc: 0.6528 - val_loss: 0.6269 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6331 - acc: 0.6580 - val_loss: 0.6216 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6284 - acc: 0.6736 - val_loss: 0.6164 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6238 - acc: 0.6943 - val_loss: 0.6112 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6193 - acc: 0.6943 - val_loss: 0.6062 - val_acc: 0.7213\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3945ca550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6719 - acc: 0.5722 - val_loss: 0.6606 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6663 - acc: 0.5825 - val_loss: 0.6545 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6608 - acc: 0.5979 - val_loss: 0.6485 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6554 - acc: 0.6186 - val_loss: 0.6426 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6500 - acc: 0.6443 - val_loss: 0.6368 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6447 - acc: 0.6701 - val_loss: 0.6310 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6394 - acc: 0.6753 - val_loss: 0.6253 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6343 - acc: 0.6907 - val_loss: 0.6197 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6292 - acc: 0.6907 - val_loss: 0.6142 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6241 - acc: 0.7113 - val_loss: 0.6087 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6191 - acc: 0.7423 - val_loss: 0.6034 - val_acc: 0.8197\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6142 - acc: 0.7474 - val_loss: 0.5981 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6094 - acc: 0.7680 - val_loss: 0.5929 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6046 - acc: 0.7835 - val_loss: 0.5877 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5999 - acc: 0.7887 - val_loss: 0.5827 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5953 - acc: 0.7990 - val_loss: 0.5777 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5907 - acc: 0.8196 - val_loss: 0.5728 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5862 - acc: 0.8247 - val_loss: 0.5680 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5818 - acc: 0.8299 - val_loss: 0.5633 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5774 - acc: 0.8299 - val_loss: 0.5586 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b821e940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7080 - acc: 0.5000 - val_loss: 0.6992 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7023 - acc: 0.5052 - val_loss: 0.6929 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6966 - acc: 0.5258 - val_loss: 0.6866 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6909 - acc: 0.5309 - val_loss: 0.6804 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6854 - acc: 0.5567 - val_loss: 0.6743 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6799 - acc: 0.5670 - val_loss: 0.6682 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6744 - acc: 0.5928 - val_loss: 0.6622 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6691 - acc: 0.6186 - val_loss: 0.6564 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6638 - acc: 0.6340 - val_loss: 0.6506 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6586 - acc: 0.6546 - val_loss: 0.6448 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6534 - acc: 0.6649 - val_loss: 0.6392 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6483 - acc: 0.6753 - val_loss: 0.6337 - val_acc: 0.6393\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6433 - acc: 0.6804 - val_loss: 0.6282 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6384 - acc: 0.6959 - val_loss: 0.6228 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6335 - acc: 0.7010 - val_loss: 0.6175 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6287 - acc: 0.7010 - val_loss: 0.6123 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6240 - acc: 0.7165 - val_loss: 0.6071 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6193 - acc: 0.7165 - val_loss: 0.6021 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6147 - acc: 0.7268 - val_loss: 0.5971 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6102 - acc: 0.7371 - val_loss: 0.5922 - val_acc: 0.7377\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa354786310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7840 - acc: 0.3247 - val_loss: 0.7986 - val_acc: 0.3443\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7777 - acc: 0.3505 - val_loss: 0.7913 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7715 - acc: 0.3608 - val_loss: 0.7841 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7653 - acc: 0.3660 - val_loss: 0.7771 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7591 - acc: 0.3918 - val_loss: 0.7701 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7531 - acc: 0.4124 - val_loss: 0.7631 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7471 - acc: 0.4278 - val_loss: 0.7563 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7412 - acc: 0.4278 - val_loss: 0.7495 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7353 - acc: 0.4433 - val_loss: 0.7429 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7295 - acc: 0.4536 - val_loss: 0.7363 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7238 - acc: 0.4639 - val_loss: 0.7298 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7181 - acc: 0.4794 - val_loss: 0.7233 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7125 - acc: 0.4897 - val_loss: 0.7170 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7070 - acc: 0.5052 - val_loss: 0.7107 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7016 - acc: 0.5103 - val_loss: 0.7046 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6962 - acc: 0.5206 - val_loss: 0.6985 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6909 - acc: 0.5515 - val_loss: 0.6925 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6856 - acc: 0.5722 - val_loss: 0.6866 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6805 - acc: 0.5825 - val_loss: 0.6808 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6754 - acc: 0.5979 - val_loss: 0.6751 - val_acc: 0.6066\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3546d68b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5504 - acc: 0.7461 - val_loss: 0.4960 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5466 - acc: 0.7565 - val_loss: 0.4927 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5429 - acc: 0.7565 - val_loss: 0.4894 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5392 - acc: 0.7617 - val_loss: 0.4862 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5356 - acc: 0.7668 - val_loss: 0.4829 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5320 - acc: 0.7668 - val_loss: 0.4796 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5285 - acc: 0.7720 - val_loss: 0.4764 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5250 - acc: 0.7720 - val_loss: 0.4732 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5215 - acc: 0.7720 - val_loss: 0.4701 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5181 - acc: 0.7720 - val_loss: 0.4669 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5147 - acc: 0.7720 - val_loss: 0.4639 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5114 - acc: 0.7824 - val_loss: 0.4609 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5081 - acc: 0.7824 - val_loss: 0.4580 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5048 - acc: 0.7927 - val_loss: 0.4551 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5016 - acc: 0.7927 - val_loss: 0.4523 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4984 - acc: 0.7876 - val_loss: 0.4496 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4953 - acc: 0.7927 - val_loss: 0.4469 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4922 - acc: 0.7979 - val_loss: 0.4442 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4892 - acc: 0.7979 - val_loss: 0.4416 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4862 - acc: 0.7979 - val_loss: 0.4391 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3545d13a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6110 - acc: 0.7047 - val_loss: 0.5749 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6065 - acc: 0.7150 - val_loss: 0.5695 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6020 - acc: 0.7150 - val_loss: 0.5643 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5976 - acc: 0.7306 - val_loss: 0.5592 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5933 - acc: 0.7358 - val_loss: 0.5542 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5891 - acc: 0.7358 - val_loss: 0.5493 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5849 - acc: 0.7565 - val_loss: 0.5445 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5808 - acc: 0.7565 - val_loss: 0.5399 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5768 - acc: 0.7617 - val_loss: 0.5353 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5729 - acc: 0.7565 - val_loss: 0.5308 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5691 - acc: 0.7513 - val_loss: 0.5265 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5653 - acc: 0.7513 - val_loss: 0.5223 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5617 - acc: 0.7513 - val_loss: 0.5181 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5580 - acc: 0.7513 - val_loss: 0.5140 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5545 - acc: 0.7565 - val_loss: 0.5099 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5509 - acc: 0.7668 - val_loss: 0.5059 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5475 - acc: 0.7720 - val_loss: 0.5020 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5441 - acc: 0.7772 - val_loss: 0.4982 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5407 - acc: 0.7772 - val_loss: 0.4945 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5374 - acc: 0.7772 - val_loss: 0.4909 - val_acc: 0.8033\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b44284c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5810 - acc: 0.7165 - val_loss: 0.5467 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5770 - acc: 0.7062 - val_loss: 0.5434 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5731 - acc: 0.7113 - val_loss: 0.5402 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5692 - acc: 0.7165 - val_loss: 0.5371 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5655 - acc: 0.7216 - val_loss: 0.5340 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5617 - acc: 0.7268 - val_loss: 0.5310 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5580 - acc: 0.7320 - val_loss: 0.5280 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5543 - acc: 0.7320 - val_loss: 0.5250 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5506 - acc: 0.7320 - val_loss: 0.5221 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5470 - acc: 0.7371 - val_loss: 0.5194 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5434 - acc: 0.7371 - val_loss: 0.5167 - val_acc: 0.7377\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5399 - acc: 0.7371 - val_loss: 0.5141 - val_acc: 0.7377\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5364 - acc: 0.7474 - val_loss: 0.5114 - val_acc: 0.7377\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5331 - acc: 0.7474 - val_loss: 0.5088 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5297 - acc: 0.7526 - val_loss: 0.5063 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5264 - acc: 0.7526 - val_loss: 0.5038 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5232 - acc: 0.7526 - val_loss: 0.5014 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5200 - acc: 0.7577 - val_loss: 0.4990 - val_acc: 0.7541\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5169 - acc: 0.7577 - val_loss: 0.4967 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5138 - acc: 0.7577 - val_loss: 0.4945 - val_acc: 0.7541\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa354786940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8295 - acc: 0.4588 - val_loss: 0.9738 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8227 - acc: 0.4691 - val_loss: 0.9665 - val_acc: 0.3115\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8160 - acc: 0.4794 - val_loss: 0.9593 - val_acc: 0.3115\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8094 - acc: 0.4794 - val_loss: 0.9522 - val_acc: 0.3115\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8030 - acc: 0.4794 - val_loss: 0.9452 - val_acc: 0.3115\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7966 - acc: 0.4794 - val_loss: 0.9382 - val_acc: 0.3443\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7903 - acc: 0.4897 - val_loss: 0.9314 - val_acc: 0.3607\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7841 - acc: 0.5052 - val_loss: 0.9245 - val_acc: 0.3607\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7780 - acc: 0.5103 - val_loss: 0.9178 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7720 - acc: 0.5103 - val_loss: 0.9112 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7661 - acc: 0.5103 - val_loss: 0.9047 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7603 - acc: 0.5155 - val_loss: 0.8983 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7545 - acc: 0.5206 - val_loss: 0.8920 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7488 - acc: 0.5309 - val_loss: 0.8858 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7432 - acc: 0.5309 - val_loss: 0.8797 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7378 - acc: 0.5361 - val_loss: 0.8737 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7324 - acc: 0.5515 - val_loss: 0.8678 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7272 - acc: 0.5567 - val_loss: 0.8620 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7220 - acc: 0.5567 - val_loss: 0.8563 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7169 - acc: 0.5670 - val_loss: 0.8508 - val_acc: 0.4754\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3945ca310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7570 - acc: 0.5619 - val_loss: 0.7487 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7512 - acc: 0.5670 - val_loss: 0.7417 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7454 - acc: 0.5773 - val_loss: 0.7348 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7397 - acc: 0.5825 - val_loss: 0.7280 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7341 - acc: 0.5773 - val_loss: 0.7212 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7285 - acc: 0.5773 - val_loss: 0.7146 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7230 - acc: 0.5773 - val_loss: 0.7081 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7176 - acc: 0.5928 - val_loss: 0.7017 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7122 - acc: 0.5928 - val_loss: 0.6954 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7069 - acc: 0.5979 - val_loss: 0.6892 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7017 - acc: 0.5979 - val_loss: 0.6831 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6965 - acc: 0.6082 - val_loss: 0.6771 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6914 - acc: 0.6186 - val_loss: 0.6711 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6864 - acc: 0.6186 - val_loss: 0.6652 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6815 - acc: 0.6186 - val_loss: 0.6594 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6765 - acc: 0.6186 - val_loss: 0.6537 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6717 - acc: 0.6134 - val_loss: 0.6480 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6669 - acc: 0.6186 - val_loss: 0.6426 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6622 - acc: 0.6289 - val_loss: 0.6372 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6576 - acc: 0.6392 - val_loss: 0.6318 - val_acc: 0.6066\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3945cadc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6991 - acc: 0.5751 - val_loss: 0.7480 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6903 - acc: 0.5855 - val_loss: 0.7362 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6816 - acc: 0.5959 - val_loss: 0.7248 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6732 - acc: 0.5959 - val_loss: 0.7138 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6649 - acc: 0.6010 - val_loss: 0.7030 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6568 - acc: 0.6114 - val_loss: 0.6923 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6489 - acc: 0.6373 - val_loss: 0.6819 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6411 - acc: 0.6373 - val_loss: 0.6718 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6336 - acc: 0.6425 - val_loss: 0.6620 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6263 - acc: 0.6477 - val_loss: 0.6525 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6191 - acc: 0.6580 - val_loss: 0.6433 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6121 - acc: 0.6684 - val_loss: 0.6345 - val_acc: 0.6393\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6053 - acc: 0.6788 - val_loss: 0.6259 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5987 - acc: 0.6788 - val_loss: 0.6177 - val_acc: 0.6393\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5923 - acc: 0.6891 - val_loss: 0.6097 - val_acc: 0.6393\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5860 - acc: 0.6943 - val_loss: 0.6020 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5799 - acc: 0.6943 - val_loss: 0.5946 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5739 - acc: 0.7047 - val_loss: 0.5874 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5681 - acc: 0.7047 - val_loss: 0.5805 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5625 - acc: 0.7098 - val_loss: 0.5737 - val_acc: 0.7049\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc2f2d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7075 - acc: 0.5337 - val_loss: 0.6769 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6993 - acc: 0.5492 - val_loss: 0.6683 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6914 - acc: 0.5596 - val_loss: 0.6600 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6836 - acc: 0.5699 - val_loss: 0.6517 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6760 - acc: 0.5699 - val_loss: 0.6437 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6686 - acc: 0.5751 - val_loss: 0.6359 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6613 - acc: 0.5803 - val_loss: 0.6283 - val_acc: 0.6393\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6542 - acc: 0.5907 - val_loss: 0.6209 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6472 - acc: 0.6010 - val_loss: 0.6137 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6404 - acc: 0.6010 - val_loss: 0.6066 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6338 - acc: 0.6166 - val_loss: 0.5998 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6273 - acc: 0.6166 - val_loss: 0.5931 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6210 - acc: 0.6425 - val_loss: 0.5865 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6149 - acc: 0.6477 - val_loss: 0.5801 - val_acc: 0.6885\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6090 - acc: 0.6580 - val_loss: 0.5739 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6032 - acc: 0.6580 - val_loss: 0.5678 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5976 - acc: 0.6632 - val_loss: 0.5618 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5921 - acc: 0.6788 - val_loss: 0.5561 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5868 - acc: 0.6839 - val_loss: 0.5505 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5816 - acc: 0.6839 - val_loss: 0.5451 - val_acc: 0.7049\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa47425b700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7424 - acc: 0.6082 - val_loss: 0.8294 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7354 - acc: 0.6082 - val_loss: 0.8202 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7284 - acc: 0.6031 - val_loss: 0.8112 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7215 - acc: 0.6082 - val_loss: 0.8024 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7148 - acc: 0.6082 - val_loss: 0.7937 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7081 - acc: 0.6289 - val_loss: 0.7852 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7015 - acc: 0.6289 - val_loss: 0.7769 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6951 - acc: 0.6289 - val_loss: 0.7687 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6887 - acc: 0.6392 - val_loss: 0.7605 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6825 - acc: 0.6392 - val_loss: 0.7525 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6763 - acc: 0.6443 - val_loss: 0.7446 - val_acc: 0.5574\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6702 - acc: 0.6443 - val_loss: 0.7369 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6642 - acc: 0.6443 - val_loss: 0.7292 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6584 - acc: 0.6443 - val_loss: 0.7216 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6525 - acc: 0.6392 - val_loss: 0.7142 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6468 - acc: 0.6392 - val_loss: 0.7068 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6412 - acc: 0.6495 - val_loss: 0.6997 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6357 - acc: 0.6546 - val_loss: 0.6926 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6303 - acc: 0.6649 - val_loss: 0.6856 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6250 - acc: 0.6649 - val_loss: 0.6787 - val_acc: 0.6230\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e28c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8079 - acc: 0.4278 - val_loss: 0.7910 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7986 - acc: 0.4381 - val_loss: 0.7812 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7895 - acc: 0.4691 - val_loss: 0.7718 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7805 - acc: 0.4691 - val_loss: 0.7627 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7717 - acc: 0.4742 - val_loss: 0.7538 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7631 - acc: 0.4845 - val_loss: 0.7452 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7547 - acc: 0.4897 - val_loss: 0.7369 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7466 - acc: 0.5052 - val_loss: 0.7288 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7386 - acc: 0.5052 - val_loss: 0.7209 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7308 - acc: 0.5103 - val_loss: 0.7133 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7233 - acc: 0.5155 - val_loss: 0.7059 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7159 - acc: 0.5155 - val_loss: 0.6986 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7087 - acc: 0.5258 - val_loss: 0.6915 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7016 - acc: 0.5309 - val_loss: 0.6846 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6946 - acc: 0.5309 - val_loss: 0.6778 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6878 - acc: 0.5361 - val_loss: 0.6711 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6811 - acc: 0.5412 - val_loss: 0.6645 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6746 - acc: 0.5412 - val_loss: 0.6581 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6683 - acc: 0.5515 - val_loss: 0.6518 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6621 - acc: 0.5619 - val_loss: 0.6458 - val_acc: 0.5902\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa474704280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7777 - acc: 0.5052 - val_loss: 0.7760 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7681 - acc: 0.5155 - val_loss: 0.7655 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7587 - acc: 0.5206 - val_loss: 0.7552 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7495 - acc: 0.5309 - val_loss: 0.7451 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7405 - acc: 0.5309 - val_loss: 0.7352 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7316 - acc: 0.5309 - val_loss: 0.7255 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7229 - acc: 0.5464 - val_loss: 0.7160 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7144 - acc: 0.5670 - val_loss: 0.7066 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7061 - acc: 0.5722 - val_loss: 0.6975 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6980 - acc: 0.5773 - val_loss: 0.6885 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6900 - acc: 0.5825 - val_loss: 0.6797 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6822 - acc: 0.5825 - val_loss: 0.6710 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6746 - acc: 0.5876 - val_loss: 0.6625 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6671 - acc: 0.5979 - val_loss: 0.6542 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6598 - acc: 0.6134 - val_loss: 0.6461 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6526 - acc: 0.6237 - val_loss: 0.6382 - val_acc: 0.6557\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6456 - acc: 0.6392 - val_loss: 0.6305 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6387 - acc: 0.6495 - val_loss: 0.6228 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6320 - acc: 0.6546 - val_loss: 0.6154 - val_acc: 0.6557\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6254 - acc: 0.6598 - val_loss: 0.6082 - val_acc: 0.6885\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0ea4ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6774 - acc: 0.6114 - val_loss: 0.6669 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6621 - acc: 0.6373 - val_loss: 0.6471 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6473 - acc: 0.6580 - val_loss: 0.6280 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6331 - acc: 0.6684 - val_loss: 0.6098 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6194 - acc: 0.6788 - val_loss: 0.5924 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6062 - acc: 0.6891 - val_loss: 0.5758 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5936 - acc: 0.7047 - val_loss: 0.5601 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5815 - acc: 0.7202 - val_loss: 0.5453 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5700 - acc: 0.7202 - val_loss: 0.5312 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5589 - acc: 0.7202 - val_loss: 0.5179 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5484 - acc: 0.7202 - val_loss: 0.5054 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5383 - acc: 0.7306 - val_loss: 0.4935 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5288 - acc: 0.7513 - val_loss: 0.4824 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5196 - acc: 0.7565 - val_loss: 0.4719 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5109 - acc: 0.7668 - val_loss: 0.4622 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5027 - acc: 0.7668 - val_loss: 0.4531 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4949 - acc: 0.7720 - val_loss: 0.4446 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4874 - acc: 0.7824 - val_loss: 0.4367 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4804 - acc: 0.7876 - val_loss: 0.4293 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4736 - acc: 0.7876 - val_loss: 0.4224 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beca4790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7193 - acc: 0.5544 - val_loss: 0.8285 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7067 - acc: 0.5648 - val_loss: 0.8130 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6945 - acc: 0.5699 - val_loss: 0.7979 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6827 - acc: 0.5699 - val_loss: 0.7831 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6711 - acc: 0.5648 - val_loss: 0.7685 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6599 - acc: 0.5855 - val_loss: 0.7544 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6490 - acc: 0.6166 - val_loss: 0.7407 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6384 - acc: 0.6218 - val_loss: 0.7273 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6281 - acc: 0.6425 - val_loss: 0.7144 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6182 - acc: 0.6580 - val_loss: 0.7019 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6085 - acc: 0.6528 - val_loss: 0.6898 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5992 - acc: 0.6891 - val_loss: 0.6781 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5902 - acc: 0.6943 - val_loss: 0.6668 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5815 - acc: 0.7047 - val_loss: 0.6559 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5730 - acc: 0.7254 - val_loss: 0.6453 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5649 - acc: 0.7461 - val_loss: 0.6350 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5570 - acc: 0.7668 - val_loss: 0.6251 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5494 - acc: 0.7720 - val_loss: 0.6155 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5420 - acc: 0.7772 - val_loss: 0.6062 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5349 - acc: 0.7824 - val_loss: 0.5972 - val_acc: 0.7377\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3545d1160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7933 - acc: 0.4433 - val_loss: 0.8585 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7775 - acc: 0.4691 - val_loss: 0.8398 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7620 - acc: 0.4742 - val_loss: 0.8216 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7469 - acc: 0.4845 - val_loss: 0.8040 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7322 - acc: 0.5000 - val_loss: 0.7871 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7180 - acc: 0.5206 - val_loss: 0.7707 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7042 - acc: 0.5464 - val_loss: 0.7549 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6909 - acc: 0.5670 - val_loss: 0.7397 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6779 - acc: 0.5722 - val_loss: 0.7250 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6653 - acc: 0.5876 - val_loss: 0.7107 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6532 - acc: 0.5979 - val_loss: 0.6969 - val_acc: 0.5738\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6414 - acc: 0.6082 - val_loss: 0.6836 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6299 - acc: 0.6340 - val_loss: 0.6707 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6189 - acc: 0.6495 - val_loss: 0.6582 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6082 - acc: 0.6495 - val_loss: 0.6461 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5978 - acc: 0.6546 - val_loss: 0.6345 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5878 - acc: 0.6856 - val_loss: 0.6233 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5781 - acc: 0.7010 - val_loss: 0.6127 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5688 - acc: 0.7216 - val_loss: 0.6024 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5599 - acc: 0.7423 - val_loss: 0.5927 - val_acc: 0.7049\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa418297040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8760 - acc: 0.4278 - val_loss: 1.1008 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8597 - acc: 0.4433 - val_loss: 1.0768 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8436 - acc: 0.4433 - val_loss: 1.0532 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8279 - acc: 0.4536 - val_loss: 1.0300 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8126 - acc: 0.4639 - val_loss: 1.0073 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7976 - acc: 0.4691 - val_loss: 0.9852 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7829 - acc: 0.4742 - val_loss: 0.9637 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7686 - acc: 0.4845 - val_loss: 0.9430 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7546 - acc: 0.5052 - val_loss: 0.9226 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7409 - acc: 0.5309 - val_loss: 0.9026 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7276 - acc: 0.5515 - val_loss: 0.8831 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7146 - acc: 0.5670 - val_loss: 0.8640 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7020 - acc: 0.5722 - val_loss: 0.8454 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6897 - acc: 0.5773 - val_loss: 0.8272 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6778 - acc: 0.5928 - val_loss: 0.8096 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6662 - acc: 0.6082 - val_loss: 0.7924 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6550 - acc: 0.6289 - val_loss: 0.7758 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6440 - acc: 0.6237 - val_loss: 0.7596 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6334 - acc: 0.6289 - val_loss: 0.7439 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6232 - acc: 0.6392 - val_loss: 0.7286 - val_acc: 0.5574\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa420354280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8563 - acc: 0.3866 - val_loss: 0.8853 - val_acc: 0.3279\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8405 - acc: 0.3969 - val_loss: 0.8670 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8251 - acc: 0.4124 - val_loss: 0.8491 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8100 - acc: 0.4175 - val_loss: 0.8315 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7953 - acc: 0.4330 - val_loss: 0.8144 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7810 - acc: 0.4381 - val_loss: 0.7979 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7670 - acc: 0.4433 - val_loss: 0.7818 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7534 - acc: 0.4691 - val_loss: 0.7662 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7401 - acc: 0.4897 - val_loss: 0.7511 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7272 - acc: 0.5103 - val_loss: 0.7364 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7147 - acc: 0.5412 - val_loss: 0.7222 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7025 - acc: 0.5567 - val_loss: 0.7084 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6907 - acc: 0.5825 - val_loss: 0.6951 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6792 - acc: 0.5928 - val_loss: 0.6822 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6681 - acc: 0.6186 - val_loss: 0.6697 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6574 - acc: 0.6340 - val_loss: 0.6575 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6470 - acc: 0.6392 - val_loss: 0.6457 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6369 - acc: 0.6495 - val_loss: 0.6343 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6272 - acc: 0.6649 - val_loss: 0.6234 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6178 - acc: 0.6907 - val_loss: 0.6129 - val_acc: 0.7377\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b8295820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8151 - acc: 0.4508 - val_loss: 0.8297 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7926 - acc: 0.4663 - val_loss: 0.8043 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7707 - acc: 0.4922 - val_loss: 0.7796 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7495 - acc: 0.5181 - val_loss: 0.7558 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7290 - acc: 0.5285 - val_loss: 0.7328 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7092 - acc: 0.5596 - val_loss: 0.7107 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6902 - acc: 0.6166 - val_loss: 0.6896 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6720 - acc: 0.6528 - val_loss: 0.6693 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6544 - acc: 0.6425 - val_loss: 0.6498 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6376 - acc: 0.6528 - val_loss: 0.6313 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6214 - acc: 0.6736 - val_loss: 0.6139 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6058 - acc: 0.6839 - val_loss: 0.5972 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5909 - acc: 0.6891 - val_loss: 0.5815 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5766 - acc: 0.6995 - val_loss: 0.5666 - val_acc: 0.6885\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5629 - acc: 0.7098 - val_loss: 0.5525 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5499 - acc: 0.7098 - val_loss: 0.5393 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5375 - acc: 0.7306 - val_loss: 0.5269 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5257 - acc: 0.7513 - val_loss: 0.5151 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5145 - acc: 0.7668 - val_loss: 0.5040 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5038 - acc: 0.7876 - val_loss: 0.4937 - val_acc: 0.7541\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41031ab80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7246 - acc: 0.5751 - val_loss: 0.7320 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7042 - acc: 0.5855 - val_loss: 0.7058 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6845 - acc: 0.5959 - val_loss: 0.6808 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6656 - acc: 0.6114 - val_loss: 0.6569 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6475 - acc: 0.6373 - val_loss: 0.6342 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6303 - acc: 0.6580 - val_loss: 0.6125 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6138 - acc: 0.6788 - val_loss: 0.5920 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5981 - acc: 0.6839 - val_loss: 0.5727 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5831 - acc: 0.6995 - val_loss: 0.5545 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5689 - acc: 0.6995 - val_loss: 0.5375 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5554 - acc: 0.7358 - val_loss: 0.5216 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5427 - acc: 0.7306 - val_loss: 0.5066 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5306 - acc: 0.7358 - val_loss: 0.4926 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5192 - acc: 0.7565 - val_loss: 0.4794 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5085 - acc: 0.7617 - val_loss: 0.4671 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4983 - acc: 0.7720 - val_loss: 0.4556 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4888 - acc: 0.7876 - val_loss: 0.4449 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4798 - acc: 0.7927 - val_loss: 0.4348 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4714 - acc: 0.7979 - val_loss: 0.4255 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4635 - acc: 0.8083 - val_loss: 0.4169 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b846ce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7716 - acc: 0.4691 - val_loss: 0.7464 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7484 - acc: 0.5103 - val_loss: 0.7249 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7261 - acc: 0.5206 - val_loss: 0.7044 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7046 - acc: 0.5412 - val_loss: 0.6848 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6840 - acc: 0.5670 - val_loss: 0.6660 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6642 - acc: 0.5876 - val_loss: 0.6481 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6452 - acc: 0.5979 - val_loss: 0.6309 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6271 - acc: 0.6392 - val_loss: 0.6146 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6098 - acc: 0.6959 - val_loss: 0.5990 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5933 - acc: 0.7113 - val_loss: 0.5843 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5777 - acc: 0.7371 - val_loss: 0.5704 - val_acc: 0.6557\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5630 - acc: 0.7680 - val_loss: 0.5573 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5490 - acc: 0.7732 - val_loss: 0.5449 - val_acc: 0.7377\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5357 - acc: 0.7835 - val_loss: 0.5331 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5231 - acc: 0.7887 - val_loss: 0.5221 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5113 - acc: 0.8041 - val_loss: 0.5116 - val_acc: 0.7705\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5000 - acc: 0.8247 - val_loss: 0.5017 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4893 - acc: 0.8247 - val_loss: 0.4924 - val_acc: 0.7869\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4793 - acc: 0.8299 - val_loss: 0.4836 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4698 - acc: 0.8351 - val_loss: 0.4753 - val_acc: 0.8197\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa39404a430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9107 - acc: 0.3763 - val_loss: 0.8760 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8855 - acc: 0.3918 - val_loss: 0.8515 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8611 - acc: 0.4072 - val_loss: 0.8276 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8373 - acc: 0.4433 - val_loss: 0.8044 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8144 - acc: 0.4742 - val_loss: 0.7821 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7923 - acc: 0.4897 - val_loss: 0.7604 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7710 - acc: 0.5103 - val_loss: 0.7394 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7506 - acc: 0.5412 - val_loss: 0.7193 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7309 - acc: 0.5567 - val_loss: 0.6999 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7120 - acc: 0.5928 - val_loss: 0.6812 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6939 - acc: 0.6134 - val_loss: 0.6631 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6764 - acc: 0.6289 - val_loss: 0.6456 - val_acc: 0.6393\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6598 - acc: 0.6392 - val_loss: 0.6289 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6438 - acc: 0.6443 - val_loss: 0.6130 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6286 - acc: 0.6598 - val_loss: 0.5978 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6141 - acc: 0.6701 - val_loss: 0.5833 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6002 - acc: 0.6701 - val_loss: 0.5696 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5870 - acc: 0.6856 - val_loss: 0.5566 - val_acc: 0.7541\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5745 - acc: 0.7010 - val_loss: 0.5441 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5626 - acc: 0.7113 - val_loss: 0.5323 - val_acc: 0.7541\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa39447dc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7251 - acc: 0.5722 - val_loss: 0.6788 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7052 - acc: 0.5979 - val_loss: 0.6585 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6861 - acc: 0.6134 - val_loss: 0.6393 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6678 - acc: 0.6289 - val_loss: 0.6212 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6503 - acc: 0.6392 - val_loss: 0.6041 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6334 - acc: 0.6649 - val_loss: 0.5880 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6174 - acc: 0.6701 - val_loss: 0.5729 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6021 - acc: 0.7062 - val_loss: 0.5586 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5876 - acc: 0.7268 - val_loss: 0.5453 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5738 - acc: 0.7371 - val_loss: 0.5328 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5608 - acc: 0.7526 - val_loss: 0.5213 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5485 - acc: 0.7629 - val_loss: 0.5107 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5367 - acc: 0.7784 - val_loss: 0.5007 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5256 - acc: 0.7938 - val_loss: 0.4914 - val_acc: 0.7705\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5151 - acc: 0.8041 - val_loss: 0.4828 - val_acc: 0.7705\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5051 - acc: 0.7990 - val_loss: 0.4748 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4957 - acc: 0.8041 - val_loss: 0.4674 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4867 - acc: 0.8093 - val_loss: 0.4605 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4783 - acc: 0.8093 - val_loss: 0.4541 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4703 - acc: 0.8093 - val_loss: 0.4482 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa378192280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6973 - acc: 0.5078 - val_loss: 0.6690 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6706 - acc: 0.5699 - val_loss: 0.6435 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6452 - acc: 0.6114 - val_loss: 0.6193 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6211 - acc: 0.6632 - val_loss: 0.5966 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5984 - acc: 0.7098 - val_loss: 0.5753 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5769 - acc: 0.7254 - val_loss: 0.5553 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5568 - acc: 0.7513 - val_loss: 0.5367 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5380 - acc: 0.7617 - val_loss: 0.5192 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5203 - acc: 0.7772 - val_loss: 0.5029 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5038 - acc: 0.7927 - val_loss: 0.4877 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4884 - acc: 0.8135 - val_loss: 0.4736 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4741 - acc: 0.8238 - val_loss: 0.4605 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4607 - acc: 0.8394 - val_loss: 0.4484 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4484 - acc: 0.8549 - val_loss: 0.4372 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4369 - acc: 0.8497 - val_loss: 0.4268 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4263 - acc: 0.8549 - val_loss: 0.4173 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4164 - acc: 0.8549 - val_loss: 0.4085 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4072 - acc: 0.8549 - val_loss: 0.4003 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3988 - acc: 0.8497 - val_loss: 0.3929 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3909 - acc: 0.8549 - val_loss: 0.3861 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3547c3b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6681 - acc: 0.5648 - val_loss: 0.6730 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6418 - acc: 0.6218 - val_loss: 0.6439 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6169 - acc: 0.6788 - val_loss: 0.6167 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5936 - acc: 0.7306 - val_loss: 0.5914 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5719 - acc: 0.7876 - val_loss: 0.5680 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5516 - acc: 0.7824 - val_loss: 0.5466 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5328 - acc: 0.8083 - val_loss: 0.5269 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5153 - acc: 0.8238 - val_loss: 0.5090 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4992 - acc: 0.8342 - val_loss: 0.4926 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4844 - acc: 0.8497 - val_loss: 0.4776 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4707 - acc: 0.8446 - val_loss: 0.4640 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4581 - acc: 0.8497 - val_loss: 0.4517 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4466 - acc: 0.8497 - val_loss: 0.4406 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4360 - acc: 0.8549 - val_loss: 0.4306 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4263 - acc: 0.8549 - val_loss: 0.4216 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4175 - acc: 0.8497 - val_loss: 0.4134 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4093 - acc: 0.8497 - val_loss: 0.4061 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4018 - acc: 0.8497 - val_loss: 0.3994 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3949 - acc: 0.8549 - val_loss: 0.3934 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3886 - acc: 0.8549 - val_loss: 0.3880 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa354487d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7310 - acc: 0.4278 - val_loss: 0.6885 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7006 - acc: 0.4691 - val_loss: 0.6587 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6718 - acc: 0.5619 - val_loss: 0.6307 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6446 - acc: 0.6031 - val_loss: 0.6045 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6190 - acc: 0.6959 - val_loss: 0.5799 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5950 - acc: 0.7371 - val_loss: 0.5570 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5726 - acc: 0.7629 - val_loss: 0.5357 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5516 - acc: 0.7732 - val_loss: 0.5160 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5321 - acc: 0.8093 - val_loss: 0.4978 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5140 - acc: 0.8299 - val_loss: 0.4810 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4973 - acc: 0.8299 - val_loss: 0.4656 - val_acc: 0.8525\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4818 - acc: 0.8299 - val_loss: 0.4515 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4674 - acc: 0.8299 - val_loss: 0.4386 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4542 - acc: 0.8299 - val_loss: 0.4267 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4419 - acc: 0.8454 - val_loss: 0.4159 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4306 - acc: 0.8454 - val_loss: 0.4060 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4202 - acc: 0.8505 - val_loss: 0.3970 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4105 - acc: 0.8557 - val_loss: 0.3888 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4017 - acc: 0.8505 - val_loss: 0.3813 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3935 - acc: 0.8505 - val_loss: 0.3746 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1e3940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7846 - acc: 0.4485 - val_loss: 0.7764 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7563 - acc: 0.4742 - val_loss: 0.7479 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7293 - acc: 0.5103 - val_loss: 0.7206 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7038 - acc: 0.5206 - val_loss: 0.6948 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6796 - acc: 0.5412 - val_loss: 0.6703 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6568 - acc: 0.5876 - val_loss: 0.6470 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6351 - acc: 0.6340 - val_loss: 0.6249 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6147 - acc: 0.6856 - val_loss: 0.6041 - val_acc: 0.6393\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5955 - acc: 0.7371 - val_loss: 0.5845 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5774 - acc: 0.7526 - val_loss: 0.5662 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5603 - acc: 0.7629 - val_loss: 0.5490 - val_acc: 0.7213\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5444 - acc: 0.7732 - val_loss: 0.5327 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5294 - acc: 0.7887 - val_loss: 0.5175 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5154 - acc: 0.7835 - val_loss: 0.5032 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5024 - acc: 0.7938 - val_loss: 0.4898 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4902 - acc: 0.8196 - val_loss: 0.4773 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4788 - acc: 0.8247 - val_loss: 0.4656 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4682 - acc: 0.8247 - val_loss: 0.4547 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4583 - acc: 0.8247 - val_loss: 0.4445 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4490 - acc: 0.8196 - val_loss: 0.4349 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac494ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7282 - acc: 0.5155 - val_loss: 0.7762 - val_acc: 0.3279\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7016 - acc: 0.5515 - val_loss: 0.7449 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6763 - acc: 0.5722 - val_loss: 0.7151 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6523 - acc: 0.6031 - val_loss: 0.6869 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6296 - acc: 0.6443 - val_loss: 0.6601 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6082 - acc: 0.6753 - val_loss: 0.6349 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5880 - acc: 0.7216 - val_loss: 0.6112 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5692 - acc: 0.7474 - val_loss: 0.5890 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5516 - acc: 0.7629 - val_loss: 0.5684 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5352 - acc: 0.7784 - val_loss: 0.5491 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5200 - acc: 0.7732 - val_loss: 0.5312 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5058 - acc: 0.7784 - val_loss: 0.5146 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4926 - acc: 0.7835 - val_loss: 0.4993 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4804 - acc: 0.7938 - val_loss: 0.4852 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4692 - acc: 0.7990 - val_loss: 0.4721 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4587 - acc: 0.8144 - val_loss: 0.4601 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4490 - acc: 0.8299 - val_loss: 0.4490 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4401 - acc: 0.8247 - val_loss: 0.4388 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4318 - acc: 0.8299 - val_loss: 0.4295 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4242 - acc: 0.8351 - val_loss: 0.4210 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc313f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7000 - acc: 0.4870 - val_loss: 0.6699 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6613 - acc: 0.5855 - val_loss: 0.6327 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6259 - acc: 0.6839 - val_loss: 0.5987 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5936 - acc: 0.7202 - val_loss: 0.5679 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5643 - acc: 0.7409 - val_loss: 0.5400 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5379 - acc: 0.7720 - val_loss: 0.5149 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5142 - acc: 0.7979 - val_loss: 0.4924 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4930 - acc: 0.8031 - val_loss: 0.4725 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4742 - acc: 0.8083 - val_loss: 0.4548 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4574 - acc: 0.7979 - val_loss: 0.4391 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4426 - acc: 0.8031 - val_loss: 0.4252 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4294 - acc: 0.8083 - val_loss: 0.4130 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4177 - acc: 0.8135 - val_loss: 0.4022 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4073 - acc: 0.8135 - val_loss: 0.3927 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3979 - acc: 0.8238 - val_loss: 0.3844 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3896 - acc: 0.8290 - val_loss: 0.3772 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3820 - acc: 0.8342 - val_loss: 0.3708 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3751 - acc: 0.8446 - val_loss: 0.3653 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3689 - acc: 0.8446 - val_loss: 0.3604 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3631 - acc: 0.8446 - val_loss: 0.3561 - val_acc: 0.8197\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3547c3c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7360 - acc: 0.4456 - val_loss: 0.6845 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6966 - acc: 0.5389 - val_loss: 0.6458 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6600 - acc: 0.6166 - val_loss: 0.6101 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6262 - acc: 0.7150 - val_loss: 0.5775 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5953 - acc: 0.7513 - val_loss: 0.5478 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5671 - acc: 0.7824 - val_loss: 0.5209 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5415 - acc: 0.8083 - val_loss: 0.4966 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5184 - acc: 0.8135 - val_loss: 0.4746 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4977 - acc: 0.8290 - val_loss: 0.4549 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4790 - acc: 0.8290 - val_loss: 0.4373 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4624 - acc: 0.8238 - val_loss: 0.4217 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4475 - acc: 0.8342 - val_loss: 0.4079 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4342 - acc: 0.8290 - val_loss: 0.3956 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4224 - acc: 0.8290 - val_loss: 0.3849 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4118 - acc: 0.8342 - val_loss: 0.3754 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4024 - acc: 0.8394 - val_loss: 0.3672 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3939 - acc: 0.8342 - val_loss: 0.3600 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3863 - acc: 0.8394 - val_loss: 0.3538 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3795 - acc: 0.8394 - val_loss: 0.3484 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3734 - acc: 0.8497 - val_loss: 0.3437 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa39447d310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6660 - acc: 0.5876 - val_loss: 0.6421 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6286 - acc: 0.6959 - val_loss: 0.6055 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5941 - acc: 0.7577 - val_loss: 0.5721 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5627 - acc: 0.7835 - val_loss: 0.5419 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5343 - acc: 0.7784 - val_loss: 0.5146 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5085 - acc: 0.8041 - val_loss: 0.4903 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4854 - acc: 0.8247 - val_loss: 0.4686 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4648 - acc: 0.8247 - val_loss: 0.4494 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4463 - acc: 0.8299 - val_loss: 0.4323 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4298 - acc: 0.8402 - val_loss: 0.4172 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4152 - acc: 0.8402 - val_loss: 0.4039 - val_acc: 0.8689\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4022 - acc: 0.8454 - val_loss: 0.3923 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3907 - acc: 0.8454 - val_loss: 0.3822 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3805 - acc: 0.8557 - val_loss: 0.3733 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3715 - acc: 0.8660 - val_loss: 0.3656 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3635 - acc: 0.8711 - val_loss: 0.3588 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3563 - acc: 0.8711 - val_loss: 0.3530 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3499 - acc: 0.8814 - val_loss: 0.3479 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3441 - acc: 0.8814 - val_loss: 0.3434 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3388 - acc: 0.8866 - val_loss: 0.3396 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beca41f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7047 - acc: 0.5000 - val_loss: 0.6828 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6662 - acc: 0.6031 - val_loss: 0.6443 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6308 - acc: 0.6856 - val_loss: 0.6091 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5984 - acc: 0.7268 - val_loss: 0.5772 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5690 - acc: 0.7474 - val_loss: 0.5482 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5425 - acc: 0.7629 - val_loss: 0.5221 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5186 - acc: 0.7835 - val_loss: 0.4987 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4971 - acc: 0.8041 - val_loss: 0.4776 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4778 - acc: 0.8299 - val_loss: 0.4589 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4605 - acc: 0.8351 - val_loss: 0.4421 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4451 - acc: 0.8351 - val_loss: 0.4272 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4313 - acc: 0.8299 - val_loss: 0.4139 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4190 - acc: 0.8196 - val_loss: 0.4021 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4080 - acc: 0.8196 - val_loss: 0.3916 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3983 - acc: 0.8196 - val_loss: 0.3823 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3895 - acc: 0.8247 - val_loss: 0.3741 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3817 - acc: 0.8247 - val_loss: 0.3668 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3747 - acc: 0.8351 - val_loss: 0.3604 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3684 - acc: 0.8454 - val_loss: 0.3547 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3627 - acc: 0.8454 - val_loss: 0.3497 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa474704430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7317 - acc: 0.4381 - val_loss: 0.6811 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6920 - acc: 0.5155 - val_loss: 0.6426 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6555 - acc: 0.6082 - val_loss: 0.6078 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6221 - acc: 0.7010 - val_loss: 0.5764 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5918 - acc: 0.7320 - val_loss: 0.5483 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5643 - acc: 0.7784 - val_loss: 0.5233 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5396 - acc: 0.7887 - val_loss: 0.5009 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5174 - acc: 0.7990 - val_loss: 0.4812 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4975 - acc: 0.8041 - val_loss: 0.4638 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4798 - acc: 0.8196 - val_loss: 0.4485 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4640 - acc: 0.8247 - val_loss: 0.4351 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4498 - acc: 0.8247 - val_loss: 0.4234 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4371 - acc: 0.8247 - val_loss: 0.4131 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4258 - acc: 0.8247 - val_loss: 0.4042 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4157 - acc: 0.8247 - val_loss: 0.3964 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4067 - acc: 0.8299 - val_loss: 0.3896 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3986 - acc: 0.8351 - val_loss: 0.3836 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3912 - acc: 0.8351 - val_loss: 0.3784 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3846 - acc: 0.8402 - val_loss: 0.3739 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3786 - acc: 0.8557 - val_loss: 0.3699 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e0d790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6826 - acc: 0.5078 - val_loss: 0.6266 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6331 - acc: 0.6580 - val_loss: 0.5803 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5891 - acc: 0.7461 - val_loss: 0.5399 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5504 - acc: 0.7772 - val_loss: 0.5050 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5168 - acc: 0.7979 - val_loss: 0.4751 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4876 - acc: 0.8083 - val_loss: 0.4496 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4626 - acc: 0.8187 - val_loss: 0.4281 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4411 - acc: 0.8238 - val_loss: 0.4101 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4227 - acc: 0.8135 - val_loss: 0.3950 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4070 - acc: 0.8238 - val_loss: 0.3824 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3936 - acc: 0.8238 - val_loss: 0.3719 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3820 - acc: 0.8238 - val_loss: 0.3633 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3720 - acc: 0.8394 - val_loss: 0.3561 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3633 - acc: 0.8446 - val_loss: 0.3502 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3556 - acc: 0.8446 - val_loss: 0.3453 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3486 - acc: 0.8497 - val_loss: 0.3413 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3423 - acc: 0.8497 - val_loss: 0.3380 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3365 - acc: 0.8549 - val_loss: 0.3353 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3310 - acc: 0.8549 - val_loss: 0.3330 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3258 - acc: 0.8601 - val_loss: 0.3311 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4582f1d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6666 - acc: 0.6218 - val_loss: 0.6216 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6157 - acc: 0.7617 - val_loss: 0.5705 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5711 - acc: 0.7979 - val_loss: 0.5266 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5326 - acc: 0.8187 - val_loss: 0.4896 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4994 - acc: 0.8497 - val_loss: 0.4586 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4711 - acc: 0.8497 - val_loss: 0.4329 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4471 - acc: 0.8446 - val_loss: 0.4116 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4269 - acc: 0.8497 - val_loss: 0.3941 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4098 - acc: 0.8549 - val_loss: 0.3799 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3954 - acc: 0.8497 - val_loss: 0.3684 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3832 - acc: 0.8549 - val_loss: 0.3592 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3728 - acc: 0.8549 - val_loss: 0.3518 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3640 - acc: 0.8601 - val_loss: 0.3459 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3563 - acc: 0.8653 - val_loss: 0.3412 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3497 - acc: 0.8705 - val_loss: 0.3377 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3437 - acc: 0.8705 - val_loss: 0.3350 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3383 - acc: 0.8601 - val_loss: 0.3329 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3334 - acc: 0.8601 - val_loss: 0.3314 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3288 - acc: 0.8601 - val_loss: 0.3304 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3245 - acc: 0.8653 - val_loss: 0.3298 - val_acc: 0.8852\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410492940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6496 - acc: 0.6546 - val_loss: 0.5813 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5982 - acc: 0.7474 - val_loss: 0.5337 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5535 - acc: 0.7887 - val_loss: 0.4934 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5150 - acc: 0.7990 - val_loss: 0.4596 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4823 - acc: 0.7990 - val_loss: 0.4315 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4547 - acc: 0.8144 - val_loss: 0.4084 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4316 - acc: 0.8144 - val_loss: 0.3896 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4122 - acc: 0.8299 - val_loss: 0.3742 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3961 - acc: 0.8299 - val_loss: 0.3617 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3825 - acc: 0.8299 - val_loss: 0.3517 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3711 - acc: 0.8351 - val_loss: 0.3436 - val_acc: 0.8525\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3614 - acc: 0.8351 - val_loss: 0.3371 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3531 - acc: 0.8351 - val_loss: 0.3317 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3458 - acc: 0.8351 - val_loss: 0.3274 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3394 - acc: 0.8402 - val_loss: 0.3238 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3337 - acc: 0.8402 - val_loss: 0.3209 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3284 - acc: 0.8505 - val_loss: 0.3185 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3236 - acc: 0.8557 - val_loss: 0.3165 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3190 - acc: 0.8660 - val_loss: 0.3147 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3146 - acc: 0.8660 - val_loss: 0.3133 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1ca550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7192 - acc: 0.4124 - val_loss: 0.6666 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6625 - acc: 0.6134 - val_loss: 0.6066 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6126 - acc: 0.7320 - val_loss: 0.5553 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5693 - acc: 0.7680 - val_loss: 0.5119 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5322 - acc: 0.7990 - val_loss: 0.4758 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5006 - acc: 0.8299 - val_loss: 0.4460 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4740 - acc: 0.8299 - val_loss: 0.4217 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4516 - acc: 0.8299 - val_loss: 0.4020 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4328 - acc: 0.8351 - val_loss: 0.3860 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4170 - acc: 0.8351 - val_loss: 0.3732 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4037 - acc: 0.8351 - val_loss: 0.3631 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3924 - acc: 0.8351 - val_loss: 0.3552 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3829 - acc: 0.8402 - val_loss: 0.3489 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3747 - acc: 0.8402 - val_loss: 0.3441 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3677 - acc: 0.8402 - val_loss: 0.3403 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3615 - acc: 0.8505 - val_loss: 0.3374 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3561 - acc: 0.8454 - val_loss: 0.3352 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3512 - acc: 0.8454 - val_loss: 0.3336 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3468 - acc: 0.8454 - val_loss: 0.3324 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3427 - acc: 0.8505 - val_loss: 0.3315 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3942a9040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7167 - acc: 0.4794 - val_loss: 0.6377 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6615 - acc: 0.5825 - val_loss: 0.5907 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6123 - acc: 0.6907 - val_loss: 0.5494 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5690 - acc: 0.7423 - val_loss: 0.5135 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5314 - acc: 0.7887 - val_loss: 0.4825 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4989 - acc: 0.8144 - val_loss: 0.4560 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4712 - acc: 0.8196 - val_loss: 0.4334 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4476 - acc: 0.8402 - val_loss: 0.4143 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4277 - acc: 0.8557 - val_loss: 0.3982 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4109 - acc: 0.8557 - val_loss: 0.3848 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3968 - acc: 0.8557 - val_loss: 0.3736 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3848 - acc: 0.8660 - val_loss: 0.3644 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3747 - acc: 0.8660 - val_loss: 0.3570 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3661 - acc: 0.8660 - val_loss: 0.3509 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3586 - acc: 0.8711 - val_loss: 0.3461 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3520 - acc: 0.8711 - val_loss: 0.3423 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3462 - acc: 0.8660 - val_loss: 0.3394 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3409 - acc: 0.8660 - val_loss: 0.3372 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3361 - acc: 0.8660 - val_loss: 0.3356 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3316 - acc: 0.8608 - val_loss: 0.3345 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4204c71f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7596 - acc: 0.5440 - val_loss: 0.7971 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7185 - acc: 0.6010 - val_loss: 0.7529 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6821 - acc: 0.6218 - val_loss: 0.7130 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6498 - acc: 0.6425 - val_loss: 0.6766 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6215 - acc: 0.6839 - val_loss: 0.6443 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5957 - acc: 0.7254 - val_loss: 0.6148 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5716 - acc: 0.7617 - val_loss: 0.5874 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5495 - acc: 0.7668 - val_loss: 0.5613 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5286 - acc: 0.7979 - val_loss: 0.5366 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5086 - acc: 0.8083 - val_loss: 0.5133 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4901 - acc: 0.8135 - val_loss: 0.4919 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4729 - acc: 0.8290 - val_loss: 0.4722 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4570 - acc: 0.8290 - val_loss: 0.4545 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4424 - acc: 0.8394 - val_loss: 0.4385 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4289 - acc: 0.8497 - val_loss: 0.4242 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4168 - acc: 0.8601 - val_loss: 0.4119 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4060 - acc: 0.8497 - val_loss: 0.4017 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3961 - acc: 0.8549 - val_loss: 0.3934 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3869 - acc: 0.8549 - val_loss: 0.3872 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3786 - acc: 0.8497 - val_loss: 0.3825 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4106e7b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0174 - acc: 0.3627 - val_loss: 0.8936 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9279 - acc: 0.3886 - val_loss: 0.7984 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8491 - acc: 0.4456 - val_loss: 0.7185 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7813 - acc: 0.4819 - val_loss: 0.6533 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7247 - acc: 0.5233 - val_loss: 0.6002 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6774 - acc: 0.5855 - val_loss: 0.5583 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6387 - acc: 0.5907 - val_loss: 0.5251 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6066 - acc: 0.6321 - val_loss: 0.4995 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5795 - acc: 0.6477 - val_loss: 0.4791 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5564 - acc: 0.6995 - val_loss: 0.4638 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5368 - acc: 0.7254 - val_loss: 0.4521 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5197 - acc: 0.7409 - val_loss: 0.4433 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5047 - acc: 0.7668 - val_loss: 0.4351 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4914 - acc: 0.7720 - val_loss: 0.4271 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4797 - acc: 0.7772 - val_loss: 0.4199 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4691 - acc: 0.7772 - val_loss: 0.4137 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4595 - acc: 0.7927 - val_loss: 0.4081 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4503 - acc: 0.8083 - val_loss: 0.4027 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4414 - acc: 0.8135 - val_loss: 0.3977 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4328 - acc: 0.8187 - val_loss: 0.3932 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b80624c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8087 - acc: 0.5052 - val_loss: 0.7894 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7505 - acc: 0.4948 - val_loss: 0.7397 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7010 - acc: 0.5258 - val_loss: 0.6989 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6601 - acc: 0.5928 - val_loss: 0.6650 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6252 - acc: 0.6237 - val_loss: 0.6353 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5963 - acc: 0.6753 - val_loss: 0.6087 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5717 - acc: 0.7113 - val_loss: 0.5855 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5500 - acc: 0.7268 - val_loss: 0.5645 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5305 - acc: 0.7577 - val_loss: 0.5457 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5124 - acc: 0.7887 - val_loss: 0.5276 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4954 - acc: 0.8041 - val_loss: 0.5097 - val_acc: 0.7869\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4794 - acc: 0.7990 - val_loss: 0.4933 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4641 - acc: 0.8041 - val_loss: 0.4777 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4495 - acc: 0.8247 - val_loss: 0.4631 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4358 - acc: 0.8299 - val_loss: 0.4499 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4227 - acc: 0.8351 - val_loss: 0.4383 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4104 - acc: 0.8299 - val_loss: 0.4276 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3989 - acc: 0.8351 - val_loss: 0.4179 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3883 - acc: 0.8454 - val_loss: 0.4100 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3786 - acc: 0.8557 - val_loss: 0.4034 - val_acc: 0.8197\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3785ca5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7154 - acc: 0.5670 - val_loss: 0.6266 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6592 - acc: 0.5979 - val_loss: 0.5819 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6141 - acc: 0.6289 - val_loss: 0.5428 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5763 - acc: 0.6701 - val_loss: 0.5103 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5447 - acc: 0.7062 - val_loss: 0.4831 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5178 - acc: 0.7216 - val_loss: 0.4600 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4950 - acc: 0.7474 - val_loss: 0.4401 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4757 - acc: 0.7990 - val_loss: 0.4223 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4592 - acc: 0.7990 - val_loss: 0.4070 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4450 - acc: 0.7938 - val_loss: 0.3938 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4327 - acc: 0.7938 - val_loss: 0.3827 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4215 - acc: 0.7990 - val_loss: 0.3733 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4114 - acc: 0.8041 - val_loss: 0.3660 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4022 - acc: 0.8144 - val_loss: 0.3604 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3939 - acc: 0.8144 - val_loss: 0.3559 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3863 - acc: 0.8093 - val_loss: 0.3525 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3794 - acc: 0.8093 - val_loss: 0.3499 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3730 - acc: 0.8093 - val_loss: 0.3479 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3670 - acc: 0.8247 - val_loss: 0.3464 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3614 - acc: 0.8247 - val_loss: 0.3453 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3945cac10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7195 - acc: 0.5309 - val_loss: 0.6284 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6640 - acc: 0.5825 - val_loss: 0.5783 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6157 - acc: 0.6495 - val_loss: 0.5381 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5750 - acc: 0.7113 - val_loss: 0.5074 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5404 - acc: 0.7268 - val_loss: 0.4834 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5109 - acc: 0.7577 - val_loss: 0.4640 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4860 - acc: 0.7835 - val_loss: 0.4476 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4651 - acc: 0.7938 - val_loss: 0.4345 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4478 - acc: 0.7938 - val_loss: 0.4244 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4334 - acc: 0.7990 - val_loss: 0.4167 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4215 - acc: 0.8041 - val_loss: 0.4104 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4116 - acc: 0.8041 - val_loss: 0.4058 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4030 - acc: 0.8093 - val_loss: 0.4029 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3955 - acc: 0.8144 - val_loss: 0.4009 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3892 - acc: 0.8247 - val_loss: 0.3995 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3835 - acc: 0.8299 - val_loss: 0.3985 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3782 - acc: 0.8299 - val_loss: 0.3978 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3732 - acc: 0.8299 - val_loss: 0.3974 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3684 - acc: 0.8299 - val_loss: 0.3970 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3637 - acc: 0.8299 - val_loss: 0.3963 - val_acc: 0.8033\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa35474d040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0420 - acc: 0.5078 - val_loss: 0.9779 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9185 - acc: 0.5026 - val_loss: 0.8383 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8118 - acc: 0.5026 - val_loss: 0.7242 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7202 - acc: 0.5078 - val_loss: 0.6322 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6435 - acc: 0.5855 - val_loss: 0.5605 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5805 - acc: 0.6684 - val_loss: 0.5056 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5301 - acc: 0.7409 - val_loss: 0.4654 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4912 - acc: 0.7979 - val_loss: 0.4367 - val_acc: 0.9180\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4599 - acc: 0.8342 - val_loss: 0.4164 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4344 - acc: 0.8238 - val_loss: 0.4018 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4133 - acc: 0.8342 - val_loss: 0.3911 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3958 - acc: 0.8238 - val_loss: 0.3828 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3810 - acc: 0.8290 - val_loss: 0.3767 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3684 - acc: 0.8238 - val_loss: 0.3724 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3581 - acc: 0.8238 - val_loss: 0.3693 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3492 - acc: 0.8290 - val_loss: 0.3670 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3414 - acc: 0.8394 - val_loss: 0.3652 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3347 - acc: 0.8394 - val_loss: 0.3635 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3287 - acc: 0.8497 - val_loss: 0.3619 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3232 - acc: 0.8497 - val_loss: 0.3602 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3546df280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9569 - acc: 0.3264 - val_loss: 0.9393 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8494 - acc: 0.3834 - val_loss: 0.8344 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7590 - acc: 0.4715 - val_loss: 0.7498 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6851 - acc: 0.5648 - val_loss: 0.6821 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6259 - acc: 0.6321 - val_loss: 0.6273 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5788 - acc: 0.6839 - val_loss: 0.5817 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5415 - acc: 0.7306 - val_loss: 0.5446 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5111 - acc: 0.7409 - val_loss: 0.5150 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4862 - acc: 0.7565 - val_loss: 0.4907 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4652 - acc: 0.7772 - val_loss: 0.4706 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4476 - acc: 0.7927 - val_loss: 0.4546 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4331 - acc: 0.7979 - val_loss: 0.4411 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4206 - acc: 0.7979 - val_loss: 0.4302 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4099 - acc: 0.7979 - val_loss: 0.4214 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4006 - acc: 0.7979 - val_loss: 0.4146 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3924 - acc: 0.7979 - val_loss: 0.4093 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3848 - acc: 0.8187 - val_loss: 0.4050 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3780 - acc: 0.8342 - val_loss: 0.4017 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3717 - acc: 0.8394 - val_loss: 0.3990 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3657 - acc: 0.8342 - val_loss: 0.3966 - val_acc: 0.8197\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3544bbca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9306 - acc: 0.4845 - val_loss: 0.7203 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8144 - acc: 0.5155 - val_loss: 0.6475 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7163 - acc: 0.5515 - val_loss: 0.5864 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6335 - acc: 0.6289 - val_loss: 0.5360 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5657 - acc: 0.6701 - val_loss: 0.4948 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5111 - acc: 0.7268 - val_loss: 0.4615 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4674 - acc: 0.7680 - val_loss: 0.4344 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4328 - acc: 0.7938 - val_loss: 0.4122 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4056 - acc: 0.8144 - val_loss: 0.3943 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3847 - acc: 0.8454 - val_loss: 0.3801 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3686 - acc: 0.8454 - val_loss: 0.3687 - val_acc: 0.8525\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3562 - acc: 0.8454 - val_loss: 0.3593 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3465 - acc: 0.8557 - val_loss: 0.3516 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3387 - acc: 0.8608 - val_loss: 0.3454 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3323 - acc: 0.8660 - val_loss: 0.3406 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3267 - acc: 0.8711 - val_loss: 0.3367 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3214 - acc: 0.8660 - val_loss: 0.3337 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3163 - acc: 0.8711 - val_loss: 0.3312 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3114 - acc: 0.8763 - val_loss: 0.3293 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3067 - acc: 0.8814 - val_loss: 0.3278 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3545661f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0644 - acc: 0.3969 - val_loss: 1.0305 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9370 - acc: 0.4588 - val_loss: 0.8955 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8266 - acc: 0.5000 - val_loss: 0.7813 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7336 - acc: 0.5567 - val_loss: 0.6871 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6552 - acc: 0.6082 - val_loss: 0.6089 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5908 - acc: 0.6546 - val_loss: 0.5455 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5383 - acc: 0.7268 - val_loss: 0.4952 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4964 - acc: 0.7474 - val_loss: 0.4571 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4632 - acc: 0.7784 - val_loss: 0.4291 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4368 - acc: 0.8041 - val_loss: 0.4077 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4159 - acc: 0.8351 - val_loss: 0.3918 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3995 - acc: 0.8299 - val_loss: 0.3805 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3865 - acc: 0.8299 - val_loss: 0.3727 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3755 - acc: 0.8402 - val_loss: 0.3674 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3663 - acc: 0.8505 - val_loss: 0.3637 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3585 - acc: 0.8454 - val_loss: 0.3609 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3518 - acc: 0.8454 - val_loss: 0.3591 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3459 - acc: 0.8454 - val_loss: 0.3583 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3405 - acc: 0.8454 - val_loss: 0.3582 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3358 - acc: 0.8454 - val_loss: 0.3585 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3544bb700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7907 - acc: 0.4897 - val_loss: 0.7357 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7121 - acc: 0.6031 - val_loss: 0.6507 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6464 - acc: 0.6598 - val_loss: 0.5810 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5920 - acc: 0.7320 - val_loss: 0.5242 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5482 - acc: 0.7680 - val_loss: 0.4783 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5129 - acc: 0.7835 - val_loss: 0.4411 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4842 - acc: 0.7887 - val_loss: 0.4124 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4609 - acc: 0.7938 - val_loss: 0.3906 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4426 - acc: 0.7887 - val_loss: 0.3749 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4278 - acc: 0.7938 - val_loss: 0.3633 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4157 - acc: 0.7938 - val_loss: 0.3555 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4054 - acc: 0.8041 - val_loss: 0.3510 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3961 - acc: 0.8144 - val_loss: 0.3488 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3878 - acc: 0.8144 - val_loss: 0.3483 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3798 - acc: 0.8247 - val_loss: 0.3487 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3725 - acc: 0.8351 - val_loss: 0.3494 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3659 - acc: 0.8402 - val_loss: 0.3500 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3597 - acc: 0.8402 - val_loss: 0.3507 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3538 - acc: 0.8454 - val_loss: 0.3515 - val_acc: 0.8852\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e44430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7450 - acc: 0.4767 - val_loss: 0.6295 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6179 - acc: 0.6373 - val_loss: 0.5282 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5256 - acc: 0.7461 - val_loss: 0.4599 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4616 - acc: 0.7979 - val_loss: 0.4158 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4190 - acc: 0.8238 - val_loss: 0.3889 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3910 - acc: 0.8394 - val_loss: 0.3735 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3723 - acc: 0.8394 - val_loss: 0.3655 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3591 - acc: 0.8394 - val_loss: 0.3611 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3487 - acc: 0.8394 - val_loss: 0.3588 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3395 - acc: 0.8394 - val_loss: 0.3572 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3311 - acc: 0.8497 - val_loss: 0.3554 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3227 - acc: 0.8497 - val_loss: 0.3533 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3145 - acc: 0.8653 - val_loss: 0.3507 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3060 - acc: 0.8756 - val_loss: 0.3484 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2976 - acc: 0.8860 - val_loss: 0.3462 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2895 - acc: 0.8808 - val_loss: 0.3442 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2819 - acc: 0.8912 - val_loss: 0.3427 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2751 - acc: 0.9016 - val_loss: 0.3410 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2686 - acc: 0.9016 - val_loss: 0.3400 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2626 - acc: 0.9067 - val_loss: 0.3394 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1ca160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8065 - acc: 0.4974 - val_loss: 0.6634 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6732 - acc: 0.6062 - val_loss: 0.5555 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5711 - acc: 0.6891 - val_loss: 0.4717 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4937 - acc: 0.7461 - val_loss: 0.4102 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4373 - acc: 0.7876 - val_loss: 0.3685 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3982 - acc: 0.8238 - val_loss: 0.3419 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3720 - acc: 0.8549 - val_loss: 0.3274 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3549 - acc: 0.8653 - val_loss: 0.3202 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3437 - acc: 0.8705 - val_loss: 0.3177 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3360 - acc: 0.8756 - val_loss: 0.3182 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3300 - acc: 0.8705 - val_loss: 0.3201 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3246 - acc: 0.8756 - val_loss: 0.3221 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3194 - acc: 0.8756 - val_loss: 0.3240 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3141 - acc: 0.8756 - val_loss: 0.3250 - val_acc: 0.8852\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa47425b040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7923 - acc: 0.5567 - val_loss: 0.6634 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6678 - acc: 0.6237 - val_loss: 0.5769 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5686 - acc: 0.6907 - val_loss: 0.5097 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4918 - acc: 0.7680 - val_loss: 0.4590 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4345 - acc: 0.8144 - val_loss: 0.4221 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3935 - acc: 0.8351 - val_loss: 0.3967 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3649 - acc: 0.8351 - val_loss: 0.3794 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3455 - acc: 0.8505 - val_loss: 0.3681 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3327 - acc: 0.8608 - val_loss: 0.3608 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3238 - acc: 0.8608 - val_loss: 0.3566 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3172 - acc: 0.8763 - val_loss: 0.3542 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3121 - acc: 0.8711 - val_loss: 0.3529 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3073 - acc: 0.8763 - val_loss: 0.3528 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3023 - acc: 0.8866 - val_loss: 0.3532 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2972 - acc: 0.8814 - val_loss: 0.3540 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2917 - acc: 0.8763 - val_loss: 0.3553 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2859 - acc: 0.8814 - val_loss: 0.3568 - val_acc: 0.8689\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2800 - acc: 0.8763 - val_loss: 0.3584 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4582f18b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9289 - acc: 0.2887 - val_loss: 0.8019 - val_acc: 0.3443\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7741 - acc: 0.3969 - val_loss: 0.6681 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6527 - acc: 0.5876 - val_loss: 0.5662 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5618 - acc: 0.7062 - val_loss: 0.4913 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4953 - acc: 0.7938 - val_loss: 0.4371 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4479 - acc: 0.7835 - val_loss: 0.3988 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4154 - acc: 0.8041 - val_loss: 0.3720 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3929 - acc: 0.8196 - val_loss: 0.3541 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3777 - acc: 0.8196 - val_loss: 0.3432 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3673 - acc: 0.8351 - val_loss: 0.3374 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3600 - acc: 0.8402 - val_loss: 0.3354 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3548 - acc: 0.8402 - val_loss: 0.3360 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3508 - acc: 0.8402 - val_loss: 0.3383 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3473 - acc: 0.8402 - val_loss: 0.3416 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3439 - acc: 0.8402 - val_loss: 0.3455 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3402 - acc: 0.8505 - val_loss: 0.3493 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e0dca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8499 - acc: 0.3660 - val_loss: 0.6665 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7144 - acc: 0.5258 - val_loss: 0.5585 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6109 - acc: 0.6392 - val_loss: 0.4831 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5332 - acc: 0.7577 - val_loss: 0.4320 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4774 - acc: 0.8144 - val_loss: 0.3985 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4379 - acc: 0.8247 - val_loss: 0.3764 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4105 - acc: 0.8351 - val_loss: 0.3613 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3918 - acc: 0.8402 - val_loss: 0.3505 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3787 - acc: 0.8557 - val_loss: 0.3431 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3692 - acc: 0.8505 - val_loss: 0.3377 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3623 - acc: 0.8505 - val_loss: 0.3340 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3569 - acc: 0.8557 - val_loss: 0.3314 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3524 - acc: 0.8505 - val_loss: 0.3297 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3481 - acc: 0.8557 - val_loss: 0.3288 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3439 - acc: 0.8557 - val_loss: 0.3287 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3395 - acc: 0.8608 - val_loss: 0.3293 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3347 - acc: 0.8505 - val_loss: 0.3304 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3295 - acc: 0.8557 - val_loss: 0.3320 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3240 - acc: 0.8608 - val_loss: 0.3336 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3181 - acc: 0.8505 - val_loss: 0.3355 - val_acc: 0.8852\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0ea4550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.9440 - acc: 0.3212 - val_loss: 0.7060 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7086 - acc: 0.5699 - val_loss: 0.5276 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5548 - acc: 0.7358 - val_loss: 0.4282 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4624 - acc: 0.8031 - val_loss: 0.3783 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4113 - acc: 0.8290 - val_loss: 0.3547 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3827 - acc: 0.8238 - val_loss: 0.3441 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3660 - acc: 0.8394 - val_loss: 0.3399 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3549 - acc: 0.8394 - val_loss: 0.3388 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3459 - acc: 0.8394 - val_loss: 0.3385 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3375 - acc: 0.8497 - val_loss: 0.3381 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3289 - acc: 0.8549 - val_loss: 0.3369 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3196 - acc: 0.8705 - val_loss: 0.3349 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3095 - acc: 0.8756 - val_loss: 0.3322 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2990 - acc: 0.8705 - val_loss: 0.3289 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2884 - acc: 0.8756 - val_loss: 0.3257 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2780 - acc: 0.8860 - val_loss: 0.3227 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2682 - acc: 0.8912 - val_loss: 0.3207 - val_acc: 0.9180\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2592 - acc: 0.8860 - val_loss: 0.3192 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2511 - acc: 0.8912 - val_loss: 0.3185 - val_acc: 0.9180\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2440 - acc: 0.9016 - val_loss: 0.3183 - val_acc: 0.9180\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beca4040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7353 - acc: 0.4922 - val_loss: 0.5638 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5794 - acc: 0.7098 - val_loss: 0.4558 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4828 - acc: 0.7876 - val_loss: 0.3929 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4267 - acc: 0.8187 - val_loss: 0.3574 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3942 - acc: 0.8238 - val_loss: 0.3389 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3753 - acc: 0.8238 - val_loss: 0.3311 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3629 - acc: 0.8394 - val_loss: 0.3285 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3535 - acc: 0.8394 - val_loss: 0.3288 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3449 - acc: 0.8446 - val_loss: 0.3305 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3362 - acc: 0.8446 - val_loss: 0.3326 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3268 - acc: 0.8549 - val_loss: 0.3347 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3169 - acc: 0.8601 - val_loss: 0.3365 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac494160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8301 - acc: 0.3299 - val_loss: 0.6283 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6218 - acc: 0.6856 - val_loss: 0.5142 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4894 - acc: 0.7938 - val_loss: 0.4474 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4107 - acc: 0.8454 - val_loss: 0.4091 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3660 - acc: 0.8608 - val_loss: 0.3866 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3409 - acc: 0.8660 - val_loss: 0.3740 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3266 - acc: 0.8608 - val_loss: 0.3671 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3177 - acc: 0.8711 - val_loss: 0.3633 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3112 - acc: 0.8763 - val_loss: 0.3608 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3054 - acc: 0.8814 - val_loss: 0.3587 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2998 - acc: 0.8814 - val_loss: 0.3569 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2938 - acc: 0.8814 - val_loss: 0.3555 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2874 - acc: 0.8814 - val_loss: 0.3544 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2805 - acc: 0.8866 - val_loss: 0.3536 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2735 - acc: 0.8814 - val_loss: 0.3523 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2663 - acc: 0.8763 - val_loss: 0.3505 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2592 - acc: 0.8814 - val_loss: 0.3487 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2522 - acc: 0.8814 - val_loss: 0.3467 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2456 - acc: 0.8814 - val_loss: 0.3449 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2391 - acc: 0.8969 - val_loss: 0.3430 - val_acc: 0.9016\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e28dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6501 - acc: 0.6392 - val_loss: 0.4920 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5227 - acc: 0.8196 - val_loss: 0.4059 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4419 - acc: 0.8402 - val_loss: 0.3601 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3941 - acc: 0.8557 - val_loss: 0.3412 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3679 - acc: 0.8454 - val_loss: 0.3374 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3539 - acc: 0.8505 - val_loss: 0.3408 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3456 - acc: 0.8505 - val_loss: 0.3474 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3395 - acc: 0.8557 - val_loss: 0.3546 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3332 - acc: 0.8557 - val_loss: 0.3610 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3258 - acc: 0.8608 - val_loss: 0.3662 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa354566c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6349 - acc: 0.6856 - val_loss: 0.5277 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5107 - acc: 0.7680 - val_loss: 0.4439 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4336 - acc: 0.7990 - val_loss: 0.3933 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3900 - acc: 0.8402 - val_loss: 0.3655 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3658 - acc: 0.8402 - val_loss: 0.3513 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3502 - acc: 0.8454 - val_loss: 0.3458 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3371 - acc: 0.8505 - val_loss: 0.3463 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3243 - acc: 0.8557 - val_loss: 0.3517 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3112 - acc: 0.8660 - val_loss: 0.3602 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2984 - acc: 0.8660 - val_loss: 0.3703 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2861 - acc: 0.8660 - val_loss: 0.3811 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3942a9160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7100 - acc: 0.5130 - val_loss: 0.4526 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4971 - acc: 0.7824 - val_loss: 0.3736 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3971 - acc: 0.8290 - val_loss: 0.3510 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3545 - acc: 0.8497 - val_loss: 0.3501 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3355 - acc: 0.8497 - val_loss: 0.3548 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3243 - acc: 0.8601 - val_loss: 0.3597 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3147 - acc: 0.8705 - val_loss: 0.3622 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3039 - acc: 0.8705 - val_loss: 0.3623 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2918 - acc: 0.8860 - val_loss: 0.3602 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4201bfb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8386 - acc: 0.3731 - val_loss: 0.5911 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5890 - acc: 0.7254 - val_loss: 0.4461 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4509 - acc: 0.8135 - val_loss: 0.3727 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3859 - acc: 0.8497 - val_loss: 0.3399 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3593 - acc: 0.8342 - val_loss: 0.3296 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3489 - acc: 0.8342 - val_loss: 0.3307 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3436 - acc: 0.8342 - val_loss: 0.3374 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3381 - acc: 0.8342 - val_loss: 0.3461 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3308 - acc: 0.8446 - val_loss: 0.3548 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3216 - acc: 0.8446 - val_loss: 0.3621 - val_acc: 0.8852\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa420257d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7992 - acc: 0.3557 - val_loss: 0.4923 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5407 - acc: 0.7784 - val_loss: 0.3754 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4155 - acc: 0.8351 - val_loss: 0.3343 - val_acc: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3613 - acc: 0.8454 - val_loss: 0.3257 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3388 - acc: 0.8660 - val_loss: 0.3295 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3292 - acc: 0.8711 - val_loss: 0.3376 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3237 - acc: 0.8711 - val_loss: 0.3456 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3186 - acc: 0.8711 - val_loss: 0.3518 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3123 - acc: 0.8763 - val_loss: 0.3561 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41008e700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6772 - acc: 0.5258 - val_loss: 0.4981 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4864 - acc: 0.8144 - val_loss: 0.4060 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4029 - acc: 0.8299 - val_loss: 0.3715 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3654 - acc: 0.8454 - val_loss: 0.3602 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3467 - acc: 0.8660 - val_loss: 0.3589 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3352 - acc: 0.8660 - val_loss: 0.3612 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3260 - acc: 0.8763 - val_loss: 0.3640 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3168 - acc: 0.8866 - val_loss: 0.3666 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3068 - acc: 0.8866 - val_loss: 0.3690 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2960 - acc: 0.8918 - val_loss: 0.3714 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa39463c790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7282 - acc: 0.5773 - val_loss: 0.4488 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5005 - acc: 0.8041 - val_loss: 0.3458 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4066 - acc: 0.8247 - val_loss: 0.3309 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3756 - acc: 0.8402 - val_loss: 0.3381 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3633 - acc: 0.8557 - val_loss: 0.3475 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3542 - acc: 0.8557 - val_loss: 0.3539 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3439 - acc: 0.8557 - val_loss: 0.3574 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3320 - acc: 0.8557 - val_loss: 0.3583 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa378461040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6474 - acc: 0.7150 - val_loss: 0.3990 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4157 - acc: 0.8238 - val_loss: 0.3450 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3504 - acc: 0.8446 - val_loss: 0.3443 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3286 - acc: 0.8549 - val_loss: 0.3510 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3144 - acc: 0.8705 - val_loss: 0.3551 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2996 - acc: 0.8601 - val_loss: 0.3559 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2832 - acc: 0.8964 - val_loss: 0.3553 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2666 - acc: 0.8860 - val_loss: 0.3552 - val_acc: 0.9016\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa37865da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6844 - acc: 0.5751 - val_loss: 0.4199 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4363 - acc: 0.8342 - val_loss: 0.3488 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3612 - acc: 0.8497 - val_loss: 0.3409 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3413 - acc: 0.8446 - val_loss: 0.3480 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3336 - acc: 0.8601 - val_loss: 0.3556 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3242 - acc: 0.8601 - val_loss: 0.3592 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3099 - acc: 0.8756 - val_loss: 0.3593 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2921 - acc: 0.8756 - val_loss: 0.3576 - val_acc: 0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3546d9430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6995 - acc: 0.4691 - val_loss: 0.4138 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4355 - acc: 0.8351 - val_loss: 0.3249 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3471 - acc: 0.8608 - val_loss: 0.3023 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3231 - acc: 0.8660 - val_loss: 0.3037 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3154 - acc: 0.8711 - val_loss: 0.3124 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3083 - acc: 0.8763 - val_loss: 0.3222 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2983 - acc: 0.8866 - val_loss: 0.3309 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2854 - acc: 0.8814 - val_loss: 0.3374 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa354647430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6519 - acc: 0.6649 - val_loss: 0.3748 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4206 - acc: 0.8299 - val_loss: 0.3256 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3635 - acc: 0.8351 - val_loss: 0.3322 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3507 - acc: 0.8402 - val_loss: 0.3479 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3437 - acc: 0.8454 - val_loss: 0.3613 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3337 - acc: 0.8608 - val_loss: 0.3687 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3195 - acc: 0.8711 - val_loss: 0.3711 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa35445ce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7138 - acc: 0.5515 - val_loss: 0.4211 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4558 - acc: 0.8041 - val_loss: 0.3456 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3821 - acc: 0.8247 - val_loss: 0.3457 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3611 - acc: 0.8247 - val_loss: 0.3586 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3504 - acc: 0.8557 - val_loss: 0.3686 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3393 - acc: 0.8557 - val_loss: 0.3738 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3256 - acc: 0.8608 - val_loss: 0.3743 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3546479d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7176 - acc: 0.5078 - val_loss: 0.3916 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4041 - acc: 0.8342 - val_loss: 0.3732 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3511 - acc: 0.8497 - val_loss: 0.3843 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3376 - acc: 0.8601 - val_loss: 0.3862 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3235 - acc: 0.8705 - val_loss: 0.3790 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3025 - acc: 0.8808 - val_loss: 0.3673 - val_acc: 0.9180\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2781 - acc: 0.9016 - val_loss: 0.3554 - val_acc: 0.9180\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2559 - acc: 0.8964 - val_loss: 0.3468 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2397 - acc: 0.9119 - val_loss: 0.3428 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2285 - acc: 0.9223 - val_loss: 0.3427 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2189 - acc: 0.9223 - val_loss: 0.3469 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2083 - acc: 0.9275 - val_loss: 0.3551 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1964 - acc: 0.9326 - val_loss: 0.3666 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1836 - acc: 0.9326 - val_loss: 0.3803 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1702 - acc: 0.9534 - val_loss: 0.3955 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa474704160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6687 - acc: 0.5544 - val_loss: 0.3479 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3932 - acc: 0.8290 - val_loss: 0.3229 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3530 - acc: 0.8342 - val_loss: 0.3396 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3462 - acc: 0.8394 - val_loss: 0.3536 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3329 - acc: 0.8601 - val_loss: 0.3581 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3098 - acc: 0.8601 - val_loss: 0.3548 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2823 - acc: 0.8860 - val_loss: 0.3480 - val_acc: 0.9016\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc364d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6631 - acc: 0.6237 - val_loss: 0.3601 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3720 - acc: 0.8299 - val_loss: 0.3377 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3275 - acc: 0.8608 - val_loss: 0.3558 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3230 - acc: 0.8711 - val_loss: 0.3719 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3154 - acc: 0.8660 - val_loss: 0.3797 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2994 - acc: 0.8814 - val_loss: 0.3800 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2788 - acc: 0.8814 - val_loss: 0.3759 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3546475e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7022 - acc: 0.4897 - val_loss: 0.3678 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3951 - acc: 0.8247 - val_loss: 0.3322 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3537 - acc: 0.8402 - val_loss: 0.3551 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3516 - acc: 0.8505 - val_loss: 0.3811 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3462 - acc: 0.8763 - val_loss: 0.3974 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3320 - acc: 0.8660 - val_loss: 0.4024 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3109 - acc: 0.8918 - val_loss: 0.3979 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa37865d310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6583 - acc: 0.6392 - val_loss: 0.3721 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3860 - acc: 0.8402 - val_loss: 0.3694 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3558 - acc: 0.8505 - val_loss: 0.3937 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3478 - acc: 0.8557 - val_loss: 0.4084 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3309 - acc: 0.8660 - val_loss: 0.4126 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3061 - acc: 0.8711 - val_loss: 0.4113 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2793 - acc: 0.8866 - val_loss: 0.4083 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa394107310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7296 - acc: 0.5440 - val_loss: 0.4141 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4453 - acc: 0.7876 - val_loss: 0.3502 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3954 - acc: 0.8238 - val_loss: 0.3281 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3627 - acc: 0.8342 - val_loss: 0.3145 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3367 - acc: 0.8549 - val_loss: 0.3029 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3144 - acc: 0.8653 - val_loss: 0.2952 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2974 - acc: 0.8756 - val_loss: 0.2938 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2877 - acc: 0.8808 - val_loss: 0.2986 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2795 - acc: 0.8860 - val_loss: 0.3115 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2703 - acc: 0.8912 - val_loss: 0.3291 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2634 - acc: 0.9016 - val_loss: 0.3436 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2577 - acc: 0.9119 - val_loss: 0.3483 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41014b700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.9113 - acc: 0.5648 - val_loss: 0.4632 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4748 - acc: 0.7668 - val_loss: 0.3627 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3875 - acc: 0.8549 - val_loss: 0.3554 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3609 - acc: 0.8497 - val_loss: 0.3939 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3558 - acc: 0.8549 - val_loss: 0.4304 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3537 - acc: 0.8549 - val_loss: 0.4475 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3468 - acc: 0.8446 - val_loss: 0.4461 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3327 - acc: 0.8705 - val_loss: 0.4295 - val_acc: 0.7705\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0ea4f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7426 - acc: 0.4742 - val_loss: 0.4105 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4450 - acc: 0.7938 - val_loss: 0.3581 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3866 - acc: 0.7990 - val_loss: 0.3682 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3693 - acc: 0.8196 - val_loss: 0.3795 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3488 - acc: 0.8351 - val_loss: 0.3834 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3252 - acc: 0.8557 - val_loss: 0.3844 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3043 - acc: 0.8557 - val_loss: 0.3807 - val_acc: 0.8852\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41014b9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.0027 - acc: 0.3711 - val_loss: 0.5724 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5317 - acc: 0.7680 - val_loss: 0.3964 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3881 - acc: 0.8351 - val_loss: 0.3572 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3643 - acc: 0.8557 - val_loss: 0.3568 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3669 - acc: 0.8402 - val_loss: 0.3594 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3604 - acc: 0.8402 - val_loss: 0.3531 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3433 - acc: 0.8608 - val_loss: 0.3431 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3223 - acc: 0.8608 - val_loss: 0.3399 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3035 - acc: 0.8608 - val_loss: 0.3500 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2921 - acc: 0.8557 - val_loss: 0.3719 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2877 - acc: 0.8557 - val_loss: 0.3994 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2859 - acc: 0.8557 - val_loss: 0.4253 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2817 - acc: 0.8660 - val_loss: 0.4451 - val_acc: 0.7869\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa47425b160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9917 - acc: 0.3969 - val_loss: 0.4964 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5169 - acc: 0.7371 - val_loss: 0.3837 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4205 - acc: 0.8351 - val_loss: 0.3432 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3949 - acc: 0.8299 - val_loss: 0.3300 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3802 - acc: 0.8608 - val_loss: 0.3314 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3648 - acc: 0.8660 - val_loss: 0.3439 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3496 - acc: 0.8557 - val_loss: 0.3623 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3365 - acc: 0.8763 - val_loss: 0.3825 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3278 - acc: 0.8763 - val_loss: 0.3937 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4204d8dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8693 - acc: 0.4301 - val_loss: 0.4262 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4156 - acc: 0.8238 - val_loss: 0.3555 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3784 - acc: 0.8394 - val_loss: 0.3621 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3616 - acc: 0.8497 - val_loss: 0.3541 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3335 - acc: 0.8549 - val_loss: 0.3375 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3068 - acc: 0.8653 - val_loss: 0.3269 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2946 - acc: 0.8756 - val_loss: 0.3287 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2953 - acc: 0.8601 - val_loss: 0.3257 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2898 - acc: 0.8705 - val_loss: 0.3179 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2745 - acc: 0.9016 - val_loss: 0.3189 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2578 - acc: 0.9067 - val_loss: 0.3316 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2452 - acc: 0.9016 - val_loss: 0.3476 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2349 - acc: 0.9067 - val_loss: 0.3598 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2243 - acc: 0.9171 - val_loss: 0.3632 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1ca310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7427 - acc: 0.5596 - val_loss: 0.4066 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4150 - acc: 0.8135 - val_loss: 0.3993 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4001 - acc: 0.8238 - val_loss: 0.3801 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3690 - acc: 0.8497 - val_loss: 0.3468 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3225 - acc: 0.8497 - val_loss: 0.3457 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2983 - acc: 0.8756 - val_loss: 0.3810 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2866 - acc: 0.9067 - val_loss: 0.4240 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2690 - acc: 0.9223 - val_loss: 0.4587 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2511 - acc: 0.9171 - val_loss: 0.4848 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2387 - acc: 0.9119 - val_loss: 0.5099 - val_acc: 0.8852\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4742ef1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0612 - acc: 0.4588 - val_loss: 0.4265 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4370 - acc: 0.8041 - val_loss: 0.4192 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3854 - acc: 0.8351 - val_loss: 0.4345 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3602 - acc: 0.8505 - val_loss: 0.4308 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3328 - acc: 0.8557 - val_loss: 0.4228 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3117 - acc: 0.8711 - val_loss: 0.4190 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2983 - acc: 0.8866 - val_loss: 0.3986 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2853 - acc: 0.8763 - val_loss: 0.3734 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2757 - acc: 0.8866 - val_loss: 0.3608 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2656 - acc: 0.8711 - val_loss: 0.3664 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2492 - acc: 0.8969 - val_loss: 0.3879 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2325 - acc: 0.8918 - val_loss: 0.4056 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2186 - acc: 0.9072 - val_loss: 0.4118 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2046 - acc: 0.9175 - val_loss: 0.4241 - val_acc: 0.9016\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4184f63a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8040 - acc: 0.5412 - val_loss: 0.4539 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4607 - acc: 0.7835 - val_loss: 0.4262 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4182 - acc: 0.8041 - val_loss: 0.4079 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3795 - acc: 0.8299 - val_loss: 0.3787 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3500 - acc: 0.8557 - val_loss: 0.3477 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3330 - acc: 0.8660 - val_loss: 0.3202 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3227 - acc: 0.8660 - val_loss: 0.3055 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3133 - acc: 0.8660 - val_loss: 0.3050 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2974 - acc: 0.8608 - val_loss: 0.3195 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2786 - acc: 0.8660 - val_loss: 0.3389 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2604 - acc: 0.8711 - val_loss: 0.3606 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2413 - acc: 0.9124 - val_loss: 0.3874 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2209 - acc: 0.9175 - val_loss: 0.4236 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa448596c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7165 - acc: 0.5825 - val_loss: 0.4014 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4465 - acc: 0.8041 - val_loss: 0.3315 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3827 - acc: 0.8299 - val_loss: 0.3214 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3371 - acc: 0.8505 - val_loss: 0.3429 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3142 - acc: 0.8557 - val_loss: 0.3720 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2982 - acc: 0.8660 - val_loss: 0.3831 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2806 - acc: 0.8814 - val_loss: 0.3816 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2628 - acc: 0.8918 - val_loss: 0.3950 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3786e5670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7706 - acc: 0.5285 - val_loss: 0.3310 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3600 - acc: 0.8601 - val_loss: 0.3461 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3649 - acc: 0.8601 - val_loss: 0.3555 - val_acc: 0.9180\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3289 - acc: 0.8601 - val_loss: 0.3861 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2871 - acc: 0.9016 - val_loss: 0.4780 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2562 - acc: 0.9067 - val_loss: 0.5329 - val_acc: 0.7705\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b8295790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9345 - acc: 0.3782 - val_loss: 0.3969 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4024 - acc: 0.8446 - val_loss: 0.4152 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4190 - acc: 0.8497 - val_loss: 0.3779 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3713 - acc: 0.8497 - val_loss: 0.3241 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3207 - acc: 0.8653 - val_loss: 0.3317 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2837 - acc: 0.8964 - val_loss: 0.3779 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2738 - acc: 0.8964 - val_loss: 0.4016 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2562 - acc: 0.9171 - val_loss: 0.4232 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2325 - acc: 0.9119 - val_loss: 0.4640 - val_acc: 0.9016\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3785a8040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0001 - acc: 0.5258 - val_loss: 0.3727 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4011 - acc: 0.8247 - val_loss: 0.4092 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3776 - acc: 0.8505 - val_loss: 0.4079 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3291 - acc: 0.8660 - val_loss: 0.4122 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3038 - acc: 0.8608 - val_loss: 0.4291 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3039 - acc: 0.8402 - val_loss: 0.4198 - val_acc: 0.8197\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa378697040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6174 - acc: 0.6443 - val_loss: 0.4286 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4270 - acc: 0.8247 - val_loss: 0.3951 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3731 - acc: 0.8557 - val_loss: 0.3277 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3253 - acc: 0.8608 - val_loss: 0.3292 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3303 - acc: 0.8557 - val_loss: 0.3588 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2757 - acc: 0.8814 - val_loss: 0.4217 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2639 - acc: 0.8866 - val_loss: 0.4472 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2436 - acc: 0.8969 - val_loss: 0.4538 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3781cf4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6863 - acc: 0.5309 - val_loss: 0.4010 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4210 - acc: 0.8351 - val_loss: 0.4030 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3687 - acc: 0.8608 - val_loss: 0.3669 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3196 - acc: 0.8814 - val_loss: 0.3572 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3235 - acc: 0.8814 - val_loss: 0.3317 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2667 - acc: 0.8969 - val_loss: 0.4003 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2504 - acc: 0.8918 - val_loss: 0.4891 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2391 - acc: 0.9072 - val_loss: 0.5339 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2138 - acc: 0.9124 - val_loss: 0.5191 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1879 - acc: 0.9278 - val_loss: 0.5118 - val_acc: 0.8033\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3544c2ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8334 - acc: 0.3420 - val_loss: 0.4512 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4504 - acc: 0.8238 - val_loss: 0.4248 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3584 - acc: 0.8601 - val_loss: 0.5137 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3754 - acc: 0.8187 - val_loss: 0.2921 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3257 - acc: 0.8549 - val_loss: 0.3421 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2845 - acc: 0.8860 - val_loss: 0.4538 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2721 - acc: 0.9119 - val_loss: 0.5053 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2475 - acc: 0.9223 - val_loss: 0.5053 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2062 - acc: 0.9223 - val_loss: 0.5123 - val_acc: 0.8197\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3781cfdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.7902 - acc: 0.4197 - val_loss: 0.5298 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5073 - acc: 0.8187 - val_loss: 0.4447 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4170 - acc: 0.8394 - val_loss: 0.3482 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3769 - acc: 0.8497 - val_loss: 0.5879 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4683 - acc: 0.7720 - val_loss: 0.4162 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2800 - acc: 0.8808 - val_loss: 0.4480 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3412 - acc: 0.8497 - val_loss: 0.4652 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3544 - acc: 0.8705 - val_loss: 0.4672 - val_acc: 0.9016\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3781cf0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6915 - acc: 0.5464 - val_loss: 0.4167 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3997 - acc: 0.8505 - val_loss: 0.3677 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3319 - acc: 0.8557 - val_loss: 0.3981 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3039 - acc: 0.8505 - val_loss: 0.3911 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2246 - acc: 0.9124 - val_loss: 0.4163 - val_acc: 0.8361\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2151 - acc: 0.9227 - val_loss: 0.4474 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1819 - acc: 0.9381 - val_loss: 0.5466 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e71700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6478 - acc: 0.5567 - val_loss: 0.3904 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5225 - acc: 0.8247 - val_loss: 0.3961 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4510 - acc: 0.8608 - val_loss: 0.2710 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3545 - acc: 0.8866 - val_loss: 0.3408 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2943 - acc: 0.8814 - val_loss: 0.4154 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2677 - acc: 0.9072 - val_loss: 0.5274 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2466 - acc: 0.8969 - val_loss: 0.5265 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2162 - acc: 0.9021 - val_loss: 0.5068 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3781cfdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8616 - acc: 0.5155 - val_loss: 0.6133 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5091 - acc: 0.8247 - val_loss: 0.5931 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4052 - acc: 0.8557 - val_loss: 0.5078 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3551 - acc: 0.8247 - val_loss: 0.3291 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4237 - acc: 0.8196 - val_loss: 0.3331 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2798 - acc: 0.8814 - val_loss: 0.5759 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3040 - acc: 0.8763 - val_loss: 0.6264 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2732 - acc: 0.9072 - val_loss: 0.6384 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2659 - acc: 0.9175 - val_loss: 0.6272 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa378300670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7859 - acc: 0.4352 - val_loss: 0.5323 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5949 - acc: 0.8342 - val_loss: 0.3498 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3702 - acc: 0.8808 - val_loss: 0.7266 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5622 - acc: 0.7824 - val_loss: 0.4524 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2883 - acc: 0.9223 - val_loss: 0.5150 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3791 - acc: 0.8964 - val_loss: 0.5475 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3661 - acc: 0.9119 - val_loss: 0.5695 - val_acc: 0.9016\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4742ef430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7106 - acc: 0.5181 - val_loss: 0.5382 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6523 - acc: 0.8238 - val_loss: 0.3281 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4523 - acc: 0.8342 - val_loss: 0.6997 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4549 - acc: 0.8394 - val_loss: 0.4108 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2941 - acc: 0.8653 - val_loss: 0.4327 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2799 - acc: 0.8705 - val_loss: 0.6384 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2510 - acc: 0.9119 - val_loss: 0.7267 - val_acc: 0.8033\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4104925e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7793 - acc: 0.5206 - val_loss: 0.7993 - val_acc: 0.7705\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6275 - acc: 0.8144 - val_loss: 0.6493 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3705 - acc: 0.8608 - val_loss: 0.3717 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3939 - acc: 0.8454 - val_loss: 0.6667 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4992 - acc: 0.7165 - val_loss: 0.6069 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4386 - acc: 0.8814 - val_loss: 0.7352 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6531 - acc: 0.8814 - val_loss: 0.7471 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6981 - acc: 0.8866 - val_loss: 0.7122 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc1e9c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7841 - acc: 0.3711 - val_loss: 0.7847 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6424 - acc: 0.8093 - val_loss: 0.4721 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4491 - acc: 0.8505 - val_loss: 1.0556 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9341 - acc: 0.5825 - val_loss: 0.7718 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4649 - acc: 0.8608 - val_loss: 1.2936 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7617 - acc: 0.8505 - val_loss: 1.5999 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8606 - acc: 0.8505 - val_loss: 1.7109 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0e0d040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7523 - acc: 0.3969 - val_loss: 0.5699 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5937 - acc: 0.8299 - val_loss: 0.3822 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3988 - acc: 0.8351 - val_loss: 1.3583 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0415 - acc: 0.6134 - val_loss: 0.3403 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3234 - acc: 0.8918 - val_loss: 0.4762 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5107 - acc: 0.8608 - val_loss: 0.6407 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6007 - acc: 0.8763 - val_loss: 0.6879 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5739 - acc: 0.8763 - val_loss: 0.6481 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5086 - acc: 0.9021 - val_loss: 0.7481 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0ea4ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7329 - acc: 0.4767 - val_loss: 0.9030 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8456 - acc: 0.8497 - val_loss: 0.7174 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7370 - acc: 0.7150 - val_loss: 1.3978 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7152 - acc: 0.8135 - val_loss: 1.9315 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0484 - acc: 0.8964 - val_loss: 2.2986 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2274 - acc: 0.8912 - val_loss: 2.3662 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0756 - acc: 0.9016 - val_loss: 2.3092 - val_acc: 0.8852\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac18d820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7958 - acc: 0.3264 - val_loss: 0.5130 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7302 - acc: 0.8394 - val_loss: 1.9575 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.8130 - acc: 0.6736 - val_loss: 3.1603 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.5733 - acc: 0.5233 - val_loss: 2.1889 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2403 - acc: 0.8601 - val_loss: 2.5595 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5464 - acc: 0.8653 - val_loss: 2.6674 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41014b040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7040 - acc: 0.4897 - val_loss: 0.9689 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8243 - acc: 0.8247 - val_loss: 0.8913 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6735 - acc: 0.7732 - val_loss: 1.1144 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5522 - acc: 0.8660 - val_loss: 1.6978 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6016 - acc: 0.8557 - val_loss: 1.6791 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4736 - acc: 0.8969 - val_loss: 1.6349 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3634 - acc: 0.9175 - val_loss: 1.6407 - val_acc: 0.7869\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac4945e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6432 - acc: 0.6134 - val_loss: 1.0728 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9640 - acc: 0.8144 - val_loss: 0.6921 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7121 - acc: 0.7216 - val_loss: 0.6136 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7247 - acc: 0.8247 - val_loss: 0.6929 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8187 - acc: 0.8454 - val_loss: 0.5686 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5887 - acc: 0.8505 - val_loss: 0.4557 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3657 - acc: 0.8608 - val_loss: 0.5591 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3026 - acc: 0.8454 - val_loss: 0.6530 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2837 - acc: 0.8454 - val_loss: 0.6360 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2494 - acc: 0.9124 - val_loss: 0.5777 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2157 - acc: 0.9330 - val_loss: 0.5516 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa378738040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7611 - acc: 0.4175 - val_loss: 1.0695 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9490 - acc: 0.8041 - val_loss: 1.2766 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1937 - acc: 0.6289 - val_loss: 0.4716 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7671 - acc: 0.8454 - val_loss: 0.6452 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1118 - acc: 0.8454 - val_loss: 0.7100 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1770 - acc: 0.8505 - val_loss: 0.9108 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9645 - acc: 0.8557 - val_loss: 0.8839 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6905 - acc: 0.9124 - val_loss: 0.9282 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa42038cb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7066 - acc: 0.4922 - val_loss: 1.7486 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3715 - acc: 0.8290 - val_loss: 6.0648 - val_acc: 0.2787\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.5633 - acc: 0.3523 - val_loss: 1.9591 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4828 - acc: 0.8653 - val_loss: 3.9793 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.6233 - acc: 0.8446 - val_loss: 5.1243 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.0893 - acc: 0.8446 - val_loss: 5.5150 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4584e9160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6827 - acc: 0.5544 - val_loss: 1.0926 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2948 - acc: 0.8394 - val_loss: 11.4834 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.2234 - acc: 0.5337 - val_loss: 1.4343 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9741 - acc: 0.8653 - val_loss: 3.5810 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.9956 - acc: 0.8342 - val_loss: 4.4389 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.0889 - acc: 0.8601 - val_loss: 4.6275 - val_acc: 0.8033\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410300670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6850 - acc: 0.5567 - val_loss: 1.3286 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2871 - acc: 0.8454 - val_loss: 6.2618 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.9080 - acc: 0.4794 - val_loss: 2.2363 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4102 - acc: 0.8402 - val_loss: 4.4979 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.3633 - acc: 0.8557 - val_loss: 6.2074 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.5409 - acc: 0.8711 - val_loss: 7.3647 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa39422e8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7134 - acc: 0.5103 - val_loss: 0.8677 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4143 - acc: 0.8247 - val_loss: 9.7449 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.1712 - acc: 0.5722 - val_loss: 3.7583 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.2463 - acc: 0.4794 - val_loss: 3.5548 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3036 - acc: 0.8351 - val_loss: 4.5001 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.9721 - acc: 0.8299 - val_loss: 4.7917 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3785b88b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6933 - acc: 0.5052 - val_loss: 0.9737 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3134 - acc: 0.8247 - val_loss: 9.3440 - val_acc: 0.2623\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.4810 - acc: 0.4124 - val_loss: 2.1521 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5730 - acc: 0.8505 - val_loss: 4.2291 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.8381 - acc: 0.8351 - val_loss: 5.3011 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.0842 - acc: 0.8402 - val_loss: 5.5982 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3546060d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7724 - acc: 0.5078 - val_loss: 0.4049 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4261 - acc: 0.7876 - val_loss: 0.4049 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3873 - acc: 0.8238 - val_loss: 0.3349 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3605 - acc: 0.8497 - val_loss: 0.2891 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3511 - acc: 0.8549 - val_loss: 0.3087 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3255 - acc: 0.8653 - val_loss: 0.3182 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3106 - acc: 0.8653 - val_loss: 0.3107 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2943 - acc: 0.8860 - val_loss: 0.3153 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2791 - acc: 0.8912 - val_loss: 0.2888 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3139 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2548 - acc: 0.8964 - val_loss: 0.3540 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2426 - acc: 0.9171 - val_loss: 0.3697 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2320 - acc: 0.9119 - val_loss: 0.4083 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2259 - acc: 0.8964 - val_loss: 0.4492 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa35418b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7107 - acc: 0.5130 - val_loss: 0.6575 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5255 - acc: 0.7824 - val_loss: 0.4827 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3992 - acc: 0.8394 - val_loss: 0.3670 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3846 - acc: 0.8497 - val_loss: 0.2997 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3934 - acc: 0.8342 - val_loss: 0.2796 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3612 - acc: 0.8446 - val_loss: 0.3123 - val_acc: 0.9180\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3139 - acc: 0.8446 - val_loss: 0.4279 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3584 - acc: 0.8290 - val_loss: 0.4170 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3060 - acc: 0.8549 - val_loss: 0.4067 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2943 - acc: 0.8653 - val_loss: 0.4090 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3541cc430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8360 - acc: 0.3763 - val_loss: 0.4573 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4379 - acc: 0.8299 - val_loss: 0.3585 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3375 - acc: 0.8814 - val_loss: 0.3546 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3679 - acc: 0.8711 - val_loss: 0.3513 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3654 - acc: 0.8711 - val_loss: 0.3500 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3216 - acc: 0.8814 - val_loss: 0.4006 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2894 - acc: 0.8763 - val_loss: 0.5004 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3377 - acc: 0.8660 - val_loss: 0.4266 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2697 - acc: 0.8660 - val_loss: 0.4351 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2768 - acc: 0.8660 - val_loss: 0.4779 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa354128af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7496 - acc: 0.5979 - val_loss: 0.3942 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4610 - acc: 0.8041 - val_loss: 0.3553 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4013 - acc: 0.8093 - val_loss: 0.3604 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3575 - acc: 0.8402 - val_loss: 0.3640 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3271 - acc: 0.8608 - val_loss: 0.3803 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3109 - acc: 0.8608 - val_loss: 0.4080 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3014 - acc: 0.8557 - val_loss: 0.4282 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41014b3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9145 - acc: 0.3608 - val_loss: 0.4551 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4445 - acc: 0.8093 - val_loss: 0.3678 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3889 - acc: 0.8351 - val_loss: 0.3695 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3902 - acc: 0.8299 - val_loss: 0.4024 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3640 - acc: 0.8454 - val_loss: 0.4398 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3498 - acc: 0.8402 - val_loss: 0.4291 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3436 - acc: 0.8608 - val_loss: 0.3920 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1ca5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6020 - acc: 0.6632 - val_loss: 0.7080 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6056 - acc: 0.8031 - val_loss: 0.5316 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4132 - acc: 0.8549 - val_loss: 0.4621 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3723 - acc: 0.8290 - val_loss: 0.3885 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4110 - acc: 0.8135 - val_loss: 0.3586 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3404 - acc: 0.8549 - val_loss: 0.4077 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2851 - acc: 0.8912 - val_loss: 0.5250 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2775 - acc: 0.9016 - val_loss: 0.6531 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3005 - acc: 0.8912 - val_loss: 0.5684 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2493 - acc: 0.9275 - val_loss: 0.5045 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4becf3af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7852 - acc: 0.4767 - val_loss: 0.4143 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5261 - acc: 0.7927 - val_loss: 0.2766 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3839 - acc: 0.8653 - val_loss: 0.4810 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4316 - acc: 0.8187 - val_loss: 0.5160 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3300 - acc: 0.8860 - val_loss: 0.6964 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3570 - acc: 0.8808 - val_loss: 0.7529 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3340 - acc: 0.8653 - val_loss: 0.7053 - val_acc: 0.8033\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa474704c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7540 - acc: 0.5464 - val_loss: 0.3668 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4672 - acc: 0.8247 - val_loss: 0.3339 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3686 - acc: 0.8814 - val_loss: 0.3804 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3533 - acc: 0.8351 - val_loss: 0.3549 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2748 - acc: 0.8918 - val_loss: 0.4021 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2517 - acc: 0.8918 - val_loss: 0.4606 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2340 - acc: 0.8969 - val_loss: 0.5245 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc2531f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6183 - acc: 0.7010 - val_loss: 0.5257 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4664 - acc: 0.8247 - val_loss: 0.3359 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3697 - acc: 0.8351 - val_loss: 0.4809 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3872 - acc: 0.8196 - val_loss: 0.3610 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3061 - acc: 0.8660 - val_loss: 0.3620 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3080 - acc: 0.8814 - val_loss: 0.4182 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2950 - acc: 0.8866 - val_loss: 0.4398 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b43dd160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8363 - acc: 0.4536 - val_loss: 0.5602 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5037 - acc: 0.7835 - val_loss: 0.3720 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4300 - acc: 0.8351 - val_loss: 0.4330 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3873 - acc: 0.7938 - val_loss: 0.4310 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3252 - acc: 0.8402 - val_loss: 0.4124 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3291 - acc: 0.8660 - val_loss: 0.4521 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3191 - acc: 0.8969 - val_loss: 0.4861 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc1e9310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7539 - acc: 0.5130 - val_loss: 0.5257 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6609 - acc: 0.7927 - val_loss: 0.3550 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4172 - acc: 0.8290 - val_loss: 1.9946 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7683 - acc: 0.6010 - val_loss: 0.4258 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3270 - acc: 0.8912 - val_loss: 0.4148 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5660 - acc: 0.8446 - val_loss: 0.5800 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6380 - acc: 0.8912 - val_loss: 0.7387 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa410492f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6415 - acc: 0.6632 - val_loss: 0.7011 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7340 - acc: 0.8342 - val_loss: 0.4886 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3803 - acc: 0.8601 - val_loss: 1.6219 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5432 - acc: 0.4611 - val_loss: 0.4672 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4125 - acc: 0.8601 - val_loss: 0.8145 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7055 - acc: 0.8497 - val_loss: 1.0738 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8777 - acc: 0.8497 - val_loss: 1.2133 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8846 - acc: 0.8549 - val_loss: 1.2921 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7973 - acc: 0.8756 - val_loss: 1.3438 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beb9f550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7115 - acc: 0.5464 - val_loss: 0.7519 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5873 - acc: 0.8247 - val_loss: 0.4716 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4460 - acc: 0.8247 - val_loss: 1.0408 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7808 - acc: 0.6237 - val_loss: 0.5018 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3776 - acc: 0.8660 - val_loss: 0.5257 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5488 - acc: 0.8557 - val_loss: 0.6561 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6095 - acc: 0.8711 - val_loss: 0.7881 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4742efb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7474 - acc: 0.4845 - val_loss: 0.8882 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6464 - acc: 0.8093 - val_loss: 0.8307 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5626 - acc: 0.7732 - val_loss: 0.5112 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8090 - acc: 0.7732 - val_loss: 0.6486 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7317 - acc: 0.8454 - val_loss: 0.8394 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6643 - acc: 0.8402 - val_loss: 0.9260 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5319 - acc: 0.8454 - val_loss: 0.9332 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4110 - acc: 0.8402 - val_loss: 0.9394 - val_acc: 0.6721\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3306d0dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0219 - acc: 0.3711 - val_loss: 0.3792 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5684 - acc: 0.7835 - val_loss: 0.4308 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4405 - acc: 0.8402 - val_loss: 0.4306 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4437 - acc: 0.8093 - val_loss: 0.6488 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3719 - acc: 0.8711 - val_loss: 0.6318 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3336 - acc: 0.8763 - val_loss: 0.4981 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4201bf820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6583 - acc: 0.6114 - val_loss: 0.8766 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9202 - acc: 0.8238 - val_loss: 0.5765 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6059 - acc: 0.7927 - val_loss: 2.3489 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.6731 - acc: 0.5648 - val_loss: 0.9659 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5828 - acc: 0.9067 - val_loss: 1.0102 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8733 - acc: 0.8705 - val_loss: 0.9975 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0220 - acc: 0.8601 - val_loss: 0.9821 - val_acc: 0.8852\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa418647ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7383 - acc: 0.5130 - val_loss: 0.7123 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8056 - acc: 0.8394 - val_loss: 1.3002 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2440 - acc: 0.5907 - val_loss: 1.1666 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8382 - acc: 0.8653 - val_loss: 2.0555 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2163 - acc: 0.8497 - val_loss: 2.4981 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1921 - acc: 0.8601 - val_loss: 2.5905 - val_acc: 0.8197\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41041a310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7770 - acc: 0.5155 - val_loss: 1.0109 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8278 - acc: 0.8144 - val_loss: 2.0933 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2125 - acc: 0.5000 - val_loss: 0.9201 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0046 - acc: 0.8041 - val_loss: 1.2710 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3511 - acc: 0.8557 - val_loss: 2.0509 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7943 - acc: 0.8505 - val_loss: 2.5381 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.9033 - acc: 0.8402 - val_loss: 2.7459 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7877 - acc: 0.8505 - val_loss: 2.7478 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4587b8550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7953 - acc: 0.5103 - val_loss: 0.8419 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8906 - acc: 0.8093 - val_loss: 2.9523 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2654 - acc: 0.4175 - val_loss: 0.9980 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9475 - acc: 0.8557 - val_loss: 1.8606 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.6529 - acc: 0.8351 - val_loss: 2.2980 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.9483 - acc: 0.8299 - val_loss: 2.3921 - val_acc: 0.8033\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3783b3ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7850 - acc: 0.5258 - val_loss: 1.9398 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2124 - acc: 0.7577 - val_loss: 1.1854 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9358 - acc: 0.8454 - val_loss: 0.6137 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7571 - acc: 0.8351 - val_loss: 0.5897 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6490 - acc: 0.7784 - val_loss: 1.9987 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.6382 - acc: 0.5825 - val_loss: 0.9809 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6253 - acc: 0.8711 - val_loss: 1.2341 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9882 - acc: 0.8608 - val_loss: 1.3269 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1246 - acc: 0.8660 - val_loss: 1.3275 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3783b3280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7254 - acc: 0.5026 - val_loss: 1.6427 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3544 - acc: 0.8394 - val_loss: 5.7443 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.0611 - acc: 0.3886 - val_loss: 1.9354 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4714 - acc: 0.8756 - val_loss: 3.7502 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.6459 - acc: 0.8756 - val_loss: 4.7619 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.1775 - acc: 0.8756 - val_loss: 5.1143 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3944b8040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6374 - acc: 0.7202 - val_loss: 1.4848 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7242 - acc: 0.8031 - val_loss: 6.9095 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.1019 - acc: 0.4508 - val_loss: 1.8189 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7603 - acc: 0.8446 - val_loss: 3.5265 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.9096 - acc: 0.8497 - val_loss: 4.6335 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.2606 - acc: 0.8394 - val_loss: 4.9869 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa378139700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6259 - acc: 0.6340 - val_loss: 1.2080 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4790 - acc: 0.8454 - val_loss: 9.5866 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.6699 - acc: 0.5825 - val_loss: 7.0544 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.2677 - acc: 0.4794 - val_loss: 3.6773 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.6135 - acc: 0.8557 - val_loss: 4.7814 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3344 - acc: 0.8557 - val_loss: 5.6142 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3541c43a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7736 - acc: 0.4588 - val_loss: 1.7957 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.4231 - acc: 0.5722 - val_loss: 1.7147 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3767 - acc: 0.8247 - val_loss: 3.4552 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3804 - acc: 0.6907 - val_loss: 2.9694 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4748 - acc: 0.8454 - val_loss: 2.7916 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.5718 - acc: 0.8608 - val_loss: 2.5467 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4180 - acc: 0.8763 - val_loss: 2.1943 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa35418a430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6985 - acc: 0.5515 - val_loss: 1.5499 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4474 - acc: 0.8196 - val_loss: 7.8319 - val_acc: 0.2787\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.4665 - acc: 0.3711 - val_loss: 2.7381 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6472 - acc: 0.8660 - val_loss: 4.9083 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.0000 - acc: 0.8608 - val_loss: 6.1599 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.6031 - acc: 0.8402 - val_loss: 6.5492 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3307c1e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7087 - acc: 0.4508 - val_loss: 1.5398 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7373 - acc: 0.8342 - val_loss: 35.4264 - val_acc: 0.1803\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 27.7615 - acc: 0.2850 - val_loss: 1.9713 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.8450 - acc: 0.8860 - val_loss: 6.0366 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.0967 - acc: 0.8601 - val_loss: 8.5740 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.6009 - acc: 0.8549 - val_loss: 9.4505 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3305c1dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6874 - acc: 0.5389 - val_loss: 1.1560 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1400 - acc: 0.8238 - val_loss: 17.6987 - val_acc: 0.2951\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 13.5576 - acc: 0.4508 - val_loss: 4.1757 - val_acc: 0.8361\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step - loss: 3.0681 - acc: 0.8549 - val_loss: 7.8872 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.3341 - acc: 0.8446 - val_loss: 9.5414 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.5522 - acc: 0.8342 - val_loss: 9.9080 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac4948b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6879 - acc: 0.4948 - val_loss: 2.4073 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.1401 - acc: 0.8041 - val_loss: 27.1621 - val_acc: 0.2295\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 21.4192 - acc: 0.2629 - val_loss: 3.3015 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.4711 - acc: 0.8505 - val_loss: 7.7755 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.9281 - acc: 0.8557 - val_loss: 11.1065 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.3420 - acc: 0.8454 - val_loss: 13.1228 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac1cab80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6837 - acc: 0.5619 - val_loss: 1.2303 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.1676 - acc: 0.7887 - val_loss: 15.1121 - val_acc: 0.3115\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 12.3593 - acc: 0.4021 - val_loss: 4.7894 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.6861 - acc: 0.8557 - val_loss: 8.5730 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.9002 - acc: 0.8402 - val_loss: 10.0693 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.4324 - acc: 0.8505 - val_loss: 10.2631 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa394457af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7382 - acc: 0.4124 - val_loss: 1.0792 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3439 - acc: 0.8144 - val_loss: 5.8812 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8047 - acc: 0.7320 - val_loss: 2.0724 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.6017 - acc: 0.8196 - val_loss: 3.3546 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.5593 - acc: 0.8557 - val_loss: 4.3915 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.7027 - acc: 0.8660 - val_loss: 3.8288 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b4428670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7511 - acc: 0.4041 - val_loss: 1.9146 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.9423 - acc: 0.8083 - val_loss: 27.5428 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 21.4272 - acc: 0.5492 - val_loss: 12.8377 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 12.3639 - acc: 0.6373 - val_loss: 9.2607 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.3537 - acc: 0.8601 - val_loss: 14.3423 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 11.5273 - acc: 0.8549 - val_loss: 16.8369 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4742efc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6727 - acc: 0.6218 - val_loss: 1.7476 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.1209 - acc: 0.8446 - val_loss: 77.2499 - val_acc: 0.1803\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 57.3006 - acc: 0.2850 - val_loss: 4.0965 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.0032 - acc: 0.8497 - val_loss: 12.4608 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.2910 - acc: 0.8601 - val_loss: 16.1154 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.5674 - acc: 0.8497 - val_loss: 16.7430 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b4428a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6872 - acc: 0.5361 - val_loss: 2.5463 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.2363 - acc: 0.8351 - val_loss: 21.8410 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 20.9958 - acc: 0.4588 - val_loss: 9.1433 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.8101 - acc: 0.8196 - val_loss: 8.5628 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.3333 - acc: 0.8557 - val_loss: 6.6633 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 9.3261 - acc: 0.8351 - val_loss: 6.6263 - val_acc: 0.9016\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b43dd9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6841 - acc: 0.5464 - val_loss: 3.6141 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.7263 - acc: 0.7990 - val_loss: 88.8574 - val_acc: 0.1967\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 68.6472 - acc: 0.2474 - val_loss: 4.2049 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.2590 - acc: 0.8093 - val_loss: 10.6076 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.1071 - acc: 0.8505 - val_loss: 15.1733 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 12.4116 - acc: 0.8402 - val_loss: 16.5146 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0ea45e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7162 - acc: 0.5000 - val_loss: 4.3665 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.3101 - acc: 0.7835 - val_loss: 45.6476 - val_acc: 0.2459\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 35.3703 - acc: 0.3093 - val_loss: 6.0386 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.3975 - acc: 0.8351 - val_loss: 12.4546 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 10.8338 - acc: 0.8505 - val_loss: 18.1141 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 13.0860 - acc: 0.8505 - val_loss: 20.7051 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4becf3670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7573 - acc: 0.5337 - val_loss: 0.5010 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4290 - acc: 0.8549 - val_loss: 0.3829 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4185 - acc: 0.8187 - val_loss: 0.5002 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3836 - acc: 0.8290 - val_loss: 0.4951 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3499 - acc: 0.8601 - val_loss: 0.3962 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3131 - acc: 0.8705 - val_loss: 0.2858 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3180 - acc: 0.8549 - val_loss: 0.3331 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2772 - acc: 0.8756 - val_loss: 0.4353 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2804 - acc: 0.8912 - val_loss: 0.4412 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2727 - acc: 0.8964 - val_loss: 0.3949 - val_acc: 0.9180\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2587 - acc: 0.8964 - val_loss: 0.4051 - val_acc: 0.9180\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4beca4790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8813 - acc: 0.4560 - val_loss: 0.4233 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4831 - acc: 0.8290 - val_loss: 0.4621 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4425 - acc: 0.8083 - val_loss: 0.3431 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3581 - acc: 0.8290 - val_loss: 0.3216 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3514 - acc: 0.8549 - val_loss: 0.3954 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3078 - acc: 0.8705 - val_loss: 0.4404 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2857 - acc: 0.8964 - val_loss: 0.4986 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2827 - acc: 0.8808 - val_loss: 0.5707 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2754 - acc: 0.8756 - val_loss: 0.5379 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4582f10d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7027 - acc: 0.5052 - val_loss: 0.3605 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4002 - acc: 0.8093 - val_loss: 0.5268 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4324 - acc: 0.8093 - val_loss: 0.3680 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4279 - acc: 0.8144 - val_loss: 0.4495 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4487 - acc: 0.8557 - val_loss: 0.4756 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4265 - acc: 0.8763 - val_loss: 0.4172 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3786061f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9462 - acc: 0.5361 - val_loss: 0.5054 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4719 - acc: 0.7887 - val_loss: 0.3151 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3847 - acc: 0.8402 - val_loss: 0.5008 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5212 - acc: 0.7165 - val_loss: 0.3510 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3962 - acc: 0.8557 - val_loss: 0.3820 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5228 - acc: 0.8505 - val_loss: 0.3415 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5678 - acc: 0.8557 - val_loss: 0.3101 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5698 - acc: 0.8454 - val_loss: 0.3753 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4962 - acc: 0.8660 - val_loss: 0.4434 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4385 - acc: 0.8763 - val_loss: 0.4370 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3790 - acc: 0.8608 - val_loss: 0.4002 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3468 - acc: 0.8351 - val_loss: 0.4673 - val_acc: 0.7541\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa448077e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7413 - acc: 0.5876 - val_loss: 0.4066 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6767 - acc: 0.7938 - val_loss: 0.4189 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5396 - acc: 0.8505 - val_loss: 0.3556 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3742 - acc: 0.8608 - val_loss: 0.3509 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4133 - acc: 0.7990 - val_loss: 0.6633 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4006 - acc: 0.8660 - val_loss: 0.9302 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5215 - acc: 0.8505 - val_loss: 0.8657 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4477 - acc: 0.8608 - val_loss: 0.6371 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3418 - acc: 0.8608 - val_loss: 0.4410 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4480775e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2385 - acc: 0.3161 - val_loss: 0.4628 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4633 - acc: 0.8497 - val_loss: 0.4430 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5055 - acc: 0.7565 - val_loss: 0.6209 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4351 - acc: 0.8497 - val_loss: 0.9062 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4937 - acc: 0.8653 - val_loss: 0.9311 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4528 - acc: 0.8756 - val_loss: 0.8033 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4838 - acc: 0.8756 - val_loss: 0.7036 - val_acc: 0.9016\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3942e5670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8867 - acc: 0.5699 - val_loss: 1.3722 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0499 - acc: 0.7461 - val_loss: 0.9007 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6931 - acc: 0.8342 - val_loss: 0.5886 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5877 - acc: 0.8290 - val_loss: 0.3287 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4333 - acc: 0.8238 - val_loss: 0.6078 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5945 - acc: 0.6839 - val_loss: 0.3471 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3018 - acc: 0.8653 - val_loss: 0.4705 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3381 - acc: 0.8497 - val_loss: 0.5942 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3440 - acc: 0.8549 - val_loss: 0.7124 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3786e58b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8258 - acc: 0.4948 - val_loss: 0.4710 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5506 - acc: 0.8299 - val_loss: 0.7034 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6955 - acc: 0.7526 - val_loss: 1.2996 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9650 - acc: 0.6598 - val_loss: 1.3107 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6357 - acc: 0.8711 - val_loss: 1.5731 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8310 - acc: 0.8711 - val_loss: 1.7427 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa39457e9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8002 - acc: 0.4691 - val_loss: 0.5414 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6968 - acc: 0.7990 - val_loss: 0.5251 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5705 - acc: 0.8351 - val_loss: 0.5987 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3972 - acc: 0.8557 - val_loss: 0.7210 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5708 - acc: 0.7268 - val_loss: 1.0244 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4943 - acc: 0.8505 - val_loss: 1.3640 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6276 - acc: 0.8505 - val_loss: 1.3843 - val_acc: 0.8033\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa378358040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0640 - acc: 0.4897 - val_loss: 0.4494 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5926 - acc: 0.8351 - val_loss: 0.5034 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7940 - acc: 0.7165 - val_loss: 0.7665 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5302 - acc: 0.8196 - val_loss: 1.1109 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6387 - acc: 0.8299 - val_loss: 1.0544 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5981 - acc: 0.8608 - val_loss: 0.9364 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3542214c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8672 - acc: 0.4249 - val_loss: 0.5868 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8853 - acc: 0.8031 - val_loss: 2.3047 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.9983 - acc: 0.5596 - val_loss: 0.6336 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6834 - acc: 0.8756 - val_loss: 0.7709 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1639 - acc: 0.8187 - val_loss: 0.9737 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2545 - acc: 0.8705 - val_loss: 1.0115 - val_acc: 0.9016\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa33079ca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6845 - acc: 0.5959 - val_loss: 0.5215 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9550 - acc: 0.8290 - val_loss: 0.3494 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5842 - acc: 0.8083 - val_loss: 1.5337 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9596 - acc: 0.8549 - val_loss: 0.9891 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6337 - acc: 0.8601 - val_loss: 1.4264 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1952 - acc: 0.7358 - val_loss: 1.2759 - val_acc: 0.8197\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4825 - acc: 0.8705 - val_loss: 1.9712 - val_acc: 0.7705\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3307c8700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7469 - acc: 0.5361 - val_loss: 0.5646 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6065 - acc: 0.8402 - val_loss: 6.4037 - val_acc: 0.2295\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.8754 - acc: 0.2320 - val_loss: 0.8236 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6837 - acc: 0.8454 - val_loss: 1.6070 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3904 - acc: 0.8660 - val_loss: 2.2086 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8260 - acc: 0.8660 - val_loss: 2.6075 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3306f6790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 0.6526 - acc: 0.6031 - val_loss: 0.6640 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7075 - acc: 0.8196 - val_loss: 4.7217 - val_acc: 0.2459\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.4177 - acc: 0.3196 - val_loss: 1.0397 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9016 - acc: 0.8505 - val_loss: 1.9547 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5871 - acc: 0.8608 - val_loss: 2.5550 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.0087 - acc: 0.8763 - val_loss: 2.8423 - val_acc: 0.8197\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bc313e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6630 - acc: 0.6082 - val_loss: 1.4205 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0559 - acc: 0.7990 - val_loss: 3.0799 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9156 - acc: 0.5361 - val_loss: 2.9966 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.2223 - acc: 0.6186 - val_loss: 0.9982 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2186 - acc: 0.8402 - val_loss: 2.0450 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.6572 - acc: 0.8505 - val_loss: 2.8066 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.7977 - acc: 0.8557 - val_loss: 3.1321 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6445 - acc: 0.8711 - val_loss: 3.2130 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4892 - acc: 0.8454 - val_loss: 3.1367 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa33079c040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6900 - acc: 0.5492 - val_loss: 1.8457 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3361 - acc: 0.8187 - val_loss: 9.8670 - val_acc: 0.2131\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.4811 - acc: 0.2694 - val_loss: 1.8950 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4689 - acc: 0.8705 - val_loss: 4.2617 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.8313 - acc: 0.8601 - val_loss: 5.7913 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.4768 - acc: 0.8653 - val_loss: 6.5899 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41014b3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6963 - acc: 0.5596 - val_loss: 1.8795 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5619 - acc: 0.8135 - val_loss: 11.3514 - val_acc: 0.2295\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 10.1367 - acc: 0.2850 - val_loss: 1.5277 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4428 - acc: 0.8549 - val_loss: 3.2383 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.8562 - acc: 0.8497 - val_loss: 4.3911 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.4226 - acc: 0.8342 - val_loss: 4.8568 - val_acc: 0.8525\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step - loss: 3.1913 - acc: 0.8497 - val_loss: 4.9986 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.6748 - acc: 0.8653 - val_loss: 5.1630 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa474704af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7462 - acc: 0.5103 - val_loss: 1.0637 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8604 - acc: 0.8505 - val_loss: 14.7553 - val_acc: 0.2131\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.4712 - acc: 0.2320 - val_loss: 2.3351 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4009 - acc: 0.8144 - val_loss: 4.2910 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.5326 - acc: 0.8814 - val_loss: 5.7704 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.4301 - acc: 0.8711 - val_loss: 6.5970 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4c0ea4820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7218 - acc: 0.5567 - val_loss: 0.8747 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7885 - acc: 0.7577 - val_loss: 2.7065 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7888 - acc: 0.8299 - val_loss: 4.8220 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8125 - acc: 0.5309 - val_loss: 1.3326 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8787 - acc: 0.8196 - val_loss: 1.5677 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.9333 - acc: 0.7526 - val_loss: 1.4502 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b43dd280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7195 - acc: 0.5773 - val_loss: 4.8202 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.3770 - acc: 0.4536 - val_loss: 1.1622 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2029 - acc: 0.8608 - val_loss: 2.9568 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.7994 - acc: 0.5825 - val_loss: 1.1829 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4666 - acc: 0.8402 - val_loss: 2.2517 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4268 - acc: 0.8814 - val_loss: 3.1000 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4737 - acc: 0.8660 - val_loss: 3.2814 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa47425b940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7502 - acc: 0.4352 - val_loss: 2.0321 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.5107 - acc: 0.8290 - val_loss: 35.2906 - val_acc: 0.2295\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 33.7504 - acc: 0.2073 - val_loss: 2.4261 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0931 - acc: 0.7979 - val_loss: 5.8250 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.3215 - acc: 0.8808 - val_loss: 8.2770 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.2196 - acc: 0.8601 - val_loss: 9.3873 - val_acc: 0.8852\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4b43dde50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7277 - acc: 0.5130 - val_loss: 1.0617 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7585 - acc: 0.8446 - val_loss: 33.0381 - val_acc: 0.1803\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 28.5573 - acc: 0.2332 - val_loss: 2.1645 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2666 - acc: 0.8187 - val_loss: 5.9276 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.9562 - acc: 0.8653 - val_loss: 8.4115 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.9180 - acc: 0.8860 - val_loss: 9.2346 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4ac494820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6606 - acc: 0.5979 - val_loss: 2.0245 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0940 - acc: 0.8144 - val_loss: 33.5804 - val_acc: 0.2295\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 28.0598 - acc: 0.2268 - val_loss: 2.8356 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9069 - acc: 0.8454 - val_loss: 7.3309 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1249 - acc: 0.8505 - val_loss: 10.4923 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.9379 - acc: 0.8454 - val_loss: 12.3004 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bed34d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7891 - acc: 0.4639 - val_loss: 2.0462 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.9176 - acc: 0.8041 - val_loss: 36.5746 - val_acc: 0.1803\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 32.3386 - acc: 0.2371 - val_loss: 3.1771 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.5366 - acc: 0.8247 - val_loss: 6.7940 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3049 - acc: 0.8402 - val_loss: 9.4069 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1639 - acc: 0.8454 - val_loss: 10.3965 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4bec57c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7851 - acc: 0.3660 - val_loss: 1.0390 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.0053 - acc: 0.8196 - val_loss: 13.5162 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.6784 - acc: 0.5773 - val_loss: 4.1836 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.0983 - acc: 0.6804 - val_loss: 4.8714 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.1308 - acc: 0.8608 - val_loss: 7.7073 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.1058 - acc: 0.8608 - val_loss: 9.0085 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4104bb670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6706 - acc: 0.5959 - val_loss: 3.6107 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.6211 - acc: 0.8238 - val_loss: 82.3804 - val_acc: 0.1803\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 71.3091 - acc: 0.2176 - val_loss: 5.3543 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.9475 - acc: 0.8238 - val_loss: 12.2913 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.2766 - acc: 0.8653 - val_loss: 18.4032 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 11.1122 - acc: 0.8342 - val_loss: 21.2382 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4485969d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7138 - acc: 0.5026 - val_loss: 6.7844 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.0552 - acc: 0.6269 - val_loss: 26.5229 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 23.6052 - acc: 0.5078 - val_loss: 15.0606 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 11.6277 - acc: 0.8342 - val_loss: 14.5561 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 12.1041 - acc: 0.8290 - val_loss: 13.2850 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 10.3392 - acc: 0.8342 - val_loss: 11.2569 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa448077040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6334 - acc: 0.6907 - val_loss: 4.4071 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.2447 - acc: 0.8144 - val_loss: 81.6680 - val_acc: 0.1967\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 70.9265 - acc: 0.2062 - val_loss: 5.3788 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.2162 - acc: 0.8299 - val_loss: 13.2872 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.0210 - acc: 0.8814 - val_loss: 20.2935 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 12.7546 - acc: 0.8763 - val_loss: 25.2621 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4107f3c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6671 - acc: 0.5773 - val_loss: 4.8206 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.6027 - acc: 0.8144 - val_loss: 93.1559 - val_acc: 0.1803\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 85.0259 - acc: 0.2320 - val_loss: 6.9797 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.9539 - acc: 0.7680 - val_loss: 12.1950 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.3985 - acc: 0.8557 - val_loss: 17.5426 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 13.2563 - acc: 0.8402 - val_loss: 19.7572 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa4107f3040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7197 - acc: 0.4227 - val_loss: 1.7913 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.7738 - acc: 0.7835 - val_loss: 43.8781 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 37.0335 - acc: 0.4794 - val_loss: 7.8872 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.1176 - acc: 0.7938 - val_loss: 5.6291 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.3201 - acc: 0.8299 - val_loss: 6.1606 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7106 - acc: 0.8557 - val_loss: 4.2261 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3b8062700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6932 - acc: 0.5233 - val_loss: 4.9986 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.9986 - acc: 0.8394 - val_loss: 116.2524 - val_acc: 0.2623\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 113.0760 - acc: 0.2435 - val_loss: 25.7988 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 18.9563 - acc: 0.7720 - val_loss: 30.6732 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 19.4255 - acc: 0.8601 - val_loss: 35.1735 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 25.0852 - acc: 0.8756 - val_loss: 34.9489 - val_acc: 0.8689\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa39457d940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7097 - acc: 0.4767 - val_loss: 30.4280 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 24.0745 - acc: 0.5751 - val_loss: 46.9206 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 35.5187 - acc: 0.5544 - val_loss: 23.7323 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.5146 - acc: 0.8549 - val_loss: 23.9327 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 19.4991 - acc: 0.8601 - val_loss: 22.5268 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.0821 - acc: 0.8549 - val_loss: 21.4010 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 14.2383 - acc: 0.8653 - val_loss: 25.1222 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 12.7751 - acc: 0.8497 - val_loss: 27.8057 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.3736 - acc: 0.8446 - val_loss: 26.2256 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.1211 - acc: 0.8290 - val_loss: 24.6060 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.8562 - acc: 0.8601 - val_loss: 25.8673 - val_acc: 0.7869\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa394572a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6687 - acc: 0.6340 - val_loss: 6.3714 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.6252 - acc: 0.8093 - val_loss: 192.8281 - val_acc: 0.1803\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 163.3755 - acc: 0.2113 - val_loss: 12.7627 - val_acc: 0.7869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.1507 - acc: 0.8041 - val_loss: 24.9011 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.0330 - acc: 0.8660 - val_loss: 37.2699 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 24.0181 - acc: 0.8608 - val_loss: 44.6183 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa35443e0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7248 - acc: 0.4536 - val_loss: 15.9777 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 13.4365 - acc: 0.6082 - val_loss: 77.3552 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 70.5350 - acc: 0.4742 - val_loss: 31.5269 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 21.7184 - acc: 0.7887 - val_loss: 29.7991 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 23.1105 - acc: 0.8247 - val_loss: 29.1670 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 22.1422 - acc: 0.8402 - val_loss: 25.9116 - val_acc: 0.8361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa3304e3550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7047 - acc: 0.5361 - val_loss: 11.8204 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.0871 - acc: 0.7526 - val_loss: 75.3320 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 49.8449 - acc: 0.5567 - val_loss: 23.9170 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 25.0496 - acc: 0.6649 - val_loss: 24.2992 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 19.4252 - acc: 0.8660 - val_loss: 35.4983 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 29.1640 - acc: 0.8454 - val_loss: 39.9648 - val_acc: 0.8525\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa330512af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100000)\n",
    "params = dict(batch_size=[16, 32, 64, 128, 256], lr= [0.000001, 0.000001, 0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "             neurons=[8, 16, 32, 64, 128, 256, 512])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "scoring = dict(Recall= make_scorer(recall_score, average='micro'), F1=make_scorer(f1_score, average='macro'))\n",
    "grid = GridSearchCV(model, params, return_train_score=True, scoring=scoring, refit=False)\n",
    "grid.fit(x_train_scaled, y_train, callbacks=[es], validation_data=(x_test_scaled, y_test))\n",
    "grid_result = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "203       0.462452      0.030415         0.042844        0.003208   \n",
      "277       0.456621      0.081855         0.048450        0.008606   \n",
      "137       0.694630      0.143883         0.040332        0.002746   \n",
      "\n",
      "    param_batch_size param_lr param_neurons  \\\n",
      "203              128      0.1             8   \n",
      "277              256      0.3           128   \n",
      "137               64    0.001           128   \n",
      "\n",
      "                                              params  split0_test_Recall  \\\n",
      "203     {'batch_size': 128, 'lr': 0.1, 'neurons': 8}            0.836735   \n",
      "277   {'batch_size': 256, 'lr': 0.3, 'neurons': 128}            0.836735   \n",
      "137  {'batch_size': 64, 'lr': 0.001, 'neurons': 128}            0.836735   \n",
      "\n",
      "     split1_test_Recall  ...  mean_test_F1  std_test_F1  rank_test_F1  \\\n",
      "203            0.857143  ...      0.818068     0.054239             1   \n",
      "277            0.857143  ...      0.816891     0.060009             2   \n",
      "137            0.857143  ...      0.815809     0.063310             3   \n",
      "\n",
      "     split0_train_F1  split1_train_F1  split2_train_F1  split3_train_F1  \\\n",
      "203         0.906311         0.887269         0.869886         0.861732   \n",
      "277         0.880508         0.888116         0.858475         0.847991   \n",
      "137         0.859968         0.834234         0.863896         0.841036   \n",
      "\n",
      "     split4_train_F1  mean_train_F1  std_train_F1  \n",
      "203         0.916244       0.888289      0.020742  \n",
      "277         0.848384       0.864695      0.016627  \n",
      "137         0.869297       0.853686      0.013608  \n",
      "\n",
      "[3 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "print(grid_result.sort_values('mean_test_F1', ascending=False)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 681us/step - loss: 0.7718 - acc: 0.4669\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.6693 - acc: 0.6488\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 683us/step - loss: 0.5881 - acc: 0.7273\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 595us/step - loss: 0.5307 - acc: 0.7727\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 763us/step - loss: 0.4837 - acc: 0.7934\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 704us/step - loss: 0.4513 - acc: 0.8058\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 790us/step - loss: 0.4249 - acc: 0.8182\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 793us/step - loss: 0.4056 - acc: 0.8223\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 649us/step - loss: 0.3907 - acc: 0.8306\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 992us/step - loss: 0.3788 - acc: 0.8347\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 766us/step - loss: 0.3694 - acc: 0.8554\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 694us/step - loss: 0.3616 - acc: 0.8554\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3549 - acc: 0.8554\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 950us/step - loss: 0.3486 - acc: 0.8636\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 601us/step - loss: 0.3427 - acc: 0.8678\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 959us/step - loss: 0.3382 - acc: 0.8678\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 685us/step - loss: 0.3328 - acc: 0.8678\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 688us/step - loss: 0.3288 - acc: 0.8678\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 915us/step - loss: 0.3243 - acc: 0.8760\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 733us/step - loss: 0.3200 - acc: 0.8719\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 586us/step - loss: 0.3162 - acc: 0.8719\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 869us/step - loss: 0.3123 - acc: 0.8760\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 813us/step - loss: 0.3088 - acc: 0.8760\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 853us/step - loss: 0.3050 - acc: 0.8802\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 567us/step - loss: 0.3015 - acc: 0.8843\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 538us/step - loss: 0.2983 - acc: 0.8843\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 983us/step - loss: 0.2951 - acc: 0.8884\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 754us/step - loss: 0.2920 - acc: 0.8926\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.2889 - acc: 0.8926\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 910us/step - loss: 0.2859 - acc: 0.8926\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 839us/step - loss: 0.2829 - acc: 0.8926\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2800 - acc: 0.8926\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 789us/step - loss: 0.2774 - acc: 0.8967\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 715us/step - loss: 0.2745 - acc: 0.9008\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 665us/step - loss: 0.2719 - acc: 0.9050\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 971us/step - loss: 0.2693 - acc: 0.9174\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 720us/step - loss: 0.2665 - acc: 0.9132\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 618us/step - loss: 0.2640 - acc: 0.9174\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 856us/step - loss: 0.2616 - acc: 0.9174\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 818us/step - loss: 0.2589 - acc: 0.9215\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 568us/step - loss: 0.2566 - acc: 0.9174\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 672us/step - loss: 0.2540 - acc: 0.9215\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 879us/step - loss: 0.2517 - acc: 0.9215\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 548us/step - loss: 0.2492 - acc: 0.9215\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 905us/step - loss: 0.2467 - acc: 0.9215\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 969us/step - loss: 0.2443 - acc: 0.9215\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 842us/step - loss: 0.2420 - acc: 0.9215\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 689us/step - loss: 0.2397 - acc: 0.9215\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 825us/step - loss: 0.2375 - acc: 0.9215\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 762us/step - loss: 0.2354 - acc: 0.9256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa420050eb0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=keras_model, epochs=50, lr=0.001, batch_size=64, neurons=128)\n",
    "model.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "pred = model.predict(x_test_scaled)\n",
    "conf_df = pd.DataFrame(data=confusion_matrix(pred, y_test),\n",
    "                   columns = [['Predicted Non Diseased', 'Predicted Diseased']],\n",
    "                   index = [['Actual Non Diseased', 'Actual Diseased']]\n",
    "                   )\n",
    "sns.heatmap(conf_df, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 587us/step - loss: 0.2332 - acc: 0.9256\n",
      "Train Score: 0.9256198406219482\n",
      "1/1 [==============================] - 0s 636us/step - loss: 0.3274 - acc: 0.9016\n",
      "Test Score: 0.9016393423080444\n",
      "Recall Score: 0.90625\n",
      "Precision Score: 0.90625\n",
      "AUC Score: 0.9014008620689655\n",
      "F1 Score: 0.90625 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Train Score:', model.score(x_train_scaled, y_train))\n",
    "print('Test Score:', model.score(x_test_scaled, y_test))\n",
    "print('Recall Score:', recall_score(y_test, model.predict(x_test_scaled)))\n",
    "print('Precision Score:', precision_score(y_test, model.predict(x_test_scaled)))\n",
    "print('AUC Score:', roc_auc_score(y_test, model.predict(x_test_scaled)))\n",
    "print('F1 Score:', f1_score(y_test, model.predict(x_test_scaled)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s 534us/step - loss: 0.7547 - acc: 0.4026\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 724us/step - loss: 0.6764 - acc: 0.6337\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 543us/step - loss: 0.6118 - acc: 0.6997\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 833us/step - loss: 0.5619 - acc: 0.7756\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 563us/step - loss: 0.5210 - acc: 0.8086\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 864us/step - loss: 0.4887 - acc: 0.8152\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 630us/step - loss: 0.4649 - acc: 0.8152\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 500us/step - loss: 0.4459 - acc: 0.8218\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 683us/step - loss: 0.4323 - acc: 0.8218\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 587us/step - loss: 0.4212 - acc: 0.8251\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 614us/step - loss: 0.4136 - acc: 0.8284\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 440us/step - loss: 0.4072 - acc: 0.8251\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 572us/step - loss: 0.4027 - acc: 0.8251\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 602us/step - loss: 0.3994 - acc: 0.8251\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 442us/step - loss: 0.3963 - acc: 0.8218\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 456us/step - loss: 0.3941 - acc: 0.8251\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 597us/step - loss: 0.3924 - acc: 0.8251\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 589us/step - loss: 0.3913 - acc: 0.8251\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 575us/step - loss: 0.3896 - acc: 0.8251\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 676us/step - loss: 0.3886 - acc: 0.8251\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 558us/step - loss: 0.3880 - acc: 0.8251\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 569us/step - loss: 0.3871 - acc: 0.8251\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 533us/step - loss: 0.3867 - acc: 0.8251\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 676us/step - loss: 0.3858 - acc: 0.8218\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 620us/step - loss: 0.3853 - acc: 0.8218\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 600us/step - loss: 0.3847 - acc: 0.8218\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 559us/step - loss: 0.3843 - acc: 0.8218\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 733us/step - loss: 0.3839 - acc: 0.8251\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 542us/step - loss: 0.3832 - acc: 0.8218\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 748us/step - loss: 0.3828 - acc: 0.8251\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 656us/step - loss: 0.3825 - acc: 0.8251\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 504us/step - loss: 0.3821 - acc: 0.8251\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 585us/step - loss: 0.3817 - acc: 0.8251\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 663us/step - loss: 0.3815 - acc: 0.8251\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 592us/step - loss: 0.3813 - acc: 0.8251\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 643us/step - loss: 0.3810 - acc: 0.8251\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 737us/step - loss: 0.3807 - acc: 0.8251\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 783us/step - loss: 0.3805 - acc: 0.8251\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 726us/step - loss: 0.3803 - acc: 0.8251\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 704us/step - loss: 0.3801 - acc: 0.8251\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 599us/step - loss: 0.3798 - acc: 0.8251\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 647us/step - loss: 0.3796 - acc: 0.8251\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 677us/step - loss: 0.3795 - acc: 0.8251\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 680us/step - loss: 0.3791 - acc: 0.8251\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 608us/step - loss: 0.3789 - acc: 0.8284\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 614us/step - loss: 0.3787 - acc: 0.8284\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 655us/step - loss: 0.3786 - acc: 0.8284\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 613us/step - loss: 0.3786 - acc: 0.8284\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 598us/step - loss: 0.3782 - acc: 0.8251\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 618us/step - loss: 0.3782 - acc: 0.8284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa3b8271970>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_for_decision_boundary(lr, neurons):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model\n",
    "model_pca = KerasClassifier(build_fn=model_for_decision_boundary, epochs=50, lr=0.001, batch_size=32, neurons=64)\n",
    "model_pca.fit(x_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "resolution = 200# 100x100 background pixels\n",
    "X2d_xmin, X2d_xmax = np.min(x_pca[:,0]), np.max(x_pca[:,0])\n",
    "X2d_ymin, X2d_ymax = np.min(x_pca[:,1]), np.max(x_pca[:,1])\n",
    "xx, yy = np.meshgrid(np.linspace(X2d_xmin, X2d_xmax, resolution), np.linspace(X2d_ymin, X2d_ymax, resolution))\n",
    "zz = model_pca.predict(np.c_[xx.ravel(), yy.ravel()]).reshape((resolution, resolution))\n",
    "plt.scatter(df_pca_no_heart_problem.iloc[:, 0], df_pca_no_heart_problem.iloc[:, 1], label='No heart problem')\n",
    "plt.scatter(df_pca_heart_problem.iloc[:, 0], df_pca_heart_problem.iloc[:, 1], label='Heart problem')\n",
    "plt.legend()\n",
    "plt.contourf(xx, yy, zz, alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
