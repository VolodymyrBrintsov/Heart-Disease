{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import recall_score, make_scorer, roc_auc_score, accuracy_score, plot_roc_curve, f1_score, precision_score, confusion_matrix\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Paired\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "age           int64\n",
      "sex           int64\n",
      "cp            int64\n",
      "trestbps      int64\n",
      "chol          int64\n",
      "fbs           int64\n",
      "restecg       int64\n",
      "thalach       int64\n",
      "exang         int64\n",
      "oldpeak     float64\n",
      "slope         int64\n",
      "ca            int64\n",
      "thal          int64\n",
      "target        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#open data set\n",
    "df = pd.read_csv('../data/heart.csv')\n",
    "#sum nan values\n",
    "print(df.isna().sum())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladimir/Desktop/Heart-Disease/venv/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show target count\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.countplot('target', data=df)\n",
    "plt.xticks(ticks = [0, 1],labels=('No problem with heart', 'Problem with heart'))\n",
    "plt.ylabel('Count')\n",
    "plt.title('Target parameter count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exang'] = df['exang'].apply(lambda x: 'yes' if x == 1 else 'no')\n",
    "df['cp'] = df['cp'].apply(lambda x: 'typical_angina' if x == 1 else\n",
    "                          'atypical_angina' if x == 2 else\n",
    "                          'non_anginal_pain' if x == 3 else\n",
    "                          'asymptomatic')\n",
    "df['fbs'] = df['fbs'].apply(lambda x: 'lower_than_120mg/ml' if x == 0 else 'higher_than_120mg/ml')\n",
    "df['restecg'] = df['restecg'].apply(lambda x: 'normal' if x == 0 else\n",
    "                                    'st_t_wave abnormality' if x == 1 else\n",
    "                                    'left_ventricular_hypertrophy')\n",
    "df['sex'] = df['sex'].apply(lambda x: 'male' if x == 1 else 'female')\n",
    "df['slope'] = df['slope'].apply(lambda x: 'upsloping' if x == 0 else 'flat' if x == 1 else 'downsloping')\n",
    "df['thal'] = df['thal'].apply(lambda x: 'normal' if x == 1 else 'fixed_defect' if x == 2 else 'reversable_defect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "x = pd.get_dummies(x)\n",
    "ct = ColumnTransformer([('scaled', StandardScaler(), x.select_dtypes(include=['int64', 'float64']).columns)],\n",
    "                       remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show dataset\n",
    "pca = PCA(n_components=2)\n",
    "x_pca = pca.fit_transform(ct.fit_transform(x))\n",
    "df_pca = pd.DataFrame(data=x_pca, columns=['1 component', '2 component'])\n",
    "df_pca['target'] = y\n",
    "df_pca_heart_problem = df_pca[df_pca['target'] == 1]\n",
    "df_pca_no_heart_problem = df_pca[df_pca['target'] == 0]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(df_pca_no_heart_problem.iloc[:, 0], df_pca_no_heart_problem.iloc[:, 1], label='No heart problem')\n",
    "plt.scatter(df_pca_heart_problem.iloc[:, 0], df_pca_heart_problem.iloc[:, 1], label='Heart problem')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 25) (242, 25)\n"
     ]
    }
   ],
   "source": [
    "#Train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "x_train_scaled = ct.fit_transform(x_train)\n",
    "x_test_scaled = ct.transform(x_test)\n",
    "print(x.shape, x_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model(lr, neurons):\n",
    "    model=Sequential()\n",
    "    model.add(InputLayer(input_shape=(x.shape[1],)))\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=keras_model, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.7844 - acc: 0.3782 - val_loss: 0.7602 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7844 - acc: 0.3782 - val_loss: 0.7602 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7844 - acc: 0.3782 - val_loss: 0.7602 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7844 - acc: 0.3782 - val_loss: 0.7602 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7843 - acc: 0.3782 - val_loss: 0.7602 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7843 - acc: 0.3782 - val_loss: 0.7601 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7843 - acc: 0.3782 - val_loss: 0.7601 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7843 - acc: 0.3782 - val_loss: 0.7601 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7843 - acc: 0.3782 - val_loss: 0.7601 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7842 - acc: 0.3782 - val_loss: 0.7600 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7842 - acc: 0.3782 - val_loss: 0.7600 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7842 - acc: 0.3782 - val_loss: 0.7600 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7842 - acc: 0.3782 - val_loss: 0.7600 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7842 - acc: 0.3782 - val_loss: 0.7600 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7841 - acc: 0.3782 - val_loss: 0.7599 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7841 - acc: 0.3782 - val_loss: 0.7599 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7841 - acc: 0.3782 - val_loss: 0.7599 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7841 - acc: 0.3782 - val_loss: 0.7599 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7841 - acc: 0.3782 - val_loss: 0.7599 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7841 - acc: 0.3782 - val_loss: 0.7598 - val_acc: 0.4262\n",
      "WARNING:tensorflow:From /home/vladimir/Desktop/Heart-Disease/venv/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6901 - acc: 0.5130 - val_loss: 0.7001 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6901 - acc: 0.5130 - val_loss: 0.7000 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6900 - acc: 0.5130 - val_loss: 0.7000 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6900 - acc: 0.5130 - val_loss: 0.7000 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6900 - acc: 0.5130 - val_loss: 0.7000 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6900 - acc: 0.5130 - val_loss: 0.7000 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6899 - acc: 0.5130 - val_loss: 0.6999 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6899 - acc: 0.5130 - val_loss: 0.6999 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6899 - acc: 0.5130 - val_loss: 0.6999 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6899 - acc: 0.5130 - val_loss: 0.6999 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6899 - acc: 0.5130 - val_loss: 0.6999 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6898 - acc: 0.5130 - val_loss: 0.6998 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6898 - acc: 0.5130 - val_loss: 0.6998 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6898 - acc: 0.5130 - val_loss: 0.6998 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6898 - acc: 0.5130 - val_loss: 0.6998 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6898 - acc: 0.5130 - val_loss: 0.6998 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6897 - acc: 0.5130 - val_loss: 0.6997 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6897 - acc: 0.5130 - val_loss: 0.6997 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6897 - acc: 0.5130 - val_loss: 0.6997 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6897 - acc: 0.5130 - val_loss: 0.6997 - val_acc: 0.5574\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6671 - acc: 0.6289 - val_loss: 0.7014 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6671 - acc: 0.6289 - val_loss: 0.7014 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6670 - acc: 0.6289 - val_loss: 0.7013 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6670 - acc: 0.6289 - val_loss: 0.7013 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6670 - acc: 0.6289 - val_loss: 0.7013 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6670 - acc: 0.6289 - val_loss: 0.7013 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6670 - acc: 0.6289 - val_loss: 0.7012 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6670 - acc: 0.6289 - val_loss: 0.7012 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6669 - acc: 0.6289 - val_loss: 0.7012 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6669 - acc: 0.6289 - val_loss: 0.7012 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6669 - acc: 0.6289 - val_loss: 0.7011 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6669 - acc: 0.6289 - val_loss: 0.7011 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6669 - acc: 0.6289 - val_loss: 0.7011 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6668 - acc: 0.6289 - val_loss: 0.7010 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6668 - acc: 0.6289 - val_loss: 0.7010 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6668 - acc: 0.6289 - val_loss: 0.7010 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6668 - acc: 0.6289 - val_loss: 0.7010 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6668 - acc: 0.6289 - val_loss: 0.7009 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6668 - acc: 0.6289 - val_loss: 0.7009 - val_acc: 0.5574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6667 - acc: 0.6289 - val_loss: 0.7009 - val_acc: 0.5574\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9558 - acc: 0.3351 - val_loss: 0.9681 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9558 - acc: 0.3351 - val_loss: 0.9681 - val_acc: 0.3115\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9557 - acc: 0.3351 - val_loss: 0.9680 - val_acc: 0.3115\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9557 - acc: 0.3351 - val_loss: 0.9680 - val_acc: 0.3115\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9556 - acc: 0.3351 - val_loss: 0.9679 - val_acc: 0.3115\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9556 - acc: 0.3351 - val_loss: 0.9679 - val_acc: 0.3115\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9555 - acc: 0.3351 - val_loss: 0.9679 - val_acc: 0.3115\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9555 - acc: 0.3351 - val_loss: 0.9678 - val_acc: 0.3115\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9554 - acc: 0.3351 - val_loss: 0.9678 - val_acc: 0.3115\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9554 - acc: 0.3351 - val_loss: 0.9677 - val_acc: 0.3115\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9553 - acc: 0.3351 - val_loss: 0.9677 - val_acc: 0.3115\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.9553 - acc: 0.3351 - val_loss: 0.9676 - val_acc: 0.3115\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9552 - acc: 0.3351 - val_loss: 0.9676 - val_acc: 0.3115\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9552 - acc: 0.3351 - val_loss: 0.9675 - val_acc: 0.3115\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9551 - acc: 0.3351 - val_loss: 0.9675 - val_acc: 0.3115\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9551 - acc: 0.3351 - val_loss: 0.9674 - val_acc: 0.3115\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9550 - acc: 0.3351 - val_loss: 0.9674 - val_acc: 0.3115\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9550 - acc: 0.3351 - val_loss: 0.9673 - val_acc: 0.3115\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9549 - acc: 0.3351 - val_loss: 0.9673 - val_acc: 0.3115\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9549 - acc: 0.3351 - val_loss: 0.9673 - val_acc: 0.3115\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.7570 - acc: 0.4639 - val_loss: 0.7282 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7569 - acc: 0.4742 - val_loss: 0.7282 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7569 - acc: 0.4742 - val_loss: 0.7282 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7569 - acc: 0.4742 - val_loss: 0.7282 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7569 - acc: 0.4742 - val_loss: 0.7281 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7569 - acc: 0.4742 - val_loss: 0.7281 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7568 - acc: 0.4742 - val_loss: 0.7281 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7568 - acc: 0.4742 - val_loss: 0.7281 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7568 - acc: 0.4742 - val_loss: 0.7281 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7568 - acc: 0.4742 - val_loss: 0.7281 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7568 - acc: 0.4742 - val_loss: 0.7280 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7567 - acc: 0.4742 - val_loss: 0.7280 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7567 - acc: 0.4742 - val_loss: 0.7280 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7567 - acc: 0.4742 - val_loss: 0.7280 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7567 - acc: 0.4742 - val_loss: 0.7280 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7567 - acc: 0.4742 - val_loss: 0.7280 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7567 - acc: 0.4742 - val_loss: 0.7279 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7566 - acc: 0.4742 - val_loss: 0.7279 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7566 - acc: 0.4742 - val_loss: 0.7279 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7566 - acc: 0.4742 - val_loss: 0.7279 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.7276 - acc: 0.5026 - val_loss: 0.7316 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7276 - acc: 0.5026 - val_loss: 0.7316 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7276 - acc: 0.5026 - val_loss: 0.7316 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7275 - acc: 0.5026 - val_loss: 0.7315 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7275 - acc: 0.5026 - val_loss: 0.7315 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7275 - acc: 0.5026 - val_loss: 0.7315 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7274 - acc: 0.5026 - val_loss: 0.7314 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7274 - acc: 0.5026 - val_loss: 0.7314 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7274 - acc: 0.5026 - val_loss: 0.7314 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7274 - acc: 0.5026 - val_loss: 0.7314 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7273 - acc: 0.5026 - val_loss: 0.7313 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7273 - acc: 0.5026 - val_loss: 0.7313 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7273 - acc: 0.5026 - val_loss: 0.7313 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7273 - acc: 0.5026 - val_loss: 0.7312 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7272 - acc: 0.5026 - val_loss: 0.7312 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7272 - acc: 0.5026 - val_loss: 0.7312 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7272 - acc: 0.5026 - val_loss: 0.7312 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7272 - acc: 0.5026 - val_loss: 0.7311 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7271 - acc: 0.5026 - val_loss: 0.7311 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7271 - acc: 0.5026 - val_loss: 0.7311 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7539 - acc: 0.4560 - val_loss: 0.7529 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7539 - acc: 0.4560 - val_loss: 0.7529 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7538 - acc: 0.4560 - val_loss: 0.7529 - val_acc: 0.4590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7538 - acc: 0.4560 - val_loss: 0.7529 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7538 - acc: 0.4560 - val_loss: 0.7528 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7538 - acc: 0.4560 - val_loss: 0.7528 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7537 - acc: 0.4560 - val_loss: 0.7528 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7537 - acc: 0.4560 - val_loss: 0.7528 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7537 - acc: 0.4560 - val_loss: 0.7528 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7536 - acc: 0.4560 - val_loss: 0.7527 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7536 - acc: 0.4560 - val_loss: 0.7527 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7536 - acc: 0.4560 - val_loss: 0.7527 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7536 - acc: 0.4560 - val_loss: 0.7526 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7535 - acc: 0.4560 - val_loss: 0.7526 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7535 - acc: 0.4560 - val_loss: 0.7526 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7535 - acc: 0.4560 - val_loss: 0.7526 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7534 - acc: 0.4560 - val_loss: 0.7525 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7534 - acc: 0.4560 - val_loss: 0.7525 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7534 - acc: 0.4560 - val_loss: 0.7525 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7533 - acc: 0.4560 - val_loss: 0.7525 - val_acc: 0.4590\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7588 - acc: 0.4072 - val_loss: 0.8066 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7588 - acc: 0.4072 - val_loss: 0.8066 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7587 - acc: 0.4124 - val_loss: 0.8066 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7587 - acc: 0.4124 - val_loss: 0.8065 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7587 - acc: 0.4124 - val_loss: 0.8065 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7586 - acc: 0.4124 - val_loss: 0.8065 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7586 - acc: 0.4124 - val_loss: 0.8064 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7586 - acc: 0.4124 - val_loss: 0.8064 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7585 - acc: 0.4124 - val_loss: 0.8064 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7585 - acc: 0.4124 - val_loss: 0.8063 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7585 - acc: 0.4124 - val_loss: 0.8063 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7585 - acc: 0.4124 - val_loss: 0.8063 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7584 - acc: 0.4124 - val_loss: 0.8062 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7584 - acc: 0.4124 - val_loss: 0.8062 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7584 - acc: 0.4124 - val_loss: 0.8061 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7583 - acc: 0.4124 - val_loss: 0.8061 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7583 - acc: 0.4124 - val_loss: 0.8061 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7583 - acc: 0.4124 - val_loss: 0.8060 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7583 - acc: 0.4124 - val_loss: 0.8060 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7582 - acc: 0.4124 - val_loss: 0.8060 - val_acc: 0.4098\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.7722 - acc: 0.5670 - val_loss: 0.8610 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7721 - acc: 0.5670 - val_loss: 0.8609 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7721 - acc: 0.5670 - val_loss: 0.8609 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7721 - acc: 0.5670 - val_loss: 0.8608 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7720 - acc: 0.5670 - val_loss: 0.8608 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7720 - acc: 0.5670 - val_loss: 0.8607 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7719 - acc: 0.5670 - val_loss: 0.8606 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7719 - acc: 0.5670 - val_loss: 0.8606 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7718 - acc: 0.5670 - val_loss: 0.8605 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7718 - acc: 0.5670 - val_loss: 0.8605 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7717 - acc: 0.5670 - val_loss: 0.8604 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7717 - acc: 0.5670 - val_loss: 0.8603 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7716 - acc: 0.5670 - val_loss: 0.8603 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7716 - acc: 0.5670 - val_loss: 0.8602 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7716 - acc: 0.5670 - val_loss: 0.8602 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7715 - acc: 0.5670 - val_loss: 0.8601 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7715 - acc: 0.5670 - val_loss: 0.8601 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7714 - acc: 0.5670 - val_loss: 0.8600 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7714 - acc: 0.5670 - val_loss: 0.8600 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7714 - acc: 0.5670 - val_loss: 0.8599 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6307 - acc: 0.6340 - val_loss: 0.6051 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6306 - acc: 0.6340 - val_loss: 0.6051 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6306 - acc: 0.6340 - val_loss: 0.6051 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6306 - acc: 0.6340 - val_loss: 0.6050 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6305 - acc: 0.6340 - val_loss: 0.6050 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6305 - acc: 0.6340 - val_loss: 0.6050 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6305 - acc: 0.6340 - val_loss: 0.6050 - val_acc: 0.7049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6305 - acc: 0.6340 - val_loss: 0.6049 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6305 - acc: 0.6340 - val_loss: 0.6049 - val_acc: 0.7049\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6304 - acc: 0.6340 - val_loss: 0.6049 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6304 - acc: 0.6340 - val_loss: 0.6048 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6304 - acc: 0.6340 - val_loss: 0.6048 - val_acc: 0.7049\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6304 - acc: 0.6340 - val_loss: 0.6048 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6303 - acc: 0.6340 - val_loss: 0.6048 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6303 - acc: 0.6340 - val_loss: 0.6047 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6303 - acc: 0.6340 - val_loss: 0.6047 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6303 - acc: 0.6340 - val_loss: 0.6047 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6302 - acc: 0.6340 - val_loss: 0.6047 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6302 - acc: 0.6340 - val_loss: 0.6046 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6302 - acc: 0.6340 - val_loss: 0.6046 - val_acc: 0.7049\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.7914 - acc: 0.4663 - val_loss: 0.7692 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7913 - acc: 0.4663 - val_loss: 0.7691 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7913 - acc: 0.4663 - val_loss: 0.7691 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7912 - acc: 0.4663 - val_loss: 0.7690 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7911 - acc: 0.4663 - val_loss: 0.7689 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7911 - acc: 0.4663 - val_loss: 0.7689 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7910 - acc: 0.4663 - val_loss: 0.7688 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7910 - acc: 0.4663 - val_loss: 0.7688 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7909 - acc: 0.4663 - val_loss: 0.7687 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7908 - acc: 0.4663 - val_loss: 0.7686 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7908 - acc: 0.4663 - val_loss: 0.7686 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7907 - acc: 0.4663 - val_loss: 0.7685 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7906 - acc: 0.4663 - val_loss: 0.7685 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7906 - acc: 0.4663 - val_loss: 0.7684 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7905 - acc: 0.4663 - val_loss: 0.7683 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7905 - acc: 0.4663 - val_loss: 0.7683 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7904 - acc: 0.4663 - val_loss: 0.7682 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7903 - acc: 0.4663 - val_loss: 0.7682 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7903 - acc: 0.4663 - val_loss: 0.7681 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7902 - acc: 0.4663 - val_loss: 0.7680 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.7456 - acc: 0.5648 - val_loss: 0.8523 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7456 - acc: 0.5648 - val_loss: 0.8522 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7455 - acc: 0.5648 - val_loss: 0.8521 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7455 - acc: 0.5648 - val_loss: 0.8521 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7454 - acc: 0.5648 - val_loss: 0.8520 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7454 - acc: 0.5648 - val_loss: 0.8519 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7453 - acc: 0.5648 - val_loss: 0.8519 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7453 - acc: 0.5648 - val_loss: 0.8518 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7453 - acc: 0.5648 - val_loss: 0.8518 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7452 - acc: 0.5648 - val_loss: 0.8517 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7452 - acc: 0.5648 - val_loss: 0.8517 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7451 - acc: 0.5648 - val_loss: 0.8516 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7451 - acc: 0.5648 - val_loss: 0.8516 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7451 - acc: 0.5648 - val_loss: 0.8515 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7450 - acc: 0.5648 - val_loss: 0.8514 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7450 - acc: 0.5648 - val_loss: 0.8514 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7449 - acc: 0.5648 - val_loss: 0.8513 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7449 - acc: 0.5648 - val_loss: 0.8513 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7449 - acc: 0.5648 - val_loss: 0.8512 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7448 - acc: 0.5648 - val_loss: 0.8511 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6749 - acc: 0.5258 - val_loss: 0.7006 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6749 - acc: 0.5258 - val_loss: 0.7006 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6748 - acc: 0.5258 - val_loss: 0.7006 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6748 - acc: 0.5258 - val_loss: 0.7006 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6748 - acc: 0.5258 - val_loss: 0.7005 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6748 - acc: 0.5258 - val_loss: 0.7005 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6747 - acc: 0.5258 - val_loss: 0.7005 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6747 - acc: 0.5258 - val_loss: 0.7004 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6747 - acc: 0.5258 - val_loss: 0.7004 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6747 - acc: 0.5258 - val_loss: 0.7004 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6746 - acc: 0.5258 - val_loss: 0.7003 - val_acc: 0.4754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6746 - acc: 0.5258 - val_loss: 0.7003 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6746 - acc: 0.5258 - val_loss: 0.7003 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6745 - acc: 0.5258 - val_loss: 0.7002 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6745 - acc: 0.5258 - val_loss: 0.7002 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6745 - acc: 0.5258 - val_loss: 0.7002 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6745 - acc: 0.5258 - val_loss: 0.7002 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6745 - acc: 0.5258 - val_loss: 0.7001 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6744 - acc: 0.5258 - val_loss: 0.7001 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6744 - acc: 0.5258 - val_loss: 0.7001 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7696 - acc: 0.4278 - val_loss: 0.7715 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7696 - acc: 0.4278 - val_loss: 0.7714 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7695 - acc: 0.4278 - val_loss: 0.7714 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7695 - acc: 0.4278 - val_loss: 0.7713 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7694 - acc: 0.4278 - val_loss: 0.7713 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7694 - acc: 0.4278 - val_loss: 0.7712 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7693 - acc: 0.4278 - val_loss: 0.7712 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7693 - acc: 0.4278 - val_loss: 0.7711 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7692 - acc: 0.4278 - val_loss: 0.7711 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7692 - acc: 0.4278 - val_loss: 0.7710 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7691 - acc: 0.4278 - val_loss: 0.7710 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7691 - acc: 0.4278 - val_loss: 0.7709 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7690 - acc: 0.4278 - val_loss: 0.7709 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7690 - acc: 0.4278 - val_loss: 0.7708 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7689 - acc: 0.4278 - val_loss: 0.7708 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7689 - acc: 0.4278 - val_loss: 0.7707 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7688 - acc: 0.4278 - val_loss: 0.7707 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7688 - acc: 0.4278 - val_loss: 0.7706 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7688 - acc: 0.4278 - val_loss: 0.7706 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7687 - acc: 0.4278 - val_loss: 0.7705 - val_acc: 0.4590\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6942 - acc: 0.5206 - val_loss: 0.6947 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6941 - acc: 0.5206 - val_loss: 0.6946 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6941 - acc: 0.5206 - val_loss: 0.6946 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6940 - acc: 0.5206 - val_loss: 0.6945 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6940 - acc: 0.5206 - val_loss: 0.6945 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6940 - acc: 0.5206 - val_loss: 0.6944 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6939 - acc: 0.5155 - val_loss: 0.6944 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6939 - acc: 0.5155 - val_loss: 0.6944 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6939 - acc: 0.5155 - val_loss: 0.6943 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6938 - acc: 0.5155 - val_loss: 0.6943 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6938 - acc: 0.5155 - val_loss: 0.6943 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6938 - acc: 0.5155 - val_loss: 0.6942 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6937 - acc: 0.5155 - val_loss: 0.6942 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6937 - acc: 0.5155 - val_loss: 0.6942 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6936 - acc: 0.5155 - val_loss: 0.6941 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6936 - acc: 0.5155 - val_loss: 0.6941 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6936 - acc: 0.5155 - val_loss: 0.6940 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6935 - acc: 0.5155 - val_loss: 0.6940 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6935 - acc: 0.5155 - val_loss: 0.6940 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6934 - acc: 0.5155 - val_loss: 0.6939 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.7314 - acc: 0.4870 - val_loss: 0.7468 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7313 - acc: 0.4870 - val_loss: 0.7467 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7313 - acc: 0.4870 - val_loss: 0.7466 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7312 - acc: 0.4870 - val_loss: 0.7465 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7312 - acc: 0.4870 - val_loss: 0.7465 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7311 - acc: 0.4870 - val_loss: 0.7464 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7310 - acc: 0.4870 - val_loss: 0.7463 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7310 - acc: 0.4870 - val_loss: 0.7463 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7309 - acc: 0.4870 - val_loss: 0.7462 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7309 - acc: 0.4870 - val_loss: 0.7461 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7308 - acc: 0.4870 - val_loss: 0.7461 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7308 - acc: 0.4870 - val_loss: 0.7460 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7307 - acc: 0.4870 - val_loss: 0.7459 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7307 - acc: 0.4870 - val_loss: 0.7459 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7306 - acc: 0.4870 - val_loss: 0.7458 - val_acc: 0.5082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7305 - acc: 0.4870 - val_loss: 0.7457 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7305 - acc: 0.4870 - val_loss: 0.7457 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7304 - acc: 0.4870 - val_loss: 0.7456 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7304 - acc: 0.4870 - val_loss: 0.7455 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7303 - acc: 0.4870 - val_loss: 0.7455 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6377 - acc: 0.6010 - val_loss: 0.6630 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6376 - acc: 0.6010 - val_loss: 0.6629 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6375 - acc: 0.6010 - val_loss: 0.6628 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6375 - acc: 0.6010 - val_loss: 0.6628 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6374 - acc: 0.6010 - val_loss: 0.6627 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6374 - acc: 0.6010 - val_loss: 0.6626 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6373 - acc: 0.6010 - val_loss: 0.6626 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6373 - acc: 0.6010 - val_loss: 0.6625 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6373 - acc: 0.6010 - val_loss: 0.6625 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6372 - acc: 0.6010 - val_loss: 0.6624 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6372 - acc: 0.6010 - val_loss: 0.6623 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6371 - acc: 0.6010 - val_loss: 0.6623 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6371 - acc: 0.6010 - val_loss: 0.6622 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6371 - acc: 0.6010 - val_loss: 0.6622 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6370 - acc: 0.6010 - val_loss: 0.6621 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6370 - acc: 0.6010 - val_loss: 0.6621 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6369 - acc: 0.6010 - val_loss: 0.6620 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6369 - acc: 0.6010 - val_loss: 0.6620 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6368 - acc: 0.6010 - val_loss: 0.6619 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6368 - acc: 0.6010 - val_loss: 0.6619 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7087 - acc: 0.5000 - val_loss: 0.7108 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7086 - acc: 0.5052 - val_loss: 0.7107 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7085 - acc: 0.5052 - val_loss: 0.7106 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7084 - acc: 0.5052 - val_loss: 0.7106 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7084 - acc: 0.5052 - val_loss: 0.7105 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7083 - acc: 0.5052 - val_loss: 0.7104 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7083 - acc: 0.5052 - val_loss: 0.7104 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7082 - acc: 0.5052 - val_loss: 0.7103 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7081 - acc: 0.5052 - val_loss: 0.7102 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7081 - acc: 0.5052 - val_loss: 0.7102 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7080 - acc: 0.5000 - val_loss: 0.7101 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7080 - acc: 0.5000 - val_loss: 0.7100 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7079 - acc: 0.5000 - val_loss: 0.7100 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7078 - acc: 0.5000 - val_loss: 0.7099 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7078 - acc: 0.5000 - val_loss: 0.7098 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7077 - acc: 0.5000 - val_loss: 0.7098 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7077 - acc: 0.5000 - val_loss: 0.7097 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7076 - acc: 0.5000 - val_loss: 0.7096 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7075 - acc: 0.5000 - val_loss: 0.7096 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7075 - acc: 0.5052 - val_loss: 0.7095 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.8286 - acc: 0.2629 - val_loss: 0.8494 - val_acc: 0.2951\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8285 - acc: 0.2629 - val_loss: 0.8493 - val_acc: 0.2951\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8284 - acc: 0.2629 - val_loss: 0.8492 - val_acc: 0.2951\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8284 - acc: 0.2629 - val_loss: 0.8491 - val_acc: 0.2951\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8283 - acc: 0.2629 - val_loss: 0.8490 - val_acc: 0.2951\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8282 - acc: 0.2629 - val_loss: 0.8489 - val_acc: 0.2951\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8281 - acc: 0.2629 - val_loss: 0.8488 - val_acc: 0.2951\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8281 - acc: 0.2629 - val_loss: 0.8487 - val_acc: 0.2951\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8280 - acc: 0.2629 - val_loss: 0.8487 - val_acc: 0.2951\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8279 - acc: 0.2629 - val_loss: 0.8486 - val_acc: 0.2951\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8278 - acc: 0.2629 - val_loss: 0.8485 - val_acc: 0.2951\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8278 - acc: 0.2629 - val_loss: 0.8484 - val_acc: 0.2951\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8277 - acc: 0.2629 - val_loss: 0.8483 - val_acc: 0.2951\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8276 - acc: 0.2629 - val_loss: 0.8482 - val_acc: 0.2951\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8275 - acc: 0.2629 - val_loss: 0.8481 - val_acc: 0.2951\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8275 - acc: 0.2629 - val_loss: 0.8481 - val_acc: 0.2951\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8274 - acc: 0.2629 - val_loss: 0.8480 - val_acc: 0.2951\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8273 - acc: 0.2629 - val_loss: 0.8479 - val_acc: 0.2951\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8272 - acc: 0.2629 - val_loss: 0.8478 - val_acc: 0.2951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8272 - acc: 0.2629 - val_loss: 0.8477 - val_acc: 0.2951\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7852 - acc: 0.4639 - val_loss: 0.7215 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7851 - acc: 0.4639 - val_loss: 0.7214 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7850 - acc: 0.4639 - val_loss: 0.7213 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7849 - acc: 0.4639 - val_loss: 0.7212 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7848 - acc: 0.4639 - val_loss: 0.7211 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7847 - acc: 0.4639 - val_loss: 0.7210 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7846 - acc: 0.4639 - val_loss: 0.7209 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7845 - acc: 0.4639 - val_loss: 0.7209 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7844 - acc: 0.4639 - val_loss: 0.7208 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7843 - acc: 0.4639 - val_loss: 0.7207 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7842 - acc: 0.4639 - val_loss: 0.7206 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7841 - acc: 0.4639 - val_loss: 0.7205 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7840 - acc: 0.4639 - val_loss: 0.7204 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7839 - acc: 0.4639 - val_loss: 0.7203 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7838 - acc: 0.4639 - val_loss: 0.7202 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7837 - acc: 0.4639 - val_loss: 0.7201 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7836 - acc: 0.4639 - val_loss: 0.7201 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7835 - acc: 0.4639 - val_loss: 0.7200 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7834 - acc: 0.4639 - val_loss: 0.7199 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7833 - acc: 0.4639 - val_loss: 0.7198 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6572 - acc: 0.6425 - val_loss: 0.6350 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6572 - acc: 0.6425 - val_loss: 0.6349 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6571 - acc: 0.6425 - val_loss: 0.6348 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6570 - acc: 0.6425 - val_loss: 0.6348 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6570 - acc: 0.6425 - val_loss: 0.6347 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6569 - acc: 0.6425 - val_loss: 0.6347 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6569 - acc: 0.6425 - val_loss: 0.6346 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6568 - acc: 0.6425 - val_loss: 0.6346 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6568 - acc: 0.6425 - val_loss: 0.6345 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6567 - acc: 0.6425 - val_loss: 0.6344 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6566 - acc: 0.6425 - val_loss: 0.6344 - val_acc: 0.7213\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6566 - acc: 0.6425 - val_loss: 0.6343 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6565 - acc: 0.6425 - val_loss: 0.6343 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6565 - acc: 0.6425 - val_loss: 0.6342 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6564 - acc: 0.6425 - val_loss: 0.6341 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6564 - acc: 0.6425 - val_loss: 0.6341 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6563 - acc: 0.6425 - val_loss: 0.6340 - val_acc: 0.7213\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6563 - acc: 0.6425 - val_loss: 0.6340 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6562 - acc: 0.6425 - val_loss: 0.6339 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6562 - acc: 0.6425 - val_loss: 0.6339 - val_acc: 0.7213\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7076 - acc: 0.5026 - val_loss: 0.7171 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7076 - acc: 0.5026 - val_loss: 0.7170 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7075 - acc: 0.5026 - val_loss: 0.7170 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7074 - acc: 0.5026 - val_loss: 0.7169 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7073 - acc: 0.5026 - val_loss: 0.7168 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7072 - acc: 0.5026 - val_loss: 0.7167 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7071 - acc: 0.5026 - val_loss: 0.7166 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7071 - acc: 0.5026 - val_loss: 0.7165 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7070 - acc: 0.5026 - val_loss: 0.7164 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7069 - acc: 0.5026 - val_loss: 0.7164 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7068 - acc: 0.5026 - val_loss: 0.7163 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7068 - acc: 0.5026 - val_loss: 0.7162 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7067 - acc: 0.5026 - val_loss: 0.7161 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7066 - acc: 0.5026 - val_loss: 0.7161 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7065 - acc: 0.5026 - val_loss: 0.7160 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7065 - acc: 0.5026 - val_loss: 0.7159 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7064 - acc: 0.5026 - val_loss: 0.7159 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7063 - acc: 0.5026 - val_loss: 0.7158 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7063 - acc: 0.5026 - val_loss: 0.7157 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7062 - acc: 0.5026 - val_loss: 0.7156 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.7336 - acc: 0.3763 - val_loss: 0.7523 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7335 - acc: 0.3763 - val_loss: 0.7522 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7334 - acc: 0.3763 - val_loss: 0.7521 - val_acc: 0.3770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7333 - acc: 0.3763 - val_loss: 0.7520 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7332 - acc: 0.3763 - val_loss: 0.7519 - val_acc: 0.3770\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7331 - acc: 0.3763 - val_loss: 0.7518 - val_acc: 0.3770\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7330 - acc: 0.3763 - val_loss: 0.7517 - val_acc: 0.3770\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7329 - acc: 0.3763 - val_loss: 0.7515 - val_acc: 0.3770\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7328 - acc: 0.3763 - val_loss: 0.7514 - val_acc: 0.3770\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7327 - acc: 0.3763 - val_loss: 0.7513 - val_acc: 0.3770\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7326 - acc: 0.3763 - val_loss: 0.7512 - val_acc: 0.3770\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7326 - acc: 0.3763 - val_loss: 0.7511 - val_acc: 0.3770\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7325 - acc: 0.3814 - val_loss: 0.7510 - val_acc: 0.3770\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7324 - acc: 0.3814 - val_loss: 0.7509 - val_acc: 0.3770\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7323 - acc: 0.3814 - val_loss: 0.7508 - val_acc: 0.3770\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7322 - acc: 0.3814 - val_loss: 0.7507 - val_acc: 0.3770\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7321 - acc: 0.3814 - val_loss: 0.7506 - val_acc: 0.3770\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7320 - acc: 0.3814 - val_loss: 0.7505 - val_acc: 0.3770\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7319 - acc: 0.3814 - val_loss: 0.7504 - val_acc: 0.3770\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7318 - acc: 0.3814 - val_loss: 0.7503 - val_acc: 0.3770\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7860 - acc: 0.4278 - val_loss: 0.7842 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7859 - acc: 0.4278 - val_loss: 0.7840 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7858 - acc: 0.4278 - val_loss: 0.7839 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7856 - acc: 0.4278 - val_loss: 0.7838 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7855 - acc: 0.4278 - val_loss: 0.7837 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7854 - acc: 0.4278 - val_loss: 0.7836 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7853 - acc: 0.4278 - val_loss: 0.7835 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7852 - acc: 0.4278 - val_loss: 0.7834 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7851 - acc: 0.4278 - val_loss: 0.7833 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7850 - acc: 0.4278 - val_loss: 0.7832 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7849 - acc: 0.4278 - val_loss: 0.7831 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7848 - acc: 0.4278 - val_loss: 0.7829 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7847 - acc: 0.4278 - val_loss: 0.7828 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7846 - acc: 0.4278 - val_loss: 0.7827 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7844 - acc: 0.4278 - val_loss: 0.7826 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7843 - acc: 0.4278 - val_loss: 0.7825 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7842 - acc: 0.4278 - val_loss: 0.7824 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7841 - acc: 0.4278 - val_loss: 0.7823 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7840 - acc: 0.4278 - val_loss: 0.7821 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7839 - acc: 0.4278 - val_loss: 0.7820 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6758 - acc: 0.5773 - val_loss: 0.6848 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6757 - acc: 0.5773 - val_loss: 0.6847 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6757 - acc: 0.5773 - val_loss: 0.6846 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6756 - acc: 0.5773 - val_loss: 0.6845 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6755 - acc: 0.5773 - val_loss: 0.6844 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6754 - acc: 0.5773 - val_loss: 0.6843 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6754 - acc: 0.5773 - val_loss: 0.6842 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6753 - acc: 0.5773 - val_loss: 0.6842 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6752 - acc: 0.5773 - val_loss: 0.6841 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6751 - acc: 0.5773 - val_loss: 0.6840 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6751 - acc: 0.5773 - val_loss: 0.6839 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6750 - acc: 0.5773 - val_loss: 0.6838 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6749 - acc: 0.5773 - val_loss: 0.6837 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6749 - acc: 0.5773 - val_loss: 0.6836 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6748 - acc: 0.5773 - val_loss: 0.6835 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6747 - acc: 0.5773 - val_loss: 0.6834 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6746 - acc: 0.5773 - val_loss: 0.6833 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6746 - acc: 0.5773 - val_loss: 0.6833 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6745 - acc: 0.5773 - val_loss: 0.6832 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6744 - acc: 0.5773 - val_loss: 0.6831 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6379 - acc: 0.7306 - val_loss: 0.6333 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6377 - acc: 0.7306 - val_loss: 0.6332 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6376 - acc: 0.7358 - val_loss: 0.6331 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6375 - acc: 0.7409 - val_loss: 0.6330 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6374 - acc: 0.7409 - val_loss: 0.6329 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6373 - acc: 0.7409 - val_loss: 0.6327 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6518 - acc: 0.687 - 0s 3ms/step - loss: 0.6372 - acc: 0.7409 - val_loss: 0.6326 - val_acc: 0.7705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6371 - acc: 0.7409 - val_loss: 0.6325 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6370 - acc: 0.7461 - val_loss: 0.6324 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6369 - acc: 0.7461 - val_loss: 0.6323 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6368 - acc: 0.7461 - val_loss: 0.6322 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6367 - acc: 0.7461 - val_loss: 0.6321 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6366 - acc: 0.7513 - val_loss: 0.6320 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6366 - acc: 0.7513 - val_loss: 0.6319 - val_acc: 0.7705\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6365 - acc: 0.7513 - val_loss: 0.6318 - val_acc: 0.7705\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6364 - acc: 0.7513 - val_loss: 0.6317 - val_acc: 0.7705\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6363 - acc: 0.7513 - val_loss: 0.6316 - val_acc: 0.7705\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6362 - acc: 0.7513 - val_loss: 0.6315 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6361 - acc: 0.7513 - val_loss: 0.6314 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6360 - acc: 0.7513 - val_loss: 0.6313 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7210 - acc: 0.4456 - val_loss: 0.7052 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7208 - acc: 0.4456 - val_loss: 0.7051 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7207 - acc: 0.4456 - val_loss: 0.7049 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7206 - acc: 0.4456 - val_loss: 0.7048 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7204 - acc: 0.4456 - val_loss: 0.7046 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7203 - acc: 0.4456 - val_loss: 0.7045 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7201 - acc: 0.4456 - val_loss: 0.7044 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7200 - acc: 0.4456 - val_loss: 0.7042 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7199 - acc: 0.4456 - val_loss: 0.7041 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7197 - acc: 0.4456 - val_loss: 0.7040 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7196 - acc: 0.4404 - val_loss: 0.7038 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7194 - acc: 0.4404 - val_loss: 0.7037 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7193 - acc: 0.4404 - val_loss: 0.7036 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7192 - acc: 0.4404 - val_loss: 0.7034 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7190 - acc: 0.4404 - val_loss: 0.7033 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7189 - acc: 0.4404 - val_loss: 0.7032 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7187 - acc: 0.4404 - val_loss: 0.7030 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7186 - acc: 0.4404 - val_loss: 0.7029 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7184 - acc: 0.4404 - val_loss: 0.7027 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7183 - acc: 0.4352 - val_loss: 0.7026 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7332 - acc: 0.3402 - val_loss: 0.7285 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7330 - acc: 0.3402 - val_loss: 0.7283 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7329 - acc: 0.3402 - val_loss: 0.7282 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7327 - acc: 0.3351 - val_loss: 0.7280 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7326 - acc: 0.3402 - val_loss: 0.7279 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7325 - acc: 0.3402 - val_loss: 0.7277 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7323 - acc: 0.3402 - val_loss: 0.7276 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7322 - acc: 0.3402 - val_loss: 0.7274 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7320 - acc: 0.3402 - val_loss: 0.7273 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7319 - acc: 0.3402 - val_loss: 0.7271 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7318 - acc: 0.3402 - val_loss: 0.7270 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7317 - acc: 0.3402 - val_loss: 0.7268 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7315 - acc: 0.3402 - val_loss: 0.7267 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7314 - acc: 0.3402 - val_loss: 0.7266 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7313 - acc: 0.3402 - val_loss: 0.7264 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7312 - acc: 0.3402 - val_loss: 0.7263 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7310 - acc: 0.3402 - val_loss: 0.7261 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7309 - acc: 0.3402 - val_loss: 0.7260 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7308 - acc: 0.3402 - val_loss: 0.7259 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7307 - acc: 0.3454 - val_loss: 0.7257 - val_acc: 0.3934\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6741 - acc: 0.5515 - val_loss: 0.6717 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6739 - acc: 0.5515 - val_loss: 0.6715 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6738 - acc: 0.5515 - val_loss: 0.6714 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6737 - acc: 0.5515 - val_loss: 0.6713 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6736 - acc: 0.5515 - val_loss: 0.6712 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6735 - acc: 0.5567 - val_loss: 0.6711 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6733 - acc: 0.5567 - val_loss: 0.6709 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6732 - acc: 0.5567 - val_loss: 0.6708 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6731 - acc: 0.5567 - val_loss: 0.6707 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6730 - acc: 0.5567 - val_loss: 0.6706 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6729 - acc: 0.5567 - val_loss: 0.6704 - val_acc: 0.5738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6728 - acc: 0.5567 - val_loss: 0.6703 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6727 - acc: 0.5567 - val_loss: 0.6702 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6726 - acc: 0.5567 - val_loss: 0.6701 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6725 - acc: 0.5567 - val_loss: 0.6700 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6724 - acc: 0.5567 - val_loss: 0.6699 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6723 - acc: 0.5567 - val_loss: 0.6698 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6722 - acc: 0.5567 - val_loss: 0.6697 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6721 - acc: 0.5567 - val_loss: 0.6695 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6719 - acc: 0.5619 - val_loss: 0.6694 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.7170 - acc: 0.5000 - val_loss: 0.7383 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7169 - acc: 0.5052 - val_loss: 0.7381 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7167 - acc: 0.5052 - val_loss: 0.7380 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7166 - acc: 0.5052 - val_loss: 0.7378 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7165 - acc: 0.5052 - val_loss: 0.7377 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7163 - acc: 0.5052 - val_loss: 0.7375 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7162 - acc: 0.5052 - val_loss: 0.7374 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7161 - acc: 0.5052 - val_loss: 0.7373 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7160 - acc: 0.5052 - val_loss: 0.7371 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7159 - acc: 0.5052 - val_loss: 0.7370 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7157 - acc: 0.5052 - val_loss: 0.7368 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7156 - acc: 0.5052 - val_loss: 0.7367 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7155 - acc: 0.5052 - val_loss: 0.7366 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7154 - acc: 0.5052 - val_loss: 0.7364 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7153 - acc: 0.5052 - val_loss: 0.7363 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7151 - acc: 0.5052 - val_loss: 0.7361 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7150 - acc: 0.5052 - val_loss: 0.7360 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7149 - acc: 0.5103 - val_loss: 0.7359 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7148 - acc: 0.5103 - val_loss: 0.7357 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7147 - acc: 0.5103 - val_loss: 0.7356 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7247 - acc: 0.5078 - val_loss: 0.7301 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7245 - acc: 0.5078 - val_loss: 0.7299 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7243 - acc: 0.5130 - val_loss: 0.7297 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7241 - acc: 0.5130 - val_loss: 0.7295 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7239 - acc: 0.5130 - val_loss: 0.7292 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7238 - acc: 0.5130 - val_loss: 0.7291 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7236 - acc: 0.5130 - val_loss: 0.7289 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7234 - acc: 0.5181 - val_loss: 0.7287 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7233 - acc: 0.5181 - val_loss: 0.7285 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7231 - acc: 0.5181 - val_loss: 0.7283 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7229 - acc: 0.5181 - val_loss: 0.7281 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7227 - acc: 0.5181 - val_loss: 0.7279 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7226 - acc: 0.5181 - val_loss: 0.7276 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7224 - acc: 0.5181 - val_loss: 0.7274 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7222 - acc: 0.5181 - val_loss: 0.7273 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7221 - acc: 0.5181 - val_loss: 0.7270 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7219 - acc: 0.5181 - val_loss: 0.7269 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7218 - acc: 0.5181 - val_loss: 0.7267 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7216 - acc: 0.5181 - val_loss: 0.7265 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7215 - acc: 0.5181 - val_loss: 0.7263 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7113 - acc: 0.4611 - val_loss: 0.7078 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7111 - acc: 0.4611 - val_loss: 0.7076 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7109 - acc: 0.4611 - val_loss: 0.7074 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7107 - acc: 0.4611 - val_loss: 0.7072 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7106 - acc: 0.4611 - val_loss: 0.7071 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7104 - acc: 0.4611 - val_loss: 0.7069 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7102 - acc: 0.4611 - val_loss: 0.7067 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7100 - acc: 0.4611 - val_loss: 0.7065 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7099 - acc: 0.4560 - val_loss: 0.7063 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7097 - acc: 0.4560 - val_loss: 0.7061 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7095 - acc: 0.4560 - val_loss: 0.7060 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7094 - acc: 0.4611 - val_loss: 0.7058 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7092 - acc: 0.4611 - val_loss: 0.7056 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7090 - acc: 0.4611 - val_loss: 0.7055 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7089 - acc: 0.4611 - val_loss: 0.7053 - val_acc: 0.4754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7087 - acc: 0.4663 - val_loss: 0.7051 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7086 - acc: 0.4663 - val_loss: 0.7050 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7084 - acc: 0.4663 - val_loss: 0.7048 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7082 - acc: 0.4663 - val_loss: 0.7047 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7081 - acc: 0.4663 - val_loss: 0.7045 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7364 - acc: 0.4072 - val_loss: 0.7367 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7361 - acc: 0.4072 - val_loss: 0.7365 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7359 - acc: 0.4072 - val_loss: 0.7362 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7357 - acc: 0.4124 - val_loss: 0.7360 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7355 - acc: 0.4124 - val_loss: 0.7358 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7353 - acc: 0.4124 - val_loss: 0.7356 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7351 - acc: 0.4124 - val_loss: 0.7354 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7349 - acc: 0.4124 - val_loss: 0.7352 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7347 - acc: 0.4124 - val_loss: 0.7350 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7345 - acc: 0.4124 - val_loss: 0.7348 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7343 - acc: 0.4124 - val_loss: 0.7346 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7341 - acc: 0.4124 - val_loss: 0.7344 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7339 - acc: 0.4124 - val_loss: 0.7342 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7338 - acc: 0.4124 - val_loss: 0.7340 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7336 - acc: 0.4124 - val_loss: 0.7338 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7334 - acc: 0.4124 - val_loss: 0.7336 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7332 - acc: 0.4124 - val_loss: 0.7334 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7330 - acc: 0.4124 - val_loss: 0.7332 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7328 - acc: 0.4124 - val_loss: 0.7330 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7327 - acc: 0.4124 - val_loss: 0.7328 - val_acc: 0.4590\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6914 - acc: 0.5103 - val_loss: 0.6878 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6912 - acc: 0.5103 - val_loss: 0.6876 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6911 - acc: 0.5103 - val_loss: 0.6874 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6909 - acc: 0.5103 - val_loss: 0.6872 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6907 - acc: 0.5103 - val_loss: 0.6870 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6905 - acc: 0.5103 - val_loss: 0.6868 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6904 - acc: 0.5103 - val_loss: 0.6866 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6902 - acc: 0.5103 - val_loss: 0.6865 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6900 - acc: 0.5103 - val_loss: 0.6863 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6899 - acc: 0.5103 - val_loss: 0.6861 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6897 - acc: 0.5206 - val_loss: 0.6859 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6896 - acc: 0.5206 - val_loss: 0.6857 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6894 - acc: 0.5206 - val_loss: 0.6855 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6893 - acc: 0.5206 - val_loss: 0.6854 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6891 - acc: 0.5206 - val_loss: 0.6852 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6890 - acc: 0.5206 - val_loss: 0.6850 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6888 - acc: 0.5206 - val_loss: 0.6848 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6886 - acc: 0.5206 - val_loss: 0.6847 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6885 - acc: 0.5206 - val_loss: 0.6845 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6884 - acc: 0.5206 - val_loss: 0.6844 - val_acc: 0.5902\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6728 - acc: 0.5670 - val_loss: 0.6788 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6726 - acc: 0.5670 - val_loss: 0.6786 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6724 - acc: 0.5670 - val_loss: 0.6784 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6723 - acc: 0.5670 - val_loss: 0.6782 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6721 - acc: 0.5670 - val_loss: 0.6781 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6720 - acc: 0.5670 - val_loss: 0.6779 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6718 - acc: 0.5670 - val_loss: 0.6777 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6717 - acc: 0.5670 - val_loss: 0.6775 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6715 - acc: 0.5722 - val_loss: 0.6774 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6714 - acc: 0.5670 - val_loss: 0.6773 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6713 - acc: 0.5670 - val_loss: 0.6771 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6711 - acc: 0.5670 - val_loss: 0.6769 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6710 - acc: 0.5670 - val_loss: 0.6768 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6709 - acc: 0.5670 - val_loss: 0.6766 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6707 - acc: 0.5670 - val_loss: 0.6764 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6706 - acc: 0.5670 - val_loss: 0.6763 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6704 - acc: 0.5670 - val_loss: 0.6761 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6703 - acc: 0.5670 - val_loss: 0.6759 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6701 - acc: 0.5670 - val_loss: 0.6758 - val_acc: 0.5738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6700 - acc: 0.5670 - val_loss: 0.6756 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.8468 - acc: 0.3472 - val_loss: 0.8244 - val_acc: 0.2951\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8446 - acc: 0.3472 - val_loss: 0.8225 - val_acc: 0.2951\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8428 - acc: 0.3472 - val_loss: 0.8207 - val_acc: 0.2951\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8410 - acc: 0.3472 - val_loss: 0.8190 - val_acc: 0.2951\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8392 - acc: 0.3523 - val_loss: 0.8174 - val_acc: 0.2951\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8376 - acc: 0.3523 - val_loss: 0.8158 - val_acc: 0.2951\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8359 - acc: 0.3575 - val_loss: 0.8142 - val_acc: 0.2951\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8343 - acc: 0.3575 - val_loss: 0.8127 - val_acc: 0.2951\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8327 - acc: 0.3575 - val_loss: 0.8112 - val_acc: 0.2951\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8311 - acc: 0.3575 - val_loss: 0.8097 - val_acc: 0.2951\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8295 - acc: 0.3575 - val_loss: 0.8083 - val_acc: 0.2951\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8279 - acc: 0.3627 - val_loss: 0.8069 - val_acc: 0.3115\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8263 - acc: 0.3627 - val_loss: 0.8055 - val_acc: 0.3115\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8249 - acc: 0.3627 - val_loss: 0.8040 - val_acc: 0.3115\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8233 - acc: 0.3627 - val_loss: 0.8027 - val_acc: 0.3115\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8219 - acc: 0.3627 - val_loss: 0.8013 - val_acc: 0.3115\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8203 - acc: 0.3679 - val_loss: 0.7999 - val_acc: 0.3115\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8188 - acc: 0.3782 - val_loss: 0.7986 - val_acc: 0.3115\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8175 - acc: 0.3782 - val_loss: 0.7974 - val_acc: 0.3115\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8163 - acc: 0.3782 - val_loss: 0.7962 - val_acc: 0.3115\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6971 - acc: 0.5544 - val_loss: 0.6607 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6954 - acc: 0.5596 - val_loss: 0.6591 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6937 - acc: 0.5596 - val_loss: 0.6576 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6922 - acc: 0.5648 - val_loss: 0.6562 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6908 - acc: 0.5648 - val_loss: 0.6548 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6894 - acc: 0.5648 - val_loss: 0.6535 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6881 - acc: 0.5648 - val_loss: 0.6522 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6869 - acc: 0.5648 - val_loss: 0.6509 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6857 - acc: 0.5648 - val_loss: 0.6496 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6844 - acc: 0.5648 - val_loss: 0.6484 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6832 - acc: 0.5648 - val_loss: 0.6474 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6821 - acc: 0.5648 - val_loss: 0.6463 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6810 - acc: 0.5648 - val_loss: 0.6453 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6800 - acc: 0.5648 - val_loss: 0.6442 - val_acc: 0.6393\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6788 - acc: 0.5648 - val_loss: 0.6430 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6776 - acc: 0.5699 - val_loss: 0.6418 - val_acc: 0.6557\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6764 - acc: 0.5699 - val_loss: 0.6407 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6753 - acc: 0.5699 - val_loss: 0.6395 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6741 - acc: 0.5803 - val_loss: 0.6384 - val_acc: 0.6557\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6730 - acc: 0.5803 - val_loss: 0.6372 - val_acc: 0.6557\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6695 - acc: 0.5464 - val_loss: 0.6651 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6680 - acc: 0.5515 - val_loss: 0.6639 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6670 - acc: 0.5567 - val_loss: 0.6627 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6659 - acc: 0.5567 - val_loss: 0.6613 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6647 - acc: 0.5567 - val_loss: 0.6601 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6637 - acc: 0.5567 - val_loss: 0.6591 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6627 - acc: 0.5567 - val_loss: 0.6580 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6617 - acc: 0.5567 - val_loss: 0.6568 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6607 - acc: 0.5567 - val_loss: 0.6554 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6595 - acc: 0.5567 - val_loss: 0.6541 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6584 - acc: 0.5567 - val_loss: 0.6528 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6573 - acc: 0.5567 - val_loss: 0.6516 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6562 - acc: 0.5567 - val_loss: 0.6503 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6551 - acc: 0.5567 - val_loss: 0.6491 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6542 - acc: 0.5567 - val_loss: 0.6478 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6531 - acc: 0.5567 - val_loss: 0.6467 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6521 - acc: 0.5567 - val_loss: 0.6456 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6511 - acc: 0.5567 - val_loss: 0.6446 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6502 - acc: 0.5567 - val_loss: 0.6435 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6492 - acc: 0.5567 - val_loss: 0.6423 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7332 - acc: 0.5515 - val_loss: 0.7490 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7309 - acc: 0.5515 - val_loss: 0.7462 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7290 - acc: 0.5515 - val_loss: 0.7436 - val_acc: 0.5410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7271 - acc: 0.5515 - val_loss: 0.7409 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7252 - acc: 0.5515 - val_loss: 0.7381 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7231 - acc: 0.5515 - val_loss: 0.7355 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7212 - acc: 0.5515 - val_loss: 0.7329 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7192 - acc: 0.5515 - val_loss: 0.7305 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7174 - acc: 0.5515 - val_loss: 0.7285 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7160 - acc: 0.5515 - val_loss: 0.7265 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7145 - acc: 0.5515 - val_loss: 0.7245 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7130 - acc: 0.5515 - val_loss: 0.7225 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7115 - acc: 0.5515 - val_loss: 0.7206 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7101 - acc: 0.5515 - val_loss: 0.7189 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7088 - acc: 0.5515 - val_loss: 0.7169 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7073 - acc: 0.5515 - val_loss: 0.7146 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7057 - acc: 0.5515 - val_loss: 0.7128 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7044 - acc: 0.5515 - val_loss: 0.7112 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7032 - acc: 0.5515 - val_loss: 0.7096 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7019 - acc: 0.5515 - val_loss: 0.7078 - val_acc: 0.5574\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7427 - acc: 0.4124 - val_loss: 0.7289 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7414 - acc: 0.4124 - val_loss: 0.7277 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7404 - acc: 0.4124 - val_loss: 0.7267 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7394 - acc: 0.4124 - val_loss: 0.7257 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7383 - acc: 0.4124 - val_loss: 0.7247 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7373 - acc: 0.4124 - val_loss: 0.7237 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7363 - acc: 0.4124 - val_loss: 0.7226 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7352 - acc: 0.4124 - val_loss: 0.7216 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7343 - acc: 0.4124 - val_loss: 0.7207 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7333 - acc: 0.4124 - val_loss: 0.7197 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7323 - acc: 0.4124 - val_loss: 0.7187 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7314 - acc: 0.4124 - val_loss: 0.7178 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7304 - acc: 0.4124 - val_loss: 0.7169 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7295 - acc: 0.4124 - val_loss: 0.7159 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7286 - acc: 0.4124 - val_loss: 0.7149 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7277 - acc: 0.4124 - val_loss: 0.7140 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7267 - acc: 0.4175 - val_loss: 0.7130 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7258 - acc: 0.4175 - val_loss: 0.7120 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7249 - acc: 0.4175 - val_loss: 0.7111 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7241 - acc: 0.4175 - val_loss: 0.7102 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5932 - acc: 0.7202 - val_loss: 0.6141 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5909 - acc: 0.7150 - val_loss: 0.6115 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5889 - acc: 0.7150 - val_loss: 0.6091 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5870 - acc: 0.7254 - val_loss: 0.6066 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5851 - acc: 0.7254 - val_loss: 0.6044 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5833 - acc: 0.7306 - val_loss: 0.6021 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5814 - acc: 0.7409 - val_loss: 0.5999 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5798 - acc: 0.7461 - val_loss: 0.5978 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5781 - acc: 0.7461 - val_loss: 0.5959 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5765 - acc: 0.7461 - val_loss: 0.5939 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5750 - acc: 0.7461 - val_loss: 0.5918 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5735 - acc: 0.7409 - val_loss: 0.5899 - val_acc: 0.7541\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5719 - acc: 0.7409 - val_loss: 0.5881 - val_acc: 0.7541\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5704 - acc: 0.7461 - val_loss: 0.5863 - val_acc: 0.7541\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5690 - acc: 0.7461 - val_loss: 0.5846 - val_acc: 0.7705\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5675 - acc: 0.7513 - val_loss: 0.5829 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5661 - acc: 0.7513 - val_loss: 0.5809 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5647 - acc: 0.7513 - val_loss: 0.5792 - val_acc: 0.7869\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5632 - acc: 0.7513 - val_loss: 0.5774 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5618 - acc: 0.7513 - val_loss: 0.5755 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7550 - acc: 0.4301 - val_loss: 0.7542 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7527 - acc: 0.4404 - val_loss: 0.7521 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7505 - acc: 0.4560 - val_loss: 0.7501 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7486 - acc: 0.4611 - val_loss: 0.7481 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7468 - acc: 0.4663 - val_loss: 0.7463 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7450 - acc: 0.4715 - val_loss: 0.7445 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7433 - acc: 0.4663 - val_loss: 0.7428 - val_acc: 0.4754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7417 - acc: 0.4715 - val_loss: 0.7410 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7399 - acc: 0.4767 - val_loss: 0.7394 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7383 - acc: 0.4767 - val_loss: 0.7376 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7365 - acc: 0.4870 - val_loss: 0.7357 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7348 - acc: 0.4819 - val_loss: 0.7340 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7331 - acc: 0.4870 - val_loss: 0.7322 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7314 - acc: 0.4870 - val_loss: 0.7304 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7297 - acc: 0.4870 - val_loss: 0.7286 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7280 - acc: 0.4870 - val_loss: 0.7269 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7264 - acc: 0.4922 - val_loss: 0.7253 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7248 - acc: 0.4922 - val_loss: 0.7236 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7231 - acc: 0.4922 - val_loss: 0.7220 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7215 - acc: 0.4922 - val_loss: 0.7203 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8134 - acc: 0.5567 - val_loss: 0.8767 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8088 - acc: 0.5567 - val_loss: 0.8709 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8044 - acc: 0.5567 - val_loss: 0.8653 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7998 - acc: 0.5567 - val_loss: 0.8596 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7957 - acc: 0.5567 - val_loss: 0.8540 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7916 - acc: 0.5567 - val_loss: 0.8491 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7879 - acc: 0.5567 - val_loss: 0.8438 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7840 - acc: 0.5567 - val_loss: 0.8385 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7802 - acc: 0.5567 - val_loss: 0.8336 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7767 - acc: 0.5567 - val_loss: 0.8287 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7729 - acc: 0.5567 - val_loss: 0.8235 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7690 - acc: 0.5567 - val_loss: 0.8188 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7657 - acc: 0.5567 - val_loss: 0.8140 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7618 - acc: 0.5567 - val_loss: 0.8087 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7579 - acc: 0.5567 - val_loss: 0.8039 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7542 - acc: 0.5619 - val_loss: 0.7993 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7508 - acc: 0.5619 - val_loss: 0.7947 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7473 - acc: 0.5619 - val_loss: 0.7900 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7436 - acc: 0.5619 - val_loss: 0.7852 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7402 - acc: 0.5670 - val_loss: 0.7804 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0272 - acc: 0.3866 - val_loss: 0.9628 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0204 - acc: 0.3866 - val_loss: 0.9566 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0138 - acc: 0.3814 - val_loss: 0.9508 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0079 - acc: 0.3814 - val_loss: 0.9455 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0021 - acc: 0.3814 - val_loss: 0.9404 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9968 - acc: 0.3814 - val_loss: 0.9351 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9908 - acc: 0.3814 - val_loss: 0.9298 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9852 - acc: 0.3814 - val_loss: 0.9246 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9797 - acc: 0.3814 - val_loss: 0.9194 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9740 - acc: 0.3763 - val_loss: 0.9143 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9684 - acc: 0.3763 - val_loss: 0.9095 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9634 - acc: 0.3763 - val_loss: 0.9046 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9582 - acc: 0.3763 - val_loss: 0.9002 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9534 - acc: 0.3814 - val_loss: 0.8959 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9488 - acc: 0.3814 - val_loss: 0.8912 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9438 - acc: 0.3814 - val_loss: 0.8867 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9389 - acc: 0.3814 - val_loss: 0.8822 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9341 - acc: 0.3814 - val_loss: 0.8781 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9296 - acc: 0.3814 - val_loss: 0.8737 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.9251 - acc: 0.3814 - val_loss: 0.8694 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8304 - acc: 0.3402 - val_loss: 0.8563 - val_acc: 0.2295\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8263 - acc: 0.3454 - val_loss: 0.8518 - val_acc: 0.2295\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8224 - acc: 0.3454 - val_loss: 0.8474 - val_acc: 0.2295\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8187 - acc: 0.3454 - val_loss: 0.8433 - val_acc: 0.2295\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8153 - acc: 0.3402 - val_loss: 0.8391 - val_acc: 0.2295\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8116 - acc: 0.3402 - val_loss: 0.8350 - val_acc: 0.2295\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8082 - acc: 0.3402 - val_loss: 0.8309 - val_acc: 0.2295\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8047 - acc: 0.3454 - val_loss: 0.8267 - val_acc: 0.2459\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8011 - acc: 0.3505 - val_loss: 0.8224 - val_acc: 0.2623\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7974 - acc: 0.3505 - val_loss: 0.8182 - val_acc: 0.2623\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7941 - acc: 0.3505 - val_loss: 0.8143 - val_acc: 0.2623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7907 - acc: 0.3505 - val_loss: 0.8103 - val_acc: 0.2623\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7874 - acc: 0.3608 - val_loss: 0.8063 - val_acc: 0.2623\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7840 - acc: 0.3608 - val_loss: 0.8026 - val_acc: 0.2623\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7808 - acc: 0.3660 - val_loss: 0.7990 - val_acc: 0.2787\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7779 - acc: 0.3660 - val_loss: 0.7954 - val_acc: 0.2951\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7748 - acc: 0.3763 - val_loss: 0.7918 - val_acc: 0.2951\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7717 - acc: 0.3814 - val_loss: 0.7878 - val_acc: 0.3115\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7685 - acc: 0.3918 - val_loss: 0.7838 - val_acc: 0.3279\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7650 - acc: 0.3969 - val_loss: 0.7797 - val_acc: 0.3443\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6835 - acc: 0.5959 - val_loss: 0.6606 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6796 - acc: 0.6010 - val_loss: 0.6570 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6765 - acc: 0.6062 - val_loss: 0.6540 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6735 - acc: 0.6114 - val_loss: 0.6508 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6707 - acc: 0.6114 - val_loss: 0.6479 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6679 - acc: 0.6166 - val_loss: 0.6448 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6651 - acc: 0.6373 - val_loss: 0.6420 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6625 - acc: 0.6477 - val_loss: 0.6396 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6601 - acc: 0.6580 - val_loss: 0.6371 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6575 - acc: 0.6632 - val_loss: 0.6342 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6548 - acc: 0.6839 - val_loss: 0.6314 - val_acc: 0.7213\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6522 - acc: 0.6891 - val_loss: 0.6288 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6496 - acc: 0.6995 - val_loss: 0.6262 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6473 - acc: 0.7047 - val_loss: 0.6235 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6447 - acc: 0.7098 - val_loss: 0.6208 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6421 - acc: 0.7202 - val_loss: 0.6180 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6396 - acc: 0.7202 - val_loss: 0.6153 - val_acc: 0.7213\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6371 - acc: 0.7202 - val_loss: 0.6126 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6348 - acc: 0.7202 - val_loss: 0.6103 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6327 - acc: 0.7202 - val_loss: 0.6083 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7222 - acc: 0.4352 - val_loss: 0.7412 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7172 - acc: 0.4352 - val_loss: 0.7366 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7136 - acc: 0.4404 - val_loss: 0.7331 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7105 - acc: 0.4611 - val_loss: 0.7294 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7071 - acc: 0.4715 - val_loss: 0.7256 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7035 - acc: 0.4819 - val_loss: 0.7218 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7000 - acc: 0.4922 - val_loss: 0.7180 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6965 - acc: 0.5026 - val_loss: 0.7144 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.5026 - val_loss: 0.7109 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6900 - acc: 0.5078 - val_loss: 0.7076 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6867 - acc: 0.5130 - val_loss: 0.7041 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6832 - acc: 0.5389 - val_loss: 0.7006 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6802 - acc: 0.5440 - val_loss: 0.6972 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6767 - acc: 0.5492 - val_loss: 0.6936 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6736 - acc: 0.5648 - val_loss: 0.6897 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6703 - acc: 0.5699 - val_loss: 0.6862 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6673 - acc: 0.5751 - val_loss: 0.6829 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6644 - acc: 0.5803 - val_loss: 0.6802 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6620 - acc: 0.5803 - val_loss: 0.6776 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6595 - acc: 0.5855 - val_loss: 0.6748 - val_acc: 0.5574\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5966 - acc: 0.7165 - val_loss: 0.5722 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5938 - acc: 0.7320 - val_loss: 0.5694 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5915 - acc: 0.7320 - val_loss: 0.5667 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5892 - acc: 0.7371 - val_loss: 0.5642 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5870 - acc: 0.7371 - val_loss: 0.5617 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5848 - acc: 0.7371 - val_loss: 0.5592 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5827 - acc: 0.7371 - val_loss: 0.5570 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5807 - acc: 0.7371 - val_loss: 0.5547 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5786 - acc: 0.7371 - val_loss: 0.5523 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5765 - acc: 0.7371 - val_loss: 0.5499 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5745 - acc: 0.7371 - val_loss: 0.5475 - val_acc: 0.7541\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5724 - acc: 0.7371 - val_loss: 0.5454 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5705 - acc: 0.7371 - val_loss: 0.5432 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5685 - acc: 0.7371 - val_loss: 0.5408 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5664 - acc: 0.7474 - val_loss: 0.5383 - val_acc: 0.7869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5642 - acc: 0.7474 - val_loss: 0.5361 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5623 - acc: 0.7474 - val_loss: 0.5339 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5604 - acc: 0.7474 - val_loss: 0.5320 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5587 - acc: 0.7577 - val_loss: 0.5301 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5569 - acc: 0.7629 - val_loss: 0.5280 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8060 - acc: 0.5258 - val_loss: 0.7802 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7992 - acc: 0.5309 - val_loss: 0.7723 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7930 - acc: 0.5361 - val_loss: 0.7642 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7870 - acc: 0.5412 - val_loss: 0.7561 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7811 - acc: 0.5464 - val_loss: 0.7491 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7757 - acc: 0.5464 - val_loss: 0.7424 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7706 - acc: 0.5515 - val_loss: 0.7359 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7656 - acc: 0.5619 - val_loss: 0.7293 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7604 - acc: 0.5619 - val_loss: 0.7226 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7549 - acc: 0.5619 - val_loss: 0.7154 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7496 - acc: 0.5567 - val_loss: 0.7084 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7445 - acc: 0.5567 - val_loss: 0.7011 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7389 - acc: 0.5567 - val_loss: 0.6943 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7334 - acc: 0.5619 - val_loss: 0.6881 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7288 - acc: 0.5619 - val_loss: 0.6823 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7243 - acc: 0.5619 - val_loss: 0.6767 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7198 - acc: 0.5619 - val_loss: 0.6717 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7155 - acc: 0.5619 - val_loss: 0.6670 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7116 - acc: 0.5619 - val_loss: 0.6619 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7073 - acc: 0.5619 - val_loss: 0.6559 - val_acc: 0.5902\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6394 - acc: 0.6598 - val_loss: 0.6344 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6359 - acc: 0.6701 - val_loss: 0.6313 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6329 - acc: 0.6701 - val_loss: 0.6281 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6299 - acc: 0.6753 - val_loss: 0.6248 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6267 - acc: 0.6753 - val_loss: 0.6215 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6237 - acc: 0.6804 - val_loss: 0.6181 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6205 - acc: 0.6804 - val_loss: 0.6148 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6177 - acc: 0.6856 - val_loss: 0.6116 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6147 - acc: 0.6907 - val_loss: 0.6085 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6120 - acc: 0.6907 - val_loss: 0.6057 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6094 - acc: 0.6907 - val_loss: 0.6031 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6068 - acc: 0.6907 - val_loss: 0.6003 - val_acc: 0.7049\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6044 - acc: 0.6959 - val_loss: 0.5975 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6019 - acc: 0.7010 - val_loss: 0.5950 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5995 - acc: 0.7010 - val_loss: 0.5925 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5972 - acc: 0.7010 - val_loss: 0.5896 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5946 - acc: 0.7010 - val_loss: 0.5866 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5921 - acc: 0.7010 - val_loss: 0.5838 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5897 - acc: 0.7010 - val_loss: 0.5812 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5875 - acc: 0.7010 - val_loss: 0.5791 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.6469 - acc: 0.6477 - val_loss: 0.6337 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6405 - acc: 0.6736 - val_loss: 0.6281 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6357 - acc: 0.6736 - val_loss: 0.6229 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6308 - acc: 0.6891 - val_loss: 0.6172 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6256 - acc: 0.6891 - val_loss: 0.6119 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6209 - acc: 0.7047 - val_loss: 0.6068 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6165 - acc: 0.7098 - val_loss: 0.6020 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6123 - acc: 0.7202 - val_loss: 0.5975 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6082 - acc: 0.7254 - val_loss: 0.5932 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6042 - acc: 0.7202 - val_loss: 0.5893 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6006 - acc: 0.7254 - val_loss: 0.5855 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5972 - acc: 0.7254 - val_loss: 0.5824 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5938 - acc: 0.7306 - val_loss: 0.5786 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5904 - acc: 0.7358 - val_loss: 0.5748 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5868 - acc: 0.7358 - val_loss: 0.5708 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5832 - acc: 0.7358 - val_loss: 0.5667 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5799 - acc: 0.7358 - val_loss: 0.5631 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5766 - acc: 0.7409 - val_loss: 0.5595 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5732 - acc: 0.7409 - val_loss: 0.5558 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5700 - acc: 0.7409 - val_loss: 0.5525 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.8399 - acc: 0.2902 - val_loss: 0.8084 - val_acc: 0.3279\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8307 - acc: 0.3109 - val_loss: 0.8002 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8230 - acc: 0.3057 - val_loss: 0.7926 - val_acc: 0.3443\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8158 - acc: 0.3161 - val_loss: 0.7853 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8092 - acc: 0.3264 - val_loss: 0.7783 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8023 - acc: 0.3316 - val_loss: 0.7714 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7960 - acc: 0.3368 - val_loss: 0.7647 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7898 - acc: 0.3368 - val_loss: 0.7583 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7839 - acc: 0.3523 - val_loss: 0.7528 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7786 - acc: 0.3523 - val_loss: 0.7472 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7730 - acc: 0.3782 - val_loss: 0.7422 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7685 - acc: 0.3886 - val_loss: 0.7372 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7642 - acc: 0.4093 - val_loss: 0.7322 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7593 - acc: 0.4093 - val_loss: 0.7272 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7550 - acc: 0.4093 - val_loss: 0.7225 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7501 - acc: 0.4249 - val_loss: 0.7169 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7446 - acc: 0.4249 - val_loss: 0.7112 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7395 - acc: 0.4301 - val_loss: 0.7059 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7343 - acc: 0.4352 - val_loss: 0.7005 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7290 - acc: 0.4404 - val_loss: 0.6951 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.7990 - acc: 0.4588 - val_loss: 0.7755 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7888 - acc: 0.4639 - val_loss: 0.7663 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7787 - acc: 0.4691 - val_loss: 0.7572 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7692 - acc: 0.4691 - val_loss: 0.7484 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7603 - acc: 0.4742 - val_loss: 0.7401 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7514 - acc: 0.4794 - val_loss: 0.7322 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7431 - acc: 0.4845 - val_loss: 0.7246 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7354 - acc: 0.4845 - val_loss: 0.7177 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7279 - acc: 0.4845 - val_loss: 0.7109 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7205 - acc: 0.4845 - val_loss: 0.7035 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7133 - acc: 0.4897 - val_loss: 0.6967 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7059 - acc: 0.4897 - val_loss: 0.6902 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6986 - acc: 0.4948 - val_loss: 0.6829 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6910 - acc: 0.5000 - val_loss: 0.6759 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6838 - acc: 0.5052 - val_loss: 0.6692 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6768 - acc: 0.5052 - val_loss: 0.6625 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6700 - acc: 0.5155 - val_loss: 0.6566 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6637 - acc: 0.5155 - val_loss: 0.6506 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6574 - acc: 0.5155 - val_loss: 0.6446 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6517 - acc: 0.5258 - val_loss: 0.6391 - val_acc: 0.5574\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8463 - acc: 0.3918 - val_loss: 0.7874 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8366 - acc: 0.3969 - val_loss: 0.7790 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8280 - acc: 0.3969 - val_loss: 0.7708 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8186 - acc: 0.4072 - val_loss: 0.7626 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8096 - acc: 0.4021 - val_loss: 0.7544 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.8016 - acc: 0.4072 - val_loss: 0.7462 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7931 - acc: 0.4124 - val_loss: 0.7382 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7855 - acc: 0.4175 - val_loss: 0.7308 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7782 - acc: 0.4175 - val_loss: 0.7237 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7711 - acc: 0.4278 - val_loss: 0.7166 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7641 - acc: 0.4278 - val_loss: 0.7100 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7577 - acc: 0.4381 - val_loss: 0.7037 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7511 - acc: 0.4485 - val_loss: 0.6974 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7449 - acc: 0.4588 - val_loss: 0.6909 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7384 - acc: 0.4742 - val_loss: 0.6848 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7324 - acc: 0.4691 - val_loss: 0.6793 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7269 - acc: 0.4742 - val_loss: 0.6737 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7212 - acc: 0.4794 - val_loss: 0.6680 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7156 - acc: 0.4948 - val_loss: 0.6622 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7097 - acc: 0.5103 - val_loss: 0.6563 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6465 - acc: 0.6598 - val_loss: 0.6335 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6416 - acc: 0.6701 - val_loss: 0.6283 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6371 - acc: 0.6701 - val_loss: 0.6233 - val_acc: 0.7213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6330 - acc: 0.6753 - val_loss: 0.6189 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6291 - acc: 0.6753 - val_loss: 0.6143 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6250 - acc: 0.6907 - val_loss: 0.6095 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6209 - acc: 0.6959 - val_loss: 0.6050 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6169 - acc: 0.7010 - val_loss: 0.6003 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6128 - acc: 0.7062 - val_loss: 0.5959 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6091 - acc: 0.7113 - val_loss: 0.5917 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6053 - acc: 0.7113 - val_loss: 0.5875 - val_acc: 0.7541\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6016 - acc: 0.7320 - val_loss: 0.5830 - val_acc: 0.7541\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5978 - acc: 0.7371 - val_loss: 0.5785 - val_acc: 0.7541\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5941 - acc: 0.7526 - val_loss: 0.5741 - val_acc: 0.7705\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5904 - acc: 0.7577 - val_loss: 0.5703 - val_acc: 0.7705\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5873 - acc: 0.7577 - val_loss: 0.5665 - val_acc: 0.7705\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5843 - acc: 0.7577 - val_loss: 0.5634 - val_acc: 0.7705\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5813 - acc: 0.7629 - val_loss: 0.5602 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5784 - acc: 0.7629 - val_loss: 0.5571 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5756 - acc: 0.7732 - val_loss: 0.5540 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6185 - acc: 0.7617 - val_loss: 0.5872 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6105 - acc: 0.7720 - val_loss: 0.5799 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6038 - acc: 0.7668 - val_loss: 0.5737 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5974 - acc: 0.7720 - val_loss: 0.5676 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5918 - acc: 0.7720 - val_loss: 0.5620 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5866 - acc: 0.7720 - val_loss: 0.5567 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5816 - acc: 0.7720 - val_loss: 0.5516 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5770 - acc: 0.7772 - val_loss: 0.5474 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5727 - acc: 0.7772 - val_loss: 0.5431 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5686 - acc: 0.7772 - val_loss: 0.5391 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5642 - acc: 0.7824 - val_loss: 0.5343 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5595 - acc: 0.7876 - val_loss: 0.5297 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5548 - acc: 0.7979 - val_loss: 0.5258 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5503 - acc: 0.7927 - val_loss: 0.5218 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5460 - acc: 0.7876 - val_loss: 0.5174 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5416 - acc: 0.7927 - val_loss: 0.5134 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5375 - acc: 0.7927 - val_loss: 0.5093 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5336 - acc: 0.7927 - val_loss: 0.5051 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5295 - acc: 0.7979 - val_loss: 0.5009 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5258 - acc: 0.7979 - val_loss: 0.4965 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6795 - acc: 0.5751 - val_loss: 0.7099 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6704 - acc: 0.5751 - val_loss: 0.7011 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6636 - acc: 0.5751 - val_loss: 0.6919 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6564 - acc: 0.5751 - val_loss: 0.6818 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6492 - acc: 0.5751 - val_loss: 0.6713 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6417 - acc: 0.5699 - val_loss: 0.6623 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6350 - acc: 0.5699 - val_loss: 0.6526 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6279 - acc: 0.5751 - val_loss: 0.6436 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6218 - acc: 0.5907 - val_loss: 0.6356 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6157 - acc: 0.6010 - val_loss: 0.6284 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6102 - acc: 0.6166 - val_loss: 0.6215 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6049 - acc: 0.6166 - val_loss: 0.6142 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5996 - acc: 0.6321 - val_loss: 0.6069 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5939 - acc: 0.6425 - val_loss: 0.6002 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5889 - acc: 0.6477 - val_loss: 0.5941 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5841 - acc: 0.6684 - val_loss: 0.5879 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5794 - acc: 0.6684 - val_loss: 0.5815 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5742 - acc: 0.6736 - val_loss: 0.5746 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5689 - acc: 0.7098 - val_loss: 0.5690 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5650 - acc: 0.7150 - val_loss: 0.5635 - val_acc: 0.7213\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7082 - acc: 0.4691 - val_loss: 0.7109 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6976 - acc: 0.5206 - val_loss: 0.7000 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6883 - acc: 0.5567 - val_loss: 0.6900 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6798 - acc: 0.5825 - val_loss: 0.6792 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6706 - acc: 0.6186 - val_loss: 0.6701 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6622 - acc: 0.6340 - val_loss: 0.6617 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6545 - acc: 0.6340 - val_loss: 0.6534 - val_acc: 0.6885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6469 - acc: 0.6598 - val_loss: 0.6449 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6396 - acc: 0.6804 - val_loss: 0.6366 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6323 - acc: 0.6959 - val_loss: 0.6285 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6255 - acc: 0.7216 - val_loss: 0.6212 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6190 - acc: 0.7216 - val_loss: 0.6141 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6125 - acc: 0.7320 - val_loss: 0.6064 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6061 - acc: 0.7474 - val_loss: 0.5988 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6000 - acc: 0.7526 - val_loss: 0.5916 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5938 - acc: 0.7577 - val_loss: 0.5846 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5876 - acc: 0.7629 - val_loss: 0.5778 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5820 - acc: 0.7835 - val_loss: 0.5715 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5763 - acc: 0.7887 - val_loss: 0.5649 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5707 - acc: 0.7887 - val_loss: 0.5586 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6107 - acc: 0.7216 - val_loss: 0.5878 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6025 - acc: 0.7474 - val_loss: 0.5804 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5953 - acc: 0.7423 - val_loss: 0.5725 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5885 - acc: 0.7423 - val_loss: 0.5650 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5819 - acc: 0.7474 - val_loss: 0.5573 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5754 - acc: 0.7526 - val_loss: 0.5504 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5694 - acc: 0.7577 - val_loss: 0.5442 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5647 - acc: 0.7629 - val_loss: 0.5383 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5594 - acc: 0.7732 - val_loss: 0.5327 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5544 - acc: 0.7784 - val_loss: 0.5268 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5499 - acc: 0.7784 - val_loss: 0.5219 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5456 - acc: 0.7784 - val_loss: 0.5169 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5408 - acc: 0.7835 - val_loss: 0.5117 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5367 - acc: 0.7938 - val_loss: 0.5063 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5322 - acc: 0.7990 - val_loss: 0.5017 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5284 - acc: 0.7990 - val_loss: 0.4971 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5243 - acc: 0.7938 - val_loss: 0.4927 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5204 - acc: 0.7938 - val_loss: 0.4883 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5167 - acc: 0.7938 - val_loss: 0.4846 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5136 - acc: 0.7938 - val_loss: 0.4812 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7442 - acc: 0.4072 - val_loss: 0.7210 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7334 - acc: 0.4227 - val_loss: 0.7100 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7237 - acc: 0.4485 - val_loss: 0.6995 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7140 - acc: 0.4948 - val_loss: 0.6896 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7053 - acc: 0.5052 - val_loss: 0.6805 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6966 - acc: 0.5155 - val_loss: 0.6722 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6890 - acc: 0.5412 - val_loss: 0.6638 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6809 - acc: 0.5464 - val_loss: 0.6559 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6741 - acc: 0.5876 - val_loss: 0.6487 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6668 - acc: 0.6186 - val_loss: 0.6410 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6597 - acc: 0.6495 - val_loss: 0.6332 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6525 - acc: 0.6649 - val_loss: 0.6252 - val_acc: 0.7049\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6455 - acc: 0.6753 - val_loss: 0.6182 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6387 - acc: 0.6804 - val_loss: 0.6107 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6318 - acc: 0.6959 - val_loss: 0.6036 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6251 - acc: 0.7010 - val_loss: 0.5969 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6188 - acc: 0.7113 - val_loss: 0.5905 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6124 - acc: 0.7216 - val_loss: 0.5839 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6062 - acc: 0.7165 - val_loss: 0.5775 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6004 - acc: 0.7320 - val_loss: 0.5713 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7310 - acc: 0.4767 - val_loss: 0.7200 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7161 - acc: 0.4767 - val_loss: 0.7073 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7039 - acc: 0.4819 - val_loss: 0.6953 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6929 - acc: 0.4767 - val_loss: 0.6835 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6812 - acc: 0.4819 - val_loss: 0.6719 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6700 - acc: 0.4922 - val_loss: 0.6606 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6592 - acc: 0.5181 - val_loss: 0.6498 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6498 - acc: 0.5389 - val_loss: 0.6405 - val_acc: 0.6393\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6404 - acc: 0.5907 - val_loss: 0.6306 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6318 - acc: 0.6218 - val_loss: 0.6213 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6229 - acc: 0.6580 - val_loss: 0.6127 - val_acc: 0.7049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6152 - acc: 0.6684 - val_loss: 0.6043 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6073 - acc: 0.6684 - val_loss: 0.5953 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5990 - acc: 0.6839 - val_loss: 0.5876 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5921 - acc: 0.6995 - val_loss: 0.5799 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5850 - acc: 0.7047 - val_loss: 0.5721 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5780 - acc: 0.7150 - val_loss: 0.5638 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5711 - acc: 0.7202 - val_loss: 0.5566 - val_acc: 0.7541\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5638 - acc: 0.7513 - val_loss: 0.5493 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5573 - acc: 0.7824 - val_loss: 0.5418 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7641 - acc: 0.3420 - val_loss: 0.7444 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7464 - acc: 0.3679 - val_loss: 0.7292 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7326 - acc: 0.4041 - val_loss: 0.7143 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7190 - acc: 0.4870 - val_loss: 0.7010 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7056 - acc: 0.5026 - val_loss: 0.6881 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6922 - acc: 0.5233 - val_loss: 0.6751 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6807 - acc: 0.5751 - val_loss: 0.6623 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6699 - acc: 0.5907 - val_loss: 0.6518 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6405 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6502 - acc: 0.6425 - val_loss: 0.6299 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6405 - acc: 0.6995 - val_loss: 0.6190 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6299 - acc: 0.7306 - val_loss: 0.6075 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6196 - acc: 0.7617 - val_loss: 0.5963 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6095 - acc: 0.7824 - val_loss: 0.5856 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5999 - acc: 0.7979 - val_loss: 0.5764 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5916 - acc: 0.8135 - val_loss: 0.5682 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5846 - acc: 0.8238 - val_loss: 0.5606 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5774 - acc: 0.8187 - val_loss: 0.5522 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5706 - acc: 0.8238 - val_loss: 0.5444 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5635 - acc: 0.8342 - val_loss: 0.5373 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.7127 - acc: 0.4485 - val_loss: 0.6999 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6980 - acc: 0.4845 - val_loss: 0.6843 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6844 - acc: 0.5361 - val_loss: 0.6697 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6717 - acc: 0.6082 - val_loss: 0.6559 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6601 - acc: 0.6340 - val_loss: 0.6433 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6494 - acc: 0.6753 - val_loss: 0.6323 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6399 - acc: 0.7062 - val_loss: 0.6220 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6309 - acc: 0.7371 - val_loss: 0.6119 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6218 - acc: 0.7474 - val_loss: 0.6022 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6134 - acc: 0.7474 - val_loss: 0.5926 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6052 - acc: 0.7629 - val_loss: 0.5833 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5973 - acc: 0.7680 - val_loss: 0.5736 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5890 - acc: 0.7732 - val_loss: 0.5641 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5809 - acc: 0.7835 - val_loss: 0.5551 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5730 - acc: 0.7887 - val_loss: 0.5466 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5659 - acc: 0.7990 - val_loss: 0.5387 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5593 - acc: 0.7938 - val_loss: 0.5312 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5529 - acc: 0.8041 - val_loss: 0.5240 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5465 - acc: 0.8041 - val_loss: 0.5172 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5401 - acc: 0.8041 - val_loss: 0.5105 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7225 - acc: 0.4536 - val_loss: 0.6886 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7048 - acc: 0.4639 - val_loss: 0.6722 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6885 - acc: 0.5258 - val_loss: 0.6566 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6742 - acc: 0.5670 - val_loss: 0.6414 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6598 - acc: 0.6237 - val_loss: 0.6269 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6469 - acc: 0.7062 - val_loss: 0.6136 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6345 - acc: 0.7010 - val_loss: 0.6008 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6231 - acc: 0.7371 - val_loss: 0.5888 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6129 - acc: 0.7526 - val_loss: 0.5784 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6032 - acc: 0.7526 - val_loss: 0.5687 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5946 - acc: 0.7526 - val_loss: 0.5593 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5867 - acc: 0.7526 - val_loss: 0.5502 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5793 - acc: 0.7680 - val_loss: 0.5428 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5722 - acc: 0.7680 - val_loss: 0.5345 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5652 - acc: 0.7835 - val_loss: 0.5262 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5576 - acc: 0.7887 - val_loss: 0.5186 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5515 - acc: 0.7938 - val_loss: 0.5110 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5447 - acc: 0.7938 - val_loss: 0.5038 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5384 - acc: 0.7938 - val_loss: 0.4963 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5319 - acc: 0.7887 - val_loss: 0.4892 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7259 - acc: 0.4278 - val_loss: 0.6788 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7103 - acc: 0.4639 - val_loss: 0.6660 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6975 - acc: 0.4897 - val_loss: 0.6524 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6846 - acc: 0.5206 - val_loss: 0.6388 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6716 - acc: 0.5928 - val_loss: 0.6265 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6604 - acc: 0.6495 - val_loss: 0.6150 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6495 - acc: 0.6856 - val_loss: 0.6040 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6389 - acc: 0.7010 - val_loss: 0.5927 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6283 - acc: 0.7320 - val_loss: 0.5819 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6186 - acc: 0.7216 - val_loss: 0.5731 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6098 - acc: 0.7423 - val_loss: 0.5644 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6011 - acc: 0.7526 - val_loss: 0.5553 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5926 - acc: 0.7577 - val_loss: 0.5463 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5845 - acc: 0.7784 - val_loss: 0.5382 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5771 - acc: 0.7938 - val_loss: 0.5298 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5691 - acc: 0.8093 - val_loss: 0.5212 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5609 - acc: 0.8093 - val_loss: 0.5128 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5536 - acc: 0.8041 - val_loss: 0.5048 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5461 - acc: 0.8041 - val_loss: 0.4979 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5401 - acc: 0.8041 - val_loss: 0.4918 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6768 - acc: 0.5959 - val_loss: 0.6738 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6587 - acc: 0.7461 - val_loss: 0.6570 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6442 - acc: 0.8083 - val_loss: 0.6410 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6295 - acc: 0.8083 - val_loss: 0.6259 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6165 - acc: 0.8342 - val_loss: 0.6128 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6045 - acc: 0.8446 - val_loss: 0.6002 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5935 - acc: 0.8497 - val_loss: 0.5881 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5826 - acc: 0.8446 - val_loss: 0.5769 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5728 - acc: 0.8342 - val_loss: 0.5663 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5638 - acc: 0.8342 - val_loss: 0.5574 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5552 - acc: 0.8394 - val_loss: 0.5469 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5464 - acc: 0.8446 - val_loss: 0.5371 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5384 - acc: 0.8446 - val_loss: 0.5291 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5312 - acc: 0.8394 - val_loss: 0.5210 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5234 - acc: 0.8394 - val_loss: 0.5123 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5158 - acc: 0.8290 - val_loss: 0.5038 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5083 - acc: 0.8290 - val_loss: 0.4951 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5010 - acc: 0.8290 - val_loss: 0.4873 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4945 - acc: 0.8290 - val_loss: 0.4813 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4886 - acc: 0.8290 - val_loss: 0.4748 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6957 - acc: 0.4974 - val_loss: 0.6776 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6731 - acc: 0.6062 - val_loss: 0.6567 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6537 - acc: 0.6684 - val_loss: 0.6379 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6365 - acc: 0.7513 - val_loss: 0.6200 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6203 - acc: 0.7824 - val_loss: 0.6038 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6061 - acc: 0.8135 - val_loss: 0.5904 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5932 - acc: 0.8083 - val_loss: 0.5773 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5817 - acc: 0.8135 - val_loss: 0.5652 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5709 - acc: 0.8135 - val_loss: 0.5549 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5619 - acc: 0.8135 - val_loss: 0.5458 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5537 - acc: 0.8187 - val_loss: 0.5377 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5462 - acc: 0.8187 - val_loss: 0.5291 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5390 - acc: 0.8238 - val_loss: 0.5208 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5315 - acc: 0.8290 - val_loss: 0.5124 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5238 - acc: 0.8394 - val_loss: 0.5040 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5161 - acc: 0.8342 - val_loss: 0.4957 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5088 - acc: 0.8342 - val_loss: 0.4887 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5023 - acc: 0.8290 - val_loss: 0.4816 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4961 - acc: 0.8238 - val_loss: 0.4744 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4894 - acc: 0.8238 - val_loss: 0.4673 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7011 - acc: 0.5000 - val_loss: 0.6960 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6794 - acc: 0.5773 - val_loss: 0.6725 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6611 - acc: 0.6598 - val_loss: 0.6525 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6443 - acc: 0.6804 - val_loss: 0.6343 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6294 - acc: 0.7010 - val_loss: 0.6169 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6161 - acc: 0.7216 - val_loss: 0.6011 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6035 - acc: 0.7371 - val_loss: 0.5878 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5930 - acc: 0.7680 - val_loss: 0.5749 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5824 - acc: 0.7887 - val_loss: 0.5623 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5719 - acc: 0.7938 - val_loss: 0.5503 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5616 - acc: 0.7938 - val_loss: 0.5372 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5507 - acc: 0.8196 - val_loss: 0.5244 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5404 - acc: 0.8299 - val_loss: 0.5131 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5308 - acc: 0.8299 - val_loss: 0.5030 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5222 - acc: 0.8247 - val_loss: 0.4929 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5136 - acc: 0.8247 - val_loss: 0.4835 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5060 - acc: 0.8299 - val_loss: 0.4751 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4988 - acc: 0.8351 - val_loss: 0.4669 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4919 - acc: 0.8351 - val_loss: 0.4591 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4852 - acc: 0.8299 - val_loss: 0.4519 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7316 - acc: 0.3866 - val_loss: 0.7194 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7080 - acc: 0.4227 - val_loss: 0.6969 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6892 - acc: 0.4794 - val_loss: 0.6756 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6705 - acc: 0.6031 - val_loss: 0.6575 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6553 - acc: 0.7062 - val_loss: 0.6401 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6399 - acc: 0.7474 - val_loss: 0.6245 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6264 - acc: 0.7835 - val_loss: 0.6096 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6140 - acc: 0.7990 - val_loss: 0.5955 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6018 - acc: 0.8196 - val_loss: 0.5825 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5914 - acc: 0.8196 - val_loss: 0.5705 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5813 - acc: 0.8351 - val_loss: 0.5596 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5717 - acc: 0.8351 - val_loss: 0.5485 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5622 - acc: 0.8402 - val_loss: 0.5372 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5529 - acc: 0.8402 - val_loss: 0.5278 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5449 - acc: 0.8402 - val_loss: 0.5186 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5378 - acc: 0.8402 - val_loss: 0.5087 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5292 - acc: 0.8402 - val_loss: 0.4994 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5217 - acc: 0.8402 - val_loss: 0.4909 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5152 - acc: 0.8402 - val_loss: 0.4829 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5089 - acc: 0.8402 - val_loss: 0.4756 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7004 - acc: 0.4742 - val_loss: 0.6704 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6813 - acc: 0.5876 - val_loss: 0.6531 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6652 - acc: 0.6701 - val_loss: 0.6367 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6504 - acc: 0.6856 - val_loss: 0.6212 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6360 - acc: 0.7320 - val_loss: 0.6071 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6233 - acc: 0.7577 - val_loss: 0.5943 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6109 - acc: 0.7732 - val_loss: 0.5820 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6003 - acc: 0.7835 - val_loss: 0.5708 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5900 - acc: 0.7887 - val_loss: 0.5593 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5797 - acc: 0.7938 - val_loss: 0.5480 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5691 - acc: 0.7990 - val_loss: 0.5374 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5603 - acc: 0.7990 - val_loss: 0.5282 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5514 - acc: 0.8041 - val_loss: 0.5191 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5428 - acc: 0.8144 - val_loss: 0.5100 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5353 - acc: 0.8196 - val_loss: 0.5016 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5274 - acc: 0.8196 - val_loss: 0.4954 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5213 - acc: 0.8247 - val_loss: 0.4904 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5153 - acc: 0.8196 - val_loss: 0.4848 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5091 - acc: 0.8247 - val_loss: 0.4778 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5026 - acc: 0.8247 - val_loss: 0.4708 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5942 - acc: 0.6684 - val_loss: 0.5600 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5837 - acc: 0.6684 - val_loss: 0.5541 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5764 - acc: 0.6632 - val_loss: 0.5485 - val_acc: 0.7541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5685 - acc: 0.6839 - val_loss: 0.5417 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5605 - acc: 0.6891 - val_loss: 0.5340 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5516 - acc: 0.6995 - val_loss: 0.5256 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5431 - acc: 0.6995 - val_loss: 0.5173 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5347 - acc: 0.6995 - val_loss: 0.5091 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5271 - acc: 0.7150 - val_loss: 0.5012 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5192 - acc: 0.7358 - val_loss: 0.4945 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5126 - acc: 0.7358 - val_loss: 0.4897 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5067 - acc: 0.7306 - val_loss: 0.4859 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5016 - acc: 0.7513 - val_loss: 0.4832 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4968 - acc: 0.7565 - val_loss: 0.4793 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4918 - acc: 0.7617 - val_loss: 0.4751 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4869 - acc: 0.7617 - val_loss: 0.4708 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4819 - acc: 0.7617 - val_loss: 0.4651 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4767 - acc: 0.7824 - val_loss: 0.4589 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4712 - acc: 0.7876 - val_loss: 0.4537 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4661 - acc: 0.8031 - val_loss: 0.4476 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6728 - acc: 0.5907 - val_loss: 0.6191 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6472 - acc: 0.5959 - val_loss: 0.5979 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6258 - acc: 0.6218 - val_loss: 0.5809 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6099 - acc: 0.6373 - val_loss: 0.5674 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5962 - acc: 0.6684 - val_loss: 0.5576 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5850 - acc: 0.6788 - val_loss: 0.5480 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5738 - acc: 0.6891 - val_loss: 0.5379 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5627 - acc: 0.7150 - val_loss: 0.5270 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5523 - acc: 0.7254 - val_loss: 0.5185 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5433 - acc: 0.7513 - val_loss: 0.5099 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5349 - acc: 0.7668 - val_loss: 0.5015 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5254 - acc: 0.7720 - val_loss: 0.4928 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5164 - acc: 0.7720 - val_loss: 0.4859 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5089 - acc: 0.7720 - val_loss: 0.4789 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5012 - acc: 0.7876 - val_loss: 0.4717 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4947 - acc: 0.7927 - val_loss: 0.4648 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4879 - acc: 0.7979 - val_loss: 0.4590 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4596 - acc: 0.843 - 0s 4ms/step - loss: 0.4822 - acc: 0.7979 - val_loss: 0.4542 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4766 - acc: 0.8031 - val_loss: 0.4491 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4710 - acc: 0.8135 - val_loss: 0.4433 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7513 - acc: 0.5103 - val_loss: 0.7284 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7231 - acc: 0.5258 - val_loss: 0.7059 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6959 - acc: 0.5515 - val_loss: 0.6859 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6749 - acc: 0.5928 - val_loss: 0.6671 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6559 - acc: 0.6186 - val_loss: 0.6521 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6398 - acc: 0.6340 - val_loss: 0.6377 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6238 - acc: 0.6546 - val_loss: 0.6243 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6081 - acc: 0.6649 - val_loss: 0.6105 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5951 - acc: 0.6804 - val_loss: 0.5976 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5821 - acc: 0.6959 - val_loss: 0.5866 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5707 - acc: 0.7113 - val_loss: 0.5749 - val_acc: 0.7541\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5599 - acc: 0.7216 - val_loss: 0.5627 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5490 - acc: 0.7320 - val_loss: 0.5504 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5379 - acc: 0.7320 - val_loss: 0.5383 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5276 - acc: 0.7423 - val_loss: 0.5270 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5172 - acc: 0.7577 - val_loss: 0.5167 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5087 - acc: 0.7680 - val_loss: 0.5067 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5001 - acc: 0.7784 - val_loss: 0.4974 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4916 - acc: 0.7835 - val_loss: 0.4876 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4830 - acc: 0.7835 - val_loss: 0.4774 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.8282 - acc: 0.4124 - val_loss: 0.7720 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7931 - acc: 0.4381 - val_loss: 0.7407 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7619 - acc: 0.4845 - val_loss: 0.7110 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7335 - acc: 0.5103 - val_loss: 0.6840 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7092 - acc: 0.5412 - val_loss: 0.6595 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6870 - acc: 0.5825 - val_loss: 0.6383 - val_acc: 0.6721\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6674 - acc: 0.5979 - val_loss: 0.6191 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6510 - acc: 0.6392 - val_loss: 0.6030 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6372 - acc: 0.6443 - val_loss: 0.5894 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6242 - acc: 0.6649 - val_loss: 0.5747 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6105 - acc: 0.6856 - val_loss: 0.5610 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5978 - acc: 0.6856 - val_loss: 0.5474 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5862 - acc: 0.6907 - val_loss: 0.5342 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5744 - acc: 0.6959 - val_loss: 0.5223 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5648 - acc: 0.7010 - val_loss: 0.5108 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5554 - acc: 0.7062 - val_loss: 0.5012 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5471 - acc: 0.7165 - val_loss: 0.4918 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5388 - acc: 0.7113 - val_loss: 0.4823 - val_acc: 0.7869\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5317 - acc: 0.7165 - val_loss: 0.4738 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5253 - acc: 0.7165 - val_loss: 0.4667 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6868 - acc: 0.5361 - val_loss: 0.7033 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6716 - acc: 0.5309 - val_loss: 0.6866 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6584 - acc: 0.5412 - val_loss: 0.6715 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6479 - acc: 0.5619 - val_loss: 0.6583 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6376 - acc: 0.5722 - val_loss: 0.6468 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6293 - acc: 0.5722 - val_loss: 0.6362 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6205 - acc: 0.5773 - val_loss: 0.6261 - val_acc: 0.6393\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6125 - acc: 0.6031 - val_loss: 0.6163 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6045 - acc: 0.6186 - val_loss: 0.6068 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5971 - acc: 0.6237 - val_loss: 0.5971 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5897 - acc: 0.6392 - val_loss: 0.5875 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5826 - acc: 0.6495 - val_loss: 0.5800 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5761 - acc: 0.6495 - val_loss: 0.5724 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5702 - acc: 0.6649 - val_loss: 0.5657 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5646 - acc: 0.6753 - val_loss: 0.5594 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5590 - acc: 0.6753 - val_loss: 0.5526 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5534 - acc: 0.6856 - val_loss: 0.5461 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5483 - acc: 0.7113 - val_loss: 0.5396 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5430 - acc: 0.7165 - val_loss: 0.5326 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5375 - acc: 0.7320 - val_loss: 0.5258 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7906 - acc: 0.4870 - val_loss: 0.7607 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7539 - acc: 0.5026 - val_loss: 0.7282 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7214 - acc: 0.5078 - val_loss: 0.6984 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6948 - acc: 0.5181 - val_loss: 0.6743 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6712 - acc: 0.5389 - val_loss: 0.6516 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6497 - acc: 0.5959 - val_loss: 0.6317 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6310 - acc: 0.6218 - val_loss: 0.6138 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6125 - acc: 0.6632 - val_loss: 0.5958 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5960 - acc: 0.7047 - val_loss: 0.5793 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5812 - acc: 0.7150 - val_loss: 0.5635 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5671 - acc: 0.7358 - val_loss: 0.5499 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5544 - acc: 0.7409 - val_loss: 0.5367 - val_acc: 0.7377\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5434 - acc: 0.7461 - val_loss: 0.5251 - val_acc: 0.7377\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5341 - acc: 0.7668 - val_loss: 0.5140 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5241 - acc: 0.7772 - val_loss: 0.5037 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5148 - acc: 0.7876 - val_loss: 0.4946 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5058 - acc: 0.7927 - val_loss: 0.4856 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4978 - acc: 0.7979 - val_loss: 0.4783 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4906 - acc: 0.7979 - val_loss: 0.4714 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4838 - acc: 0.7979 - val_loss: 0.4644 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6462 - acc: 0.5751 - val_loss: 0.6437 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6283 - acc: 0.5803 - val_loss: 0.6228 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6144 - acc: 0.6166 - val_loss: 0.6051 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6016 - acc: 0.6580 - val_loss: 0.5907 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5904 - acc: 0.6891 - val_loss: 0.5764 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5803 - acc: 0.7254 - val_loss: 0.5644 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5713 - acc: 0.7358 - val_loss: 0.5522 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5622 - acc: 0.7358 - val_loss: 0.5406 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5525 - acc: 0.7513 - val_loss: 0.5295 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5436 - acc: 0.7513 - val_loss: 0.5186 - val_acc: 0.8197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5350 - acc: 0.7565 - val_loss: 0.5076 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5265 - acc: 0.7617 - val_loss: 0.4979 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5185 - acc: 0.7720 - val_loss: 0.4891 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5116 - acc: 0.7720 - val_loss: 0.4812 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5042 - acc: 0.7772 - val_loss: 0.4731 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4975 - acc: 0.7772 - val_loss: 0.4654 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4904 - acc: 0.7824 - val_loss: 0.4584 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4841 - acc: 0.7876 - val_loss: 0.4521 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4792 - acc: 0.7876 - val_loss: 0.4479 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4744 - acc: 0.7876 - val_loss: 0.4427 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.8183 - acc: 0.5412 - val_loss: 0.7387 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7812 - acc: 0.5619 - val_loss: 0.7055 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7516 - acc: 0.5722 - val_loss: 0.6785 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7269 - acc: 0.5773 - val_loss: 0.6541 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7035 - acc: 0.5825 - val_loss: 0.6311 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6817 - acc: 0.5876 - val_loss: 0.6106 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6617 - acc: 0.6031 - val_loss: 0.5921 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6430 - acc: 0.6186 - val_loss: 0.5752 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6256 - acc: 0.6443 - val_loss: 0.5592 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6097 - acc: 0.6598 - val_loss: 0.5440 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5954 - acc: 0.6804 - val_loss: 0.5310 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5821 - acc: 0.7010 - val_loss: 0.5176 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5693 - acc: 0.7113 - val_loss: 0.5045 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5575 - acc: 0.7268 - val_loss: 0.4918 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5462 - acc: 0.7371 - val_loss: 0.4797 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5349 - acc: 0.7423 - val_loss: 0.4675 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5239 - acc: 0.7423 - val_loss: 0.4565 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5148 - acc: 0.7474 - val_loss: 0.4453 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5036 - acc: 0.7577 - val_loss: 0.4357 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4932 - acc: 0.7784 - val_loss: 0.4263 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.7140 - acc: 0.5309 - val_loss: 0.6784 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6824 - acc: 0.5515 - val_loss: 0.6467 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6590 - acc: 0.5825 - val_loss: 0.6205 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6381 - acc: 0.6134 - val_loss: 0.5978 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6197 - acc: 0.6495 - val_loss: 0.5756 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6027 - acc: 0.6959 - val_loss: 0.5562 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5882 - acc: 0.7062 - val_loss: 0.5380 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5735 - acc: 0.7165 - val_loss: 0.5219 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5610 - acc: 0.7320 - val_loss: 0.5057 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5475 - acc: 0.7268 - val_loss: 0.4908 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5353 - acc: 0.7371 - val_loss: 0.4775 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5257 - acc: 0.7629 - val_loss: 0.4647 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5155 - acc: 0.7732 - val_loss: 0.4531 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5061 - acc: 0.7784 - val_loss: 0.4432 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4975 - acc: 0.7887 - val_loss: 0.4366 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4899 - acc: 0.7887 - val_loss: 0.4312 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4843 - acc: 0.7938 - val_loss: 0.4268 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4764 - acc: 0.7990 - val_loss: 0.4204 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4696 - acc: 0.7938 - val_loss: 0.4145 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4635 - acc: 0.7938 - val_loss: 0.4077 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 0.6038 - acc: 0.7165 - val_loss: 0.5837 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5828 - acc: 0.7320 - val_loss: 0.5613 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5648 - acc: 0.7371 - val_loss: 0.5410 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5487 - acc: 0.7577 - val_loss: 0.5225 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5333 - acc: 0.7577 - val_loss: 0.5052 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5194 - acc: 0.7629 - val_loss: 0.4901 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5048 - acc: 0.7680 - val_loss: 0.4771 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4936 - acc: 0.7732 - val_loss: 0.4634 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4812 - acc: 0.7990 - val_loss: 0.4509 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4698 - acc: 0.8093 - val_loss: 0.4405 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4586 - acc: 0.8196 - val_loss: 0.4308 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4492 - acc: 0.8247 - val_loss: 0.4221 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4405 - acc: 0.8247 - val_loss: 0.4147 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4319 - acc: 0.8247 - val_loss: 0.4083 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4246 - acc: 0.8247 - val_loss: 0.4009 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4181 - acc: 0.8299 - val_loss: 0.3927 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4103 - acc: 0.8351 - val_loss: 0.3861 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4050 - acc: 0.8351 - val_loss: 0.3795 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3991 - acc: 0.8351 - val_loss: 0.3756 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3927 - acc: 0.8402 - val_loss: 0.3718 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6991 - acc: 0.5130 - val_loss: 0.6764 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6528 - acc: 0.5803 - val_loss: 0.6355 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6185 - acc: 0.6166 - val_loss: 0.6042 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5903 - acc: 0.6788 - val_loss: 0.5768 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5667 - acc: 0.7254 - val_loss: 0.5527 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5456 - acc: 0.7617 - val_loss: 0.5335 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5278 - acc: 0.7824 - val_loss: 0.5170 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5122 - acc: 0.7772 - val_loss: 0.5034 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4979 - acc: 0.7824 - val_loss: 0.4897 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4850 - acc: 0.7876 - val_loss: 0.4756 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4725 - acc: 0.8031 - val_loss: 0.4609 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4603 - acc: 0.8031 - val_loss: 0.4511 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4498 - acc: 0.8083 - val_loss: 0.4434 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4405 - acc: 0.8083 - val_loss: 0.4370 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4320 - acc: 0.8135 - val_loss: 0.4310 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4246 - acc: 0.8187 - val_loss: 0.4249 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4159 - acc: 0.8290 - val_loss: 0.4169 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4085 - acc: 0.8290 - val_loss: 0.4107 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4013 - acc: 0.8290 - val_loss: 0.4078 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3950 - acc: 0.8446 - val_loss: 0.4038 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7099 - acc: 0.5181 - val_loss: 0.7074 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6736 - acc: 0.5492 - val_loss: 0.6693 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6434 - acc: 0.6062 - val_loss: 0.6356 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6173 - acc: 0.6528 - val_loss: 0.6055 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5951 - acc: 0.6995 - val_loss: 0.5790 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5741 - acc: 0.7098 - val_loss: 0.5553 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5551 - acc: 0.7254 - val_loss: 0.5332 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5384 - acc: 0.7306 - val_loss: 0.5119 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5207 - acc: 0.7358 - val_loss: 0.4931 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5060 - acc: 0.7565 - val_loss: 0.4747 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4908 - acc: 0.7720 - val_loss: 0.4576 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4764 - acc: 0.7824 - val_loss: 0.4434 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4641 - acc: 0.7876 - val_loss: 0.4298 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4533 - acc: 0.7979 - val_loss: 0.4185 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4441 - acc: 0.7927 - val_loss: 0.4067 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4344 - acc: 0.7979 - val_loss: 0.3971 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4268 - acc: 0.8031 - val_loss: 0.3909 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4197 - acc: 0.8083 - val_loss: 0.3837 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4125 - acc: 0.8083 - val_loss: 0.3776 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4064 - acc: 0.8135 - val_loss: 0.3722 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6488 - acc: 0.6546 - val_loss: 0.6313 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6121 - acc: 0.7371 - val_loss: 0.5911 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5815 - acc: 0.7732 - val_loss: 0.5563 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5539 - acc: 0.7938 - val_loss: 0.5235 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5297 - acc: 0.8144 - val_loss: 0.4969 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5084 - acc: 0.8196 - val_loss: 0.4727 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4882 - acc: 0.8247 - val_loss: 0.4518 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4714 - acc: 0.8247 - val_loss: 0.4337 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4561 - acc: 0.8196 - val_loss: 0.4177 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4426 - acc: 0.8299 - val_loss: 0.4036 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4307 - acc: 0.8505 - val_loss: 0.3904 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4206 - acc: 0.8608 - val_loss: 0.3783 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4106 - acc: 0.8660 - val_loss: 0.3680 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4021 - acc: 0.8660 - val_loss: 0.3623 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3942 - acc: 0.8660 - val_loss: 0.3571 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3867 - acc: 0.8711 - val_loss: 0.3513 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3798 - acc: 0.8711 - val_loss: 0.3454 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3732 - acc: 0.8711 - val_loss: 0.3393 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3676 - acc: 0.8711 - val_loss: 0.3364 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3626 - acc: 0.8660 - val_loss: 0.3306 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6726 - acc: 0.5309 - val_loss: 0.6259 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6372 - acc: 0.6082 - val_loss: 0.5919 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6088 - acc: 0.6546 - val_loss: 0.5634 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5843 - acc: 0.7320 - val_loss: 0.5382 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5634 - acc: 0.7526 - val_loss: 0.5141 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5436 - acc: 0.7629 - val_loss: 0.4925 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5261 - acc: 0.7835 - val_loss: 0.4739 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5098 - acc: 0.7938 - val_loss: 0.4592 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4966 - acc: 0.7938 - val_loss: 0.4440 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4823 - acc: 0.7887 - val_loss: 0.4301 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4697 - acc: 0.7938 - val_loss: 0.4168 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4591 - acc: 0.7887 - val_loss: 0.4058 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4486 - acc: 0.7835 - val_loss: 0.3957 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4393 - acc: 0.7835 - val_loss: 0.3872 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4310 - acc: 0.7835 - val_loss: 0.3800 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4231 - acc: 0.8093 - val_loss: 0.3731 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4169 - acc: 0.8093 - val_loss: 0.3686 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4118 - acc: 0.8041 - val_loss: 0.3657 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4076 - acc: 0.8196 - val_loss: 0.3628 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4031 - acc: 0.8247 - val_loss: 0.3600 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7796 - acc: 0.4433 - val_loss: 0.8308 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7322 - acc: 0.5258 - val_loss: 0.7814 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6952 - acc: 0.5464 - val_loss: 0.7357 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6619 - acc: 0.6082 - val_loss: 0.6974 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6322 - acc: 0.6443 - val_loss: 0.6608 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6055 - acc: 0.6804 - val_loss: 0.6265 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5807 - acc: 0.7113 - val_loss: 0.5956 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5575 - acc: 0.7732 - val_loss: 0.5699 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5383 - acc: 0.7835 - val_loss: 0.5468 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5214 - acc: 0.8144 - val_loss: 0.5262 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5056 - acc: 0.8196 - val_loss: 0.5063 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4895 - acc: 0.8351 - val_loss: 0.4881 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4765 - acc: 0.8351 - val_loss: 0.4713 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4640 - acc: 0.8351 - val_loss: 0.4580 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4533 - acc: 0.8299 - val_loss: 0.4467 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4446 - acc: 0.8351 - val_loss: 0.4359 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4370 - acc: 0.8402 - val_loss: 0.4239 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4277 - acc: 0.8402 - val_loss: 0.4135 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4197 - acc: 0.8402 - val_loss: 0.4050 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4121 - acc: 0.8402 - val_loss: 0.3971 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7397 - acc: 0.4767 - val_loss: 0.7086 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6624 - acc: 0.6477 - val_loss: 0.6479 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6159 - acc: 0.7358 - val_loss: 0.5992 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5719 - acc: 0.7720 - val_loss: 0.5614 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5391 - acc: 0.7772 - val_loss: 0.5260 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5087 - acc: 0.8135 - val_loss: 0.4963 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4823 - acc: 0.8135 - val_loss: 0.4655 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4586 - acc: 0.8394 - val_loss: 0.4380 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4393 - acc: 0.8497 - val_loss: 0.4200 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4257 - acc: 0.8446 - val_loss: 0.4077 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4121 - acc: 0.8497 - val_loss: 0.3946 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4011 - acc: 0.8497 - val_loss: 0.3811 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3903 - acc: 0.8549 - val_loss: 0.3693 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3827 - acc: 0.8549 - val_loss: 0.3598 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3753 - acc: 0.8549 - val_loss: 0.3535 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3677 - acc: 0.8497 - val_loss: 0.3544 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3602 - acc: 0.8446 - val_loss: 0.3577 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3574 - acc: 0.8394 - val_loss: 0.3646 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3541 - acc: 0.8290 - val_loss: 0.3640 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3494 - acc: 0.8290 - val_loss: 0.3592 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6930 - acc: 0.5751 - val_loss: 0.6494 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6330 - acc: 0.6788 - val_loss: 0.5927 - val_acc: 0.6885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5903 - acc: 0.7254 - val_loss: 0.5460 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5588 - acc: 0.7565 - val_loss: 0.5155 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5340 - acc: 0.7720 - val_loss: 0.4873 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5132 - acc: 0.7824 - val_loss: 0.4603 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4924 - acc: 0.7927 - val_loss: 0.4357 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4734 - acc: 0.8083 - val_loss: 0.4185 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4601 - acc: 0.8135 - val_loss: 0.4085 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4491 - acc: 0.8135 - val_loss: 0.3966 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4374 - acc: 0.8135 - val_loss: 0.3835 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4266 - acc: 0.8238 - val_loss: 0.3718 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4171 - acc: 0.8238 - val_loss: 0.3616 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4090 - acc: 0.8290 - val_loss: 0.3537 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4023 - acc: 0.8290 - val_loss: 0.3459 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3958 - acc: 0.8342 - val_loss: 0.3385 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3893 - acc: 0.8342 - val_loss: 0.3332 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3828 - acc: 0.8394 - val_loss: 0.3301 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3749 - acc: 0.8446 - val_loss: 0.3275 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3694 - acc: 0.8394 - val_loss: 0.3253 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6100 - acc: 0.7165 - val_loss: 0.5646 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5600 - acc: 0.7732 - val_loss: 0.5213 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5285 - acc: 0.7835 - val_loss: 0.4882 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4999 - acc: 0.7732 - val_loss: 0.4593 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4771 - acc: 0.7990 - val_loss: 0.4368 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4590 - acc: 0.7990 - val_loss: 0.4163 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4422 - acc: 0.8093 - val_loss: 0.3977 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4256 - acc: 0.8093 - val_loss: 0.3815 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4119 - acc: 0.8247 - val_loss: 0.3701 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3990 - acc: 0.8351 - val_loss: 0.3595 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3887 - acc: 0.8402 - val_loss: 0.3491 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3801 - acc: 0.8402 - val_loss: 0.3397 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3726 - acc: 0.8351 - val_loss: 0.3331 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3660 - acc: 0.8351 - val_loss: 0.3275 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3594 - acc: 0.8402 - val_loss: 0.3237 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3538 - acc: 0.8402 - val_loss: 0.3181 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3494 - acc: 0.8454 - val_loss: 0.3137 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3446 - acc: 0.8505 - val_loss: 0.3148 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3392 - acc: 0.8454 - val_loss: 0.3173 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3334 - acc: 0.8557 - val_loss: 0.3198 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6663 - acc: 0.5876 - val_loss: 0.6571 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6147 - acc: 0.6804 - val_loss: 0.6069 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5767 - acc: 0.7165 - val_loss: 0.5613 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5431 - acc: 0.7320 - val_loss: 0.5206 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5138 - acc: 0.7835 - val_loss: 0.4868 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4901 - acc: 0.8093 - val_loss: 0.4601 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4711 - acc: 0.8299 - val_loss: 0.4370 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4552 - acc: 0.8196 - val_loss: 0.4160 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4393 - acc: 0.8093 - val_loss: 0.3990 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4258 - acc: 0.8041 - val_loss: 0.3904 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4154 - acc: 0.8196 - val_loss: 0.3862 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4090 - acc: 0.8299 - val_loss: 0.3818 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4029 - acc: 0.8299 - val_loss: 0.3733 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3943 - acc: 0.8299 - val_loss: 0.3618 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3861 - acc: 0.8351 - val_loss: 0.3517 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3782 - acc: 0.8351 - val_loss: 0.3426 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3714 - acc: 0.8299 - val_loss: 0.3360 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3654 - acc: 0.8351 - val_loss: 0.3308 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3599 - acc: 0.8351 - val_loss: 0.3293 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3558 - acc: 0.8402 - val_loss: 0.3296 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6699 - acc: 0.6134 - val_loss: 0.6199 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6227 - acc: 0.7216 - val_loss: 0.5776 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5867 - acc: 0.7784 - val_loss: 0.5424 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5576 - acc: 0.8041 - val_loss: 0.5093 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5305 - acc: 0.8041 - val_loss: 0.4813 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5071 - acc: 0.8144 - val_loss: 0.4565 - val_acc: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4868 - acc: 0.8196 - val_loss: 0.4360 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4695 - acc: 0.8299 - val_loss: 0.4195 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4552 - acc: 0.8454 - val_loss: 0.4055 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4434 - acc: 0.8454 - val_loss: 0.3938 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4338 - acc: 0.8402 - val_loss: 0.3828 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4231 - acc: 0.8505 - val_loss: 0.3745 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4128 - acc: 0.8608 - val_loss: 0.3686 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4028 - acc: 0.8557 - val_loss: 0.3620 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3934 - acc: 0.8608 - val_loss: 0.3550 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3865 - acc: 0.8608 - val_loss: 0.3491 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3798 - acc: 0.8608 - val_loss: 0.3443 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3734 - acc: 0.8608 - val_loss: 0.3421 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3672 - acc: 0.8660 - val_loss: 0.3421 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3628 - acc: 0.8660 - val_loss: 0.3423 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6640 - acc: 0.6114 - val_loss: 0.5881 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5895 - acc: 0.7772 - val_loss: 0.5263 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5365 - acc: 0.7979 - val_loss: 0.4784 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4977 - acc: 0.7927 - val_loss: 0.4453 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4694 - acc: 0.8187 - val_loss: 0.4170 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4466 - acc: 0.8187 - val_loss: 0.3975 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4265 - acc: 0.8238 - val_loss: 0.3823 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4093 - acc: 0.8187 - val_loss: 0.3767 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3918 - acc: 0.8187 - val_loss: 0.3719 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3792 - acc: 0.8342 - val_loss: 0.3680 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3704 - acc: 0.8497 - val_loss: 0.3763 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3614 - acc: 0.8549 - val_loss: 0.3719 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3524 - acc: 0.8549 - val_loss: 0.3617 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3446 - acc: 0.8497 - val_loss: 0.3495 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3362 - acc: 0.8549 - val_loss: 0.3440 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3301 - acc: 0.8601 - val_loss: 0.3351 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3259 - acc: 0.8601 - val_loss: 0.3309 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3185 - acc: 0.8705 - val_loss: 0.3360 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3133 - acc: 0.8705 - val_loss: 0.3422 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3090 - acc: 0.8756 - val_loss: 0.3412 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7146 - acc: 0.4508 - val_loss: 0.6158 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6110 - acc: 0.7150 - val_loss: 0.5348 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5459 - acc: 0.8187 - val_loss: 0.4826 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5024 - acc: 0.8290 - val_loss: 0.4409 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4690 - acc: 0.8342 - val_loss: 0.4084 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4430 - acc: 0.8290 - val_loss: 0.3860 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4271 - acc: 0.8238 - val_loss: 0.3748 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4166 - acc: 0.8238 - val_loss: 0.3645 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4033 - acc: 0.8238 - val_loss: 0.3550 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3907 - acc: 0.8446 - val_loss: 0.3469 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3811 - acc: 0.8446 - val_loss: 0.3413 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3718 - acc: 0.8497 - val_loss: 0.3364 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3662 - acc: 0.8446 - val_loss: 0.3297 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3639 - acc: 0.8394 - val_loss: 0.3258 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3620 - acc: 0.8446 - val_loss: 0.3236 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3560 - acc: 0.8497 - val_loss: 0.3261 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3494 - acc: 0.8549 - val_loss: 0.3322 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3444 - acc: 0.8549 - val_loss: 0.3445 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3408 - acc: 0.8653 - val_loss: 0.3385 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3366 - acc: 0.8705 - val_loss: 0.3340 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6558 - acc: 0.6186 - val_loss: 0.6001 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5701 - acc: 0.7680 - val_loss: 0.5222 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5082 - acc: 0.8093 - val_loss: 0.4628 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4638 - acc: 0.8247 - val_loss: 0.4214 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4304 - acc: 0.8093 - val_loss: 0.3910 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4097 - acc: 0.8351 - val_loss: 0.3698 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3916 - acc: 0.8351 - val_loss: 0.3574 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3806 - acc: 0.8351 - val_loss: 0.3463 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3712 - acc: 0.8402 - val_loss: 0.3392 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3611 - acc: 0.8351 - val_loss: 0.3380 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3521 - acc: 0.8557 - val_loss: 0.3390 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3448 - acc: 0.8557 - val_loss: 0.3384 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3392 - acc: 0.8608 - val_loss: 0.3369 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3341 - acc: 0.8711 - val_loss: 0.3413 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3308 - acc: 0.8660 - val_loss: 0.3449 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3268 - acc: 0.8608 - val_loss: 0.3413 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3213 - acc: 0.8660 - val_loss: 0.3351 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3163 - acc: 0.8918 - val_loss: 0.3265 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3128 - acc: 0.8866 - val_loss: 0.3224 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3103 - acc: 0.8866 - val_loss: 0.3181 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6774 - acc: 0.5722 - val_loss: 0.6468 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6017 - acc: 0.7113 - val_loss: 0.5598 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5469 - acc: 0.7680 - val_loss: 0.4965 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5073 - acc: 0.7680 - val_loss: 0.4506 - val_acc: 0.9180\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4769 - acc: 0.7732 - val_loss: 0.4197 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4551 - acc: 0.7784 - val_loss: 0.3953 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4366 - acc: 0.7835 - val_loss: 0.3763 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4227 - acc: 0.7938 - val_loss: 0.3583 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4115 - acc: 0.7938 - val_loss: 0.3454 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4041 - acc: 0.8144 - val_loss: 0.3359 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3973 - acc: 0.8196 - val_loss: 0.3278 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3900 - acc: 0.8196 - val_loss: 0.3216 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3809 - acc: 0.8247 - val_loss: 0.3261 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3716 - acc: 0.8247 - val_loss: 0.3324 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3652 - acc: 0.8454 - val_loss: 0.3308 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3593 - acc: 0.8505 - val_loss: 0.3254 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3544 - acc: 0.8454 - val_loss: 0.3191 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3493 - acc: 0.8505 - val_loss: 0.3213 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3442 - acc: 0.8557 - val_loss: 0.3263 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3425 - acc: 0.8660 - val_loss: 0.3305 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7066 - acc: 0.5103 - val_loss: 0.6259 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6200 - acc: 0.6701 - val_loss: 0.5491 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5650 - acc: 0.7577 - val_loss: 0.4958 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5219 - acc: 0.8041 - val_loss: 0.4572 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4905 - acc: 0.7990 - val_loss: 0.4290 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4645 - acc: 0.8144 - val_loss: 0.4089 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4447 - acc: 0.8247 - val_loss: 0.3961 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4274 - acc: 0.8299 - val_loss: 0.3839 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4122 - acc: 0.8351 - val_loss: 0.3718 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3990 - acc: 0.8402 - val_loss: 0.3653 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3879 - acc: 0.8299 - val_loss: 0.3610 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3780 - acc: 0.8351 - val_loss: 0.3537 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3689 - acc: 0.8557 - val_loss: 0.3490 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3611 - acc: 0.8608 - val_loss: 0.3407 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3546 - acc: 0.8608 - val_loss: 0.3387 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3470 - acc: 0.8557 - val_loss: 0.3406 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3423 - acc: 0.8608 - val_loss: 0.3358 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3365 - acc: 0.8660 - val_loss: 0.3285 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3332 - acc: 0.8608 - val_loss: 0.3234 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3296 - acc: 0.8711 - val_loss: 0.3208 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7073 - acc: 0.5337 - val_loss: 0.6047 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5917 - acc: 0.7876 - val_loss: 0.5087 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5205 - acc: 0.8083 - val_loss: 0.4471 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4716 - acc: 0.8342 - val_loss: 0.4041 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4423 - acc: 0.8394 - val_loss: 0.3769 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4207 - acc: 0.8446 - val_loss: 0.3590 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3978 - acc: 0.8601 - val_loss: 0.3543 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3801 - acc: 0.8446 - val_loss: 0.3539 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3694 - acc: 0.8549 - val_loss: 0.3489 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3559 - acc: 0.8601 - val_loss: 0.3314 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3422 - acc: 0.8601 - val_loss: 0.3218 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3322 - acc: 0.8653 - val_loss: 0.3203 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3250 - acc: 0.8653 - val_loss: 0.3120 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3171 - acc: 0.8653 - val_loss: 0.3125 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3101 - acc: 0.8653 - val_loss: 0.3104 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3051 - acc: 0.8705 - val_loss: 0.3143 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3000 - acc: 0.8653 - val_loss: 0.3166 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2953 - acc: 0.8705 - val_loss: 0.3194 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2909 - acc: 0.8808 - val_loss: 0.3189 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2872 - acc: 0.8808 - val_loss: 0.3155 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6659 - acc: 0.6114 - val_loss: 0.5636 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5493 - acc: 0.7772 - val_loss: 0.4792 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4917 - acc: 0.8135 - val_loss: 0.4241 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4495 - acc: 0.8135 - val_loss: 0.3871 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4230 - acc: 0.8135 - val_loss: 0.3638 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4017 - acc: 0.8497 - val_loss: 0.3522 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3877 - acc: 0.8394 - val_loss: 0.3394 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3765 - acc: 0.8549 - val_loss: 0.3277 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3678 - acc: 0.8549 - val_loss: 0.3198 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3630 - acc: 0.8497 - val_loss: 0.3135 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3561 - acc: 0.8497 - val_loss: 0.3110 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3482 - acc: 0.8653 - val_loss: 0.3147 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3398 - acc: 0.8653 - val_loss: 0.3264 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3387 - acc: 0.8653 - val_loss: 0.3363 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3324 - acc: 0.8653 - val_loss: 0.3268 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3259 - acc: 0.8705 - val_loss: 0.3207 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6549 - acc: 0.6340 - val_loss: 0.5525 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5379 - acc: 0.8247 - val_loss: 0.4584 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4710 - acc: 0.8299 - val_loss: 0.3969 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4297 - acc: 0.8299 - val_loss: 0.3591 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4030 - acc: 0.8402 - val_loss: 0.3420 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3833 - acc: 0.8557 - val_loss: 0.3289 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3680 - acc: 0.8557 - val_loss: 0.3204 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3560 - acc: 0.8660 - val_loss: 0.3140 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3463 - acc: 0.8660 - val_loss: 0.3062 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3393 - acc: 0.8814 - val_loss: 0.3051 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3315 - acc: 0.8814 - val_loss: 0.3007 - val_acc: 0.9180\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3252 - acc: 0.8866 - val_loss: 0.3080 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3195 - acc: 0.8866 - val_loss: 0.3056 - val_acc: 0.9180\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3126 - acc: 0.8814 - val_loss: 0.3139 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3089 - acc: 0.8763 - val_loss: 0.3210 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3061 - acc: 0.8763 - val_loss: 0.3133 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6362 - acc: 0.6340 - val_loss: 0.5650 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5396 - acc: 0.7371 - val_loss: 0.4701 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4811 - acc: 0.7835 - val_loss: 0.4141 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4444 - acc: 0.7990 - val_loss: 0.3811 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4200 - acc: 0.7990 - val_loss: 0.3567 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4032 - acc: 0.8041 - val_loss: 0.3408 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3917 - acc: 0.8247 - val_loss: 0.3327 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3799 - acc: 0.8351 - val_loss: 0.3267 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3706 - acc: 0.8402 - val_loss: 0.3220 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3623 - acc: 0.8454 - val_loss: 0.3176 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3545 - acc: 0.8505 - val_loss: 0.3302 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3504 - acc: 0.8454 - val_loss: 0.3338 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3459 - acc: 0.8505 - val_loss: 0.3275 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3390 - acc: 0.8505 - val_loss: 0.3180 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3350 - acc: 0.8608 - val_loss: 0.3122 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3312 - acc: 0.8557 - val_loss: 0.3081 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3238 - acc: 0.8608 - val_loss: 0.3179 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3212 - acc: 0.8608 - val_loss: 0.3234 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3179 - acc: 0.8660 - val_loss: 0.3185 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3136 - acc: 0.8608 - val_loss: 0.3137 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6528 - acc: 0.6701 - val_loss: 0.5326 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5420 - acc: 0.7990 - val_loss: 0.4484 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4786 - acc: 0.8299 - val_loss: 0.3956 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4346 - acc: 0.8402 - val_loss: 0.3657 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4054 - acc: 0.8299 - val_loss: 0.3545 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3874 - acc: 0.8351 - val_loss: 0.3415 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3764 - acc: 0.8454 - val_loss: 0.3329 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3677 - acc: 0.8505 - val_loss: 0.3341 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3584 - acc: 0.8557 - val_loss: 0.3280 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3515 - acc: 0.8505 - val_loss: 0.3265 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3441 - acc: 0.8557 - val_loss: 0.3288 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3349 - acc: 0.8660 - val_loss: 0.3395 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3344 - acc: 0.8711 - val_loss: 0.3343 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3277 - acc: 0.8763 - val_loss: 0.3312 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3247 - acc: 0.8763 - val_loss: 0.3189 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3212 - acc: 0.8814 - val_loss: 0.3216 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3190 - acc: 0.8763 - val_loss: 0.3220 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3147 - acc: 0.8763 - val_loss: 0.3283 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3108 - acc: 0.8763 - val_loss: 0.3250 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3096 - acc: 0.8814 - val_loss: 0.3282 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6598 - acc: 0.6321 - val_loss: 0.5196 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5195 - acc: 0.7979 - val_loss: 0.4249 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4497 - acc: 0.8135 - val_loss: 0.3698 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4090 - acc: 0.8238 - val_loss: 0.3407 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3780 - acc: 0.8446 - val_loss: 0.3282 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3533 - acc: 0.8549 - val_loss: 0.3278 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3365 - acc: 0.8446 - val_loss: 0.3511 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3354 - acc: 0.8497 - val_loss: 0.3683 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3276 - acc: 0.8446 - val_loss: 0.3402 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3141 - acc: 0.8705 - val_loss: 0.3364 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3073 - acc: 0.8705 - val_loss: 0.3256 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3035 - acc: 0.8601 - val_loss: 0.3123 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3010 - acc: 0.8756 - val_loss: 0.3068 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2986 - acc: 0.8756 - val_loss: 0.3017 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2956 - acc: 0.8705 - val_loss: 0.3050 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2887 - acc: 0.8756 - val_loss: 0.3160 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2813 - acc: 0.8756 - val_loss: 0.3259 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2757 - acc: 0.8860 - val_loss: 0.3324 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2712 - acc: 0.8860 - val_loss: 0.3281 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6591 - acc: 0.6425 - val_loss: 0.5248 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5235 - acc: 0.7824 - val_loss: 0.4366 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4594 - acc: 0.7927 - val_loss: 0.3798 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4133 - acc: 0.8031 - val_loss: 0.3485 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3899 - acc: 0.8135 - val_loss: 0.3286 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3705 - acc: 0.8238 - val_loss: 0.3238 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3540 - acc: 0.8394 - val_loss: 0.3219 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3421 - acc: 0.8446 - val_loss: 0.3254 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3338 - acc: 0.8446 - val_loss: 0.3231 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3255 - acc: 0.8601 - val_loss: 0.3191 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3208 - acc: 0.8653 - val_loss: 0.3385 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3239 - acc: 0.8756 - val_loss: 0.3570 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3268 - acc: 0.8912 - val_loss: 0.3393 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3120 - acc: 0.8860 - val_loss: 0.3177 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3033 - acc: 0.8860 - val_loss: 0.3051 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2938 - acc: 0.8756 - val_loss: 0.3100 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2845 - acc: 0.8808 - val_loss: 0.3305 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2866 - acc: 0.8808 - val_loss: 0.3561 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2820 - acc: 0.8860 - val_loss: 0.3478 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2746 - acc: 0.8808 - val_loss: 0.3339 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6052 - acc: 0.7474 - val_loss: 0.4828 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4816 - acc: 0.8351 - val_loss: 0.3994 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4136 - acc: 0.8454 - val_loss: 0.3474 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3712 - acc: 0.8557 - val_loss: 0.3211 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3511 - acc: 0.8711 - val_loss: 0.3045 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3394 - acc: 0.8763 - val_loss: 0.2987 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3311 - acc: 0.8814 - val_loss: 0.2938 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3204 - acc: 0.8763 - val_loss: 0.2988 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3094 - acc: 0.8763 - val_loss: 0.3027 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3025 - acc: 0.8763 - val_loss: 0.3078 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2975 - acc: 0.8763 - val_loss: 0.3020 - val_acc: 0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2925 - acc: 0.8711 - val_loss: 0.3168 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6591 - acc: 0.6186 - val_loss: 0.5172 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5245 - acc: 0.7990 - val_loss: 0.4185 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4562 - acc: 0.8093 - val_loss: 0.3760 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4229 - acc: 0.8299 - val_loss: 0.3567 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4035 - acc: 0.8247 - val_loss: 0.3459 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3858 - acc: 0.8402 - val_loss: 0.3278 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3765 - acc: 0.8557 - val_loss: 0.3185 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3643 - acc: 0.8557 - val_loss: 0.3288 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3572 - acc: 0.8299 - val_loss: 0.3308 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3515 - acc: 0.8402 - val_loss: 0.3299 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3431 - acc: 0.8505 - val_loss: 0.3240 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3353 - acc: 0.8505 - val_loss: 0.3254 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6549 - acc: 0.6237 - val_loss: 0.5299 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5220 - acc: 0.8299 - val_loss: 0.4355 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4508 - acc: 0.8299 - val_loss: 0.4006 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4141 - acc: 0.8402 - val_loss: 0.3793 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3901 - acc: 0.8454 - val_loss: 0.3700 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3721 - acc: 0.8660 - val_loss: 0.3520 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3596 - acc: 0.8557 - val_loss: 0.3371 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3508 - acc: 0.8557 - val_loss: 0.3346 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3414 - acc: 0.8608 - val_loss: 0.3396 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3328 - acc: 0.8711 - val_loss: 0.3527 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3303 - acc: 0.8763 - val_loss: 0.3562 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3250 - acc: 0.8763 - val_loss: 0.3375 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3192 - acc: 0.8711 - val_loss: 0.3310 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3168 - acc: 0.8660 - val_loss: 0.3279 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3109 - acc: 0.8660 - val_loss: 0.3328 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3003 - acc: 0.8814 - val_loss: 0.3508 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3007 - acc: 0.8918 - val_loss: 0.3647 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2973 - acc: 0.8969 - val_loss: 0.3615 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2904 - acc: 0.8969 - val_loss: 0.3430 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6465 - acc: 0.6114 - val_loss: 0.5299 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4796 - acc: 0.8083 - val_loss: 0.4968 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4347 - acc: 0.8394 - val_loss: 0.4317 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3866 - acc: 0.8549 - val_loss: 0.3850 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3608 - acc: 0.8601 - val_loss: 0.3613 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3388 - acc: 0.8653 - val_loss: 0.3555 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3252 - acc: 0.8705 - val_loss: 0.3455 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3174 - acc: 0.8705 - val_loss: 0.3470 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3077 - acc: 0.8653 - val_loss: 0.3435 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3011 - acc: 0.8601 - val_loss: 0.3544 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3045 - acc: 0.8912 - val_loss: 0.3958 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3074 - acc: 0.8912 - val_loss: 0.3728 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2993 - acc: 0.8860 - val_loss: 0.3444 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2928 - acc: 0.8912 - val_loss: 0.3341 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2892 - acc: 0.8860 - val_loss: 0.3500 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2828 - acc: 0.8964 - val_loss: 0.3546 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2787 - acc: 0.8912 - val_loss: 0.3690 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2744 - acc: 0.8912 - val_loss: 0.3687 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2690 - acc: 0.9067 - val_loss: 0.3667 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7328 - acc: 0.5233 - val_loss: 0.5675 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6077 - acc: 0.6788 - val_loss: 0.4838 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5299 - acc: 0.7358 - val_loss: 0.4044 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4769 - acc: 0.7772 - val_loss: 0.3641 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4637 - acc: 0.7565 - val_loss: 0.3422 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4535 - acc: 0.7772 - val_loss: 0.3285 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4223 - acc: 0.7979 - val_loss: 0.3153 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3981 - acc: 0.7927 - val_loss: 0.3074 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3818 - acc: 0.8394 - val_loss: 0.3011 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3596 - acc: 0.8238 - val_loss: 0.3085 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3454 - acc: 0.8446 - val_loss: 0.3308 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3430 - acc: 0.8497 - val_loss: 0.3356 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3342 - acc: 0.8601 - val_loss: 0.3270 - val_acc: 0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3191 - acc: 0.8601 - val_loss: 0.3144 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7607 - acc: 0.4330 - val_loss: 0.6338 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5953 - acc: 0.6237 - val_loss: 0.5327 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5563 - acc: 0.6856 - val_loss: 0.4824 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5154 - acc: 0.7113 - val_loss: 0.4395 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4684 - acc: 0.8093 - val_loss: 0.4078 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4354 - acc: 0.8299 - val_loss: 0.3901 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4119 - acc: 0.8299 - val_loss: 0.3737 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3893 - acc: 0.8505 - val_loss: 0.3576 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3698 - acc: 0.8711 - val_loss: 0.3392 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3574 - acc: 0.8763 - val_loss: 0.3218 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3448 - acc: 0.8763 - val_loss: 0.3391 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3359 - acc: 0.8918 - val_loss: 0.3308 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3263 - acc: 0.9021 - val_loss: 0.3244 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3168 - acc: 0.8918 - val_loss: 0.3141 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3117 - acc: 0.8814 - val_loss: 0.3021 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3043 - acc: 0.8918 - val_loss: 0.2876 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3130 - acc: 0.8763 - val_loss: 0.3056 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3036 - acc: 0.8866 - val_loss: 0.3359 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3006 - acc: 0.8969 - val_loss: 0.3223 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2952 - acc: 0.9021 - val_loss: 0.3207 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.8056 - acc: 0.4845 - val_loss: 0.6065 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5704 - acc: 0.7268 - val_loss: 0.4407 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4583 - acc: 0.8144 - val_loss: 0.3537 - val_acc: 0.9180\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4042 - acc: 0.8247 - val_loss: 0.3163 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3721 - acc: 0.8505 - val_loss: 0.3149 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3578 - acc: 0.8505 - val_loss: 0.3208 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3504 - acc: 0.8557 - val_loss: 0.3066 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3404 - acc: 0.8454 - val_loss: 0.3052 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3327 - acc: 0.8608 - val_loss: 0.3136 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3234 - acc: 0.8763 - val_loss: 0.3236 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3146 - acc: 0.8866 - val_loss: 0.3135 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3097 - acc: 0.8814 - val_loss: 0.3161 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3029 - acc: 0.8814 - val_loss: 0.3218 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7082 - acc: 0.4897 - val_loss: 0.5841 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5798 - acc: 0.7113 - val_loss: 0.5084 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5126 - acc: 0.7835 - val_loss: 0.4653 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4679 - acc: 0.7887 - val_loss: 0.4222 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4300 - acc: 0.8093 - val_loss: 0.3919 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4047 - acc: 0.8351 - val_loss: 0.3781 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3816 - acc: 0.8454 - val_loss: 0.3809 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3673 - acc: 0.8402 - val_loss: 0.3628 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3546 - acc: 0.8454 - val_loss: 0.3754 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3436 - acc: 0.8660 - val_loss: 0.3748 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3398 - acc: 0.8505 - val_loss: 0.3605 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3427 - acc: 0.8351 - val_loss: 0.3563 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3349 - acc: 0.8660 - val_loss: 0.3724 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3264 - acc: 0.8763 - val_loss: 0.4048 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3262 - acc: 0.8711 - val_loss: 0.3960 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3208 - acc: 0.8711 - val_loss: 0.3727 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3235 - acc: 0.8660 - val_loss: 0.3584 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7373 - acc: 0.5389 - val_loss: 0.5699 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5192 - acc: 0.7668 - val_loss: 0.4452 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4480 - acc: 0.7979 - val_loss: 0.3822 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4009 - acc: 0.8083 - val_loss: 0.3589 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3720 - acc: 0.8290 - val_loss: 0.3370 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3525 - acc: 0.8497 - val_loss: 0.3478 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3384 - acc: 0.8497 - val_loss: 0.3511 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3269 - acc: 0.8601 - val_loss: 0.3325 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3230 - acc: 0.8601 - val_loss: 0.3184 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3162 - acc: 0.8601 - val_loss: 0.3284 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3056 - acc: 0.8756 - val_loss: 0.3525 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2943 - acc: 0.8808 - val_loss: 0.3628 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2943 - acc: 0.8808 - val_loss: 0.3850 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2885 - acc: 0.8756 - val_loss: 0.4205 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7465 - acc: 0.4560 - val_loss: 0.5555 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5403 - acc: 0.7461 - val_loss: 0.4344 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4644 - acc: 0.8135 - val_loss: 0.3782 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4119 - acc: 0.8238 - val_loss: 0.3427 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3905 - acc: 0.8238 - val_loss: 0.3232 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3735 - acc: 0.8187 - val_loss: 0.3353 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3574 - acc: 0.8187 - val_loss: 0.3595 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3462 - acc: 0.8394 - val_loss: 0.3810 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3348 - acc: 0.8394 - val_loss: 0.3738 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3225 - acc: 0.8497 - val_loss: 0.3532 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6214 - acc: 0.6701 - val_loss: 0.4442 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4355 - acc: 0.8041 - val_loss: 0.3547 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3665 - acc: 0.8299 - val_loss: 0.3184 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3383 - acc: 0.8557 - val_loss: 0.3114 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3297 - acc: 0.8608 - val_loss: 0.2986 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3141 - acc: 0.8763 - val_loss: 0.3099 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3029 - acc: 0.8866 - val_loss: 0.3281 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2912 - acc: 0.8763 - val_loss: 0.3374 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2870 - acc: 0.8763 - val_loss: 0.3554 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2841 - acc: 0.8918 - val_loss: 0.3994 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6990 - acc: 0.5619 - val_loss: 0.4595 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4778 - acc: 0.8041 - val_loss: 0.3758 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4126 - acc: 0.8196 - val_loss: 0.3339 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3863 - acc: 0.8196 - val_loss: 0.3243 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3712 - acc: 0.8247 - val_loss: 0.3215 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3623 - acc: 0.8247 - val_loss: 0.3174 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3483 - acc: 0.8351 - val_loss: 0.3387 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3413 - acc: 0.8351 - val_loss: 0.3145 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3288 - acc: 0.8454 - val_loss: 0.3055 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3220 - acc: 0.8402 - val_loss: 0.3129 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3144 - acc: 0.8557 - val_loss: 0.3138 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3072 - acc: 0.8557 - val_loss: 0.3077 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3003 - acc: 0.8557 - val_loss: 0.3159 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2946 - acc: 0.8608 - val_loss: 0.3162 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5982 - acc: 0.6804 - val_loss: 0.3853 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4423 - acc: 0.8093 - val_loss: 0.3342 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3880 - acc: 0.8351 - val_loss: 0.3647 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3610 - acc: 0.8454 - val_loss: 0.3379 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3535 - acc: 0.8454 - val_loss: 0.3299 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3428 - acc: 0.8505 - val_loss: 0.3505 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3301 - acc: 0.8866 - val_loss: 0.3710 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3236 - acc: 0.8918 - val_loss: 0.3457 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3142 - acc: 0.8866 - val_loss: 0.3256 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3176 - acc: 0.8557 - val_loss: 0.3077 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3119 - acc: 0.8557 - val_loss: 0.3175 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3015 - acc: 0.8814 - val_loss: 0.3395 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2906 - acc: 0.8814 - val_loss: 0.3372 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2868 - acc: 0.8814 - val_loss: 0.3472 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2795 - acc: 0.8866 - val_loss: 0.3641 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6913 - acc: 0.6010 - val_loss: 0.4443 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4776 - acc: 0.7772 - val_loss: 0.3691 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3906 - acc: 0.8187 - val_loss: 0.3825 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3592 - acc: 0.8187 - val_loss: 0.3665 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3381 - acc: 0.8394 - val_loss: 0.3954 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3418 - acc: 0.8342 - val_loss: 0.4125 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3280 - acc: 0.8705 - val_loss: 0.3754 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3117 - acc: 0.8756 - val_loss: 0.3499 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3017 - acc: 0.8653 - val_loss: 0.3415 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2938 - acc: 0.8601 - val_loss: 0.3137 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2929 - acc: 0.8653 - val_loss: 0.3382 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2753 - acc: 0.8860 - val_loss: 0.3855 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2705 - acc: 0.8756 - val_loss: 0.3603 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2634 - acc: 0.8964 - val_loss: 0.4104 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2568 - acc: 0.8860 - val_loss: 0.4029 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6578 - acc: 0.6321 - val_loss: 0.4414 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4277 - acc: 0.8187 - val_loss: 0.3615 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.3697 - acc: 0.8394 - val_loss: 0.3268 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3507 - acc: 0.8394 - val_loss: 0.3356 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3353 - acc: 0.8446 - val_loss: 0.3393 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3189 - acc: 0.8601 - val_loss: 0.3143 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2998 - acc: 0.8705 - val_loss: 0.3125 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2949 - acc: 0.8808 - val_loss: 0.3130 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2844 - acc: 0.8860 - val_loss: 0.3599 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2901 - acc: 0.8912 - val_loss: 0.3475 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2719 - acc: 0.8860 - val_loss: 0.3118 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2648 - acc: 0.8912 - val_loss: 0.3231 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2506 - acc: 0.9223 - val_loss: 0.3500 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2523 - acc: 0.9067 - val_loss: 0.3379 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2592 - acc: 0.8912 - val_loss: 0.3432 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2678 - acc: 0.8860 - val_loss: 0.3443 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7753 - acc: 0.4845 - val_loss: 0.4575 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4758 - acc: 0.7990 - val_loss: 0.3146 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3997 - acc: 0.8247 - val_loss: 0.3010 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3560 - acc: 0.8608 - val_loss: 0.2806 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3350 - acc: 0.8763 - val_loss: 0.2687 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3202 - acc: 0.8763 - val_loss: 0.2829 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3078 - acc: 0.8763 - val_loss: 0.3042 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3014 - acc: 0.8814 - val_loss: 0.3242 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2988 - acc: 0.8711 - val_loss: 0.3312 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2955 - acc: 0.8660 - val_loss: 0.3281 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5616 - acc: 0.7320 - val_loss: 0.3682 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4171 - acc: 0.8299 - val_loss: 0.3408 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3747 - acc: 0.8247 - val_loss: 0.3149 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3523 - acc: 0.8402 - val_loss: 0.3124 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3384 - acc: 0.8351 - val_loss: 0.3392 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3213 - acc: 0.8557 - val_loss: 0.2982 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3036 - acc: 0.8711 - val_loss: 0.3118 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2932 - acc: 0.8660 - val_loss: 0.3050 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2775 - acc: 0.8763 - val_loss: 0.3102 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2624 - acc: 0.8969 - val_loss: 0.3168 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2613 - acc: 0.8969 - val_loss: 0.3194 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5837 - acc: 0.6907 - val_loss: 0.4183 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4168 - acc: 0.8454 - val_loss: 0.3667 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3701 - acc: 0.8557 - val_loss: 0.3494 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3459 - acc: 0.8557 - val_loss: 0.3625 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3350 - acc: 0.8608 - val_loss: 0.3514 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3165 - acc: 0.8814 - val_loss: 0.3525 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3047 - acc: 0.9021 - val_loss: 0.3724 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2966 - acc: 0.8969 - val_loss: 0.3910 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5339 - acc: 0.7409 - val_loss: 0.3894 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3585 - acc: 0.8238 - val_loss: 0.3337 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3429 - acc: 0.8394 - val_loss: 0.3404 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3073 - acc: 0.8653 - val_loss: 0.3845 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2822 - acc: 0.8912 - val_loss: 0.3368 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2885 - acc: 0.8860 - val_loss: 0.3262 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3131 - acc: 0.8653 - val_loss: 0.3542 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2762 - acc: 0.8964 - val_loss: 0.3912 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2604 - acc: 0.9016 - val_loss: 0.3994 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2401 - acc: 0.9119 - val_loss: 0.3943 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2302 - acc: 0.9016 - val_loss: 0.3941 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5464 - acc: 0.7358 - val_loss: 0.3486 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3678 - acc: 0.8446 - val_loss: 0.3405 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3356 - acc: 0.8497 - val_loss: 0.3532 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3231 - acc: 0.8653 - val_loss: 0.3293 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3019 - acc: 0.8446 - val_loss: 0.3182 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3075 - acc: 0.8549 - val_loss: 0.3403 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2780 - acc: 0.8912 - val_loss: 0.3853 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2677 - acc: 0.8964 - val_loss: 0.3700 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2499 - acc: 0.9016 - val_loss: 0.3466 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2370 - acc: 0.9016 - val_loss: 0.3499 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5658 - acc: 0.6959 - val_loss: 0.3499 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3636 - acc: 0.8402 - val_loss: 0.3442 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3402 - acc: 0.8608 - val_loss: 0.3173 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3087 - acc: 0.8814 - val_loss: 0.2928 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2853 - acc: 0.8918 - val_loss: 0.3135 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2784 - acc: 0.8918 - val_loss: 0.3019 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2694 - acc: 0.9021 - val_loss: 0.3025 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2552 - acc: 0.9124 - val_loss: 0.3707 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2644 - acc: 0.8866 - val_loss: 0.3184 - val_acc: 0.9180\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5573 - acc: 0.7216 - val_loss: 0.3203 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4188 - acc: 0.8247 - val_loss: 0.2852 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3725 - acc: 0.8608 - val_loss: 0.3301 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3492 - acc: 0.8557 - val_loss: 0.2871 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3305 - acc: 0.8505 - val_loss: 0.2939 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3073 - acc: 0.8711 - val_loss: 0.3183 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2910 - acc: 0.8711 - val_loss: 0.3278 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5488 - acc: 0.7062 - val_loss: 0.3806 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3945 - acc: 0.8093 - val_loss: 0.3949 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3579 - acc: 0.8454 - val_loss: 0.3642 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3393 - acc: 0.8660 - val_loss: 0.4309 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3291 - acc: 0.8660 - val_loss: 0.3717 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3109 - acc: 0.8763 - val_loss: 0.3223 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3181 - acc: 0.8505 - val_loss: 0.3283 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2920 - acc: 0.8763 - val_loss: 0.3341 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2785 - acc: 0.8918 - val_loss: 0.3413 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2654 - acc: 0.8969 - val_loss: 0.3416 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2517 - acc: 0.9021 - val_loss: 0.3424 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5237 - acc: 0.7254 - val_loss: 0.3204 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3583 - acc: 0.8238 - val_loss: 0.3374 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3134 - acc: 0.8549 - val_loss: 0.3735 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2819 - acc: 0.8808 - val_loss: 0.3857 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2689 - acc: 0.8808 - val_loss: 0.4155 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2980 - acc: 0.8601 - val_loss: 0.3640 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5468 - acc: 0.6995 - val_loss: 0.3493 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3972 - acc: 0.8290 - val_loss: 0.3502 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3494 - acc: 0.8290 - val_loss: 0.3113 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3183 - acc: 0.8342 - val_loss: 0.3625 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3159 - acc: 0.8808 - val_loss: 0.4409 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2802 - acc: 0.8808 - val_loss: 0.3748 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2980 - acc: 0.8808 - val_loss: 0.3895 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2944 - acc: 0.8653 - val_loss: 0.4771 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5148 - acc: 0.7216 - val_loss: 0.2994 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3484 - acc: 0.8557 - val_loss: 0.3571 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3178 - acc: 0.8866 - val_loss: 0.3261 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3021 - acc: 0.8608 - val_loss: 0.3072 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2820 - acc: 0.8711 - val_loss: 0.3833 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2774 - acc: 0.8866 - val_loss: 0.4260 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5326 - acc: 0.7526 - val_loss: 0.2975 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3919 - acc: 0.8247 - val_loss: 0.3302 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3789 - acc: 0.8454 - val_loss: 0.3898 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3491 - acc: 0.8505 - val_loss: 0.3060 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3176 - acc: 0.8814 - val_loss: 0.3698 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3112 - acc: 0.8608 - val_loss: 0.3740 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5068 - acc: 0.7423 - val_loss: 0.3576 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3731 - acc: 0.8247 - val_loss: 0.3507 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3332 - acc: 0.8608 - val_loss: 0.3451 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3134 - acc: 0.8763 - val_loss: 0.4223 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3094 - acc: 0.8763 - val_loss: 0.3671 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2744 - acc: 0.8763 - val_loss: 0.3568 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2623 - acc: 0.8918 - val_loss: 0.3659 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2421 - acc: 0.9021 - val_loss: 0.3893 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4855 - acc: 0.8031 - val_loss: 0.3512 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3221 - acc: 0.8549 - val_loss: 0.3496 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3061 - acc: 0.8756 - val_loss: 0.3670 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2996 - acc: 0.8860 - val_loss: 0.3410 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2820 - acc: 0.8808 - val_loss: 0.4164 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2885 - acc: 0.8756 - val_loss: 0.3600 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2670 - acc: 0.8860 - val_loss: 0.3447 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2634 - acc: 0.9067 - val_loss: 0.3676 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2442 - acc: 0.8912 - val_loss: 0.4313 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5571 - acc: 0.6736 - val_loss: 0.3556 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3779 - acc: 0.8446 - val_loss: 0.3476 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3712 - acc: 0.8446 - val_loss: 0.3363 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3195 - acc: 0.8601 - val_loss: 0.4245 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3028 - acc: 0.8756 - val_loss: 0.3581 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2723 - acc: 0.8860 - val_loss: 0.4120 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2413 - acc: 0.9016 - val_loss: 0.4317 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2256 - acc: 0.9275 - val_loss: 0.4124 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4872 - acc: 0.7577 - val_loss: 0.3569 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3487 - acc: 0.8557 - val_loss: 0.3311 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3253 - acc: 0.8660 - val_loss: 0.3627 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2701 - acc: 0.8814 - val_loss: 0.4116 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2501 - acc: 0.8969 - val_loss: 0.3434 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2283 - acc: 0.9124 - val_loss: 0.4180 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2148 - acc: 0.9021 - val_loss: 0.3820 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5456 - acc: 0.6804 - val_loss: 0.4562 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4522 - acc: 0.8093 - val_loss: 0.3110 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3599 - acc: 0.8454 - val_loss: 0.3035 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3157 - acc: 0.8557 - val_loss: 0.3577 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2905 - acc: 0.8866 - val_loss: 0.3837 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2622 - acc: 0.8814 - val_loss: 0.3877 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2394 - acc: 0.8969 - val_loss: 0.4056 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2147 - acc: 0.9175 - val_loss: 0.4261 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5239 - acc: 0.7577 - val_loss: 0.3768 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3498 - acc: 0.8505 - val_loss: 0.3375 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3396 - acc: 0.8557 - val_loss: 0.3815 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3421 - acc: 0.8299 - val_loss: 0.3068 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3293 - acc: 0.8711 - val_loss: 0.2978 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2939 - acc: 0.8505 - val_loss: 0.4219 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2916 - acc: 0.8660 - val_loss: 0.3664 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2524 - acc: 0.8763 - val_loss: 0.3531 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2251 - acc: 0.9072 - val_loss: 0.4711 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2167 - acc: 0.9227 - val_loss: 0.4849 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 48ms/step - loss: 0.4429 - acc: 0.7720 - val_loss: 0.4652 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3392 - acc: 0.8653 - val_loss: 0.3665 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3031 - acc: 0.8756 - val_loss: 0.4171 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2790 - acc: 0.8705 - val_loss: 0.3646 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2778 - acc: 0.8808 - val_loss: 0.4229 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2539 - acc: 0.9016 - val_loss: 0.4828 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2470 - acc: 0.8808 - val_loss: 0.5090 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2306 - acc: 0.9119 - val_loss: 0.4646 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1863 - acc: 0.9326 - val_loss: 0.4996 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4730 - acc: 0.7617 - val_loss: 0.3176 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3734 - acc: 0.8342 - val_loss: 0.3443 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3473 - acc: 0.8342 - val_loss: 0.3235 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3073 - acc: 0.8601 - val_loss: 0.3426 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2744 - acc: 0.9223 - val_loss: 0.3883 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2743 - acc: 0.8549 - val_loss: 0.3912 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4693 - acc: 0.7887 - val_loss: 0.3467 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3498 - acc: 0.8763 - val_loss: 0.4128 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3116 - acc: 0.8763 - val_loss: 0.3515 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2690 - acc: 0.8608 - val_loss: 0.3678 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2620 - acc: 0.8918 - val_loss: 0.4435 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2424 - acc: 0.8969 - val_loss: 0.3888 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4621 - acc: 0.7320 - val_loss: 0.3265 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4015 - acc: 0.8505 - val_loss: 0.4775 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3712 - acc: 0.8299 - val_loss: 0.3211 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3549 - acc: 0.8351 - val_loss: 0.4236 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3144 - acc: 0.8402 - val_loss: 0.3418 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2772 - acc: 0.8660 - val_loss: 0.4056 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2555 - acc: 0.8866 - val_loss: 0.3704 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2247 - acc: 0.9072 - val_loss: 0.4011 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4780 - acc: 0.7165 - val_loss: 0.4449 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4093 - acc: 0.8557 - val_loss: 0.3565 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3537 - acc: 0.8505 - val_loss: 0.3663 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2905 - acc: 0.8918 - val_loss: 0.3813 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2553 - acc: 0.9175 - val_loss: 0.3805 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2932 - acc: 0.8608 - val_loss: 0.4515 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2871 - acc: 0.8969 - val_loss: 0.6505 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4546 - acc: 0.7720 - val_loss: 0.3682 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3435 - acc: 0.8497 - val_loss: 0.4776 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3010 - acc: 0.8808 - val_loss: 0.4013 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3239 - acc: 0.8756 - val_loss: 0.4941 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3405 - acc: 0.8653 - val_loss: 0.4312 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3051 - acc: 0.8912 - val_loss: 0.5077 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4564 - acc: 0.7668 - val_loss: 0.3689 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3701 - acc: 0.8446 - val_loss: 0.4778 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3523 - acc: 0.8601 - val_loss: 0.3539 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2984 - acc: 0.8601 - val_loss: 0.4228 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2495 - acc: 0.9067 - val_loss: 0.4551 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2227 - acc: 0.9119 - val_loss: 0.4512 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1934 - acc: 0.9326 - val_loss: 0.5645 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1901 - acc: 0.9326 - val_loss: 0.5556 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5085 - acc: 0.7165 - val_loss: 0.3197 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4731 - acc: 0.8454 - val_loss: 0.3720 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3555 - acc: 0.8608 - val_loss: 0.3817 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3228 - acc: 0.8763 - val_loss: 0.3446 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3213 - acc: 0.8660 - val_loss: 0.3649 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2803 - acc: 0.8918 - val_loss: 0.4208 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6366 - acc: 0.6546 - val_loss: 0.4660 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5496 - acc: 0.7887 - val_loss: 0.4275 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4429 - acc: 0.8144 - val_loss: 0.4034 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3993 - acc: 0.8454 - val_loss: 0.3942 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3627 - acc: 0.8608 - val_loss: 0.3581 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3210 - acc: 0.8918 - val_loss: 0.4230 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3159 - acc: 0.8660 - val_loss: 0.4808 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3087 - acc: 0.8814 - val_loss: 0.5167 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3086 - acc: 0.8814 - val_loss: 0.5119 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2916 - acc: 0.8918 - val_loss: 0.5887 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6624 - acc: 0.5876 - val_loss: 0.3969 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5115 - acc: 0.7371 - val_loss: 0.4435 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4271 - acc: 0.8247 - val_loss: 0.3164 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4296 - acc: 0.7887 - val_loss: 0.2974 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3583 - acc: 0.8402 - val_loss: 0.4117 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3671 - acc: 0.8196 - val_loss: 0.4238 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3468 - acc: 0.8402 - val_loss: 0.3356 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3352 - acc: 0.8557 - val_loss: 0.3321 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3235 - acc: 0.8505 - val_loss: 0.4065 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 49ms/step - loss: 0.5295 - acc: 0.7461 - val_loss: 0.5178 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3402 - acc: 0.8808 - val_loss: 0.3158 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3088 - acc: 0.8705 - val_loss: 0.4480 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3045 - acc: 0.8705 - val_loss: 0.4169 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3015 - acc: 0.8808 - val_loss: 0.5289 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2879 - acc: 0.8860 - val_loss: 0.3640 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2691 - acc: 0.8964 - val_loss: 0.3458 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5986 - acc: 0.7513 - val_loss: 0.4515 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3777 - acc: 0.8342 - val_loss: 0.3097 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3560 - acc: 0.8497 - val_loss: 0.3651 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3334 - acc: 0.8601 - val_loss: 0.3429 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2972 - acc: 0.8653 - val_loss: 0.4244 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2823 - acc: 0.8756 - val_loss: 0.4232 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3160 - acc: 0.8446 - val_loss: 0.4433 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6321 - acc: 0.6340 - val_loss: 0.4347 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3389 - acc: 0.8505 - val_loss: 0.3639 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3132 - acc: 0.8711 - val_loss: 0.3823 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2914 - acc: 0.8660 - val_loss: 0.3858 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2904 - acc: 0.8660 - val_loss: 0.4619 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2522 - acc: 0.8918 - val_loss: 0.4974 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2422 - acc: 0.8918 - val_loss: 0.5845 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6470 - acc: 0.6392 - val_loss: 0.4666 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3996 - acc: 0.8093 - val_loss: 0.3188 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3652 - acc: 0.8041 - val_loss: 0.4253 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3658 - acc: 0.8144 - val_loss: 0.3434 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3206 - acc: 0.8247 - val_loss: 0.4040 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3021 - acc: 0.8454 - val_loss: 0.3727 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2843 - acc: 0.8454 - val_loss: 0.3546 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6301 - acc: 0.6546 - val_loss: 0.3689 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4057 - acc: 0.8247 - val_loss: 0.4941 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3806 - acc: 0.8402 - val_loss: 0.4389 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3697 - acc: 0.8247 - val_loss: 0.4971 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3284 - acc: 0.8351 - val_loss: 0.4004 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3376 - acc: 0.8041 - val_loss: 0.4270 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4958 - acc: 0.7409 - val_loss: 0.6067 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4094 - acc: 0.8187 - val_loss: 0.3447 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3139 - acc: 0.8653 - val_loss: 0.3925 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2653 - acc: 0.9067 - val_loss: 0.5394 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2900 - acc: 0.8705 - val_loss: 0.4067 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2441 - acc: 0.9223 - val_loss: 0.5959 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1826 - acc: 0.9378 - val_loss: 0.7146 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5636 - acc: 0.7772 - val_loss: 0.3783 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4507 - acc: 0.8497 - val_loss: 0.6088 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4166 - acc: 0.7824 - val_loss: 0.3944 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3651 - acc: 0.8394 - val_loss: 0.4603 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3027 - acc: 0.8705 - val_loss: 0.4364 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2399 - acc: 0.9016 - val_loss: 0.5167 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5251 - acc: 0.7474 - val_loss: 0.7188 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4986 - acc: 0.7577 - val_loss: 0.3465 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4466 - acc: 0.8041 - val_loss: 0.6018 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4201 - acc: 0.8402 - val_loss: 0.7815 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3475 - acc: 0.8299 - val_loss: 0.4145 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3155 - acc: 0.8505 - val_loss: 0.4135 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2888 - acc: 0.8557 - val_loss: 0.4777 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6843 - acc: 0.6959 - val_loss: 0.3489 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4278 - acc: 0.8196 - val_loss: 0.4001 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3530 - acc: 0.8299 - val_loss: 0.3369 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3175 - acc: 0.8505 - val_loss: 0.4591 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2746 - acc: 0.8557 - val_loss: 0.4170 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2599 - acc: 0.8763 - val_loss: 0.5317 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2388 - acc: 0.9021 - val_loss: 0.5950 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1918 - acc: 0.9227 - val_loss: 0.6869 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7869 - acc: 0.6701 - val_loss: 0.3686 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4634 - acc: 0.8196 - val_loss: 0.4541 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4154 - acc: 0.8144 - val_loss: 0.4308 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3185 - acc: 0.8814 - val_loss: 0.4208 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2971 - acc: 0.8660 - val_loss: 0.4524 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2544 - acc: 0.8918 - val_loss: 0.5468 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5971 - acc: 0.7150 - val_loss: 0.4914 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3724 - acc: 0.8497 - val_loss: 0.3882 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2917 - acc: 0.8653 - val_loss: 0.4575 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3261 - acc: 0.8860 - val_loss: 0.4578 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2554 - acc: 0.9067 - val_loss: 0.4320 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2351 - acc: 0.8912 - val_loss: 0.5969 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2385 - acc: 0.8912 - val_loss: 0.5565 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5838 - acc: 0.7306 - val_loss: 0.3716 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4093 - acc: 0.8238 - val_loss: 0.5132 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4646 - acc: 0.8497 - val_loss: 0.4280 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4195 - acc: 0.8238 - val_loss: 0.4283 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2766 - acc: 0.8808 - val_loss: 0.5195 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2637 - acc: 0.8964 - val_loss: 0.4507 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6270 - acc: 0.7010 - val_loss: 0.4503 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3775 - acc: 0.8505 - val_loss: 0.3700 - val_acc: 0.9180\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3186 - acc: 0.8711 - val_loss: 0.4406 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2581 - acc: 0.8969 - val_loss: 0.3484 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2602 - acc: 0.9021 - val_loss: 0.4341 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1804 - acc: 0.9330 - val_loss: 0.4672 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1507 - acc: 0.9485 - val_loss: 0.6549 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1406 - acc: 0.9433 - val_loss: 0.8162 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0896 - acc: 0.9794 - val_loss: 0.4887 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6597 - acc: 0.7423 - val_loss: 0.3197 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3900 - acc: 0.8247 - val_loss: 0.3318 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3967 - acc: 0.8608 - val_loss: 0.4565 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3292 - acc: 0.8557 - val_loss: 0.3786 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2855 - acc: 0.8454 - val_loss: 0.6248 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3432 - acc: 0.8505 - val_loss: 0.5698 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6797 - acc: 0.7320 - val_loss: 0.3559 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4627 - acc: 0.7784 - val_loss: 0.5741 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3974 - acc: 0.8454 - val_loss: 0.3548 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3404 - acc: 0.8402 - val_loss: 0.5760 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3236 - acc: 0.8299 - val_loss: 0.3943 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3126 - acc: 0.8557 - val_loss: 0.4536 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2756 - acc: 0.9021 - val_loss: 0.5752 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2407 - acc: 0.8969 - val_loss: 0.5595 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.8565 - acc: 0.6684 - val_loss: 0.4207 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3983 - acc: 0.8446 - val_loss: 0.5396 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2920 - acc: 0.8808 - val_loss: 0.3867 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2726 - acc: 0.8756 - val_loss: 0.4696 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2443 - acc: 0.8860 - val_loss: 0.5091 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2189 - acc: 0.9326 - val_loss: 0.4638 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1760 - acc: 0.9223 - val_loss: 0.6240 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1198 - acc: 0.9585 - val_loss: 0.7195 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.2341 - acc: 0.6425 - val_loss: 0.3809 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3987 - acc: 0.8135 - val_loss: 0.3175 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3711 - acc: 0.8446 - val_loss: 0.4520 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3058 - acc: 0.8808 - val_loss: 0.4342 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2523 - acc: 0.8964 - val_loss: 0.5202 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2497 - acc: 0.8964 - val_loss: 0.4268 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2100 - acc: 0.9171 - val_loss: 0.4569 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.0335 - acc: 0.7474 - val_loss: 0.6290 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6934 - acc: 0.8351 - val_loss: 0.6550 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4073 - acc: 0.8196 - val_loss: 0.4563 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2897 - acc: 0.8814 - val_loss: 0.4764 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2689 - acc: 0.8814 - val_loss: 0.5467 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2368 - acc: 0.9021 - val_loss: 0.6144 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2792 - acc: 0.8814 - val_loss: 0.5781 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2328 - acc: 0.8918 - val_loss: 0.5109 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7772 - acc: 0.7474 - val_loss: 0.5340 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5691 - acc: 0.7784 - val_loss: 0.5466 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3848 - acc: 0.8351 - val_loss: 0.4649 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2919 - acc: 0.8557 - val_loss: 0.4793 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2594 - acc: 0.8814 - val_loss: 0.5713 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2377 - acc: 0.8866 - val_loss: 0.6330 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1877 - acc: 0.9072 - val_loss: 0.5888 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2400 - acc: 0.8866 - val_loss: 0.6483 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7344 - acc: 0.6959 - val_loss: 0.3944 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4586 - acc: 0.8351 - val_loss: 0.4250 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4790 - acc: 0.8660 - val_loss: 1.1773 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4800 - acc: 0.8454 - val_loss: 0.5856 - val_acc: 0.8197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3211 - acc: 0.8505 - val_loss: 0.4795 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2348 - acc: 0.9021 - val_loss: 0.8840 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.0704 - acc: 0.6321 - val_loss: 0.6840 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6805 - acc: 0.8187 - val_loss: 0.3028 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3789 - acc: 0.8497 - val_loss: 0.7016 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3442 - acc: 0.8808 - val_loss: 0.3684 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3264 - acc: 0.8601 - val_loss: 0.5603 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2949 - acc: 0.8497 - val_loss: 0.5929 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2785 - acc: 0.8549 - val_loss: 0.6369 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.9778 - acc: 0.6995 - val_loss: 1.3842 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5873 - acc: 0.7772 - val_loss: 1.1577 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5833 - acc: 0.8497 - val_loss: 0.7472 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3151 - acc: 0.8808 - val_loss: 0.5229 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2924 - acc: 0.8912 - val_loss: 0.4416 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2826 - acc: 0.8705 - val_loss: 0.7256 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2375 - acc: 0.9067 - val_loss: 0.9214 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1415 - acc: 0.9637 - val_loss: 1.0275 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1902 - acc: 0.9275 - val_loss: 1.3798 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1926 - acc: 0.9378 - val_loss: 1.1400 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.5179 - acc: 0.6082 - val_loss: 0.4099 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4323 - acc: 0.8660 - val_loss: 0.6103 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3773 - acc: 0.8041 - val_loss: 0.3924 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3020 - acc: 0.8814 - val_loss: 0.6176 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2338 - acc: 0.9072 - val_loss: 0.5033 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2831 - acc: 0.8814 - val_loss: 1.3077 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4716 - acc: 0.8351 - val_loss: 0.7083 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3671 - acc: 0.8814 - val_loss: 0.7137 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.2982 - acc: 0.6495 - val_loss: 0.7962 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6933 - acc: 0.8247 - val_loss: 0.3031 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3473 - acc: 0.8454 - val_loss: 0.5756 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3046 - acc: 0.8918 - val_loss: 0.6445 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2346 - acc: 0.8969 - val_loss: 0.5912 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1833 - acc: 0.9124 - val_loss: 0.7597 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1698 - acc: 0.9278 - val_loss: 0.7370 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.0959 - acc: 0.7423 - val_loss: 0.4886 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6854 - acc: 0.7526 - val_loss: 0.7405 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5567 - acc: 0.8351 - val_loss: 0.5411 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3970 - acc: 0.8969 - val_loss: 0.4569 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2789 - acc: 0.9021 - val_loss: 0.5832 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2104 - acc: 0.9330 - val_loss: 0.7672 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1548 - acc: 0.9381 - val_loss: 0.8358 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1617 - acc: 0.9330 - val_loss: 0.9288 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1024 - acc: 0.9691 - val_loss: 1.1437 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.8636 - acc: 0.6632 - val_loss: 1.5115 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7895 - acc: 0.8187 - val_loss: 0.9669 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4406 - acc: 0.7927 - val_loss: 0.7384 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4993 - acc: 0.8497 - val_loss: 0.8551 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4609 - acc: 0.8497 - val_loss: 0.3894 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2492 - acc: 0.8964 - val_loss: 0.7101 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3075 - acc: 0.8912 - val_loss: 0.5917 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1806 - acc: 0.9067 - val_loss: 0.5939 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1378 - acc: 0.9275 - val_loss: 0.6564 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0840 - acc: 0.9793 - val_loss: 0.7090 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.5463 - acc: 0.6891 - val_loss: 2.3727 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.3449 - acc: 0.8342 - val_loss: 0.9097 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4881 - acc: 0.7409 - val_loss: 0.8990 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3081 - acc: 0.8446 - val_loss: 0.9887 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2354 - acc: 0.8860 - val_loss: 0.8014 - val_acc: 0.9180\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2023 - acc: 0.8860 - val_loss: 0.8926 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1716 - acc: 0.9275 - val_loss: 1.0576 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1380 - acc: 0.9223 - val_loss: 1.1381 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1104 - acc: 0.9585 - val_loss: 1.1620 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0778 - acc: 0.9845 - val_loss: 1.3452 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.7710 - acc: 0.6804 - val_loss: 1.2302 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0149 - acc: 0.8402 - val_loss: 0.3824 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4212 - acc: 0.8144 - val_loss: 0.8033 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3248 - acc: 0.8814 - val_loss: 0.9876 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2222 - acc: 0.9021 - val_loss: 0.8252 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1901 - acc: 0.9278 - val_loss: 0.9501 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1541 - acc: 0.9536 - val_loss: 1.1380 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.4999 - acc: 0.5464 - val_loss: 1.5040 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.9666 - acc: 0.7629 - val_loss: 0.8638 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4239 - acc: 0.7938 - val_loss: 0.3356 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3809 - acc: 0.8196 - val_loss: 0.3780 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2865 - acc: 0.8763 - val_loss: 0.4432 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2482 - acc: 0.8814 - val_loss: 0.5091 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2039 - acc: 0.9072 - val_loss: 0.7318 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1749 - acc: 0.9433 - val_loss: 0.8878 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.8883 - acc: 0.6804 - val_loss: 1.6140 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1438 - acc: 0.7784 - val_loss: 0.6638 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5610 - acc: 0.7887 - val_loss: 1.8174 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6086 - acc: 0.8711 - val_loss: 1.3337 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3210 - acc: 0.8763 - val_loss: 1.2586 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2171 - acc: 0.8866 - val_loss: 1.2588 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1629 - acc: 0.9175 - val_loss: 1.2411 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7325 - acc: 0.4301 - val_loss: 0.7279 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7325 - acc: 0.4301 - val_loss: 0.7279 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7325 - acc: 0.4301 - val_loss: 0.7279 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7325 - acc: 0.4301 - val_loss: 0.7279 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7325 - acc: 0.4301 - val_loss: 0.7278 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7325 - acc: 0.4301 - val_loss: 0.7278 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7325 - acc: 0.4301 - val_loss: 0.7278 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7325 - acc: 0.4301 - val_loss: 0.7278 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7325 - acc: 0.4301 - val_loss: 0.7278 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7325 - acc: 0.4301 - val_loss: 0.7278 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7325 - acc: 0.4301 - val_loss: 0.7278 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7325 - acc: 0.4301 - val_loss: 0.7278 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7325 - acc: 0.4301 - val_loss: 0.7278 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7325 - acc: 0.4301 - val_loss: 0.7278 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7325 - acc: 0.4301 - val_loss: 0.7278 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7324 - acc: 0.4301 - val_loss: 0.7278 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7324 - acc: 0.4301 - val_loss: 0.7278 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7324 - acc: 0.4301 - val_loss: 0.7278 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7324 - acc: 0.4301 - val_loss: 0.7278 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7324 - acc: 0.4301 - val_loss: 0.7278 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8614 - acc: 0.4249 - val_loss: 0.7902 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8614 - acc: 0.4249 - val_loss: 0.7902 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8614 - acc: 0.4249 - val_loss: 0.7902 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8614 - acc: 0.4249 - val_loss: 0.7902 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8614 - acc: 0.4249 - val_loss: 0.7901 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8613 - acc: 0.4249 - val_loss: 0.7901 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8613 - acc: 0.4249 - val_loss: 0.7901 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8613 - acc: 0.4249 - val_loss: 0.7901 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8613 - acc: 0.4249 - val_loss: 0.7901 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8613 - acc: 0.4249 - val_loss: 0.7901 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8613 - acc: 0.4249 - val_loss: 0.7901 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8612 - acc: 0.4249 - val_loss: 0.7900 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8612 - acc: 0.4249 - val_loss: 0.7900 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8612 - acc: 0.4249 - val_loss: 0.7900 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8612 - acc: 0.4249 - val_loss: 0.7900 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8612 - acc: 0.4249 - val_loss: 0.7900 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8612 - acc: 0.4249 - val_loss: 0.7900 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8611 - acc: 0.4249 - val_loss: 0.7900 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8611 - acc: 0.4249 - val_loss: 0.7900 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8611 - acc: 0.4249 - val_loss: 0.7899 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.8908 - acc: 0.4536 - val_loss: 0.9644 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8907 - acc: 0.4536 - val_loss: 0.9644 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8907 - acc: 0.4536 - val_loss: 0.9644 - val_acc: 0.4754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8907 - acc: 0.4536 - val_loss: 0.9644 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8906 - acc: 0.4536 - val_loss: 0.9643 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8906 - acc: 0.4536 - val_loss: 0.9643 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8906 - acc: 0.4536 - val_loss: 0.9643 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8906 - acc: 0.4536 - val_loss: 0.9642 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8905 - acc: 0.4536 - val_loss: 0.9642 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8905 - acc: 0.4536 - val_loss: 0.9642 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8905 - acc: 0.4536 - val_loss: 0.9642 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8904 - acc: 0.4536 - val_loss: 0.9641 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8904 - acc: 0.4536 - val_loss: 0.9641 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8904 - acc: 0.4536 - val_loss: 0.9641 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8904 - acc: 0.4536 - val_loss: 0.9641 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8903 - acc: 0.4536 - val_loss: 0.9640 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8903 - acc: 0.4536 - val_loss: 0.9640 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8903 - acc: 0.4536 - val_loss: 0.9640 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8903 - acc: 0.4536 - val_loss: 0.9639 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8902 - acc: 0.4536 - val_loss: 0.9639 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7107 - acc: 0.5309 - val_loss: 0.8078 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7107 - acc: 0.5309 - val_loss: 0.8077 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7107 - acc: 0.5309 - val_loss: 0.8077 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7107 - acc: 0.5309 - val_loss: 0.8077 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7107 - acc: 0.5309 - val_loss: 0.8077 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7107 - acc: 0.5309 - val_loss: 0.8077 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7106 - acc: 0.5309 - val_loss: 0.8077 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7106 - acc: 0.5309 - val_loss: 0.8076 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7106 - acc: 0.5309 - val_loss: 0.8076 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7106 - acc: 0.5309 - val_loss: 0.8076 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7106 - acc: 0.5309 - val_loss: 0.8076 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7106 - acc: 0.5309 - val_loss: 0.8076 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7106 - acc: 0.5309 - val_loss: 0.8076 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7106 - acc: 0.5309 - val_loss: 0.8076 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7106 - acc: 0.5309 - val_loss: 0.8075 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7105 - acc: 0.5309 - val_loss: 0.8075 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7105 - acc: 0.5309 - val_loss: 0.8075 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7105 - acc: 0.5309 - val_loss: 0.8075 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7105 - acc: 0.5309 - val_loss: 0.8075 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7105 - acc: 0.5309 - val_loss: 0.8075 - val_acc: 0.3934\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7445 - acc: 0.5103 - val_loss: 0.6517 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7445 - acc: 0.5103 - val_loss: 0.6517 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7445 - acc: 0.5103 - val_loss: 0.6517 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7445 - acc: 0.5103 - val_loss: 0.6517 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7445 - acc: 0.5103 - val_loss: 0.6516 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7445 - acc: 0.5103 - val_loss: 0.6516 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7445 - acc: 0.5103 - val_loss: 0.6516 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7445 - acc: 0.5103 - val_loss: 0.6516 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7444 - acc: 0.5103 - val_loss: 0.6516 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7444 - acc: 0.5103 - val_loss: 0.6516 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7444 - acc: 0.5103 - val_loss: 0.6516 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7444 - acc: 0.5103 - val_loss: 0.6516 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7444 - acc: 0.5103 - val_loss: 0.6516 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7444 - acc: 0.5103 - val_loss: 0.6516 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7444 - acc: 0.5103 - val_loss: 0.6516 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7444 - acc: 0.5103 - val_loss: 0.6515 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7444 - acc: 0.5103 - val_loss: 0.6515 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7444 - acc: 0.5103 - val_loss: 0.6515 - val_acc: 0.6066\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7444 - acc: 0.5103 - val_loss: 0.6515 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7444 - acc: 0.5103 - val_loss: 0.6515 - val_acc: 0.6066\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7581 - acc: 0.4663 - val_loss: 0.7762 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7581 - acc: 0.4663 - val_loss: 0.7762 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7581 - acc: 0.4663 - val_loss: 0.7761 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7581 - acc: 0.4663 - val_loss: 0.7761 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7581 - acc: 0.4663 - val_loss: 0.7761 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7580 - acc: 0.4663 - val_loss: 0.7761 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7580 - acc: 0.4663 - val_loss: 0.7761 - val_acc: 0.4262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7580 - acc: 0.4663 - val_loss: 0.7761 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7580 - acc: 0.4663 - val_loss: 0.7760 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7580 - acc: 0.4663 - val_loss: 0.7760 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7580 - acc: 0.4663 - val_loss: 0.7760 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7579 - acc: 0.4663 - val_loss: 0.7760 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7579 - acc: 0.4663 - val_loss: 0.7760 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7579 - acc: 0.4663 - val_loss: 0.7760 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7579 - acc: 0.4663 - val_loss: 0.7760 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7579 - acc: 0.4663 - val_loss: 0.7759 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7579 - acc: 0.4663 - val_loss: 0.7759 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7579 - acc: 0.4663 - val_loss: 0.7759 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7578 - acc: 0.4663 - val_loss: 0.7759 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7578 - acc: 0.4663 - val_loss: 0.7759 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7173 - acc: 0.5907 - val_loss: 0.7571 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7173 - acc: 0.5907 - val_loss: 0.7570 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7173 - acc: 0.5907 - val_loss: 0.7570 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7172 - acc: 0.5907 - val_loss: 0.7570 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7172 - acc: 0.5907 - val_loss: 0.7570 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7172 - acc: 0.5907 - val_loss: 0.7569 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7172 - acc: 0.5907 - val_loss: 0.7569 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7172 - acc: 0.5907 - val_loss: 0.7569 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7172 - acc: 0.5907 - val_loss: 0.7569 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7172 - acc: 0.5907 - val_loss: 0.7569 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7171 - acc: 0.5907 - val_loss: 0.7569 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7171 - acc: 0.5907 - val_loss: 0.7568 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7171 - acc: 0.5907 - val_loss: 0.7568 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7171 - acc: 0.5907 - val_loss: 0.7568 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7171 - acc: 0.5907 - val_loss: 0.7568 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7171 - acc: 0.5907 - val_loss: 0.7568 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7171 - acc: 0.5907 - val_loss: 0.7568 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7171 - acc: 0.5907 - val_loss: 0.7567 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7171 - acc: 0.5907 - val_loss: 0.7567 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7170 - acc: 0.5907 - val_loss: 0.7567 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6526 - acc: 0.6701 - val_loss: 0.6800 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6526 - acc: 0.6701 - val_loss: 0.6800 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6525 - acc: 0.6701 - val_loss: 0.6799 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6525 - acc: 0.6701 - val_loss: 0.6799 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6525 - acc: 0.6701 - val_loss: 0.6799 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6525 - acc: 0.6701 - val_loss: 0.6799 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6525 - acc: 0.6701 - val_loss: 0.6799 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6525 - acc: 0.6701 - val_loss: 0.6799 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6525 - acc: 0.6701 - val_loss: 0.6799 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6525 - acc: 0.6701 - val_loss: 0.6798 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6524 - acc: 0.6701 - val_loss: 0.6798 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6524 - acc: 0.6701 - val_loss: 0.6798 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6524 - acc: 0.6701 - val_loss: 0.6798 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6524 - acc: 0.6701 - val_loss: 0.6798 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6524 - acc: 0.6701 - val_loss: 0.6798 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6524 - acc: 0.6701 - val_loss: 0.6798 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6524 - acc: 0.6701 - val_loss: 0.6798 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6524 - acc: 0.6701 - val_loss: 0.6797 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6524 - acc: 0.6701 - val_loss: 0.6797 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6524 - acc: 0.6701 - val_loss: 0.6797 - val_acc: 0.5902\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7144 - acc: 0.5464 - val_loss: 0.6982 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7144 - acc: 0.5464 - val_loss: 0.6982 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7144 - acc: 0.5464 - val_loss: 0.6981 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7144 - acc: 0.5464 - val_loss: 0.6981 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7144 - acc: 0.5464 - val_loss: 0.6981 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7143 - acc: 0.5464 - val_loss: 0.6981 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7143 - acc: 0.5464 - val_loss: 0.6981 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7143 - acc: 0.5464 - val_loss: 0.6981 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7143 - acc: 0.5464 - val_loss: 0.6981 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7143 - acc: 0.5464 - val_loss: 0.6980 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7143 - acc: 0.5464 - val_loss: 0.6980 - val_acc: 0.6230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7143 - acc: 0.5464 - val_loss: 0.6980 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7143 - acc: 0.5464 - val_loss: 0.6980 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7142 - acc: 0.5464 - val_loss: 0.6980 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7142 - acc: 0.5464 - val_loss: 0.6980 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7142 - acc: 0.5464 - val_loss: 0.6979 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7142 - acc: 0.5464 - val_loss: 0.6979 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7142 - acc: 0.5464 - val_loss: 0.6979 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7142 - acc: 0.5464 - val_loss: 0.6979 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7141 - acc: 0.5464 - val_loss: 0.6979 - val_acc: 0.6230\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6878 - acc: 0.5309 - val_loss: 0.7184 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6878 - acc: 0.5309 - val_loss: 0.7184 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6877 - acc: 0.5309 - val_loss: 0.7184 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6877 - acc: 0.5309 - val_loss: 0.7184 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6877 - acc: 0.5309 - val_loss: 0.7184 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6877 - acc: 0.5309 - val_loss: 0.7183 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6877 - acc: 0.5309 - val_loss: 0.7183 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6877 - acc: 0.5309 - val_loss: 0.7183 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6877 - acc: 0.5309 - val_loss: 0.7183 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6876 - acc: 0.5309 - val_loss: 0.7183 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6876 - acc: 0.5309 - val_loss: 0.7183 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6876 - acc: 0.5309 - val_loss: 0.7183 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6876 - acc: 0.5309 - val_loss: 0.7182 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6876 - acc: 0.5309 - val_loss: 0.7182 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6876 - acc: 0.5309 - val_loss: 0.7182 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6876 - acc: 0.5309 - val_loss: 0.7182 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6876 - acc: 0.5309 - val_loss: 0.7182 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6875 - acc: 0.5309 - val_loss: 0.7182 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6875 - acc: 0.5309 - val_loss: 0.7182 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6875 - acc: 0.5309 - val_loss: 0.7181 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7797 - acc: 0.4508 - val_loss: 0.7703 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7796 - acc: 0.4508 - val_loss: 0.7702 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7796 - acc: 0.4508 - val_loss: 0.7702 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7796 - acc: 0.4508 - val_loss: 0.7702 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7795 - acc: 0.4508 - val_loss: 0.7701 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7795 - acc: 0.4508 - val_loss: 0.7701 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7795 - acc: 0.4508 - val_loss: 0.7701 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7795 - acc: 0.4508 - val_loss: 0.7701 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7794 - acc: 0.4508 - val_loss: 0.7700 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7794 - acc: 0.4508 - val_loss: 0.7700 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7794 - acc: 0.4508 - val_loss: 0.7700 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7794 - acc: 0.4508 - val_loss: 0.7700 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7794 - acc: 0.4508 - val_loss: 0.7699 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7793 - acc: 0.4508 - val_loss: 0.7699 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7793 - acc: 0.4508 - val_loss: 0.7699 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7793 - acc: 0.4508 - val_loss: 0.7698 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7793 - acc: 0.4508 - val_loss: 0.7698 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7792 - acc: 0.4508 - val_loss: 0.7698 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7792 - acc: 0.4508 - val_loss: 0.7698 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7792 - acc: 0.4508 - val_loss: 0.7697 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9848 - acc: 0.3990 - val_loss: 0.9137 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9848 - acc: 0.3990 - val_loss: 0.9136 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9847 - acc: 0.3990 - val_loss: 0.9136 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9847 - acc: 0.3990 - val_loss: 0.9136 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9846 - acc: 0.3990 - val_loss: 0.9135 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9846 - acc: 0.3990 - val_loss: 0.9135 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9846 - acc: 0.3990 - val_loss: 0.9135 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9845 - acc: 0.3990 - val_loss: 0.9134 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9845 - acc: 0.3990 - val_loss: 0.9134 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9845 - acc: 0.3990 - val_loss: 0.9134 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9844 - acc: 0.3990 - val_loss: 0.9133 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9844 - acc: 0.3990 - val_loss: 0.9133 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9844 - acc: 0.3990 - val_loss: 0.9133 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9843 - acc: 0.3990 - val_loss: 0.9132 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9843 - acc: 0.3990 - val_loss: 0.9132 - val_acc: 0.4262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9842 - acc: 0.3990 - val_loss: 0.9132 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9842 - acc: 0.3990 - val_loss: 0.9131 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9841 - acc: 0.3990 - val_loss: 0.9131 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9841 - acc: 0.3990 - val_loss: 0.9131 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9841 - acc: 0.3990 - val_loss: 0.9130 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8919 - acc: 0.2938 - val_loss: 0.9115 - val_acc: 0.2623\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8918 - acc: 0.2938 - val_loss: 0.9115 - val_acc: 0.2623\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8918 - acc: 0.2938 - val_loss: 0.9115 - val_acc: 0.2623\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8918 - acc: 0.2938 - val_loss: 0.9114 - val_acc: 0.2623\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8917 - acc: 0.2938 - val_loss: 0.9114 - val_acc: 0.2623\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8917 - acc: 0.2938 - val_loss: 0.9113 - val_acc: 0.2623\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8917 - acc: 0.2938 - val_loss: 0.9113 - val_acc: 0.2623\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8916 - acc: 0.2938 - val_loss: 0.9113 - val_acc: 0.2623\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8916 - acc: 0.2938 - val_loss: 0.9112 - val_acc: 0.2623\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8916 - acc: 0.2938 - val_loss: 0.9112 - val_acc: 0.2623\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8915 - acc: 0.2938 - val_loss: 0.9112 - val_acc: 0.2623\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8915 - acc: 0.2938 - val_loss: 0.9111 - val_acc: 0.2623\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8915 - acc: 0.2938 - val_loss: 0.9111 - val_acc: 0.2623\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8915 - acc: 0.2938 - val_loss: 0.9111 - val_acc: 0.2623\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8914 - acc: 0.2938 - val_loss: 0.9110 - val_acc: 0.2623\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8914 - acc: 0.2938 - val_loss: 0.9110 - val_acc: 0.2623\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8914 - acc: 0.2938 - val_loss: 0.9110 - val_acc: 0.2623\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8913 - acc: 0.2938 - val_loss: 0.9110 - val_acc: 0.2623\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8913 - acc: 0.2938 - val_loss: 0.9109 - val_acc: 0.2623\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8913 - acc: 0.2938 - val_loss: 0.9109 - val_acc: 0.2623\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6724 - acc: 0.6031 - val_loss: 0.7828 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6724 - acc: 0.6031 - val_loss: 0.7828 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6724 - acc: 0.6031 - val_loss: 0.7827 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6723 - acc: 0.6031 - val_loss: 0.7827 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6723 - acc: 0.6031 - val_loss: 0.7827 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6723 - acc: 0.6031 - val_loss: 0.7826 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6723 - acc: 0.6031 - val_loss: 0.7826 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6723 - acc: 0.6031 - val_loss: 0.7826 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6722 - acc: 0.6031 - val_loss: 0.7825 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6722 - acc: 0.6031 - val_loss: 0.7825 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6722 - acc: 0.6031 - val_loss: 0.7825 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6722 - acc: 0.6031 - val_loss: 0.7824 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6722 - acc: 0.6031 - val_loss: 0.7824 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6721 - acc: 0.6031 - val_loss: 0.7824 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6721 - acc: 0.6031 - val_loss: 0.7823 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6721 - acc: 0.6031 - val_loss: 0.7823 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6721 - acc: 0.6031 - val_loss: 0.7823 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6721 - acc: 0.6031 - val_loss: 0.7823 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6721 - acc: 0.6031 - val_loss: 0.7822 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6720 - acc: 0.6031 - val_loss: 0.7822 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7984 - acc: 0.3866 - val_loss: 0.7546 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7984 - acc: 0.3866 - val_loss: 0.7546 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7984 - acc: 0.3866 - val_loss: 0.7545 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7984 - acc: 0.3866 - val_loss: 0.7545 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7983 - acc: 0.3866 - val_loss: 0.7545 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7983 - acc: 0.3866 - val_loss: 0.7545 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7983 - acc: 0.3866 - val_loss: 0.7544 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7983 - acc: 0.3866 - val_loss: 0.7544 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7982 - acc: 0.3866 - val_loss: 0.7544 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7982 - acc: 0.3866 - val_loss: 0.7544 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7982 - acc: 0.3866 - val_loss: 0.7543 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7982 - acc: 0.3866 - val_loss: 0.7543 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7981 - acc: 0.3866 - val_loss: 0.7543 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7981 - acc: 0.3866 - val_loss: 0.7543 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7981 - acc: 0.3866 - val_loss: 0.7542 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7981 - acc: 0.3866 - val_loss: 0.7542 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7980 - acc: 0.3866 - val_loss: 0.7542 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7980 - acc: 0.3866 - val_loss: 0.7542 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7980 - acc: 0.3866 - val_loss: 0.7541 - val_acc: 0.4590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7980 - acc: 0.3866 - val_loss: 0.7541 - val_acc: 0.4590\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7039 - acc: 0.5181 - val_loss: 0.7199 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7039 - acc: 0.5181 - val_loss: 0.7199 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7038 - acc: 0.5181 - val_loss: 0.7198 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7038 - acc: 0.5181 - val_loss: 0.7198 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7038 - acc: 0.5181 - val_loss: 0.7198 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7038 - acc: 0.5181 - val_loss: 0.7197 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7037 - acc: 0.5181 - val_loss: 0.7197 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7037 - acc: 0.5181 - val_loss: 0.7197 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7037 - acc: 0.5181 - val_loss: 0.7196 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7036 - acc: 0.5181 - val_loss: 0.7196 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7036 - acc: 0.5181 - val_loss: 0.7196 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7036 - acc: 0.5181 - val_loss: 0.7196 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7036 - acc: 0.5181 - val_loss: 0.7195 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7035 - acc: 0.5181 - val_loss: 0.7195 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7035 - acc: 0.5181 - val_loss: 0.7195 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7035 - acc: 0.5181 - val_loss: 0.7194 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7035 - acc: 0.5181 - val_loss: 0.7194 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7034 - acc: 0.5181 - val_loss: 0.7194 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7034 - acc: 0.5181 - val_loss: 0.7194 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7034 - acc: 0.5181 - val_loss: 0.7193 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7057 - acc: 0.4819 - val_loss: 0.6678 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7057 - acc: 0.4819 - val_loss: 0.6678 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7056 - acc: 0.4819 - val_loss: 0.6678 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7056 - acc: 0.4819 - val_loss: 0.6678 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7056 - acc: 0.4819 - val_loss: 0.6677 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7055 - acc: 0.4819 - val_loss: 0.6677 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7055 - acc: 0.4819 - val_loss: 0.6677 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7055 - acc: 0.4819 - val_loss: 0.6676 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7055 - acc: 0.4819 - val_loss: 0.6676 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7054 - acc: 0.4819 - val_loss: 0.6676 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7054 - acc: 0.4819 - val_loss: 0.6676 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7054 - acc: 0.4819 - val_loss: 0.6675 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7054 - acc: 0.4819 - val_loss: 0.6675 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7053 - acc: 0.4819 - val_loss: 0.6675 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7053 - acc: 0.4819 - val_loss: 0.6674 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7053 - acc: 0.4819 - val_loss: 0.6674 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7053 - acc: 0.4819 - val_loss: 0.6674 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7052 - acc: 0.4819 - val_loss: 0.6674 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7052 - acc: 0.4819 - val_loss: 0.6673 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7052 - acc: 0.4819 - val_loss: 0.6673 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6890 - acc: 0.5567 - val_loss: 0.6975 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6889 - acc: 0.5567 - val_loss: 0.6974 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6889 - acc: 0.5567 - val_loss: 0.6974 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6889 - acc: 0.5567 - val_loss: 0.6974 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6888 - acc: 0.5567 - val_loss: 0.6973 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6888 - acc: 0.5567 - val_loss: 0.6973 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6888 - acc: 0.5567 - val_loss: 0.6973 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6888 - acc: 0.5567 - val_loss: 0.6972 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6887 - acc: 0.5567 - val_loss: 0.6972 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6887 - acc: 0.5567 - val_loss: 0.6972 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6887 - acc: 0.5567 - val_loss: 0.6971 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6886 - acc: 0.5567 - val_loss: 0.6971 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6886 - acc: 0.5567 - val_loss: 0.6971 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6886 - acc: 0.5567 - val_loss: 0.6970 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6886 - acc: 0.5567 - val_loss: 0.6970 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6885 - acc: 0.5567 - val_loss: 0.6970 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6885 - acc: 0.5567 - val_loss: 0.6970 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6885 - acc: 0.5567 - val_loss: 0.6969 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6885 - acc: 0.5567 - val_loss: 0.6969 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6884 - acc: 0.5567 - val_loss: 0.6969 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7614 - acc: 0.4485 - val_loss: 0.7187 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7613 - acc: 0.4485 - val_loss: 0.7186 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7613 - acc: 0.4485 - val_loss: 0.7186 - val_acc: 0.4918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7612 - acc: 0.4485 - val_loss: 0.7185 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7612 - acc: 0.4485 - val_loss: 0.7185 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7612 - acc: 0.4485 - val_loss: 0.7185 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7611 - acc: 0.4485 - val_loss: 0.7184 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7611 - acc: 0.4485 - val_loss: 0.7184 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7610 - acc: 0.4485 - val_loss: 0.7183 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7610 - acc: 0.4485 - val_loss: 0.7183 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7610 - acc: 0.4485 - val_loss: 0.7183 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7609 - acc: 0.4485 - val_loss: 0.7182 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7609 - acc: 0.4485 - val_loss: 0.7182 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7608 - acc: 0.4485 - val_loss: 0.7182 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7608 - acc: 0.4485 - val_loss: 0.7181 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7608 - acc: 0.4485 - val_loss: 0.7181 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7607 - acc: 0.4485 - val_loss: 0.7180 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7607 - acc: 0.4485 - val_loss: 0.7180 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7606 - acc: 0.4485 - val_loss: 0.7180 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7606 - acc: 0.4485 - val_loss: 0.7179 - val_acc: 0.4918\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6912 - acc: 0.4742 - val_loss: 0.6830 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6912 - acc: 0.4742 - val_loss: 0.6830 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6911 - acc: 0.4742 - val_loss: 0.6829 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6911 - acc: 0.4742 - val_loss: 0.6829 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6910 - acc: 0.4742 - val_loss: 0.6829 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6910 - acc: 0.4742 - val_loss: 0.6828 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6910 - acc: 0.4742 - val_loss: 0.6828 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6909 - acc: 0.4742 - val_loss: 0.6828 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6909 - acc: 0.4742 - val_loss: 0.6827 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6909 - acc: 0.4742 - val_loss: 0.6827 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6908 - acc: 0.4742 - val_loss: 0.6827 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6908 - acc: 0.4691 - val_loss: 0.6826 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6908 - acc: 0.4691 - val_loss: 0.6826 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6907 - acc: 0.4691 - val_loss: 0.6826 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6907 - acc: 0.4691 - val_loss: 0.6825 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6907 - acc: 0.4691 - val_loss: 0.6825 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6906 - acc: 0.4691 - val_loss: 0.6825 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6906 - acc: 0.4691 - val_loss: 0.6824 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6906 - acc: 0.4691 - val_loss: 0.6824 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6905 - acc: 0.4691 - val_loss: 0.6824 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6992 - acc: 0.5181 - val_loss: 0.7058 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6992 - acc: 0.5181 - val_loss: 0.7058 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6991 - acc: 0.5181 - val_loss: 0.7058 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6991 - acc: 0.5181 - val_loss: 0.7057 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6991 - acc: 0.5181 - val_loss: 0.7057 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6990 - acc: 0.5181 - val_loss: 0.7056 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6990 - acc: 0.5181 - val_loss: 0.7056 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6989 - acc: 0.5181 - val_loss: 0.7055 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6989 - acc: 0.5181 - val_loss: 0.7055 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6988 - acc: 0.5181 - val_loss: 0.7055 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6988 - acc: 0.5181 - val_loss: 0.7054 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6988 - acc: 0.5181 - val_loss: 0.7054 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6987 - acc: 0.5181 - val_loss: 0.7053 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6987 - acc: 0.5181 - val_loss: 0.7053 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6986 - acc: 0.5181 - val_loss: 0.7052 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6986 - acc: 0.5181 - val_loss: 0.7052 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6986 - acc: 0.5181 - val_loss: 0.7051 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6985 - acc: 0.5181 - val_loss: 0.7051 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6985 - acc: 0.5181 - val_loss: 0.7051 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6985 - acc: 0.5181 - val_loss: 0.7050 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7043 - acc: 0.4508 - val_loss: 0.7066 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7043 - acc: 0.4508 - val_loss: 0.7066 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7042 - acc: 0.4508 - val_loss: 0.7065 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7042 - acc: 0.4508 - val_loss: 0.7065 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7041 - acc: 0.4508 - val_loss: 0.7065 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7041 - acc: 0.4508 - val_loss: 0.7064 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7041 - acc: 0.4508 - val_loss: 0.7064 - val_acc: 0.5082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7040 - acc: 0.4508 - val_loss: 0.7063 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7040 - acc: 0.4508 - val_loss: 0.7063 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7040 - acc: 0.4508 - val_loss: 0.7063 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7039 - acc: 0.4508 - val_loss: 0.7063 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7039 - acc: 0.4508 - val_loss: 0.7062 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7039 - acc: 0.4508 - val_loss: 0.7062 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7039 - acc: 0.4508 - val_loss: 0.7062 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7038 - acc: 0.4508 - val_loss: 0.7061 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7038 - acc: 0.4508 - val_loss: 0.7061 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7038 - acc: 0.4508 - val_loss: 0.7061 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7037 - acc: 0.4508 - val_loss: 0.7060 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7037 - acc: 0.4508 - val_loss: 0.7060 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7037 - acc: 0.4508 - val_loss: 0.7060 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6967 - acc: 0.5309 - val_loss: 0.6964 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6966 - acc: 0.5309 - val_loss: 0.6964 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6966 - acc: 0.5309 - val_loss: 0.6963 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6965 - acc: 0.5309 - val_loss: 0.6963 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6965 - acc: 0.5309 - val_loss: 0.6963 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6965 - acc: 0.5309 - val_loss: 0.6962 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6964 - acc: 0.5309 - val_loss: 0.6962 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6964 - acc: 0.5309 - val_loss: 0.6961 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6963 - acc: 0.5309 - val_loss: 0.6961 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6963 - acc: 0.5309 - val_loss: 0.6960 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6963 - acc: 0.5309 - val_loss: 0.6960 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6962 - acc: 0.5309 - val_loss: 0.6959 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6962 - acc: 0.5361 - val_loss: 0.6959 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6961 - acc: 0.5361 - val_loss: 0.6958 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6961 - acc: 0.5361 - val_loss: 0.6958 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6961 - acc: 0.5361 - val_loss: 0.6958 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6960 - acc: 0.5361 - val_loss: 0.6957 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6960 - acc: 0.5361 - val_loss: 0.6957 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6959 - acc: 0.5361 - val_loss: 0.6956 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6959 - acc: 0.5361 - val_loss: 0.6956 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6976 - acc: 0.5103 - val_loss: 0.6775 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6975 - acc: 0.5103 - val_loss: 0.6774 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6975 - acc: 0.5103 - val_loss: 0.6774 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6974 - acc: 0.5103 - val_loss: 0.6773 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6974 - acc: 0.5103 - val_loss: 0.6773 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6973 - acc: 0.5103 - val_loss: 0.6772 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6973 - acc: 0.5103 - val_loss: 0.6772 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6972 - acc: 0.5103 - val_loss: 0.6771 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6972 - acc: 0.5103 - val_loss: 0.6771 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6971 - acc: 0.5103 - val_loss: 0.6770 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6971 - acc: 0.5103 - val_loss: 0.6770 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6970 - acc: 0.5103 - val_loss: 0.6769 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6970 - acc: 0.5103 - val_loss: 0.6769 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6969 - acc: 0.5103 - val_loss: 0.6768 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6969 - acc: 0.5103 - val_loss: 0.6768 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6968 - acc: 0.5103 - val_loss: 0.6767 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6968 - acc: 0.5103 - val_loss: 0.6767 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6967 - acc: 0.5103 - val_loss: 0.6766 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6967 - acc: 0.5103 - val_loss: 0.6766 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6966 - acc: 0.5103 - val_loss: 0.6765 - val_acc: 0.5902\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7525 - acc: 0.3763 - val_loss: 0.7714 - val_acc: 0.2951\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7525 - acc: 0.3763 - val_loss: 0.7714 - val_acc: 0.2951\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7524 - acc: 0.3763 - val_loss: 0.7713 - val_acc: 0.2951\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7524 - acc: 0.3763 - val_loss: 0.7712 - val_acc: 0.2951\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7523 - acc: 0.3763 - val_loss: 0.7712 - val_acc: 0.2951\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7523 - acc: 0.3763 - val_loss: 0.7712 - val_acc: 0.2951\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7523 - acc: 0.3763 - val_loss: 0.7711 - val_acc: 0.2951\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7522 - acc: 0.3763 - val_loss: 0.7711 - val_acc: 0.2951\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7522 - acc: 0.3763 - val_loss: 0.7710 - val_acc: 0.2951\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7521 - acc: 0.3763 - val_loss: 0.7709 - val_acc: 0.2951\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7521 - acc: 0.3763 - val_loss: 0.7709 - val_acc: 0.2951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7520 - acc: 0.3763 - val_loss: 0.7708 - val_acc: 0.2951\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7520 - acc: 0.3763 - val_loss: 0.7708 - val_acc: 0.2951\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7519 - acc: 0.3763 - val_loss: 0.7707 - val_acc: 0.2951\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7519 - acc: 0.3763 - val_loss: 0.7707 - val_acc: 0.2951\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7518 - acc: 0.3763 - val_loss: 0.7706 - val_acc: 0.2951\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7518 - acc: 0.3763 - val_loss: 0.7706 - val_acc: 0.2951\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7517 - acc: 0.3763 - val_loss: 0.7705 - val_acc: 0.2787\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7517 - acc: 0.3763 - val_loss: 0.7705 - val_acc: 0.2787\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7517 - acc: 0.3763 - val_loss: 0.7704 - val_acc: 0.2787\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7160 - acc: 0.4819 - val_loss: 0.7306 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7159 - acc: 0.4819 - val_loss: 0.7305 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7158 - acc: 0.4819 - val_loss: 0.7304 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7158 - acc: 0.4819 - val_loss: 0.7303 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7157 - acc: 0.4819 - val_loss: 0.7303 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7157 - acc: 0.4819 - val_loss: 0.7302 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7156 - acc: 0.4819 - val_loss: 0.7301 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7156 - acc: 0.4819 - val_loss: 0.7301 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7155 - acc: 0.4819 - val_loss: 0.7300 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7154 - acc: 0.4819 - val_loss: 0.7299 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7154 - acc: 0.4819 - val_loss: 0.7299 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7153 - acc: 0.4819 - val_loss: 0.7298 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7153 - acc: 0.4819 - val_loss: 0.7298 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7152 - acc: 0.4819 - val_loss: 0.7297 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7152 - acc: 0.4819 - val_loss: 0.7297 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7151 - acc: 0.4819 - val_loss: 0.7296 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7151 - acc: 0.4819 - val_loss: 0.7296 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7150 - acc: 0.4819 - val_loss: 0.7295 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7150 - acc: 0.4819 - val_loss: 0.7295 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7150 - acc: 0.4819 - val_loss: 0.7295 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6464 - acc: 0.6736 - val_loss: 0.6393 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6463 - acc: 0.6736 - val_loss: 0.6392 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6463 - acc: 0.6736 - val_loss: 0.6392 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6463 - acc: 0.6736 - val_loss: 0.6391 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6462 - acc: 0.6736 - val_loss: 0.6391 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6462 - acc: 0.6736 - val_loss: 0.6390 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6461 - acc: 0.6736 - val_loss: 0.6390 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6461 - acc: 0.6736 - val_loss: 0.6389 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6460 - acc: 0.6736 - val_loss: 0.6389 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6460 - acc: 0.6736 - val_loss: 0.6389 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6460 - acc: 0.6736 - val_loss: 0.6388 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6459 - acc: 0.6736 - val_loss: 0.6388 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6459 - acc: 0.6736 - val_loss: 0.6387 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6459 - acc: 0.6736 - val_loss: 0.6387 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6458 - acc: 0.6736 - val_loss: 0.6386 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6458 - acc: 0.6736 - val_loss: 0.6386 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6457 - acc: 0.6788 - val_loss: 0.6385 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6457 - acc: 0.6788 - val_loss: 0.6385 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6456 - acc: 0.6788 - val_loss: 0.6385 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6456 - acc: 0.6788 - val_loss: 0.6384 - val_acc: 0.6230\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6855 - acc: 0.5619 - val_loss: 0.6947 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6855 - acc: 0.5619 - val_loss: 0.6946 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6854 - acc: 0.5619 - val_loss: 0.6945 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6853 - acc: 0.5619 - val_loss: 0.6944 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6852 - acc: 0.5619 - val_loss: 0.6944 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6852 - acc: 0.5619 - val_loss: 0.6943 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6851 - acc: 0.5619 - val_loss: 0.6942 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6850 - acc: 0.5619 - val_loss: 0.6941 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6850 - acc: 0.5619 - val_loss: 0.6941 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6849 - acc: 0.5619 - val_loss: 0.6940 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6848 - acc: 0.5619 - val_loss: 0.6939 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6848 - acc: 0.5619 - val_loss: 0.6939 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6847 - acc: 0.5619 - val_loss: 0.6938 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6846 - acc: 0.5619 - val_loss: 0.6937 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6846 - acc: 0.5619 - val_loss: 0.6937 - val_acc: 0.5902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6845 - acc: 0.5619 - val_loss: 0.6936 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6845 - acc: 0.5619 - val_loss: 0.6935 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6844 - acc: 0.5619 - val_loss: 0.6934 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6843 - acc: 0.5619 - val_loss: 0.6934 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6843 - acc: 0.5619 - val_loss: 0.6933 - val_acc: 0.5902\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6717 - acc: 0.6237 - val_loss: 0.6696 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6716 - acc: 0.6237 - val_loss: 0.6696 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6716 - acc: 0.6237 - val_loss: 0.6695 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6715 - acc: 0.6237 - val_loss: 0.6694 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6715 - acc: 0.6237 - val_loss: 0.6694 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6714 - acc: 0.6237 - val_loss: 0.6693 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6714 - acc: 0.6237 - val_loss: 0.6692 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6713 - acc: 0.6237 - val_loss: 0.6692 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6713 - acc: 0.6237 - val_loss: 0.6691 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6712 - acc: 0.6237 - val_loss: 0.6690 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6712 - acc: 0.6237 - val_loss: 0.6690 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6711 - acc: 0.6237 - val_loss: 0.6689 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6710 - acc: 0.6237 - val_loss: 0.6688 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6710 - acc: 0.6237 - val_loss: 0.6687 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6709 - acc: 0.6237 - val_loss: 0.6687 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6709 - acc: 0.6237 - val_loss: 0.6686 - val_acc: 0.6557\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6708 - acc: 0.6237 - val_loss: 0.6685 - val_acc: 0.6557\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6708 - acc: 0.6237 - val_loss: 0.6685 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6707 - acc: 0.6237 - val_loss: 0.6684 - val_acc: 0.6557\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6706 - acc: 0.6237 - val_loss: 0.6683 - val_acc: 0.6557\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6774 - acc: 0.5567 - val_loss: 0.6791 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6774 - acc: 0.5567 - val_loss: 0.6790 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6773 - acc: 0.5567 - val_loss: 0.6789 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6772 - acc: 0.5567 - val_loss: 0.6788 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6772 - acc: 0.5567 - val_loss: 0.6788 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6771 - acc: 0.5567 - val_loss: 0.6787 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6771 - acc: 0.5567 - val_loss: 0.6786 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6770 - acc: 0.5567 - val_loss: 0.6786 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6769 - acc: 0.5567 - val_loss: 0.6785 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6769 - acc: 0.5567 - val_loss: 0.6784 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6768 - acc: 0.5567 - val_loss: 0.6784 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6768 - acc: 0.5567 - val_loss: 0.6783 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6767 - acc: 0.5567 - val_loss: 0.6782 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6767 - acc: 0.5567 - val_loss: 0.6782 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6766 - acc: 0.5567 - val_loss: 0.6781 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6766 - acc: 0.5567 - val_loss: 0.6781 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6765 - acc: 0.5567 - val_loss: 0.6780 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6764 - acc: 0.5567 - val_loss: 0.6779 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6764 - acc: 0.5567 - val_loss: 0.6778 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6763 - acc: 0.5567 - val_loss: 0.6778 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7229 - acc: 0.4041 - val_loss: 0.7261 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7228 - acc: 0.4041 - val_loss: 0.7260 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7227 - acc: 0.4041 - val_loss: 0.7259 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7226 - acc: 0.4041 - val_loss: 0.7258 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7225 - acc: 0.4041 - val_loss: 0.7257 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7224 - acc: 0.4041 - val_loss: 0.7257 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7224 - acc: 0.4041 - val_loss: 0.7256 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7223 - acc: 0.4041 - val_loss: 0.7255 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7222 - acc: 0.4041 - val_loss: 0.7254 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7221 - acc: 0.4041 - val_loss: 0.7253 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7221 - acc: 0.4041 - val_loss: 0.7252 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7220 - acc: 0.4041 - val_loss: 0.7252 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7219 - acc: 0.4041 - val_loss: 0.7251 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7218 - acc: 0.4041 - val_loss: 0.7250 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7217 - acc: 0.4041 - val_loss: 0.7249 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7216 - acc: 0.4041 - val_loss: 0.7248 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7215 - acc: 0.4041 - val_loss: 0.7247 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7215 - acc: 0.4041 - val_loss: 0.7246 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7214 - acc: 0.4041 - val_loss: 0.7244 - val_acc: 0.4262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7213 - acc: 0.4041 - val_loss: 0.7243 - val_acc: 0.4262\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7106 - acc: 0.4404 - val_loss: 0.7184 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7105 - acc: 0.4404 - val_loss: 0.7183 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7104 - acc: 0.4404 - val_loss: 0.7181 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7103 - acc: 0.4456 - val_loss: 0.7180 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7102 - acc: 0.4456 - val_loss: 0.7179 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7101 - acc: 0.4456 - val_loss: 0.7178 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7100 - acc: 0.4456 - val_loss: 0.7177 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7099 - acc: 0.4456 - val_loss: 0.7176 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7098 - acc: 0.4456 - val_loss: 0.7176 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7098 - acc: 0.4456 - val_loss: 0.7175 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7097 - acc: 0.4456 - val_loss: 0.7174 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7096 - acc: 0.4508 - val_loss: 0.7173 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7095 - acc: 0.4508 - val_loss: 0.7173 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7095 - acc: 0.4508 - val_loss: 0.7172 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7094 - acc: 0.4508 - val_loss: 0.7171 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7094 - acc: 0.4560 - val_loss: 0.7170 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7093 - acc: 0.4560 - val_loss: 0.7170 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7092 - acc: 0.4560 - val_loss: 0.7169 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7091 - acc: 0.4560 - val_loss: 0.7168 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7090 - acc: 0.4560 - val_loss: 0.7167 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6871 - acc: 0.5361 - val_loss: 0.6789 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6869 - acc: 0.5361 - val_loss: 0.6788 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6868 - acc: 0.5361 - val_loss: 0.6787 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6867 - acc: 0.5361 - val_loss: 0.6786 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6866 - acc: 0.5361 - val_loss: 0.6785 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6865 - acc: 0.5361 - val_loss: 0.6783 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6864 - acc: 0.5361 - val_loss: 0.6782 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6863 - acc: 0.5361 - val_loss: 0.6781 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6862 - acc: 0.5361 - val_loss: 0.6780 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6861 - acc: 0.5361 - val_loss: 0.6779 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6860 - acc: 0.5361 - val_loss: 0.6778 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6860 - acc: 0.5361 - val_loss: 0.6777 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6859 - acc: 0.5361 - val_loss: 0.6776 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6858 - acc: 0.5361 - val_loss: 0.6775 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6857 - acc: 0.5361 - val_loss: 0.6774 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6856 - acc: 0.5361 - val_loss: 0.6773 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6855 - acc: 0.5361 - val_loss: 0.6772 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6854 - acc: 0.5361 - val_loss: 0.6771 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6853 - acc: 0.5361 - val_loss: 0.6770 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6852 - acc: 0.5361 - val_loss: 0.6769 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7220 - acc: 0.4433 - val_loss: 0.7179 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7219 - acc: 0.4433 - val_loss: 0.7178 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7218 - acc: 0.4433 - val_loss: 0.7177 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7217 - acc: 0.4433 - val_loss: 0.7176 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7216 - acc: 0.4433 - val_loss: 0.7175 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7215 - acc: 0.4433 - val_loss: 0.7174 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7214 - acc: 0.4433 - val_loss: 0.7173 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7213 - acc: 0.4433 - val_loss: 0.7172 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7212 - acc: 0.4433 - val_loss: 0.7171 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7211 - acc: 0.4433 - val_loss: 0.7170 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7210 - acc: 0.4433 - val_loss: 0.7168 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7209 - acc: 0.4433 - val_loss: 0.7167 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7208 - acc: 0.4433 - val_loss: 0.7166 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7207 - acc: 0.4433 - val_loss: 0.7165 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7206 - acc: 0.4433 - val_loss: 0.7164 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7205 - acc: 0.4433 - val_loss: 0.7163 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7204 - acc: 0.4433 - val_loss: 0.7162 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7203 - acc: 0.4433 - val_loss: 0.7161 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7201 - acc: 0.4433 - val_loss: 0.7160 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7201 - acc: 0.4433 - val_loss: 0.7159 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6446 - acc: 0.7526 - val_loss: 0.6547 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6445 - acc: 0.7526 - val_loss: 0.6546 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6444 - acc: 0.7526 - val_loss: 0.6545 - val_acc: 0.7213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6443 - acc: 0.7526 - val_loss: 0.6544 - val_acc: 0.7213\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6442 - acc: 0.7526 - val_loss: 0.6543 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6441 - acc: 0.7526 - val_loss: 0.6542 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6440 - acc: 0.7526 - val_loss: 0.6541 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6440 - acc: 0.7526 - val_loss: 0.6540 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6439 - acc: 0.7526 - val_loss: 0.6539 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6438 - acc: 0.7526 - val_loss: 0.6539 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6437 - acc: 0.7526 - val_loss: 0.6538 - val_acc: 0.7213\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6437 - acc: 0.7526 - val_loss: 0.6537 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6436 - acc: 0.7526 - val_loss: 0.6536 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6435 - acc: 0.7526 - val_loss: 0.6535 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6435 - acc: 0.7526 - val_loss: 0.6534 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6434 - acc: 0.7526 - val_loss: 0.6534 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6433 - acc: 0.7526 - val_loss: 0.6533 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6432 - acc: 0.7526 - val_loss: 0.6532 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6432 - acc: 0.7526 - val_loss: 0.6531 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6431 - acc: 0.7526 - val_loss: 0.6530 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8169 - acc: 0.3731 - val_loss: 0.8244 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8152 - acc: 0.3782 - val_loss: 0.8230 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8137 - acc: 0.3782 - val_loss: 0.8217 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8123 - acc: 0.3834 - val_loss: 0.8204 - val_acc: 0.3607\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8109 - acc: 0.3834 - val_loss: 0.8192 - val_acc: 0.3607\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8097 - acc: 0.3834 - val_loss: 0.8182 - val_acc: 0.3607\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8087 - acc: 0.3834 - val_loss: 0.8172 - val_acc: 0.3607\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8077 - acc: 0.3834 - val_loss: 0.8162 - val_acc: 0.3607\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8066 - acc: 0.3886 - val_loss: 0.8151 - val_acc: 0.3607\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8054 - acc: 0.3886 - val_loss: 0.8139 - val_acc: 0.3607\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8043 - acc: 0.3886 - val_loss: 0.8128 - val_acc: 0.3607\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8031 - acc: 0.3886 - val_loss: 0.8118 - val_acc: 0.3607\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8021 - acc: 0.3886 - val_loss: 0.8108 - val_acc: 0.3607\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8011 - acc: 0.3834 - val_loss: 0.8099 - val_acc: 0.3607\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8001 - acc: 0.3834 - val_loss: 0.8090 - val_acc: 0.3607\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7992 - acc: 0.3834 - val_loss: 0.8080 - val_acc: 0.3607\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7982 - acc: 0.3834 - val_loss: 0.8070 - val_acc: 0.3770\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7972 - acc: 0.3834 - val_loss: 0.8061 - val_acc: 0.3770\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7964 - acc: 0.3834 - val_loss: 0.8054 - val_acc: 0.3770\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7956 - acc: 0.3834 - val_loss: 0.8046 - val_acc: 0.3770\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.1412 - acc: 0.3834 - val_loss: 1.0702 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1380 - acc: 0.3834 - val_loss: 1.0674 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1350 - acc: 0.3834 - val_loss: 1.0648 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1324 - acc: 0.3834 - val_loss: 1.0623 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1295 - acc: 0.3834 - val_loss: 1.0596 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1266 - acc: 0.3834 - val_loss: 1.0570 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1238 - acc: 0.3834 - val_loss: 1.0544 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1210 - acc: 0.3834 - val_loss: 1.0521 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1185 - acc: 0.3834 - val_loss: 1.0498 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1161 - acc: 0.3834 - val_loss: 1.0475 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1136 - acc: 0.3834 - val_loss: 1.0452 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1111 - acc: 0.3834 - val_loss: 1.0429 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1087 - acc: 0.3886 - val_loss: 1.0407 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1065 - acc: 0.3886 - val_loss: 1.0386 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1044 - acc: 0.3886 - val_loss: 1.0365 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1021 - acc: 0.3886 - val_loss: 1.0344 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1000 - acc: 0.3886 - val_loss: 1.0324 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0979 - acc: 0.3886 - val_loss: 1.0305 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0959 - acc: 0.3886 - val_loss: 1.0286 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0938 - acc: 0.3886 - val_loss: 1.0264 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7436 - acc: 0.5515 - val_loss: 0.7769 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7423 - acc: 0.5515 - val_loss: 0.7754 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7410 - acc: 0.5515 - val_loss: 0.7740 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7399 - acc: 0.5515 - val_loss: 0.7726 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7387 - acc: 0.5515 - val_loss: 0.7712 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7376 - acc: 0.5515 - val_loss: 0.7700 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7365 - acc: 0.5515 - val_loss: 0.7688 - val_acc: 0.5246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7355 - acc: 0.5515 - val_loss: 0.7676 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7345 - acc: 0.5515 - val_loss: 0.7665 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7335 - acc: 0.5515 - val_loss: 0.7653 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7325 - acc: 0.5515 - val_loss: 0.7640 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7313 - acc: 0.5515 - val_loss: 0.7627 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7303 - acc: 0.5515 - val_loss: 0.7615 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7292 - acc: 0.5515 - val_loss: 0.7601 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7281 - acc: 0.5515 - val_loss: 0.7588 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7270 - acc: 0.5515 - val_loss: 0.7575 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7258 - acc: 0.5515 - val_loss: 0.7561 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7247 - acc: 0.5515 - val_loss: 0.7549 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7236 - acc: 0.5515 - val_loss: 0.7538 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7227 - acc: 0.5515 - val_loss: 0.7528 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6533 - acc: 0.6134 - val_loss: 0.7130 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6526 - acc: 0.6134 - val_loss: 0.7120 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6521 - acc: 0.6186 - val_loss: 0.7110 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6515 - acc: 0.6186 - val_loss: 0.7102 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6510 - acc: 0.6289 - val_loss: 0.7095 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6505 - acc: 0.6289 - val_loss: 0.7087 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6500 - acc: 0.6340 - val_loss: 0.7080 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6496 - acc: 0.6340 - val_loss: 0.7073 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6491 - acc: 0.6340 - val_loss: 0.7066 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6487 - acc: 0.6340 - val_loss: 0.7060 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6482 - acc: 0.6340 - val_loss: 0.7053 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6478 - acc: 0.6340 - val_loss: 0.7047 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6473 - acc: 0.6340 - val_loss: 0.7041 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6468 - acc: 0.6340 - val_loss: 0.7034 - val_acc: 0.6885\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6464 - acc: 0.6392 - val_loss: 0.7027 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6460 - acc: 0.6392 - val_loss: 0.7021 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6456 - acc: 0.6392 - val_loss: 0.7016 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6452 - acc: 0.6392 - val_loss: 0.7011 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6449 - acc: 0.6392 - val_loss: 0.7004 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6445 - acc: 0.6392 - val_loss: 0.6997 - val_acc: 0.6885\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7749 - acc: 0.4691 - val_loss: 0.7655 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7736 - acc: 0.4794 - val_loss: 0.7643 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7725 - acc: 0.4845 - val_loss: 0.7631 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7715 - acc: 0.4897 - val_loss: 0.7621 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7705 - acc: 0.4897 - val_loss: 0.7610 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7695 - acc: 0.4897 - val_loss: 0.7598 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7684 - acc: 0.4845 - val_loss: 0.7588 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7674 - acc: 0.4845 - val_loss: 0.7578 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7665 - acc: 0.4845 - val_loss: 0.7567 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7655 - acc: 0.4897 - val_loss: 0.7557 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7645 - acc: 0.4897 - val_loss: 0.7547 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7635 - acc: 0.4897 - val_loss: 0.7536 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7625 - acc: 0.4897 - val_loss: 0.7525 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7615 - acc: 0.4948 - val_loss: 0.7515 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7605 - acc: 0.4948 - val_loss: 0.7505 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7596 - acc: 0.4948 - val_loss: 0.7495 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7585 - acc: 0.4948 - val_loss: 0.7485 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7575 - acc: 0.4948 - val_loss: 0.7476 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7566 - acc: 0.4948 - val_loss: 0.7465 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7556 - acc: 0.5000 - val_loss: 0.7455 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6893 - acc: 0.5440 - val_loss: 0.6971 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6880 - acc: 0.5389 - val_loss: 0.6960 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6869 - acc: 0.5389 - val_loss: 0.6950 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6859 - acc: 0.5389 - val_loss: 0.6940 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6849 - acc: 0.5389 - val_loss: 0.6930 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6839 - acc: 0.5389 - val_loss: 0.6920 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6830 - acc: 0.5389 - val_loss: 0.6911 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6820 - acc: 0.5389 - val_loss: 0.6902 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6812 - acc: 0.5440 - val_loss: 0.6892 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6801 - acc: 0.5440 - val_loss: 0.6881 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6791 - acc: 0.5492 - val_loss: 0.6870 - val_acc: 0.5902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6780 - acc: 0.5596 - val_loss: 0.6859 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6770 - acc: 0.5648 - val_loss: 0.6848 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6760 - acc: 0.5648 - val_loss: 0.6838 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6751 - acc: 0.5648 - val_loss: 0.6828 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6742 - acc: 0.5648 - val_loss: 0.6819 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6733 - acc: 0.5699 - val_loss: 0.6809 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6724 - acc: 0.5699 - val_loss: 0.6798 - val_acc: 0.6066\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6715 - acc: 0.5699 - val_loss: 0.6788 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6706 - acc: 0.5699 - val_loss: 0.6779 - val_acc: 0.6066\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.7428 - acc: 0.4611 - val_loss: 0.7176 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7410 - acc: 0.4663 - val_loss: 0.7159 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7395 - acc: 0.4715 - val_loss: 0.7145 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7381 - acc: 0.4767 - val_loss: 0.7131 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7368 - acc: 0.4767 - val_loss: 0.7119 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7358 - acc: 0.4767 - val_loss: 0.7110 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7349 - acc: 0.4767 - val_loss: 0.7101 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7341 - acc: 0.4767 - val_loss: 0.7093 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7333 - acc: 0.4767 - val_loss: 0.7085 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7325 - acc: 0.4819 - val_loss: 0.7076 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7316 - acc: 0.4819 - val_loss: 0.7068 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7307 - acc: 0.4819 - val_loss: 0.7058 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7298 - acc: 0.4819 - val_loss: 0.7049 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7289 - acc: 0.4819 - val_loss: 0.7041 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7281 - acc: 0.4870 - val_loss: 0.7032 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7272 - acc: 0.4870 - val_loss: 0.7022 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7263 - acc: 0.4870 - val_loss: 0.7012 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7254 - acc: 0.4922 - val_loss: 0.7001 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7244 - acc: 0.4922 - val_loss: 0.6990 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7234 - acc: 0.4922 - val_loss: 0.6979 - val_acc: 0.5246\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7221 - acc: 0.4948 - val_loss: 0.6793 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7188 - acc: 0.4948 - val_loss: 0.6761 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7157 - acc: 0.5103 - val_loss: 0.6732 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7130 - acc: 0.5052 - val_loss: 0.6704 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7102 - acc: 0.5052 - val_loss: 0.6676 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7074 - acc: 0.5103 - val_loss: 0.6648 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7047 - acc: 0.5206 - val_loss: 0.6622 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7022 - acc: 0.5206 - val_loss: 0.6595 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6995 - acc: 0.5206 - val_loss: 0.6569 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6970 - acc: 0.5206 - val_loss: 0.6542 - val_acc: 0.6393\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6946 - acc: 0.5258 - val_loss: 0.6517 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6920 - acc: 0.5309 - val_loss: 0.6493 - val_acc: 0.6393\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6897 - acc: 0.5464 - val_loss: 0.6467 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6873 - acc: 0.5464 - val_loss: 0.6443 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6850 - acc: 0.5515 - val_loss: 0.6417 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6825 - acc: 0.5515 - val_loss: 0.6392 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6800 - acc: 0.5670 - val_loss: 0.6366 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6776 - acc: 0.5773 - val_loss: 0.6342 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6753 - acc: 0.5825 - val_loss: 0.6320 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6730 - acc: 0.5979 - val_loss: 0.6297 - val_acc: 0.6721\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7767 - acc: 0.5464 - val_loss: 0.7446 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7741 - acc: 0.5464 - val_loss: 0.7418 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7718 - acc: 0.5464 - val_loss: 0.7392 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7696 - acc: 0.5464 - val_loss: 0.7366 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7673 - acc: 0.5464 - val_loss: 0.7340 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7651 - acc: 0.5464 - val_loss: 0.7315 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7629 - acc: 0.5464 - val_loss: 0.7290 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7607 - acc: 0.5464 - val_loss: 0.7266 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7586 - acc: 0.5464 - val_loss: 0.7245 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7565 - acc: 0.5464 - val_loss: 0.7223 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7546 - acc: 0.5464 - val_loss: 0.7202 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7527 - acc: 0.5464 - val_loss: 0.7180 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7507 - acc: 0.5464 - val_loss: 0.7157 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7487 - acc: 0.5464 - val_loss: 0.7135 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7468 - acc: 0.5464 - val_loss: 0.7114 - val_acc: 0.5410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7449 - acc: 0.5464 - val_loss: 0.7093 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7431 - acc: 0.5464 - val_loss: 0.7075 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7416 - acc: 0.5464 - val_loss: 0.7058 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7401 - acc: 0.5464 - val_loss: 0.7042 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7388 - acc: 0.5464 - val_loss: 0.7026 - val_acc: 0.5574\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8258 - acc: 0.3454 - val_loss: 0.7761 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8231 - acc: 0.3454 - val_loss: 0.7741 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8207 - acc: 0.3505 - val_loss: 0.7720 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8184 - acc: 0.3505 - val_loss: 0.7702 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8164 - acc: 0.3557 - val_loss: 0.7685 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8146 - acc: 0.3557 - val_loss: 0.7667 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8126 - acc: 0.3557 - val_loss: 0.7649 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8107 - acc: 0.3557 - val_loss: 0.7632 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8088 - acc: 0.3608 - val_loss: 0.7617 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8070 - acc: 0.3660 - val_loss: 0.7602 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8051 - acc: 0.3660 - val_loss: 0.7587 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8035 - acc: 0.3711 - val_loss: 0.7572 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8018 - acc: 0.3711 - val_loss: 0.7557 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8001 - acc: 0.3763 - val_loss: 0.7541 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7984 - acc: 0.3763 - val_loss: 0.7525 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7966 - acc: 0.3866 - val_loss: 0.7510 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7950 - acc: 0.3866 - val_loss: 0.7495 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7933 - acc: 0.3918 - val_loss: 0.7479 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7917 - acc: 0.3969 - val_loss: 0.7464 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7900 - acc: 0.4021 - val_loss: 0.7448 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6844 - acc: 0.5751 - val_loss: 0.6736 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6819 - acc: 0.5803 - val_loss: 0.6712 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6799 - acc: 0.5907 - val_loss: 0.6691 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6780 - acc: 0.5959 - val_loss: 0.6672 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6764 - acc: 0.5959 - val_loss: 0.6656 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6748 - acc: 0.5959 - val_loss: 0.6641 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6734 - acc: 0.5959 - val_loss: 0.6625 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6720 - acc: 0.5959 - val_loss: 0.6609 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6704 - acc: 0.5959 - val_loss: 0.6594 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6690 - acc: 0.5959 - val_loss: 0.6580 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6677 - acc: 0.5959 - val_loss: 0.6569 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6665 - acc: 0.5959 - val_loss: 0.6560 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6654 - acc: 0.5959 - val_loss: 0.6550 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6642 - acc: 0.5959 - val_loss: 0.6537 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6630 - acc: 0.5959 - val_loss: 0.6525 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6618 - acc: 0.5959 - val_loss: 0.6514 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6607 - acc: 0.6010 - val_loss: 0.6501 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6595 - acc: 0.6010 - val_loss: 0.6486 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6581 - acc: 0.6062 - val_loss: 0.6471 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6569 - acc: 0.6062 - val_loss: 0.6460 - val_acc: 0.5738\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7305 - acc: 0.4819 - val_loss: 0.6876 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7276 - acc: 0.4870 - val_loss: 0.6851 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7250 - acc: 0.4922 - val_loss: 0.6826 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7226 - acc: 0.4922 - val_loss: 0.6800 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7201 - acc: 0.4974 - val_loss: 0.6776 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7178 - acc: 0.5078 - val_loss: 0.6755 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7158 - acc: 0.5181 - val_loss: 0.6736 - val_acc: 0.6393\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7139 - acc: 0.5181 - val_loss: 0.6715 - val_acc: 0.6393\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7119 - acc: 0.5233 - val_loss: 0.6693 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7096 - acc: 0.5337 - val_loss: 0.6670 - val_acc: 0.6393\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7074 - acc: 0.5389 - val_loss: 0.6649 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7052 - acc: 0.5389 - val_loss: 0.6629 - val_acc: 0.6393\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7030 - acc: 0.5389 - val_loss: 0.6607 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7008 - acc: 0.5389 - val_loss: 0.6586 - val_acc: 0.6393\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6988 - acc: 0.5440 - val_loss: 0.6569 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6971 - acc: 0.5440 - val_loss: 0.6552 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6953 - acc: 0.5440 - val_loss: 0.6536 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6936 - acc: 0.5544 - val_loss: 0.6521 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6919 - acc: 0.5544 - val_loss: 0.6506 - val_acc: 0.6230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6904 - acc: 0.5596 - val_loss: 0.6491 - val_acc: 0.6230\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7980 - acc: 0.3299 - val_loss: 0.8365 - val_acc: 0.2623\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7953 - acc: 0.3299 - val_loss: 0.8339 - val_acc: 0.2623\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7931 - acc: 0.3351 - val_loss: 0.8315 - val_acc: 0.2623\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7910 - acc: 0.3454 - val_loss: 0.8290 - val_acc: 0.2623\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7889 - acc: 0.3454 - val_loss: 0.8266 - val_acc: 0.2623\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7868 - acc: 0.3505 - val_loss: 0.8242 - val_acc: 0.2623\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7846 - acc: 0.3505 - val_loss: 0.8218 - val_acc: 0.2623\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7825 - acc: 0.3505 - val_loss: 0.8194 - val_acc: 0.2623\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7805 - acc: 0.3505 - val_loss: 0.8171 - val_acc: 0.2623\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7785 - acc: 0.3505 - val_loss: 0.8149 - val_acc: 0.2623\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7766 - acc: 0.3505 - val_loss: 0.8127 - val_acc: 0.2623\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7748 - acc: 0.3557 - val_loss: 0.8106 - val_acc: 0.2623\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7730 - acc: 0.3608 - val_loss: 0.8086 - val_acc: 0.2623\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7711 - acc: 0.3660 - val_loss: 0.8064 - val_acc: 0.2787\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7693 - acc: 0.3660 - val_loss: 0.8042 - val_acc: 0.2951\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7674 - acc: 0.3660 - val_loss: 0.8021 - val_acc: 0.3115\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7657 - acc: 0.3660 - val_loss: 0.8002 - val_acc: 0.3115\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7640 - acc: 0.3660 - val_loss: 0.7981 - val_acc: 0.3279\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7622 - acc: 0.3660 - val_loss: 0.7960 - val_acc: 0.3279\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7604 - acc: 0.3660 - val_loss: 0.7941 - val_acc: 0.3279\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6643 - acc: 0.5979 - val_loss: 0.6196 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6615 - acc: 0.6134 - val_loss: 0.6174 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6593 - acc: 0.6134 - val_loss: 0.6154 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6574 - acc: 0.6237 - val_loss: 0.6135 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6554 - acc: 0.6237 - val_loss: 0.6116 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6535 - acc: 0.6289 - val_loss: 0.6097 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6515 - acc: 0.6340 - val_loss: 0.6078 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6495 - acc: 0.6289 - val_loss: 0.6059 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6475 - acc: 0.6340 - val_loss: 0.6038 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6455 - acc: 0.6392 - val_loss: 0.6018 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6436 - acc: 0.6443 - val_loss: 0.5999 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6415 - acc: 0.6598 - val_loss: 0.5979 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6395 - acc: 0.6701 - val_loss: 0.5961 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6378 - acc: 0.6856 - val_loss: 0.5942 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6359 - acc: 0.6856 - val_loss: 0.5924 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6343 - acc: 0.6959 - val_loss: 0.5909 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6327 - acc: 0.7113 - val_loss: 0.5892 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6311 - acc: 0.7216 - val_loss: 0.5874 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6292 - acc: 0.7320 - val_loss: 0.5855 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6274 - acc: 0.7320 - val_loss: 0.5839 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7607 - acc: 0.4124 - val_loss: 0.7182 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7577 - acc: 0.4124 - val_loss: 0.7158 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7553 - acc: 0.4175 - val_loss: 0.7135 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7528 - acc: 0.4175 - val_loss: 0.7113 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7505 - acc: 0.4175 - val_loss: 0.7092 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7483 - acc: 0.4227 - val_loss: 0.7071 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7459 - acc: 0.4278 - val_loss: 0.7049 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7436 - acc: 0.4278 - val_loss: 0.7028 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7414 - acc: 0.4278 - val_loss: 0.7007 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7392 - acc: 0.4278 - val_loss: 0.6988 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7371 - acc: 0.4278 - val_loss: 0.6971 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7352 - acc: 0.4278 - val_loss: 0.6954 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7335 - acc: 0.4330 - val_loss: 0.6938 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7317 - acc: 0.4330 - val_loss: 0.6923 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7301 - acc: 0.4381 - val_loss: 0.6909 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7286 - acc: 0.4381 - val_loss: 0.6896 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7272 - acc: 0.4381 - val_loss: 0.6883 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7257 - acc: 0.4381 - val_loss: 0.6869 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7242 - acc: 0.4381 - val_loss: 0.6855 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7227 - acc: 0.4381 - val_loss: 0.6842 - val_acc: 0.5082\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6436 - acc: 0.6736 - val_loss: 0.6101 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6401 - acc: 0.6788 - val_loss: 0.6069 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6375 - acc: 0.6788 - val_loss: 0.6038 - val_acc: 0.6557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6348 - acc: 0.6839 - val_loss: 0.6011 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6324 - acc: 0.6839 - val_loss: 0.5987 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6303 - acc: 0.6839 - val_loss: 0.5965 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6282 - acc: 0.6788 - val_loss: 0.5946 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6263 - acc: 0.6736 - val_loss: 0.5925 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6243 - acc: 0.6736 - val_loss: 0.5904 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6224 - acc: 0.6736 - val_loss: 0.5883 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6205 - acc: 0.6839 - val_loss: 0.5863 - val_acc: 0.7213\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6186 - acc: 0.6839 - val_loss: 0.5843 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6166 - acc: 0.6891 - val_loss: 0.5821 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6147 - acc: 0.6943 - val_loss: 0.5800 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6127 - acc: 0.6995 - val_loss: 0.5779 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6108 - acc: 0.6995 - val_loss: 0.5757 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6087 - acc: 0.7150 - val_loss: 0.5734 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6066 - acc: 0.7150 - val_loss: 0.5714 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6046 - acc: 0.7150 - val_loss: 0.5692 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6026 - acc: 0.7150 - val_loss: 0.5671 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7835 - acc: 0.4819 - val_loss: 0.7737 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7771 - acc: 0.4870 - val_loss: 0.7683 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7719 - acc: 0.4819 - val_loss: 0.7636 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7675 - acc: 0.4819 - val_loss: 0.7593 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7632 - acc: 0.4870 - val_loss: 0.7551 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7593 - acc: 0.4922 - val_loss: 0.7509 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7553 - acc: 0.5078 - val_loss: 0.7473 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7518 - acc: 0.5285 - val_loss: 0.7440 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7486 - acc: 0.5337 - val_loss: 0.7404 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7448 - acc: 0.5337 - val_loss: 0.7365 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7406 - acc: 0.5285 - val_loss: 0.7320 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7363 - acc: 0.5337 - val_loss: 0.7275 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7316 - acc: 0.5492 - val_loss: 0.7230 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7273 - acc: 0.5544 - val_loss: 0.7192 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7236 - acc: 0.5596 - val_loss: 0.7156 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7198 - acc: 0.5596 - val_loss: 0.7121 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7161 - acc: 0.5596 - val_loss: 0.7085 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7124 - acc: 0.5596 - val_loss: 0.7048 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7084 - acc: 0.5699 - val_loss: 0.7011 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7049 - acc: 0.5803 - val_loss: 0.6974 - val_acc: 0.4754\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6516 - acc: 0.6289 - val_loss: 0.6069 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6472 - acc: 0.6340 - val_loss: 0.6027 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6431 - acc: 0.6289 - val_loss: 0.5988 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6394 - acc: 0.6392 - val_loss: 0.5950 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6357 - acc: 0.6443 - val_loss: 0.5911 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6320 - acc: 0.6495 - val_loss: 0.5873 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6285 - acc: 0.6598 - val_loss: 0.5838 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6251 - acc: 0.6649 - val_loss: 0.5804 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6220 - acc: 0.6649 - val_loss: 0.5769 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6187 - acc: 0.6753 - val_loss: 0.5736 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6156 - acc: 0.6753 - val_loss: 0.5704 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6126 - acc: 0.6804 - val_loss: 0.5672 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6095 - acc: 0.6856 - val_loss: 0.5641 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6067 - acc: 0.6907 - val_loss: 0.5613 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6038 - acc: 0.6959 - val_loss: 0.5584 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6011 - acc: 0.7062 - val_loss: 0.5557 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5984 - acc: 0.7062 - val_loss: 0.5530 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5958 - acc: 0.7113 - val_loss: 0.5503 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5932 - acc: 0.7165 - val_loss: 0.5477 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5909 - acc: 0.7165 - val_loss: 0.5453 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6831 - acc: 0.5206 - val_loss: 0.6456 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6783 - acc: 0.5206 - val_loss: 0.6419 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6746 - acc: 0.5309 - val_loss: 0.6384 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6710 - acc: 0.5464 - val_loss: 0.6353 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6677 - acc: 0.5464 - val_loss: 0.6323 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6646 - acc: 0.5515 - val_loss: 0.6295 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6614 - acc: 0.5464 - val_loss: 0.6268 - val_acc: 0.6557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6587 - acc: 0.5515 - val_loss: 0.6247 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6562 - acc: 0.5670 - val_loss: 0.6222 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6538 - acc: 0.5722 - val_loss: 0.6196 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6508 - acc: 0.5825 - val_loss: 0.6169 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6481 - acc: 0.5928 - val_loss: 0.6144 - val_acc: 0.7049\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6455 - acc: 0.5979 - val_loss: 0.6118 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6427 - acc: 0.5979 - val_loss: 0.6090 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6397 - acc: 0.6031 - val_loss: 0.6061 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6370 - acc: 0.6134 - val_loss: 0.6035 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6344 - acc: 0.6082 - val_loss: 0.6013 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6321 - acc: 0.6134 - val_loss: 0.5991 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6300 - acc: 0.6134 - val_loss: 0.5970 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6279 - acc: 0.6134 - val_loss: 0.5949 - val_acc: 0.7049\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.8420 - acc: 0.3660 - val_loss: 0.8316 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8372 - acc: 0.3660 - val_loss: 0.8271 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8330 - acc: 0.3608 - val_loss: 0.8232 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8291 - acc: 0.3660 - val_loss: 0.8195 - val_acc: 0.3607\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8254 - acc: 0.3711 - val_loss: 0.8162 - val_acc: 0.3607\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8223 - acc: 0.3763 - val_loss: 0.8130 - val_acc: 0.3607\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8192 - acc: 0.3763 - val_loss: 0.8100 - val_acc: 0.3607\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8162 - acc: 0.3763 - val_loss: 0.8070 - val_acc: 0.3607\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8132 - acc: 0.3763 - val_loss: 0.8040 - val_acc: 0.3607\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8102 - acc: 0.3918 - val_loss: 0.8008 - val_acc: 0.3607\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8071 - acc: 0.3918 - val_loss: 0.7979 - val_acc: 0.3607\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8042 - acc: 0.3918 - val_loss: 0.7949 - val_acc: 0.3607\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8013 - acc: 0.3918 - val_loss: 0.7918 - val_acc: 0.3607\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7982 - acc: 0.3918 - val_loss: 0.7886 - val_acc: 0.3607\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7951 - acc: 0.3918 - val_loss: 0.7854 - val_acc: 0.3607\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7920 - acc: 0.3918 - val_loss: 0.7821 - val_acc: 0.3770\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7888 - acc: 0.3918 - val_loss: 0.7787 - val_acc: 0.3770\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7856 - acc: 0.3918 - val_loss: 0.7753 - val_acc: 0.3770\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7825 - acc: 0.3918 - val_loss: 0.7724 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7794 - acc: 0.3918 - val_loss: 0.7696 - val_acc: 0.3934\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6708 - acc: 0.6425 - val_loss: 0.6566 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6660 - acc: 0.6477 - val_loss: 0.6526 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6623 - acc: 0.6580 - val_loss: 0.6486 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6587 - acc: 0.6684 - val_loss: 0.6449 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6554 - acc: 0.6684 - val_loss: 0.6411 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6517 - acc: 0.6684 - val_loss: 0.6374 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6486 - acc: 0.6684 - val_loss: 0.6345 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6456 - acc: 0.6736 - val_loss: 0.6313 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6426 - acc: 0.6891 - val_loss: 0.6281 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6396 - acc: 0.6943 - val_loss: 0.6249 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6366 - acc: 0.6995 - val_loss: 0.6217 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6339 - acc: 0.7047 - val_loss: 0.6189 - val_acc: 0.7049\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6313 - acc: 0.7098 - val_loss: 0.6161 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6287 - acc: 0.7150 - val_loss: 0.6133 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6261 - acc: 0.7202 - val_loss: 0.6103 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6234 - acc: 0.7306 - val_loss: 0.6076 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6208 - acc: 0.7409 - val_loss: 0.6051 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6186 - acc: 0.7409 - val_loss: 0.6029 - val_acc: 0.7541\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6166 - acc: 0.7409 - val_loss: 0.6005 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6141 - acc: 0.7409 - val_loss: 0.5982 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6587 - acc: 0.5855 - val_loss: 0.6822 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6539 - acc: 0.6166 - val_loss: 0.6773 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6498 - acc: 0.6166 - val_loss: 0.6726 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6460 - acc: 0.6269 - val_loss: 0.6680 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6422 - acc: 0.6321 - val_loss: 0.6634 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6384 - acc: 0.6321 - val_loss: 0.6593 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6352 - acc: 0.6321 - val_loss: 0.6557 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6323 - acc: 0.6373 - val_loss: 0.6523 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6296 - acc: 0.6425 - val_loss: 0.6488 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6267 - acc: 0.6580 - val_loss: 0.6454 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6241 - acc: 0.6580 - val_loss: 0.6420 - val_acc: 0.5902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6213 - acc: 0.6684 - val_loss: 0.6386 - val_acc: 0.6066\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6188 - acc: 0.6684 - val_loss: 0.6354 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6164 - acc: 0.6684 - val_loss: 0.6327 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6143 - acc: 0.6736 - val_loss: 0.6304 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6123 - acc: 0.6736 - val_loss: 0.6279 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6102 - acc: 0.6788 - val_loss: 0.6253 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6079 - acc: 0.6891 - val_loss: 0.6228 - val_acc: 0.6066\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6057 - acc: 0.6891 - val_loss: 0.6200 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6034 - acc: 0.6995 - val_loss: 0.6171 - val_acc: 0.6066\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6316 - acc: 0.6082 - val_loss: 0.6081 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6263 - acc: 0.6186 - val_loss: 0.6029 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6221 - acc: 0.6289 - val_loss: 0.5980 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6181 - acc: 0.6546 - val_loss: 0.5933 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6143 - acc: 0.6804 - val_loss: 0.5890 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6107 - acc: 0.6907 - val_loss: 0.5850 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6073 - acc: 0.7010 - val_loss: 0.5807 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6034 - acc: 0.7062 - val_loss: 0.5763 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5998 - acc: 0.7216 - val_loss: 0.5718 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5961 - acc: 0.7320 - val_loss: 0.5676 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5926 - acc: 0.7423 - val_loss: 0.5635 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5892 - acc: 0.7474 - val_loss: 0.5595 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5860 - acc: 0.7474 - val_loss: 0.5556 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5828 - acc: 0.7474 - val_loss: 0.5518 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5798 - acc: 0.7474 - val_loss: 0.5483 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5768 - acc: 0.7474 - val_loss: 0.5449 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5741 - acc: 0.7474 - val_loss: 0.5417 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5714 - acc: 0.7474 - val_loss: 0.5388 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5689 - acc: 0.7474 - val_loss: 0.5358 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5664 - acc: 0.7526 - val_loss: 0.5330 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7746 - acc: 0.4433 - val_loss: 0.7357 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7665 - acc: 0.4536 - val_loss: 0.7292 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7599 - acc: 0.4588 - val_loss: 0.7223 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7528 - acc: 0.4691 - val_loss: 0.7158 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7459 - acc: 0.4845 - val_loss: 0.7095 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7387 - acc: 0.4794 - val_loss: 0.7033 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7321 - acc: 0.4897 - val_loss: 0.6973 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7255 - acc: 0.5000 - val_loss: 0.6914 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7195 - acc: 0.5052 - val_loss: 0.6857 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7138 - acc: 0.5103 - val_loss: 0.6803 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7084 - acc: 0.5361 - val_loss: 0.6749 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7028 - acc: 0.5412 - val_loss: 0.6699 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6974 - acc: 0.5567 - val_loss: 0.6651 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6924 - acc: 0.5670 - val_loss: 0.6603 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6868 - acc: 0.5773 - val_loss: 0.6556 - val_acc: 0.6557\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6817 - acc: 0.5825 - val_loss: 0.6512 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6770 - acc: 0.5928 - val_loss: 0.6468 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6720 - acc: 0.6082 - val_loss: 0.6427 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6676 - acc: 0.6134 - val_loss: 0.6392 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6639 - acc: 0.6082 - val_loss: 0.6357 - val_acc: 0.6721\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7010 - acc: 0.5103 - val_loss: 0.7028 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6949 - acc: 0.5206 - val_loss: 0.6970 - val_acc: 0.4426\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6895 - acc: 0.5309 - val_loss: 0.6914 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6845 - acc: 0.5412 - val_loss: 0.6857 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6795 - acc: 0.5515 - val_loss: 0.6801 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6744 - acc: 0.5670 - val_loss: 0.6751 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6700 - acc: 0.5670 - val_loss: 0.6704 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6660 - acc: 0.5825 - val_loss: 0.6659 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6623 - acc: 0.5876 - val_loss: 0.6619 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6586 - acc: 0.5979 - val_loss: 0.6579 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6552 - acc: 0.6082 - val_loss: 0.6542 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6519 - acc: 0.6134 - val_loss: 0.6503 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6485 - acc: 0.6237 - val_loss: 0.6459 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6446 - acc: 0.6289 - val_loss: 0.6413 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6407 - acc: 0.6289 - val_loss: 0.6371 - val_acc: 0.5574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6370 - acc: 0.6443 - val_loss: 0.6329 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6333 - acc: 0.6443 - val_loss: 0.6286 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6294 - acc: 0.6649 - val_loss: 0.6242 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6255 - acc: 0.6753 - val_loss: 0.6198 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6218 - acc: 0.6856 - val_loss: 0.6155 - val_acc: 0.5902\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7241 - acc: 0.5078 - val_loss: 0.7249 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7156 - acc: 0.5181 - val_loss: 0.7161 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7083 - acc: 0.5285 - val_loss: 0.7083 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7025 - acc: 0.5389 - val_loss: 0.7023 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6973 - acc: 0.5440 - val_loss: 0.6968 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6925 - acc: 0.5492 - val_loss: 0.6909 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6876 - acc: 0.5648 - val_loss: 0.6849 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6827 - acc: 0.5907 - val_loss: 0.6786 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6776 - acc: 0.6062 - val_loss: 0.6722 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6726 - acc: 0.6062 - val_loss: 0.6656 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6674 - acc: 0.6114 - val_loss: 0.6593 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6624 - acc: 0.6114 - val_loss: 0.6540 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6583 - acc: 0.6373 - val_loss: 0.6497 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6546 - acc: 0.6373 - val_loss: 0.6448 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6502 - acc: 0.6632 - val_loss: 0.6395 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6457 - acc: 0.6736 - val_loss: 0.6347 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6417 - acc: 0.6736 - val_loss: 0.6300 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6373 - acc: 0.6943 - val_loss: 0.6253 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6333 - acc: 0.7047 - val_loss: 0.6212 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6295 - acc: 0.7047 - val_loss: 0.6174 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6944 - acc: 0.5233 - val_loss: 0.6817 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6857 - acc: 0.5751 - val_loss: 0.6746 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6800 - acc: 0.6010 - val_loss: 0.6694 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6751 - acc: 0.6218 - val_loss: 0.6638 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6702 - acc: 0.6321 - val_loss: 0.6584 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6650 - acc: 0.6425 - val_loss: 0.6527 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6595 - acc: 0.6580 - val_loss: 0.6472 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6541 - acc: 0.6788 - val_loss: 0.6422 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6495 - acc: 0.6943 - val_loss: 0.6371 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6451 - acc: 0.6943 - val_loss: 0.6322 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6409 - acc: 0.6995 - val_loss: 0.6275 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6367 - acc: 0.6943 - val_loss: 0.6232 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6330 - acc: 0.7098 - val_loss: 0.6187 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6291 - acc: 0.7202 - val_loss: 0.6144 - val_acc: 0.7705\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6253 - acc: 0.7254 - val_loss: 0.6101 - val_acc: 0.7705\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6213 - acc: 0.7409 - val_loss: 0.6057 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6168 - acc: 0.7513 - val_loss: 0.6010 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6124 - acc: 0.7617 - val_loss: 0.5962 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6080 - acc: 0.7772 - val_loss: 0.5918 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6037 - acc: 0.7979 - val_loss: 0.5878 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6560 - acc: 0.5412 - val_loss: 0.6319 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6467 - acc: 0.5825 - val_loss: 0.6237 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6395 - acc: 0.6082 - val_loss: 0.6171 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6333 - acc: 0.6392 - val_loss: 0.6111 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6276 - acc: 0.6598 - val_loss: 0.6049 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6217 - acc: 0.6856 - val_loss: 0.5988 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6161 - acc: 0.6959 - val_loss: 0.5930 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6106 - acc: 0.7165 - val_loss: 0.5873 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6051 - acc: 0.7268 - val_loss: 0.5814 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5995 - acc: 0.7268 - val_loss: 0.5761 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5946 - acc: 0.7320 - val_loss: 0.5712 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5896 - acc: 0.7474 - val_loss: 0.5659 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5844 - acc: 0.7577 - val_loss: 0.5604 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5791 - acc: 0.7680 - val_loss: 0.5552 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5741 - acc: 0.7784 - val_loss: 0.5497 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5687 - acc: 0.7938 - val_loss: 0.5444 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5639 - acc: 0.8196 - val_loss: 0.5392 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5588 - acc: 0.8196 - val_loss: 0.5339 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5543 - acc: 0.8247 - val_loss: 0.5289 - val_acc: 0.8033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5496 - acc: 0.8299 - val_loss: 0.5241 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7184 - acc: 0.3969 - val_loss: 0.7296 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7094 - acc: 0.4278 - val_loss: 0.7206 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7019 - acc: 0.4639 - val_loss: 0.7123 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6949 - acc: 0.5155 - val_loss: 0.7047 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6883 - acc: 0.5412 - val_loss: 0.6974 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6819 - acc: 0.5876 - val_loss: 0.6907 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6764 - acc: 0.5979 - val_loss: 0.6842 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6707 - acc: 0.6289 - val_loss: 0.6773 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6650 - acc: 0.6443 - val_loss: 0.6702 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6591 - acc: 0.6649 - val_loss: 0.6629 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6533 - acc: 0.6907 - val_loss: 0.6563 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6480 - acc: 0.7062 - val_loss: 0.6509 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6436 - acc: 0.7165 - val_loss: 0.6463 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6399 - acc: 0.7216 - val_loss: 0.6415 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6360 - acc: 0.7320 - val_loss: 0.6369 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6325 - acc: 0.7371 - val_loss: 0.6330 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6292 - acc: 0.7526 - val_loss: 0.6292 - val_acc: 0.7213\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6260 - acc: 0.7474 - val_loss: 0.6252 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6225 - acc: 0.7526 - val_loss: 0.6209 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6186 - acc: 0.7577 - val_loss: 0.6163 - val_acc: 0.7213\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6992 - acc: 0.5464 - val_loss: 0.6753 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6897 - acc: 0.5928 - val_loss: 0.6668 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6818 - acc: 0.6134 - val_loss: 0.6592 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6745 - acc: 0.6237 - val_loss: 0.6518 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6681 - acc: 0.6598 - val_loss: 0.6448 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6617 - acc: 0.6649 - val_loss: 0.6381 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6554 - acc: 0.6804 - val_loss: 0.6314 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6493 - acc: 0.6804 - val_loss: 0.6250 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6430 - acc: 0.7062 - val_loss: 0.6194 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6377 - acc: 0.7165 - val_loss: 0.6140 - val_acc: 0.7213\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6323 - acc: 0.7423 - val_loss: 0.6085 - val_acc: 0.7541\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6270 - acc: 0.7887 - val_loss: 0.6031 - val_acc: 0.7541\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6217 - acc: 0.8041 - val_loss: 0.5975 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6167 - acc: 0.8041 - val_loss: 0.5922 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6119 - acc: 0.8144 - val_loss: 0.5874 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6075 - acc: 0.8196 - val_loss: 0.5828 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6032 - acc: 0.8299 - val_loss: 0.5782 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5990 - acc: 0.8299 - val_loss: 0.5737 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5949 - acc: 0.8247 - val_loss: 0.5691 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5907 - acc: 0.8196 - val_loss: 0.5647 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6946 - acc: 0.5078 - val_loss: 0.6855 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6836 - acc: 0.5648 - val_loss: 0.6758 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6747 - acc: 0.6269 - val_loss: 0.6654 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6663 - acc: 0.6425 - val_loss: 0.6558 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6582 - acc: 0.6995 - val_loss: 0.6465 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6502 - acc: 0.7047 - val_loss: 0.6375 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6421 - acc: 0.7202 - val_loss: 0.6288 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6345 - acc: 0.7254 - val_loss: 0.6205 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6277 - acc: 0.7565 - val_loss: 0.6128 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6210 - acc: 0.7617 - val_loss: 0.6052 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6143 - acc: 0.7876 - val_loss: 0.5977 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6082 - acc: 0.7979 - val_loss: 0.5908 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6021 - acc: 0.7979 - val_loss: 0.5847 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5965 - acc: 0.7927 - val_loss: 0.5784 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5910 - acc: 0.7927 - val_loss: 0.5723 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5861 - acc: 0.7979 - val_loss: 0.5668 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5813 - acc: 0.7979 - val_loss: 0.5614 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5765 - acc: 0.8031 - val_loss: 0.5566 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5719 - acc: 0.8135 - val_loss: 0.5518 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5673 - acc: 0.8135 - val_loss: 0.5472 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6535 - acc: 0.6580 - val_loss: 0.6206 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6422 - acc: 0.6839 - val_loss: 0.6104 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6325 - acc: 0.7098 - val_loss: 0.6021 - val_acc: 0.8033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6249 - acc: 0.7254 - val_loss: 0.5951 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6178 - acc: 0.7668 - val_loss: 0.5878 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6105 - acc: 0.7720 - val_loss: 0.5808 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6043 - acc: 0.7772 - val_loss: 0.5746 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5987 - acc: 0.7876 - val_loss: 0.5687 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5936 - acc: 0.7824 - val_loss: 0.5627 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5882 - acc: 0.7824 - val_loss: 0.5569 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5832 - acc: 0.7876 - val_loss: 0.5514 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5780 - acc: 0.7824 - val_loss: 0.5463 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5735 - acc: 0.7876 - val_loss: 0.5416 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5688 - acc: 0.7876 - val_loss: 0.5368 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5642 - acc: 0.7876 - val_loss: 0.5326 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5599 - acc: 0.7927 - val_loss: 0.5286 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5556 - acc: 0.7927 - val_loss: 0.5246 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5514 - acc: 0.7927 - val_loss: 0.5205 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5474 - acc: 0.7927 - val_loss: 0.5165 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5436 - acc: 0.7876 - val_loss: 0.5125 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6571 - acc: 0.6959 - val_loss: 0.6471 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6469 - acc: 0.7216 - val_loss: 0.6375 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6392 - acc: 0.7577 - val_loss: 0.6291 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6319 - acc: 0.7629 - val_loss: 0.6212 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6250 - acc: 0.7680 - val_loss: 0.6140 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6187 - acc: 0.7732 - val_loss: 0.6068 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6120 - acc: 0.7784 - val_loss: 0.5991 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6053 - acc: 0.7887 - val_loss: 0.5912 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5982 - acc: 0.7938 - val_loss: 0.5831 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5911 - acc: 0.7938 - val_loss: 0.5751 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5843 - acc: 0.7990 - val_loss: 0.5680 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5780 - acc: 0.7990 - val_loss: 0.5612 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5720 - acc: 0.7990 - val_loss: 0.5546 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5662 - acc: 0.8144 - val_loss: 0.5487 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5609 - acc: 0.8144 - val_loss: 0.5430 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5556 - acc: 0.8144 - val_loss: 0.5369 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5505 - acc: 0.8196 - val_loss: 0.5308 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5449 - acc: 0.8196 - val_loss: 0.5251 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5399 - acc: 0.8196 - val_loss: 0.5194 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5350 - acc: 0.8247 - val_loss: 0.5140 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7141 - acc: 0.4485 - val_loss: 0.7049 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7011 - acc: 0.4845 - val_loss: 0.6920 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6900 - acc: 0.5412 - val_loss: 0.6810 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6802 - acc: 0.5567 - val_loss: 0.6712 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6716 - acc: 0.5876 - val_loss: 0.6619 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6632 - acc: 0.6186 - val_loss: 0.6523 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6550 - acc: 0.6753 - val_loss: 0.6434 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6473 - acc: 0.7010 - val_loss: 0.6343 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6391 - acc: 0.7371 - val_loss: 0.6249 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6307 - acc: 0.7526 - val_loss: 0.6160 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6234 - acc: 0.7784 - val_loss: 0.6077 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6162 - acc: 0.7784 - val_loss: 0.6000 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6093 - acc: 0.8041 - val_loss: 0.5923 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6027 - acc: 0.8144 - val_loss: 0.5848 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5964 - acc: 0.8093 - val_loss: 0.5777 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5903 - acc: 0.8144 - val_loss: 0.5709 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5847 - acc: 0.8144 - val_loss: 0.5651 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5798 - acc: 0.8144 - val_loss: 0.5599 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5752 - acc: 0.8196 - val_loss: 0.5549 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5707 - acc: 0.8247 - val_loss: 0.5505 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6881 - acc: 0.5928 - val_loss: 0.6963 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6759 - acc: 0.6443 - val_loss: 0.6846 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6664 - acc: 0.6701 - val_loss: 0.6757 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6588 - acc: 0.6907 - val_loss: 0.6671 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6508 - acc: 0.7423 - val_loss: 0.6582 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6433 - acc: 0.7577 - val_loss: 0.6492 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6358 - acc: 0.7629 - val_loss: 0.6406 - val_acc: 0.6721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6285 - acc: 0.7577 - val_loss: 0.6321 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6213 - acc: 0.7835 - val_loss: 0.6238 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6145 - acc: 0.7990 - val_loss: 0.6164 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6081 - acc: 0.8093 - val_loss: 0.6090 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6021 - acc: 0.8093 - val_loss: 0.6019 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5961 - acc: 0.8093 - val_loss: 0.5952 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5906 - acc: 0.7990 - val_loss: 0.5885 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5848 - acc: 0.8041 - val_loss: 0.5821 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5793 - acc: 0.8093 - val_loss: 0.5758 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5739 - acc: 0.8093 - val_loss: 0.5698 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5689 - acc: 0.8041 - val_loss: 0.5643 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5638 - acc: 0.8041 - val_loss: 0.5586 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5589 - acc: 0.7990 - val_loss: 0.5523 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8739 - acc: 0.5130 - val_loss: 0.8432 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8516 - acc: 0.5233 - val_loss: 0.8247 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8345 - acc: 0.5233 - val_loss: 0.8087 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8211 - acc: 0.5337 - val_loss: 0.7928 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8073 - acc: 0.5389 - val_loss: 0.7773 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7941 - acc: 0.5440 - val_loss: 0.7629 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7820 - acc: 0.5440 - val_loss: 0.7490 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7690 - acc: 0.5492 - val_loss: 0.7352 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7555 - acc: 0.5492 - val_loss: 0.7217 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7433 - acc: 0.5492 - val_loss: 0.7082 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7311 - acc: 0.5596 - val_loss: 0.6948 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7199 - acc: 0.5751 - val_loss: 0.6830 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7094 - acc: 0.5907 - val_loss: 0.6731 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7007 - acc: 0.5907 - val_loss: 0.6639 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6922 - acc: 0.5959 - val_loss: 0.6542 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6831 - acc: 0.5959 - val_loss: 0.6444 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6741 - acc: 0.6062 - val_loss: 0.6354 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6660 - acc: 0.6269 - val_loss: 0.6269 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6580 - acc: 0.6218 - val_loss: 0.6191 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6501 - acc: 0.6269 - val_loss: 0.6119 - val_acc: 0.6721\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6963 - acc: 0.5855 - val_loss: 0.7082 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6849 - acc: 0.5855 - val_loss: 0.6975 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6752 - acc: 0.5959 - val_loss: 0.6878 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6668 - acc: 0.6114 - val_loss: 0.6795 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6596 - acc: 0.6166 - val_loss: 0.6715 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6526 - acc: 0.6218 - val_loss: 0.6644 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6464 - acc: 0.6373 - val_loss: 0.6579 - val_acc: 0.6393\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6407 - acc: 0.6425 - val_loss: 0.6517 - val_acc: 0.6393\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6350 - acc: 0.6528 - val_loss: 0.6453 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6289 - acc: 0.6528 - val_loss: 0.6383 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6232 - acc: 0.6632 - val_loss: 0.6321 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6181 - acc: 0.6684 - val_loss: 0.6266 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6130 - acc: 0.6736 - val_loss: 0.6213 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6082 - acc: 0.6788 - val_loss: 0.6163 - val_acc: 0.6885\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6038 - acc: 0.6943 - val_loss: 0.6121 - val_acc: 0.6885\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5998 - acc: 0.6943 - val_loss: 0.6083 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5961 - acc: 0.6995 - val_loss: 0.6049 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5927 - acc: 0.7047 - val_loss: 0.6023 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5896 - acc: 0.7047 - val_loss: 0.5982 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5859 - acc: 0.7098 - val_loss: 0.5939 - val_acc: 0.6721\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7051 - acc: 0.5722 - val_loss: 0.7083 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6892 - acc: 0.5876 - val_loss: 0.6952 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6770 - acc: 0.6031 - val_loss: 0.6825 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6655 - acc: 0.6031 - val_loss: 0.6690 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6528 - acc: 0.6237 - val_loss: 0.6551 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6405 - acc: 0.6443 - val_loss: 0.6420 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6284 - acc: 0.6753 - val_loss: 0.6301 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6179 - acc: 0.6856 - val_loss: 0.6197 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6086 - acc: 0.6959 - val_loss: 0.6110 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6003 - acc: 0.7062 - val_loss: 0.6026 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5920 - acc: 0.7113 - val_loss: 0.5940 - val_acc: 0.6230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5842 - acc: 0.7062 - val_loss: 0.5855 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5763 - acc: 0.7010 - val_loss: 0.5775 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5689 - acc: 0.7113 - val_loss: 0.5698 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5619 - acc: 0.7371 - val_loss: 0.5620 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5548 - acc: 0.7423 - val_loss: 0.5542 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5483 - acc: 0.7577 - val_loss: 0.5465 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5415 - acc: 0.7680 - val_loss: 0.5396 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5356 - acc: 0.7732 - val_loss: 0.5334 - val_acc: 0.7377\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5303 - acc: 0.7732 - val_loss: 0.5270 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7650 - acc: 0.3299 - val_loss: 0.8075 - val_acc: 0.2787\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7575 - acc: 0.3299 - val_loss: 0.7979 - val_acc: 0.2787\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7504 - acc: 0.3402 - val_loss: 0.7891 - val_acc: 0.2951\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7446 - acc: 0.3557 - val_loss: 0.7821 - val_acc: 0.2951\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7395 - acc: 0.3660 - val_loss: 0.7755 - val_acc: 0.3115\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7345 - acc: 0.3711 - val_loss: 0.7689 - val_acc: 0.3115\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7293 - acc: 0.3866 - val_loss: 0.7630 - val_acc: 0.3279\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7247 - acc: 0.4124 - val_loss: 0.7577 - val_acc: 0.3443\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7205 - acc: 0.4485 - val_loss: 0.7529 - val_acc: 0.3443\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7164 - acc: 0.4639 - val_loss: 0.7478 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7120 - acc: 0.4845 - val_loss: 0.7422 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7077 - acc: 0.5052 - val_loss: 0.7362 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7037 - acc: 0.5309 - val_loss: 0.7305 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6996 - acc: 0.5464 - val_loss: 0.7250 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6961 - acc: 0.5670 - val_loss: 0.7206 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6930 - acc: 0.5773 - val_loss: 0.7161 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6894 - acc: 0.5876 - val_loss: 0.7112 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6859 - acc: 0.6031 - val_loss: 0.7065 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6827 - acc: 0.6186 - val_loss: 0.7020 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6795 - acc: 0.6186 - val_loss: 0.6978 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6667 - acc: 0.6186 - val_loss: 0.6210 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6549 - acc: 0.6392 - val_loss: 0.6092 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6445 - acc: 0.6443 - val_loss: 0.5994 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6351 - acc: 0.6546 - val_loss: 0.5902 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6271 - acc: 0.6649 - val_loss: 0.5818 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6201 - acc: 0.6753 - val_loss: 0.5741 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6138 - acc: 0.6753 - val_loss: 0.5668 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6074 - acc: 0.6701 - val_loss: 0.5600 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6008 - acc: 0.6804 - val_loss: 0.5532 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5941 - acc: 0.6804 - val_loss: 0.5470 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5878 - acc: 0.6856 - val_loss: 0.5416 - val_acc: 0.7541\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5823 - acc: 0.6907 - val_loss: 0.5357 - val_acc: 0.7541\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5755 - acc: 0.6959 - val_loss: 0.5296 - val_acc: 0.7541\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5699 - acc: 0.7062 - val_loss: 0.5236 - val_acc: 0.7541\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5638 - acc: 0.7113 - val_loss: 0.5184 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5589 - acc: 0.7113 - val_loss: 0.5144 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5551 - acc: 0.7216 - val_loss: 0.5104 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5512 - acc: 0.7165 - val_loss: 0.5060 - val_acc: 0.7869\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5472 - acc: 0.7216 - val_loss: 0.5013 - val_acc: 0.7869\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5428 - acc: 0.7320 - val_loss: 0.4968 - val_acc: 0.7869\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8136 - acc: 0.3316 - val_loss: 0.8213 - val_acc: 0.2459\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7928 - acc: 0.3368 - val_loss: 0.7998 - val_acc: 0.2459\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7752 - acc: 0.3679 - val_loss: 0.7805 - val_acc: 0.2623\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7595 - acc: 0.3938 - val_loss: 0.7629 - val_acc: 0.2951\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7447 - acc: 0.4301 - val_loss: 0.7463 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7310 - acc: 0.4404 - val_loss: 0.7296 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7169 - acc: 0.4870 - val_loss: 0.7128 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7032 - acc: 0.5181 - val_loss: 0.6974 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6906 - acc: 0.5648 - val_loss: 0.6834 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6790 - acc: 0.5959 - val_loss: 0.6705 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6681 - acc: 0.6477 - val_loss: 0.6595 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6590 - acc: 0.6632 - val_loss: 0.6479 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6491 - acc: 0.6839 - val_loss: 0.6365 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6396 - acc: 0.6891 - val_loss: 0.6268 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6316 - acc: 0.7047 - val_loss: 0.6176 - val_acc: 0.7213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6238 - acc: 0.7098 - val_loss: 0.6080 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6162 - acc: 0.7254 - val_loss: 0.5990 - val_acc: 0.7213\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6086 - acc: 0.7461 - val_loss: 0.5901 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6011 - acc: 0.7409 - val_loss: 0.5812 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5938 - acc: 0.7306 - val_loss: 0.5731 - val_acc: 0.7541\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7419 - acc: 0.4301 - val_loss: 0.7105 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7222 - acc: 0.4767 - val_loss: 0.6935 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7077 - acc: 0.5078 - val_loss: 0.6797 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6962 - acc: 0.5337 - val_loss: 0.6678 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6852 - acc: 0.5596 - val_loss: 0.6553 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6738 - acc: 0.5803 - val_loss: 0.6431 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6624 - acc: 0.6218 - val_loss: 0.6309 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6514 - acc: 0.6477 - val_loss: 0.6195 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6405 - acc: 0.6736 - val_loss: 0.6084 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6305 - acc: 0.6839 - val_loss: 0.5983 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6215 - acc: 0.7098 - val_loss: 0.5888 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6125 - acc: 0.7202 - val_loss: 0.5790 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6038 - acc: 0.7461 - val_loss: 0.5685 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5950 - acc: 0.7565 - val_loss: 0.5578 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5859 - acc: 0.7617 - val_loss: 0.5480 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5784 - acc: 0.7668 - val_loss: 0.5393 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5713 - acc: 0.7772 - val_loss: 0.5309 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5651 - acc: 0.7824 - val_loss: 0.5239 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5596 - acc: 0.7876 - val_loss: 0.5170 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5541 - acc: 0.7876 - val_loss: 0.5102 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7310 - acc: 0.4742 - val_loss: 0.6974 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7097 - acc: 0.4897 - val_loss: 0.6800 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6937 - acc: 0.5103 - val_loss: 0.6643 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6795 - acc: 0.5206 - val_loss: 0.6501 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6656 - acc: 0.5361 - val_loss: 0.6371 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6538 - acc: 0.5464 - val_loss: 0.6246 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6417 - acc: 0.5670 - val_loss: 0.6130 - val_acc: 0.6393\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6312 - acc: 0.5928 - val_loss: 0.6033 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6220 - acc: 0.6082 - val_loss: 0.5939 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6130 - acc: 0.6134 - val_loss: 0.5846 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6042 - acc: 0.6289 - val_loss: 0.5756 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5959 - acc: 0.6649 - val_loss: 0.5664 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5873 - acc: 0.6701 - val_loss: 0.5571 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5787 - acc: 0.6959 - val_loss: 0.5480 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5710 - acc: 0.7113 - val_loss: 0.5397 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5638 - acc: 0.7268 - val_loss: 0.5322 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5567 - acc: 0.7423 - val_loss: 0.5249 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5503 - acc: 0.7526 - val_loss: 0.5179 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5435 - acc: 0.7680 - val_loss: 0.5111 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5376 - acc: 0.7732 - val_loss: 0.5046 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6716 - acc: 0.6082 - val_loss: 0.6446 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6545 - acc: 0.6546 - val_loss: 0.6293 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6414 - acc: 0.6701 - val_loss: 0.6139 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6282 - acc: 0.6804 - val_loss: 0.5987 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6153 - acc: 0.7113 - val_loss: 0.5844 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6040 - acc: 0.7216 - val_loss: 0.5709 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5929 - acc: 0.7320 - val_loss: 0.5584 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5830 - acc: 0.7320 - val_loss: 0.5467 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5736 - acc: 0.7423 - val_loss: 0.5353 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5646 - acc: 0.7423 - val_loss: 0.5247 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5569 - acc: 0.7320 - val_loss: 0.5142 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5488 - acc: 0.7371 - val_loss: 0.5045 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5419 - acc: 0.7474 - val_loss: 0.4954 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5356 - acc: 0.7577 - val_loss: 0.4879 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5297 - acc: 0.7680 - val_loss: 0.4808 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5243 - acc: 0.7680 - val_loss: 0.4738 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5190 - acc: 0.7784 - val_loss: 0.4669 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5135 - acc: 0.7887 - val_loss: 0.4602 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5080 - acc: 0.7887 - val_loss: 0.4541 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5033 - acc: 0.7938 - val_loss: 0.4485 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5919 - acc: 0.6856 - val_loss: 0.6351 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5755 - acc: 0.7165 - val_loss: 0.6184 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5606 - acc: 0.7371 - val_loss: 0.6030 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5474 - acc: 0.7371 - val_loss: 0.5901 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5357 - acc: 0.7526 - val_loss: 0.5776 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5249 - acc: 0.7526 - val_loss: 0.5654 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5149 - acc: 0.7629 - val_loss: 0.5539 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5054 - acc: 0.7629 - val_loss: 0.5431 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4963 - acc: 0.7732 - val_loss: 0.5333 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4887 - acc: 0.7732 - val_loss: 0.5255 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4823 - acc: 0.7887 - val_loss: 0.5189 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4766 - acc: 0.7835 - val_loss: 0.5119 - val_acc: 0.7377\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4703 - acc: 0.7938 - val_loss: 0.5038 - val_acc: 0.7377\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4637 - acc: 0.7990 - val_loss: 0.4952 - val_acc: 0.7377\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4573 - acc: 0.8041 - val_loss: 0.4861 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4501 - acc: 0.8093 - val_loss: 0.4770 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4445 - acc: 0.8144 - val_loss: 0.4692 - val_acc: 0.7705\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4395 - acc: 0.8144 - val_loss: 0.4633 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4351 - acc: 0.8144 - val_loss: 0.4581 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4310 - acc: 0.8196 - val_loss: 0.4532 - val_acc: 0.7705\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9498 - acc: 0.3627 - val_loss: 0.9438 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9064 - acc: 0.3679 - val_loss: 0.9029 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8732 - acc: 0.3731 - val_loss: 0.8673 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8453 - acc: 0.3990 - val_loss: 0.8366 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8207 - acc: 0.4456 - val_loss: 0.8108 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8013 - acc: 0.4767 - val_loss: 0.7857 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7802 - acc: 0.5026 - val_loss: 0.7619 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7604 - acc: 0.5181 - val_loss: 0.7413 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7429 - acc: 0.5389 - val_loss: 0.7239 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7274 - acc: 0.5648 - val_loss: 0.7074 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7128 - acc: 0.5648 - val_loss: 0.6938 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7017 - acc: 0.5648 - val_loss: 0.6834 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6905 - acc: 0.5699 - val_loss: 0.6717 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6794 - acc: 0.6010 - val_loss: 0.6589 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6669 - acc: 0.6269 - val_loss: 0.6449 - val_acc: 0.6885\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6548 - acc: 0.6425 - val_loss: 0.6332 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6442 - acc: 0.6736 - val_loss: 0.6220 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6316 - acc: 0.6891 - val_loss: 0.6096 - val_acc: 0.7213\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6199 - acc: 0.7047 - val_loss: 0.5978 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6088 - acc: 0.6943 - val_loss: 0.5864 - val_acc: 0.7377\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5542 - acc: 0.7306 - val_loss: 0.4632 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5289 - acc: 0.7461 - val_loss: 0.4428 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5113 - acc: 0.7565 - val_loss: 0.4316 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4992 - acc: 0.7772 - val_loss: 0.4245 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4902 - acc: 0.7772 - val_loss: 0.4188 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4818 - acc: 0.7979 - val_loss: 0.4120 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4728 - acc: 0.8031 - val_loss: 0.4042 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4650 - acc: 0.8187 - val_loss: 0.3973 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4570 - acc: 0.8238 - val_loss: 0.3887 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4484 - acc: 0.8342 - val_loss: 0.3807 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4412 - acc: 0.8238 - val_loss: 0.3740 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4340 - acc: 0.8238 - val_loss: 0.3683 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4284 - acc: 0.8342 - val_loss: 0.3626 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4225 - acc: 0.8342 - val_loss: 0.3584 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4174 - acc: 0.8394 - val_loss: 0.3542 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4122 - acc: 0.8394 - val_loss: 0.3503 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4076 - acc: 0.8290 - val_loss: 0.3484 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4037 - acc: 0.8290 - val_loss: 0.3463 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3994 - acc: 0.8290 - val_loss: 0.3429 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3953 - acc: 0.8290 - val_loss: 0.3402 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7156 - acc: 0.5515 - val_loss: 0.6781 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6854 - acc: 0.5515 - val_loss: 0.6504 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6616 - acc: 0.5515 - val_loss: 0.6251 - val_acc: 0.5738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6400 - acc: 0.5619 - val_loss: 0.6026 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6204 - acc: 0.5825 - val_loss: 0.5828 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6034 - acc: 0.6031 - val_loss: 0.5644 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5870 - acc: 0.6237 - val_loss: 0.5479 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5728 - acc: 0.6598 - val_loss: 0.5329 - val_acc: 0.7377\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5590 - acc: 0.6907 - val_loss: 0.5189 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5467 - acc: 0.7320 - val_loss: 0.5068 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5354 - acc: 0.7423 - val_loss: 0.4954 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5246 - acc: 0.7680 - val_loss: 0.4840 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5144 - acc: 0.7887 - val_loss: 0.4729 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5052 - acc: 0.7938 - val_loss: 0.4622 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4956 - acc: 0.7990 - val_loss: 0.4520 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4856 - acc: 0.7990 - val_loss: 0.4423 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4762 - acc: 0.8196 - val_loss: 0.4341 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4681 - acc: 0.8144 - val_loss: 0.4274 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4600 - acc: 0.8144 - val_loss: 0.4226 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4539 - acc: 0.8144 - val_loss: 0.4170 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6663 - acc: 0.6031 - val_loss: 0.6053 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6413 - acc: 0.6495 - val_loss: 0.5871 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6217 - acc: 0.6649 - val_loss: 0.5706 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6042 - acc: 0.6856 - val_loss: 0.5565 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5905 - acc: 0.6907 - val_loss: 0.5427 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5773 - acc: 0.7268 - val_loss: 0.5293 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5646 - acc: 0.7320 - val_loss: 0.5188 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5546 - acc: 0.7474 - val_loss: 0.5093 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5446 - acc: 0.7629 - val_loss: 0.4996 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5356 - acc: 0.7577 - val_loss: 0.4910 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5267 - acc: 0.7629 - val_loss: 0.4821 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5177 - acc: 0.7629 - val_loss: 0.4731 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5095 - acc: 0.7784 - val_loss: 0.4645 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5007 - acc: 0.7835 - val_loss: 0.4562 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4927 - acc: 0.7835 - val_loss: 0.4483 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4856 - acc: 0.7784 - val_loss: 0.4411 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4790 - acc: 0.7887 - val_loss: 0.4342 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4733 - acc: 0.7938 - val_loss: 0.4279 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4682 - acc: 0.7887 - val_loss: 0.4225 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4641 - acc: 0.7938 - val_loss: 0.4175 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7770 - acc: 0.4536 - val_loss: 0.7427 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7444 - acc: 0.5000 - val_loss: 0.7118 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7195 - acc: 0.5258 - val_loss: 0.6823 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6960 - acc: 0.5412 - val_loss: 0.6566 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6749 - acc: 0.5515 - val_loss: 0.6330 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6536 - acc: 0.5979 - val_loss: 0.6109 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6340 - acc: 0.6134 - val_loss: 0.5905 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6163 - acc: 0.6598 - val_loss: 0.5714 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5997 - acc: 0.6701 - val_loss: 0.5542 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5838 - acc: 0.6959 - val_loss: 0.5397 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5718 - acc: 0.7010 - val_loss: 0.5259 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5587 - acc: 0.7320 - val_loss: 0.5131 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5470 - acc: 0.7526 - val_loss: 0.5006 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5355 - acc: 0.7577 - val_loss: 0.4899 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5257 - acc: 0.7629 - val_loss: 0.4809 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5177 - acc: 0.7680 - val_loss: 0.4722 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5094 - acc: 0.7732 - val_loss: 0.4651 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5023 - acc: 0.7784 - val_loss: 0.4583 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4956 - acc: 0.7835 - val_loss: 0.4515 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4893 - acc: 0.7887 - val_loss: 0.4446 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6615 - acc: 0.5959 - val_loss: 0.6382 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6230 - acc: 0.6632 - val_loss: 0.6020 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5932 - acc: 0.7358 - val_loss: 0.5726 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5697 - acc: 0.7461 - val_loss: 0.5479 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5481 - acc: 0.7617 - val_loss: 0.5240 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5288 - acc: 0.7617 - val_loss: 0.5019 - val_acc: 0.7869\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5118 - acc: 0.7824 - val_loss: 0.4826 - val_acc: 0.7705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4984 - acc: 0.7824 - val_loss: 0.4670 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4873 - acc: 0.7927 - val_loss: 0.4531 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4768 - acc: 0.7979 - val_loss: 0.4401 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4662 - acc: 0.8083 - val_loss: 0.4299 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4579 - acc: 0.8187 - val_loss: 0.4227 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4509 - acc: 0.8238 - val_loss: 0.4161 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4435 - acc: 0.8290 - val_loss: 0.4096 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4363 - acc: 0.8342 - val_loss: 0.4031 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4291 - acc: 0.8394 - val_loss: 0.3976 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4228 - acc: 0.8549 - val_loss: 0.3925 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4168 - acc: 0.8549 - val_loss: 0.3896 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4117 - acc: 0.8497 - val_loss: 0.3855 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4067 - acc: 0.8549 - val_loss: 0.3779 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7599 - acc: 0.4767 - val_loss: 0.7502 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7159 - acc: 0.5389 - val_loss: 0.7148 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6864 - acc: 0.5751 - val_loss: 0.6830 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6608 - acc: 0.6010 - val_loss: 0.6579 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6384 - acc: 0.6528 - val_loss: 0.6370 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6191 - acc: 0.6891 - val_loss: 0.6150 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5980 - acc: 0.7306 - val_loss: 0.5939 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5797 - acc: 0.7461 - val_loss: 0.5743 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5613 - acc: 0.7617 - val_loss: 0.5549 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5446 - acc: 0.7668 - val_loss: 0.5363 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5284 - acc: 0.7668 - val_loss: 0.5197 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5141 - acc: 0.7876 - val_loss: 0.5038 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5006 - acc: 0.7927 - val_loss: 0.4903 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4886 - acc: 0.7876 - val_loss: 0.4777 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4788 - acc: 0.7927 - val_loss: 0.4668 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4700 - acc: 0.7927 - val_loss: 0.4575 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4623 - acc: 0.7927 - val_loss: 0.4498 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4564 - acc: 0.7927 - val_loss: 0.4417 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4499 - acc: 0.7979 - val_loss: 0.4331 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4425 - acc: 0.7927 - val_loss: 0.4247 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6967 - acc: 0.4794 - val_loss: 0.6120 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6516 - acc: 0.5928 - val_loss: 0.5755 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6164 - acc: 0.7010 - val_loss: 0.5460 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5891 - acc: 0.7320 - val_loss: 0.5199 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5643 - acc: 0.7577 - val_loss: 0.4981 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5440 - acc: 0.7629 - val_loss: 0.4792 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5272 - acc: 0.7887 - val_loss: 0.4644 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5146 - acc: 0.7990 - val_loss: 0.4541 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5041 - acc: 0.8041 - val_loss: 0.4454 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4959 - acc: 0.8041 - val_loss: 0.4378 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4867 - acc: 0.8093 - val_loss: 0.4285 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4766 - acc: 0.8144 - val_loss: 0.4187 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4677 - acc: 0.8093 - val_loss: 0.4112 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4602 - acc: 0.8144 - val_loss: 0.4040 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4535 - acc: 0.8144 - val_loss: 0.3990 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4480 - acc: 0.8196 - val_loss: 0.3921 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4409 - acc: 0.8196 - val_loss: 0.3844 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4338 - acc: 0.8196 - val_loss: 0.3763 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4263 - acc: 0.8247 - val_loss: 0.3690 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4190 - acc: 0.8299 - val_loss: 0.3635 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6289 - acc: 0.6237 - val_loss: 0.5433 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5972 - acc: 0.6753 - val_loss: 0.5177 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5732 - acc: 0.7268 - val_loss: 0.4965 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5541 - acc: 0.7577 - val_loss: 0.4758 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5368 - acc: 0.7732 - val_loss: 0.4586 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5220 - acc: 0.7990 - val_loss: 0.4478 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5100 - acc: 0.7887 - val_loss: 0.4380 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4995 - acc: 0.7835 - val_loss: 0.4277 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4897 - acc: 0.7887 - val_loss: 0.4187 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4810 - acc: 0.8144 - val_loss: 0.4099 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4725 - acc: 0.8144 - val_loss: 0.4041 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4642 - acc: 0.8144 - val_loss: 0.3985 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4563 - acc: 0.8247 - val_loss: 0.3928 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4490 - acc: 0.8299 - val_loss: 0.3874 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4419 - acc: 0.8299 - val_loss: 0.3811 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4354 - acc: 0.8299 - val_loss: 0.3746 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4289 - acc: 0.8247 - val_loss: 0.3685 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4242 - acc: 0.8247 - val_loss: 0.3659 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4200 - acc: 0.8247 - val_loss: 0.3631 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4162 - acc: 0.8247 - val_loss: 0.3590 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6717 - acc: 0.5722 - val_loss: 0.6972 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6348 - acc: 0.6392 - val_loss: 0.6671 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6081 - acc: 0.6701 - val_loss: 0.6406 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5856 - acc: 0.6856 - val_loss: 0.6138 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5640 - acc: 0.7165 - val_loss: 0.5881 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5432 - acc: 0.7423 - val_loss: 0.5645 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5255 - acc: 0.7577 - val_loss: 0.5406 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5080 - acc: 0.7732 - val_loss: 0.5192 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4915 - acc: 0.7938 - val_loss: 0.5011 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4780 - acc: 0.7887 - val_loss: 0.4861 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4660 - acc: 0.7938 - val_loss: 0.4731 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4548 - acc: 0.7990 - val_loss: 0.4616 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4444 - acc: 0.8144 - val_loss: 0.4506 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4347 - acc: 0.8144 - val_loss: 0.4399 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4268 - acc: 0.8144 - val_loss: 0.4299 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4186 - acc: 0.8247 - val_loss: 0.4202 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4109 - acc: 0.8402 - val_loss: 0.4111 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4037 - acc: 0.8402 - val_loss: 0.4025 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3979 - acc: 0.8402 - val_loss: 0.3951 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3933 - acc: 0.8402 - val_loss: 0.3886 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6399 - acc: 0.6425 - val_loss: 0.5926 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5877 - acc: 0.7409 - val_loss: 0.5488 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5512 - acc: 0.7824 - val_loss: 0.5120 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5188 - acc: 0.7927 - val_loss: 0.4838 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4947 - acc: 0.8031 - val_loss: 0.4608 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4736 - acc: 0.8083 - val_loss: 0.4413 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4544 - acc: 0.8083 - val_loss: 0.4267 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4397 - acc: 0.8135 - val_loss: 0.4172 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4286 - acc: 0.8187 - val_loss: 0.4129 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4204 - acc: 0.8238 - val_loss: 0.4087 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4127 - acc: 0.8342 - val_loss: 0.4053 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4029 - acc: 0.8446 - val_loss: 0.3969 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3944 - acc: 0.8290 - val_loss: 0.3879 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3858 - acc: 0.8238 - val_loss: 0.3834 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3792 - acc: 0.8446 - val_loss: 0.3785 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3731 - acc: 0.8446 - val_loss: 0.3732 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3668 - acc: 0.8446 - val_loss: 0.3700 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3614 - acc: 0.8497 - val_loss: 0.3653 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3561 - acc: 0.8601 - val_loss: 0.3634 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3518 - acc: 0.8549 - val_loss: 0.3647 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7067 - acc: 0.5130 - val_loss: 0.6726 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6428 - acc: 0.6736 - val_loss: 0.6152 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5972 - acc: 0.7565 - val_loss: 0.5698 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5624 - acc: 0.7772 - val_loss: 0.5313 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5307 - acc: 0.7824 - val_loss: 0.5012 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5080 - acc: 0.7876 - val_loss: 0.4777 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4907 - acc: 0.7824 - val_loss: 0.4622 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4811 - acc: 0.7772 - val_loss: 0.4477 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4702 - acc: 0.7876 - val_loss: 0.4356 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4601 - acc: 0.8031 - val_loss: 0.4249 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4505 - acc: 0.8135 - val_loss: 0.4176 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4424 - acc: 0.8135 - val_loss: 0.4108 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4354 - acc: 0.8135 - val_loss: 0.4037 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4278 - acc: 0.8238 - val_loss: 0.3968 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4203 - acc: 0.8290 - val_loss: 0.3904 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4134 - acc: 0.8394 - val_loss: 0.3842 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4068 - acc: 0.8342 - val_loss: 0.3786 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4006 - acc: 0.8394 - val_loss: 0.3730 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3942 - acc: 0.8394 - val_loss: 0.3673 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3879 - acc: 0.8497 - val_loss: 0.3621 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7095 - acc: 0.4948 - val_loss: 0.6622 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6536 - acc: 0.6546 - val_loss: 0.6157 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6168 - acc: 0.7423 - val_loss: 0.5859 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5922 - acc: 0.7732 - val_loss: 0.5591 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5689 - acc: 0.7938 - val_loss: 0.5337 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5461 - acc: 0.8041 - val_loss: 0.5115 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5281 - acc: 0.8351 - val_loss: 0.4925 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5103 - acc: 0.8351 - val_loss: 0.4741 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4927 - acc: 0.8557 - val_loss: 0.4565 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4762 - acc: 0.8505 - val_loss: 0.4395 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4603 - acc: 0.8557 - val_loss: 0.4241 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4457 - acc: 0.8711 - val_loss: 0.4098 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4319 - acc: 0.8660 - val_loss: 0.3986 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4202 - acc: 0.8557 - val_loss: 0.3893 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4100 - acc: 0.8557 - val_loss: 0.3812 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4009 - acc: 0.8454 - val_loss: 0.3754 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3930 - acc: 0.8505 - val_loss: 0.3687 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3853 - acc: 0.8557 - val_loss: 0.3633 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3784 - acc: 0.8660 - val_loss: 0.3581 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3718 - acc: 0.8711 - val_loss: 0.3539 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6577 - acc: 0.6649 - val_loss: 0.6051 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6075 - acc: 0.7216 - val_loss: 0.5611 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5720 - acc: 0.7680 - val_loss: 0.5250 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5448 - acc: 0.7784 - val_loss: 0.4957 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5203 - acc: 0.7887 - val_loss: 0.4684 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4998 - acc: 0.7938 - val_loss: 0.4453 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4816 - acc: 0.8144 - val_loss: 0.4248 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4672 - acc: 0.8196 - val_loss: 0.4079 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4552 - acc: 0.8196 - val_loss: 0.3934 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4459 - acc: 0.8196 - val_loss: 0.3820 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4404 - acc: 0.8196 - val_loss: 0.3735 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4333 - acc: 0.8247 - val_loss: 0.3657 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4267 - acc: 0.8247 - val_loss: 0.3582 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4187 - acc: 0.8351 - val_loss: 0.3521 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4099 - acc: 0.8402 - val_loss: 0.3477 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4030 - acc: 0.8402 - val_loss: 0.3427 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3970 - acc: 0.8402 - val_loss: 0.3376 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3919 - acc: 0.8454 - val_loss: 0.3330 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3868 - acc: 0.8402 - val_loss: 0.3292 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3822 - acc: 0.8454 - val_loss: 0.3258 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6976 - acc: 0.5258 - val_loss: 0.6768 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6469 - acc: 0.5464 - val_loss: 0.6313 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6150 - acc: 0.6186 - val_loss: 0.5900 - val_acc: 0.7213\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5855 - acc: 0.6701 - val_loss: 0.5576 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5615 - acc: 0.7577 - val_loss: 0.5302 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5391 - acc: 0.7784 - val_loss: 0.5050 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5190 - acc: 0.8041 - val_loss: 0.4824 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5010 - acc: 0.8041 - val_loss: 0.4623 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4841 - acc: 0.8041 - val_loss: 0.4453 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4691 - acc: 0.8144 - val_loss: 0.4316 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4558 - acc: 0.8144 - val_loss: 0.4192 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4439 - acc: 0.8144 - val_loss: 0.4071 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4335 - acc: 0.8247 - val_loss: 0.3973 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4246 - acc: 0.8144 - val_loss: 0.3910 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4171 - acc: 0.8299 - val_loss: 0.3835 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4100 - acc: 0.8299 - val_loss: 0.3776 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4030 - acc: 0.8299 - val_loss: 0.3694 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3960 - acc: 0.8402 - val_loss: 0.3600 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3910 - acc: 0.8454 - val_loss: 0.3528 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3856 - acc: 0.8454 - val_loss: 0.3464 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7178 - acc: 0.4819 - val_loss: 0.6374 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6343 - acc: 0.6373 - val_loss: 0.5692 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5772 - acc: 0.7824 - val_loss: 0.5185 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5358 - acc: 0.8031 - val_loss: 0.4771 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5026 - acc: 0.7927 - val_loss: 0.4449 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4763 - acc: 0.7979 - val_loss: 0.4172 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4543 - acc: 0.8031 - val_loss: 0.3938 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4378 - acc: 0.8031 - val_loss: 0.3746 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4244 - acc: 0.8187 - val_loss: 0.3596 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4149 - acc: 0.8394 - val_loss: 0.3484 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4037 - acc: 0.8394 - val_loss: 0.3412 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3911 - acc: 0.8290 - val_loss: 0.3387 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3788 - acc: 0.8394 - val_loss: 0.3441 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3721 - acc: 0.8342 - val_loss: 0.3566 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3690 - acc: 0.8187 - val_loss: 0.3674 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3675 - acc: 0.8290 - val_loss: 0.3700 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3643 - acc: 0.8342 - val_loss: 0.3670 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7089 - acc: 0.4715 - val_loss: 0.6536 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6241 - acc: 0.6736 - val_loss: 0.5790 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5689 - acc: 0.7513 - val_loss: 0.5248 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5255 - acc: 0.7772 - val_loss: 0.4813 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4938 - acc: 0.7824 - val_loss: 0.4474 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4690 - acc: 0.7927 - val_loss: 0.4197 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4488 - acc: 0.7927 - val_loss: 0.4002 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4315 - acc: 0.8031 - val_loss: 0.3889 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4173 - acc: 0.8238 - val_loss: 0.3793 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4074 - acc: 0.8342 - val_loss: 0.3699 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3977 - acc: 0.8342 - val_loss: 0.3615 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3898 - acc: 0.8290 - val_loss: 0.3550 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3835 - acc: 0.8290 - val_loss: 0.3505 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3775 - acc: 0.8394 - val_loss: 0.3503 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3725 - acc: 0.8342 - val_loss: 0.3490 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3676 - acc: 0.8290 - val_loss: 0.3451 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3622 - acc: 0.8342 - val_loss: 0.3378 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3570 - acc: 0.8394 - val_loss: 0.3329 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3538 - acc: 0.8394 - val_loss: 0.3327 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3506 - acc: 0.8446 - val_loss: 0.3317 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6835 - acc: 0.5464 - val_loss: 0.5920 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5978 - acc: 0.7474 - val_loss: 0.5232 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5394 - acc: 0.7680 - val_loss: 0.4693 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4956 - acc: 0.7680 - val_loss: 0.4309 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4633 - acc: 0.7938 - val_loss: 0.4024 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4385 - acc: 0.8093 - val_loss: 0.3795 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4166 - acc: 0.8247 - val_loss: 0.3621 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3995 - acc: 0.8299 - val_loss: 0.3496 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3881 - acc: 0.8454 - val_loss: 0.3391 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3787 - acc: 0.8505 - val_loss: 0.3307 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3710 - acc: 0.8505 - val_loss: 0.3243 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3619 - acc: 0.8505 - val_loss: 0.3216 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3523 - acc: 0.8608 - val_loss: 0.3236 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3443 - acc: 0.8711 - val_loss: 0.3282 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3379 - acc: 0.8866 - val_loss: 0.3353 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3333 - acc: 0.8763 - val_loss: 0.3367 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3283 - acc: 0.8866 - val_loss: 0.3368 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6509 - acc: 0.6598 - val_loss: 0.5881 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5822 - acc: 0.7680 - val_loss: 0.5250 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5346 - acc: 0.8041 - val_loss: 0.4770 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4970 - acc: 0.8247 - val_loss: 0.4424 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4694 - acc: 0.8402 - val_loss: 0.4168 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4461 - acc: 0.8454 - val_loss: 0.3931 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4273 - acc: 0.8454 - val_loss: 0.3724 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4095 - acc: 0.8454 - val_loss: 0.3562 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3971 - acc: 0.8454 - val_loss: 0.3422 - val_acc: 0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3892 - acc: 0.8505 - val_loss: 0.3292 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3838 - acc: 0.8505 - val_loss: 0.3204 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3814 - acc: 0.8505 - val_loss: 0.3140 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3769 - acc: 0.8505 - val_loss: 0.3099 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3740 - acc: 0.8505 - val_loss: 0.3079 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3672 - acc: 0.8557 - val_loss: 0.3094 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3601 - acc: 0.8505 - val_loss: 0.3125 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3523 - acc: 0.8608 - val_loss: 0.3198 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3485 - acc: 0.8557 - val_loss: 0.3282 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3453 - acc: 0.8557 - val_loss: 0.3348 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6549 - acc: 0.6546 - val_loss: 0.5953 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5866 - acc: 0.7474 - val_loss: 0.5296 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5366 - acc: 0.7887 - val_loss: 0.4840 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5038 - acc: 0.7990 - val_loss: 0.4512 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4786 - acc: 0.8144 - val_loss: 0.4240 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4558 - acc: 0.8144 - val_loss: 0.4020 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4393 - acc: 0.8144 - val_loss: 0.3842 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4268 - acc: 0.8144 - val_loss: 0.3691 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4146 - acc: 0.8144 - val_loss: 0.3560 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4051 - acc: 0.8144 - val_loss: 0.3464 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3965 - acc: 0.8144 - val_loss: 0.3394 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3874 - acc: 0.8144 - val_loss: 0.3342 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3813 - acc: 0.8144 - val_loss: 0.3298 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3746 - acc: 0.8299 - val_loss: 0.3281 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3683 - acc: 0.8299 - val_loss: 0.3264 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3622 - acc: 0.8454 - val_loss: 0.3272 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3554 - acc: 0.8505 - val_loss: 0.3336 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3531 - acc: 0.8557 - val_loss: 0.3387 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3510 - acc: 0.8608 - val_loss: 0.3372 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3493 - acc: 0.8505 - val_loss: 0.3330 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6634 - acc: 0.6166 - val_loss: 0.5844 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5691 - acc: 0.8446 - val_loss: 0.5102 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5095 - acc: 0.8549 - val_loss: 0.4672 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4681 - acc: 0.8497 - val_loss: 0.4287 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4347 - acc: 0.8394 - val_loss: 0.3949 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4111 - acc: 0.8342 - val_loss: 0.3678 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3938 - acc: 0.8342 - val_loss: 0.3486 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3827 - acc: 0.8290 - val_loss: 0.3365 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3778 - acc: 0.8238 - val_loss: 0.3292 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3758 - acc: 0.8238 - val_loss: 0.3254 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3670 - acc: 0.8394 - val_loss: 0.3239 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3548 - acc: 0.8394 - val_loss: 0.3270 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3425 - acc: 0.8549 - val_loss: 0.3338 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3365 - acc: 0.8497 - val_loss: 0.3380 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3317 - acc: 0.8497 - val_loss: 0.3351 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3276 - acc: 0.8497 - val_loss: 0.3309 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7016 - acc: 0.5026 - val_loss: 0.6033 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5951 - acc: 0.7513 - val_loss: 0.5207 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5278 - acc: 0.7927 - val_loss: 0.4661 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4882 - acc: 0.8031 - val_loss: 0.4327 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4638 - acc: 0.8031 - val_loss: 0.4099 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4402 - acc: 0.8031 - val_loss: 0.3919 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4197 - acc: 0.8135 - val_loss: 0.3781 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4042 - acc: 0.8135 - val_loss: 0.3659 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3912 - acc: 0.8187 - val_loss: 0.3537 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3823 - acc: 0.8187 - val_loss: 0.3444 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3766 - acc: 0.8187 - val_loss: 0.3367 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3728 - acc: 0.8187 - val_loss: 0.3303 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3651 - acc: 0.8342 - val_loss: 0.3267 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3563 - acc: 0.8394 - val_loss: 0.3246 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3477 - acc: 0.8394 - val_loss: 0.3234 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3412 - acc: 0.8394 - val_loss: 0.3220 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3356 - acc: 0.8446 - val_loss: 0.3231 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3283 - acc: 0.8601 - val_loss: 0.3339 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3276 - acc: 0.8549 - val_loss: 0.3489 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3284 - acc: 0.8653 - val_loss: 0.3581 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6947 - acc: 0.5309 - val_loss: 0.5853 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5850 - acc: 0.8299 - val_loss: 0.5063 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5155 - acc: 0.8299 - val_loss: 0.4544 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4758 - acc: 0.8299 - val_loss: 0.4162 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4487 - acc: 0.8144 - val_loss: 0.3859 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4227 - acc: 0.8247 - val_loss: 0.3625 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3986 - acc: 0.8454 - val_loss: 0.3472 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3841 - acc: 0.8505 - val_loss: 0.3369 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3724 - acc: 0.8557 - val_loss: 0.3304 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3611 - acc: 0.8557 - val_loss: 0.3307 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3499 - acc: 0.8660 - val_loss: 0.3340 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3421 - acc: 0.8660 - val_loss: 0.3351 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3363 - acc: 0.8711 - val_loss: 0.3340 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3306 - acc: 0.8866 - val_loss: 0.3289 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2507 - acc: 0.937 - 0s 6ms/step - loss: 0.3254 - acc: 0.8866 - val_loss: 0.3226 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3206 - acc: 0.8814 - val_loss: 0.3175 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3170 - acc: 0.8814 - val_loss: 0.3168 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3123 - acc: 0.8866 - val_loss: 0.3201 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3084 - acc: 0.8969 - val_loss: 0.3253 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3068 - acc: 0.8763 - val_loss: 0.3315 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6629 - acc: 0.6856 - val_loss: 0.5549 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5657 - acc: 0.7938 - val_loss: 0.4821 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5140 - acc: 0.8144 - val_loss: 0.4315 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4760 - acc: 0.8093 - val_loss: 0.3909 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4450 - acc: 0.8196 - val_loss: 0.3608 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4234 - acc: 0.8196 - val_loss: 0.3431 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4036 - acc: 0.8351 - val_loss: 0.3425 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3987 - acc: 0.8351 - val_loss: 0.3412 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3908 - acc: 0.8299 - val_loss: 0.3339 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3838 - acc: 0.8299 - val_loss: 0.3281 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3752 - acc: 0.8351 - val_loss: 0.3213 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3674 - acc: 0.8454 - val_loss: 0.3208 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3611 - acc: 0.8505 - val_loss: 0.3186 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3549 - acc: 0.8557 - val_loss: 0.3201 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3486 - acc: 0.8608 - val_loss: 0.3250 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3446 - acc: 0.8814 - val_loss: 0.3276 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3414 - acc: 0.8814 - val_loss: 0.3230 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3362 - acc: 0.8814 - val_loss: 0.3211 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6905 - acc: 0.5464 - val_loss: 0.5869 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5754 - acc: 0.8041 - val_loss: 0.5135 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5171 - acc: 0.7938 - val_loss: 0.4576 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4770 - acc: 0.8093 - val_loss: 0.4132 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4447 - acc: 0.8144 - val_loss: 0.3823 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4190 - acc: 0.8196 - val_loss: 0.3624 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3966 - acc: 0.8247 - val_loss: 0.3509 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3797 - acc: 0.8299 - val_loss: 0.3461 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3691 - acc: 0.8505 - val_loss: 0.3458 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3605 - acc: 0.8557 - val_loss: 0.3479 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3563 - acc: 0.8557 - val_loss: 0.3485 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3540 - acc: 0.8454 - val_loss: 0.3556 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3496 - acc: 0.8505 - val_loss: 0.3548 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3457 - acc: 0.8505 - val_loss: 0.3497 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7508 - acc: 0.3938 - val_loss: 0.7015 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6832 - acc: 0.5285 - val_loss: 0.6482 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6346 - acc: 0.6788 - val_loss: 0.6001 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5906 - acc: 0.7202 - val_loss: 0.5565 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5509 - acc: 0.7824 - val_loss: 0.5166 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5130 - acc: 0.8135 - val_loss: 0.4716 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4747 - acc: 0.8238 - val_loss: 0.4293 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4402 - acc: 0.8238 - val_loss: 0.3973 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4103 - acc: 0.8446 - val_loss: 0.3770 - val_acc: 0.8361\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3856 - acc: 0.8549 - val_loss: 0.3627 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3690 - acc: 0.8497 - val_loss: 0.3453 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3593 - acc: 0.8601 - val_loss: 0.3343 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3517 - acc: 0.8653 - val_loss: 0.3286 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3446 - acc: 0.8653 - val_loss: 0.3264 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3356 - acc: 0.8705 - val_loss: 0.3295 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3264 - acc: 0.8756 - val_loss: 0.3360 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3147 - acc: 0.8756 - val_loss: 0.3372 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3100 - acc: 0.8705 - val_loss: 0.3399 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3051 - acc: 0.8705 - val_loss: 0.3444 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.6077 - acc: 0.6580 - val_loss: 0.4804 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5202 - acc: 0.7720 - val_loss: 0.4083 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4613 - acc: 0.7824 - val_loss: 0.3586 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4287 - acc: 0.7979 - val_loss: 0.3338 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4073 - acc: 0.8031 - val_loss: 0.3172 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3991 - acc: 0.8135 - val_loss: 0.3114 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3943 - acc: 0.8083 - val_loss: 0.3119 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3891 - acc: 0.8135 - val_loss: 0.3132 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3811 - acc: 0.8394 - val_loss: 0.3153 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3708 - acc: 0.8446 - val_loss: 0.3244 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3647 - acc: 0.8394 - val_loss: 0.3439 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7288 - acc: 0.3814 - val_loss: 0.6893 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6673 - acc: 0.6753 - val_loss: 0.6433 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6284 - acc: 0.7577 - val_loss: 0.6007 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5914 - acc: 0.7680 - val_loss: 0.5556 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5516 - acc: 0.7680 - val_loss: 0.5115 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5142 - acc: 0.7938 - val_loss: 0.4778 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4813 - acc: 0.8041 - val_loss: 0.4406 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4452 - acc: 0.8247 - val_loss: 0.4031 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4125 - acc: 0.8454 - val_loss: 0.3667 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3854 - acc: 0.8557 - val_loss: 0.3413 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3685 - acc: 0.8557 - val_loss: 0.3286 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3535 - acc: 0.8557 - val_loss: 0.3333 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3439 - acc: 0.8402 - val_loss: 0.3540 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3417 - acc: 0.8454 - val_loss: 0.3854 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3460 - acc: 0.8454 - val_loss: 0.4082 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3501 - acc: 0.8402 - val_loss: 0.4062 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7779 - acc: 0.5258 - val_loss: 0.7575 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6727 - acc: 0.5928 - val_loss: 0.6489 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6078 - acc: 0.6701 - val_loss: 0.5682 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5594 - acc: 0.7113 - val_loss: 0.5159 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5253 - acc: 0.7423 - val_loss: 0.4681 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4917 - acc: 0.7629 - val_loss: 0.4257 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4659 - acc: 0.7680 - val_loss: 0.3906 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4424 - acc: 0.7784 - val_loss: 0.3652 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4235 - acc: 0.7784 - val_loss: 0.3546 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4086 - acc: 0.7784 - val_loss: 0.3567 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3983 - acc: 0.7938 - val_loss: 0.3706 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3920 - acc: 0.7990 - val_loss: 0.3809 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3838 - acc: 0.8144 - val_loss: 0.3802 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3730 - acc: 0.8196 - val_loss: 0.3698 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8937 - acc: 0.4536 - val_loss: 0.7184 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7411 - acc: 0.5567 - val_loss: 0.6302 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6523 - acc: 0.6289 - val_loss: 0.5711 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5968 - acc: 0.7113 - val_loss: 0.5275 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5557 - acc: 0.7577 - val_loss: 0.4897 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5219 - acc: 0.7938 - val_loss: 0.4564 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4954 - acc: 0.7990 - val_loss: 0.4271 - val_acc: 0.8197\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4716 - acc: 0.7990 - val_loss: 0.4070 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4546 - acc: 0.8041 - val_loss: 0.3957 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4420 - acc: 0.8144 - val_loss: 0.3897 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4324 - acc: 0.8144 - val_loss: 0.3838 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4216 - acc: 0.8247 - val_loss: 0.3797 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4133 - acc: 0.8299 - val_loss: 0.3746 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4069 - acc: 0.8351 - val_loss: 0.3686 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4014 - acc: 0.8299 - val_loss: 0.3630 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3948 - acc: 0.8351 - val_loss: 0.3599 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3876 - acc: 0.8402 - val_loss: 0.3594 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3782 - acc: 0.8402 - val_loss: 0.3650 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3702 - acc: 0.8402 - val_loss: 0.3772 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3645 - acc: 0.8299 - val_loss: 0.3893 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7994 - acc: 0.4560 - val_loss: 0.6243 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5831 - acc: 0.7306 - val_loss: 0.4667 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4753 - acc: 0.8135 - val_loss: 0.3902 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4155 - acc: 0.8342 - val_loss: 0.3443 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3834 - acc: 0.8187 - val_loss: 0.3271 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3613 - acc: 0.8238 - val_loss: 0.3289 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3481 - acc: 0.8187 - val_loss: 0.3348 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3357 - acc: 0.8187 - val_loss: 0.3256 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3260 - acc: 0.8342 - val_loss: 0.3165 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3208 - acc: 0.8342 - val_loss: 0.3110 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3143 - acc: 0.8446 - val_loss: 0.3163 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3089 - acc: 0.8290 - val_loss: 0.3450 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3136 - acc: 0.8394 - val_loss: 0.3575 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3164 - acc: 0.8549 - val_loss: 0.3570 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3140 - acc: 0.8446 - val_loss: 0.3427 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7733 - acc: 0.4767 - val_loss: 0.6059 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5973 - acc: 0.7254 - val_loss: 0.4917 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5127 - acc: 0.8083 - val_loss: 0.4118 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4502 - acc: 0.8342 - val_loss: 0.3585 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4054 - acc: 0.8342 - val_loss: 0.3185 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3801 - acc: 0.8342 - val_loss: 0.2967 - val_acc: 0.9180\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3740 - acc: 0.8394 - val_loss: 0.2888 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3739 - acc: 0.8342 - val_loss: 0.2876 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3705 - acc: 0.8342 - val_loss: 0.2919 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3564 - acc: 0.8601 - val_loss: 0.3051 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3408 - acc: 0.8756 - val_loss: 0.3177 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3339 - acc: 0.8705 - val_loss: 0.3198 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3258 - acc: 0.8653 - val_loss: 0.3123 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.8315 - acc: 0.4278 - val_loss: 0.6982 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6407 - acc: 0.5876 - val_loss: 0.5751 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5389 - acc: 0.8196 - val_loss: 0.4852 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4672 - acc: 0.8402 - val_loss: 0.4261 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4205 - acc: 0.8402 - val_loss: 0.4023 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4009 - acc: 0.8505 - val_loss: 0.4040 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3914 - acc: 0.8402 - val_loss: 0.4015 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3804 - acc: 0.8608 - val_loss: 0.3982 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3655 - acc: 0.8608 - val_loss: 0.3885 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3485 - acc: 0.8711 - val_loss: 0.3716 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3312 - acc: 0.8866 - val_loss: 0.3531 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3172 - acc: 0.8814 - val_loss: 0.3385 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3080 - acc: 0.8608 - val_loss: 0.3249 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3000 - acc: 0.8711 - val_loss: 0.3190 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2942 - acc: 0.8763 - val_loss: 0.3179 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2906 - acc: 0.8660 - val_loss: 0.3241 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2848 - acc: 0.8711 - val_loss: 0.3414 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2805 - acc: 0.8660 - val_loss: 0.3499 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2779 - acc: 0.8660 - val_loss: 0.3526 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2758 - acc: 0.8660 - val_loss: 0.3523 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6212 - acc: 0.6701 - val_loss: 0.5004 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5219 - acc: 0.7371 - val_loss: 0.4252 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4773 - acc: 0.7732 - val_loss: 0.3745 - val_acc: 0.9180\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4406 - acc: 0.7577 - val_loss: 0.3625 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4245 - acc: 0.7887 - val_loss: 0.3771 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4220 - acc: 0.7835 - val_loss: 0.3893 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4137 - acc: 0.7938 - val_loss: 0.3788 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3982 - acc: 0.7990 - val_loss: 0.3574 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3825 - acc: 0.8144 - val_loss: 0.3457 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3702 - acc: 0.7990 - val_loss: 0.3295 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3598 - acc: 0.8196 - val_loss: 0.3115 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3520 - acc: 0.8454 - val_loss: 0.2974 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3450 - acc: 0.8505 - val_loss: 0.2858 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3385 - acc: 0.8557 - val_loss: 0.2757 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3343 - acc: 0.8660 - val_loss: 0.2724 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3283 - acc: 0.8608 - val_loss: 0.2797 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3182 - acc: 0.8660 - val_loss: 0.3082 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3114 - acc: 0.8763 - val_loss: 0.3455 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3064 - acc: 0.8763 - val_loss: 0.3583 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3002 - acc: 0.8763 - val_loss: 0.3529 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6934 - acc: 0.5206 - val_loss: 0.5557 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5813 - acc: 0.7268 - val_loss: 0.4700 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5159 - acc: 0.7629 - val_loss: 0.4208 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4761 - acc: 0.7732 - val_loss: 0.3995 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4480 - acc: 0.7887 - val_loss: 0.3752 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4290 - acc: 0.7938 - val_loss: 0.3588 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4128 - acc: 0.8041 - val_loss: 0.3418 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3960 - acc: 0.8093 - val_loss: 0.3292 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3839 - acc: 0.8351 - val_loss: 0.3215 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3732 - acc: 0.8402 - val_loss: 0.3151 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3676 - acc: 0.8402 - val_loss: 0.3120 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3636 - acc: 0.8454 - val_loss: 0.3149 - val_acc: 0.9180\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3536 - acc: 0.8557 - val_loss: 0.3332 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3502 - acc: 0.8660 - val_loss: 0.3657 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3513 - acc: 0.8299 - val_loss: 0.3641 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3470 - acc: 0.8454 - val_loss: 0.3545 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5862 - acc: 0.7047 - val_loss: 0.4216 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4580 - acc: 0.8083 - val_loss: 0.3374 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3990 - acc: 0.8031 - val_loss: 0.3197 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3613 - acc: 0.8394 - val_loss: 0.3416 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3389 - acc: 0.8497 - val_loss: 0.3420 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3190 - acc: 0.8446 - val_loss: 0.3219 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3199 - acc: 0.8601 - val_loss: 0.3280 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3163 - acc: 0.8705 - val_loss: 0.3528 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6295 - acc: 0.6580 - val_loss: 0.4539 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4593 - acc: 0.7720 - val_loss: 0.3866 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4040 - acc: 0.7979 - val_loss: 0.3620 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3723 - acc: 0.8394 - val_loss: 0.3408 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3594 - acc: 0.8549 - val_loss: 0.3339 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3659 - acc: 0.8394 - val_loss: 0.3374 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3624 - acc: 0.8394 - val_loss: 0.3499 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3428 - acc: 0.8497 - val_loss: 0.4005 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3436 - acc: 0.8497 - val_loss: 0.4431 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3515 - acc: 0.8497 - val_loss: 0.4388 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.7178 - acc: 0.5773 - val_loss: 0.4894 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5004 - acc: 0.7887 - val_loss: 0.3752 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4364 - acc: 0.8093 - val_loss: 0.3189 - val_acc: 0.9180\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3905 - acc: 0.8299 - val_loss: 0.2937 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3644 - acc: 0.8351 - val_loss: 0.2883 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3383 - acc: 0.8608 - val_loss: 0.3075 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3257 - acc: 0.8711 - val_loss: 0.3466 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3350 - acc: 0.8763 - val_loss: 0.3709 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3370 - acc: 0.8711 - val_loss: 0.3502 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3214 - acc: 0.8763 - val_loss: 0.3178 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6434 - acc: 0.6443 - val_loss: 0.4663 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4648 - acc: 0.7990 - val_loss: 0.3655 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4032 - acc: 0.7990 - val_loss: 0.3384 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3831 - acc: 0.8402 - val_loss: 0.3185 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3814 - acc: 0.8247 - val_loss: 0.3158 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3641 - acc: 0.8402 - val_loss: 0.3645 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3588 - acc: 0.8299 - val_loss: 0.4191 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3738 - acc: 0.8299 - val_loss: 0.4186 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3593 - acc: 0.8402 - val_loss: 0.3764 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3357 - acc: 0.8608 - val_loss: 0.3450 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6834 - acc: 0.5515 - val_loss: 0.4982 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4904 - acc: 0.8041 - val_loss: 0.4129 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4414 - acc: 0.7887 - val_loss: 0.3731 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4068 - acc: 0.8247 - val_loss: 0.3687 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3838 - acc: 0.8608 - val_loss: 0.3806 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3747 - acc: 0.8454 - val_loss: 0.3822 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3591 - acc: 0.8402 - val_loss: 0.3737 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3457 - acc: 0.8608 - val_loss: 0.3628 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3347 - acc: 0.8660 - val_loss: 0.3746 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3279 - acc: 0.8608 - val_loss: 0.3691 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3167 - acc: 0.8711 - val_loss: 0.3420 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3161 - acc: 0.8763 - val_loss: 0.3443 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3104 - acc: 0.8866 - val_loss: 0.3683 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3032 - acc: 0.8866 - val_loss: 0.4045 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2981 - acc: 0.8918 - val_loss: 0.4292 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3001 - acc: 0.8866 - val_loss: 0.4744 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6528 - acc: 0.6062 - val_loss: 0.4762 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4661 - acc: 0.7927 - val_loss: 0.4038 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3967 - acc: 0.8135 - val_loss: 0.3744 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3704 - acc: 0.8238 - val_loss: 0.3683 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3514 - acc: 0.8290 - val_loss: 0.3626 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3388 - acc: 0.8342 - val_loss: 0.3597 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3222 - acc: 0.8497 - val_loss: 0.3734 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3089 - acc: 0.8601 - val_loss: 0.4056 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3040 - acc: 0.8756 - val_loss: 0.4093 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2900 - acc: 0.8705 - val_loss: 0.3682 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2798 - acc: 0.8705 - val_loss: 0.3257 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3006 - acc: 0.8705 - val_loss: 0.3271 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3030 - acc: 0.8653 - val_loss: 0.3392 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2798 - acc: 0.8756 - val_loss: 0.3654 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2581 - acc: 0.8912 - val_loss: 0.3806 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2535 - acc: 0.9067 - val_loss: 0.3851 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5543 - acc: 0.6995 - val_loss: 0.4084 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4107 - acc: 0.8135 - val_loss: 0.4062 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3792 - acc: 0.8290 - val_loss: 0.3890 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3672 - acc: 0.8446 - val_loss: 0.3934 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3580 - acc: 0.8446 - val_loss: 0.3706 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3500 - acc: 0.8394 - val_loss: 0.3580 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3363 - acc: 0.8342 - val_loss: 0.3567 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3172 - acc: 0.8497 - val_loss: 0.3645 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3046 - acc: 0.8549 - val_loss: 0.3506 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2943 - acc: 0.8601 - val_loss: 0.3310 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2923 - acc: 0.8446 - val_loss: 0.3545 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3036 - acc: 0.8238 - val_loss: 0.3491 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3003 - acc: 0.8342 - val_loss: 0.3264 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2900 - acc: 0.8549 - val_loss: 0.3312 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2735 - acc: 0.8756 - val_loss: 0.3533 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2709 - acc: 0.8756 - val_loss: 0.3611 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2669 - acc: 0.8912 - val_loss: 0.3539 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2564 - acc: 0.9016 - val_loss: 0.3399 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7577 - acc: 0.4691 - val_loss: 0.4992 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4939 - acc: 0.7990 - val_loss: 0.3814 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3960 - acc: 0.8351 - val_loss: 0.3685 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3543 - acc: 0.8505 - val_loss: 0.4101 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3539 - acc: 0.8454 - val_loss: 0.4276 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3410 - acc: 0.8608 - val_loss: 0.3814 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3131 - acc: 0.8557 - val_loss: 0.3398 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3168 - acc: 0.8608 - val_loss: 0.3304 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3140 - acc: 0.8660 - val_loss: 0.3456 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2989 - acc: 0.8608 - val_loss: 0.3763 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2877 - acc: 0.8814 - val_loss: 0.3869 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2771 - acc: 0.8814 - val_loss: 0.3619 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2669 - acc: 0.8866 - val_loss: 0.3406 - val_acc: 0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6216 - acc: 0.6443 - val_loss: 0.4012 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4603 - acc: 0.8196 - val_loss: 0.3776 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4097 - acc: 0.8299 - val_loss: 0.3363 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3797 - acc: 0.8557 - val_loss: 0.3073 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3646 - acc: 0.8608 - val_loss: 0.3062 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3515 - acc: 0.8660 - val_loss: 0.3025 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3464 - acc: 0.8557 - val_loss: 0.3060 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3416 - acc: 0.8505 - val_loss: 0.3120 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3388 - acc: 0.8505 - val_loss: 0.3182 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3343 - acc: 0.8557 - val_loss: 0.3343 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3200 - acc: 0.8763 - val_loss: 0.3973 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5624 - acc: 0.7474 - val_loss: 0.3932 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4094 - acc: 0.8402 - val_loss: 0.3573 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3768 - acc: 0.8196 - val_loss: 0.4228 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3802 - acc: 0.8196 - val_loss: 0.3866 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3535 - acc: 0.8454 - val_loss: 0.3314 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3646 - acc: 0.8299 - val_loss: 0.3203 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3753 - acc: 0.8196 - val_loss: 0.3226 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3591 - acc: 0.8144 - val_loss: 0.3311 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3326 - acc: 0.8454 - val_loss: 0.3559 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3080 - acc: 0.8711 - val_loss: 0.4020 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3012 - acc: 0.8814 - val_loss: 0.4543 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6177 - acc: 0.6580 - val_loss: 0.3812 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4088 - acc: 0.8135 - val_loss: 0.3301 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3588 - acc: 0.8446 - val_loss: 0.3470 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3380 - acc: 0.8497 - val_loss: 0.3306 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3380 - acc: 0.8497 - val_loss: 0.3390 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3252 - acc: 0.8601 - val_loss: 0.3566 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3032 - acc: 0.8705 - val_loss: 0.3869 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6394 - acc: 0.5907 - val_loss: 0.3625 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4075 - acc: 0.8135 - val_loss: 0.3361 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3730 - acc: 0.8290 - val_loss: 0.3662 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3571 - acc: 0.8549 - val_loss: 0.3375 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3386 - acc: 0.8394 - val_loss: 0.3201 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3360 - acc: 0.8342 - val_loss: 0.3268 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3377 - acc: 0.8394 - val_loss: 0.3472 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2912 - acc: 0.8860 - val_loss: 0.4500 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3356 - acc: 0.8549 - val_loss: 0.4681 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3149 - acc: 0.8497 - val_loss: 0.3883 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6064 - acc: 0.6701 - val_loss: 0.3477 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3771 - acc: 0.8454 - val_loss: 0.3260 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3361 - acc: 0.8505 - val_loss: 0.3181 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3220 - acc: 0.8557 - val_loss: 0.3425 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3084 - acc: 0.8711 - val_loss: 0.3818 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3028 - acc: 0.8763 - val_loss: 0.4071 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2930 - acc: 0.8918 - val_loss: 0.3602 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2796 - acc: 0.8969 - val_loss: 0.3358 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6494 - acc: 0.5979 - val_loss: 0.3487 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4264 - acc: 0.7990 - val_loss: 0.3051 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4147 - acc: 0.8041 - val_loss: 0.3033 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4198 - acc: 0.8093 - val_loss: 0.2995 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3794 - acc: 0.8299 - val_loss: 0.3254 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3521 - acc: 0.8505 - val_loss: 0.3574 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3312 - acc: 0.8711 - val_loss: 0.3307 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3178 - acc: 0.8557 - val_loss: 0.3124 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3077 - acc: 0.8608 - val_loss: 0.3312 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5983 - acc: 0.7113 - val_loss: 0.3481 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4046 - acc: 0.8247 - val_loss: 0.3235 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3846 - acc: 0.8454 - val_loss: 0.3434 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3645 - acc: 0.8608 - val_loss: 0.3698 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3473 - acc: 0.8557 - val_loss: 0.3558 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3165 - acc: 0.8660 - val_loss: 0.3246 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3109 - acc: 0.8711 - val_loss: 0.3427 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6016 - acc: 0.6995 - val_loss: 0.3227 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4066 - acc: 0.8135 - val_loss: 0.3705 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3537 - acc: 0.8290 - val_loss: 0.4358 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3202 - acc: 0.8601 - val_loss: 0.4039 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2910 - acc: 0.8705 - val_loss: 0.4550 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3047 - acc: 0.8653 - val_loss: 0.4135 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5740 - acc: 0.6425 - val_loss: 0.3271 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3797 - acc: 0.8187 - val_loss: 0.3779 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3738 - acc: 0.8394 - val_loss: 0.3936 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3419 - acc: 0.8497 - val_loss: 0.4218 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3233 - acc: 0.8601 - val_loss: 0.3605 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3043 - acc: 0.8497 - val_loss: 0.3234 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3242 - acc: 0.8497 - val_loss: 0.3448 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3015 - acc: 0.8497 - val_loss: 0.3888 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2790 - acc: 0.8756 - val_loss: 0.4249 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2621 - acc: 0.8860 - val_loss: 0.4007 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2382 - acc: 0.9016 - val_loss: 0.3770 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5817 - acc: 0.6134 - val_loss: 0.3330 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3535 - acc: 0.8608 - val_loss: 0.3838 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3696 - acc: 0.8402 - val_loss: 0.3772 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3473 - acc: 0.8557 - val_loss: 0.3126 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3118 - acc: 0.8763 - val_loss: 0.2859 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3029 - acc: 0.8660 - val_loss: 0.3179 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2827 - acc: 0.8711 - val_loss: 0.3876 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2795 - acc: 0.9072 - val_loss: 0.4124 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2626 - acc: 0.8918 - val_loss: 0.3879 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2422 - acc: 0.9021 - val_loss: 0.3770 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.5687 - acc: 0.6804 - val_loss: 0.3323 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3989 - acc: 0.8093 - val_loss: 0.3425 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3687 - acc: 0.8351 - val_loss: 0.3289 - val_acc: 0.9180\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3755 - acc: 0.8505 - val_loss: 0.3301 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3409 - acc: 0.8608 - val_loss: 0.3562 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3092 - acc: 0.8660 - val_loss: 0.3593 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2970 - acc: 0.8608 - val_loss: 0.3188 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3020 - acc: 0.8557 - val_loss: 0.3562 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3075 - acc: 0.8763 - val_loss: 0.3546 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2849 - acc: 0.8711 - val_loss: 0.3232 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2684 - acc: 0.8763 - val_loss: 0.3318 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2476 - acc: 0.8814 - val_loss: 0.3684 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5555 - acc: 0.7062 - val_loss: 0.3575 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3764 - acc: 0.8299 - val_loss: 0.4041 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3763 - acc: 0.8505 - val_loss: 0.4175 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3905 - acc: 0.8402 - val_loss: 0.3774 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3738 - acc: 0.8351 - val_loss: 0.3270 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3825 - acc: 0.8402 - val_loss: 0.3106 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3632 - acc: 0.8247 - val_loss: 0.3282 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3144 - acc: 0.8660 - val_loss: 0.3719 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2927 - acc: 0.8814 - val_loss: 0.3658 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2790 - acc: 0.8918 - val_loss: 0.3421 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2881 - acc: 0.8763 - val_loss: 0.3476 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5312 - acc: 0.7098 - val_loss: 0.3285 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3815 - acc: 0.8446 - val_loss: 0.4365 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3737 - acc: 0.8549 - val_loss: 0.4201 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3489 - acc: 0.8653 - val_loss: 0.4533 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3378 - acc: 0.8653 - val_loss: 0.4788 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3047 - acc: 0.8705 - val_loss: 0.3546 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5631 - acc: 0.6477 - val_loss: 0.3287 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3905 - acc: 0.8342 - val_loss: 0.3852 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3631 - acc: 0.8497 - val_loss: 0.3948 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3421 - acc: 0.8808 - val_loss: 0.3851 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2947 - acc: 0.8860 - val_loss: 0.3617 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2715 - acc: 0.8860 - val_loss: 0.3800 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5563 - acc: 0.6856 - val_loss: 0.3252 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3550 - acc: 0.8247 - val_loss: 0.3587 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3192 - acc: 0.8763 - val_loss: 0.3956 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3062 - acc: 0.8660 - val_loss: 0.3819 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2749 - acc: 0.8608 - val_loss: 0.3549 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2884 - acc: 0.8763 - val_loss: 0.3427 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5701 - acc: 0.6907 - val_loss: 0.3989 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4148 - acc: 0.8144 - val_loss: 0.3734 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3798 - acc: 0.8454 - val_loss: 0.3599 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3220 - acc: 0.8608 - val_loss: 0.4346 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3305 - acc: 0.8505 - val_loss: 0.5361 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3876 - acc: 0.8247 - val_loss: 0.4023 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3353 - acc: 0.8454 - val_loss: 0.3133 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3443 - acc: 0.8299 - val_loss: 0.3081 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3008 - acc: 0.8608 - val_loss: 0.3308 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2719 - acc: 0.8557 - val_loss: 0.3418 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2618 - acc: 0.8660 - val_loss: 0.3681 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2493 - acc: 0.8918 - val_loss: 0.3666 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2595 - acc: 0.8866 - val_loss: 0.4309 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5455 - acc: 0.6907 - val_loss: 0.3355 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4123 - acc: 0.8299 - val_loss: 0.4568 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4273 - acc: 0.8196 - val_loss: 0.4673 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3701 - acc: 0.8557 - val_loss: 0.3464 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3165 - acc: 0.8763 - val_loss: 0.3897 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3107 - acc: 0.8711 - val_loss: 0.4158 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6336 - acc: 0.6321 - val_loss: 0.4204 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3978 - acc: 0.8290 - val_loss: 0.3538 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4467 - acc: 0.7824 - val_loss: 0.3486 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4154 - acc: 0.7876 - val_loss: 0.3359 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3647 - acc: 0.8342 - val_loss: 0.3680 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3479 - acc: 0.8394 - val_loss: 0.3383 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3277 - acc: 0.8290 - val_loss: 0.3342 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3679 - acc: 0.8290 - val_loss: 0.3605 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3221 - acc: 0.8549 - val_loss: 0.3859 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3137 - acc: 0.8497 - val_loss: 0.3543 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3230 - acc: 0.8497 - val_loss: 0.3232 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3426 - acc: 0.8446 - val_loss: 0.3317 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3330 - acc: 0.8549 - val_loss: 0.3415 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3185 - acc: 0.8601 - val_loss: 0.3488 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2985 - acc: 0.8756 - val_loss: 0.3463 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2920 - acc: 0.8756 - val_loss: 0.3334 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.8799 - acc: 0.5959 - val_loss: 0.4838 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4693 - acc: 0.7979 - val_loss: 0.4500 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4271 - acc: 0.8394 - val_loss: 0.4972 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4105 - acc: 0.8446 - val_loss: 0.4728 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3827 - acc: 0.8653 - val_loss: 0.4677 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3891 - acc: 0.8705 - val_loss: 0.4654 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3781 - acc: 0.8653 - val_loss: 0.4735 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6176 - acc: 0.6753 - val_loss: 0.3396 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3996 - acc: 0.8505 - val_loss: 0.3161 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3471 - acc: 0.8814 - val_loss: 0.4292 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3562 - acc: 0.8557 - val_loss: 0.4323 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3314 - acc: 0.8866 - val_loss: 0.2929 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3767 - acc: 0.8402 - val_loss: 0.2917 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3225 - acc: 0.8505 - val_loss: 0.4833 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3080 - acc: 0.8660 - val_loss: 0.4537 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2918 - acc: 0.8918 - val_loss: 0.4010 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3034 - acc: 0.8608 - val_loss: 0.4170 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2701 - acc: 0.8866 - val_loss: 0.4371 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5733 - acc: 0.7268 - val_loss: 0.3521 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5601 - acc: 0.7835 - val_loss: 0.3578 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3928 - acc: 0.8454 - val_loss: 0.3951 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3850 - acc: 0.8505 - val_loss: 0.4661 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3953 - acc: 0.8402 - val_loss: 0.4424 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3873 - acc: 0.8505 - val_loss: 0.3888 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5623 - acc: 0.6959 - val_loss: 0.4454 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4149 - acc: 0.8351 - val_loss: 0.3975 - val_acc: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4174 - acc: 0.8454 - val_loss: 0.3941 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3847 - acc: 0.8505 - val_loss: 0.3606 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3451 - acc: 0.8660 - val_loss: 0.3489 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3241 - acc: 0.8608 - val_loss: 0.4522 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2992 - acc: 0.8763 - val_loss: 0.4690 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2772 - acc: 0.8763 - val_loss: 0.5047 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2555 - acc: 0.8866 - val_loss: 0.5209 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2570 - acc: 0.8866 - val_loss: 0.5312 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6660 - acc: 0.5959 - val_loss: 0.3255 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4372 - acc: 0.8083 - val_loss: 0.3343 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3554 - acc: 0.8446 - val_loss: 0.5143 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4129 - acc: 0.8394 - val_loss: 0.3752 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3189 - acc: 0.8653 - val_loss: 0.2821 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3213 - acc: 0.8290 - val_loss: 0.3130 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3297 - acc: 0.8446 - val_loss: 0.4078 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3023 - acc: 0.8497 - val_loss: 0.4803 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2936 - acc: 0.8653 - val_loss: 0.4529 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2683 - acc: 0.8808 - val_loss: 0.4655 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5310 - acc: 0.7150 - val_loss: 0.6990 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4573 - acc: 0.8290 - val_loss: 0.3858 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4197 - acc: 0.8187 - val_loss: 0.3548 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3493 - acc: 0.8394 - val_loss: 0.3692 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3271 - acc: 0.8446 - val_loss: 0.3611 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2850 - acc: 0.8756 - val_loss: 0.3615 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2861 - acc: 0.8394 - val_loss: 0.3917 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2862 - acc: 0.8446 - val_loss: 0.4449 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6154 - acc: 0.6495 - val_loss: 0.2932 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3920 - acc: 0.8557 - val_loss: 0.3356 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3565 - acc: 0.8557 - val_loss: 0.3053 - val_acc: 0.9180\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3336 - acc: 0.8505 - val_loss: 0.3173 - val_acc: 0.9180\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3081 - acc: 0.8866 - val_loss: 0.4703 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3320 - acc: 0.8402 - val_loss: 0.3753 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5447 - acc: 0.6804 - val_loss: 0.4419 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4550 - acc: 0.8041 - val_loss: 0.3625 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3841 - acc: 0.8196 - val_loss: 0.2939 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3527 - acc: 0.8299 - val_loss: 0.3654 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3493 - acc: 0.8247 - val_loss: 0.4155 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3210 - acc: 0.8402 - val_loss: 0.4188 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3101 - acc: 0.8402 - val_loss: 0.4783 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3179 - acc: 0.8505 - val_loss: 0.4806 - val_acc: 0.9016\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6459 - acc: 0.6701 - val_loss: 0.5236 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5254 - acc: 0.7784 - val_loss: 0.3833 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3670 - acc: 0.8144 - val_loss: 0.3326 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4105 - acc: 0.8196 - val_loss: 0.3220 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3337 - acc: 0.8505 - val_loss: 0.4492 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3776 - acc: 0.8711 - val_loss: 0.5676 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3842 - acc: 0.8608 - val_loss: 0.5526 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3159 - acc: 0.8866 - val_loss: 0.4512 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2995 - acc: 0.8763 - val_loss: 0.4378 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7576 - acc: 0.5959 - val_loss: 0.5395 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6132 - acc: 0.7254 - val_loss: 0.6251 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4763 - acc: 0.7927 - val_loss: 0.3368 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3459 - acc: 0.8446 - val_loss: 0.2985 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3640 - acc: 0.8653 - val_loss: 0.3411 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3180 - acc: 0.8601 - val_loss: 0.3892 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2986 - acc: 0.8756 - val_loss: 0.4044 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2761 - acc: 0.8756 - val_loss: 0.4530 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2630 - acc: 0.8860 - val_loss: 0.4740 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6837 - acc: 0.6425 - val_loss: 0.5733 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4748 - acc: 0.7927 - val_loss: 0.3201 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3565 - acc: 0.8238 - val_loss: 0.3106 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3144 - acc: 0.8705 - val_loss: 0.4438 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2987 - acc: 0.8808 - val_loss: 0.4630 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2797 - acc: 0.8912 - val_loss: 0.4362 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3087 - acc: 0.8549 - val_loss: 0.4341 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3140 - acc: 0.8601 - val_loss: 0.5750 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.5687 - acc: 0.7474 - val_loss: 0.3723 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3689 - acc: 0.8505 - val_loss: 0.3359 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3322 - acc: 0.8763 - val_loss: 0.7261 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4123 - acc: 0.8402 - val_loss: 0.4474 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4367 - acc: 0.8247 - val_loss: 0.4285 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3750 - acc: 0.8454 - val_loss: 0.4533 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3384 - acc: 0.8557 - val_loss: 0.5695 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6084 - acc: 0.6959 - val_loss: 0.4739 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3790 - acc: 0.8454 - val_loss: 0.3373 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3598 - acc: 0.8144 - val_loss: 0.4736 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3455 - acc: 0.8093 - val_loss: 0.4117 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3500 - acc: 0.8299 - val_loss: 0.4853 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3252 - acc: 0.8299 - val_loss: 0.5731 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3158 - acc: 0.8608 - val_loss: 0.5209 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6192 - acc: 0.6959 - val_loss: 0.7484 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5068 - acc: 0.8505 - val_loss: 0.3695 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4615 - acc: 0.8247 - val_loss: 0.3503 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3692 - acc: 0.8660 - val_loss: 0.4449 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3593 - acc: 0.8711 - val_loss: 0.4011 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3245 - acc: 0.8660 - val_loss: 0.3375 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3474 - acc: 0.8247 - val_loss: 0.3511 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3005 - acc: 0.8711 - val_loss: 0.4983 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3127 - acc: 0.9021 - val_loss: 0.5223 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2970 - acc: 0.8866 - val_loss: 0.4883 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2718 - acc: 0.8763 - val_loss: 0.4618 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5094 - acc: 0.7306 - val_loss: 0.7264 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3993 - acc: 0.8497 - val_loss: 0.5222 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3097 - acc: 0.8756 - val_loss: 0.3589 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3918 - acc: 0.8187 - val_loss: 0.6094 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3565 - acc: 0.8756 - val_loss: 0.6210 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2848 - acc: 0.8912 - val_loss: 0.4770 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2252 - acc: 0.9119 - val_loss: 0.6399 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2267 - acc: 0.9119 - val_loss: 0.6637 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7745 - acc: 0.6839 - val_loss: 0.8867 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7539 - acc: 0.6166 - val_loss: 0.4959 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4624 - acc: 0.8083 - val_loss: 0.4127 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3930 - acc: 0.7979 - val_loss: 0.5741 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4483 - acc: 0.8135 - val_loss: 0.6719 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3983 - acc: 0.8238 - val_loss: 0.6655 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3337 - acc: 0.8394 - val_loss: 0.5802 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2972 - acc: 0.8653 - val_loss: 0.5905 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6360 - acc: 0.6649 - val_loss: 0.4174 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4223 - acc: 0.8557 - val_loss: 0.3829 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2976 - acc: 0.8711 - val_loss: 0.4297 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2962 - acc: 0.8814 - val_loss: 0.4706 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2769 - acc: 0.8918 - val_loss: 0.4185 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3376 - acc: 0.8814 - val_loss: 0.4662 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2953 - acc: 0.8814 - val_loss: 0.5891 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6940 - acc: 0.6082 - val_loss: 0.2936 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5206 - acc: 0.8041 - val_loss: 0.5737 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4718 - acc: 0.7990 - val_loss: 0.4001 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3438 - acc: 0.8660 - val_loss: 0.3253 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3237 - acc: 0.8505 - val_loss: 0.3754 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2744 - acc: 0.8866 - val_loss: 0.4637 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5941 - acc: 0.7165 - val_loss: 0.7986 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5633 - acc: 0.7938 - val_loss: 0.3481 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4314 - acc: 0.8093 - val_loss: 0.4034 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3151 - acc: 0.8454 - val_loss: 0.5430 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2974 - acc: 0.8660 - val_loss: 0.4994 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3651 - acc: 0.8144 - val_loss: 0.4022 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3305 - acc: 0.8144 - val_loss: 0.4855 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0377 - acc: 0.6218 - val_loss: 0.4606 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4624 - acc: 0.8238 - val_loss: 0.5341 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4408 - acc: 0.8342 - val_loss: 0.7895 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3875 - acc: 0.8342 - val_loss: 0.4685 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3411 - acc: 0.8705 - val_loss: 0.8400 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3641 - acc: 0.8446 - val_loss: 0.7209 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5813 - acc: 0.7202 - val_loss: 1.1961 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8025 - acc: 0.7927 - val_loss: 0.5767 - val_acc: 0.9180\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9818 - acc: 0.7720 - val_loss: 0.5732 - val_acc: 0.8033\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5140 - acc: 0.7668 - val_loss: 0.6610 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4795 - acc: 0.7927 - val_loss: 0.4062 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4202 - acc: 0.8031 - val_loss: 0.3533 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3904 - acc: 0.8238 - val_loss: 0.3779 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2891 - acc: 0.8912 - val_loss: 0.4183 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2744 - acc: 0.8964 - val_loss: 0.4719 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2674 - acc: 0.9016 - val_loss: 0.4885 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2316 - acc: 0.9119 - val_loss: 0.5191 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5669 - acc: 0.7010 - val_loss: 0.8161 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6467 - acc: 0.7784 - val_loss: 1.2508 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7063 - acc: 0.8247 - val_loss: 0.8260 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5048 - acc: 0.8557 - val_loss: 0.5426 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3763 - acc: 0.7990 - val_loss: 0.4453 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2999 - acc: 0.8763 - val_loss: 0.4670 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2752 - acc: 0.8918 - val_loss: 0.6267 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2701 - acc: 0.8918 - val_loss: 0.6447 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2263 - acc: 0.8866 - val_loss: 0.5841 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2215 - acc: 0.8969 - val_loss: 0.6237 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6449 - acc: 0.7268 - val_loss: 3.0355 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.5648 - acc: 0.6649 - val_loss: 0.4226 - val_acc: 0.9180\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6663 - acc: 0.8299 - val_loss: 0.6927 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5487 - acc: 0.8299 - val_loss: 0.5570 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3213 - acc: 0.8557 - val_loss: 0.3491 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2898 - acc: 0.8608 - val_loss: 0.4027 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2510 - acc: 0.8918 - val_loss: 0.4624 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2618 - acc: 0.8866 - val_loss: 0.6092 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3144 - acc: 0.8969 - val_loss: 0.9477 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4444 - acc: 0.8969 - val_loss: 0.9364 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7424 - acc: 0.7113 - val_loss: 0.8731 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9545 - acc: 0.6907 - val_loss: 2.4863 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.9316 - acc: 0.4691 - val_loss: 0.4255 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5085 - acc: 0.8402 - val_loss: 0.5016 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6813 - acc: 0.8608 - val_loss: 0.4504 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4526 - acc: 0.8402 - val_loss: 0.4196 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3899 - acc: 0.8144 - val_loss: 0.5280 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3662 - acc: 0.8247 - val_loss: 0.9561 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4001 - acc: 0.8351 - val_loss: 0.8716 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3898 - acc: 0.8402 - val_loss: 0.6676 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4631 - acc: 0.8505 - val_loss: 0.5614 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.2182 - acc: 0.6321 - val_loss: 0.6721 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7234 - acc: 0.8135 - val_loss: 0.3985 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3104 - acc: 0.8653 - val_loss: 0.4446 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3100 - acc: 0.8756 - val_loss: 0.6244 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3051 - acc: 0.8912 - val_loss: 0.6561 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2573 - acc: 0.9067 - val_loss: 0.6264 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2156 - acc: 0.9119 - val_loss: 0.6594 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.7807 - acc: 0.5596 - val_loss: 3.3771 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0765 - acc: 0.5233 - val_loss: 0.4336 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5346 - acc: 0.8031 - val_loss: 0.3853 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4665 - acc: 0.8342 - val_loss: 0.5686 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4182 - acc: 0.8290 - val_loss: 0.5978 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3807 - acc: 0.8290 - val_loss: 0.4545 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3137 - acc: 0.8446 - val_loss: 0.4065 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3259 - acc: 0.8497 - val_loss: 0.4301 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.3514 - acc: 0.5722 - val_loss: 1.6548 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0602 - acc: 0.7835 - val_loss: 0.7728 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4528 - acc: 0.8660 - val_loss: 0.7967 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3315 - acc: 0.8711 - val_loss: 0.6741 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2925 - acc: 0.8557 - val_loss: 0.7098 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2424 - acc: 0.8711 - val_loss: 0.8629 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2368 - acc: 0.9072 - val_loss: 0.8426 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2217 - acc: 0.8918 - val_loss: 0.8615 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1564 - acc: 0.9433 - val_loss: 0.9620 - val_acc: 0.8033\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7881 - acc: 0.6649 - val_loss: 2.3572 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3391 - acc: 0.7320 - val_loss: 1.2777 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8347 - acc: 0.8093 - val_loss: 0.6754 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5938 - acc: 0.8196 - val_loss: 0.5238 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3848 - acc: 0.8402 - val_loss: 0.5824 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2916 - acc: 0.8660 - val_loss: 0.5002 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2443 - acc: 0.9072 - val_loss: 0.4859 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2247 - acc: 0.9175 - val_loss: 0.4973 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1928 - acc: 0.9175 - val_loss: 0.5623 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1753 - acc: 0.9381 - val_loss: 0.7137 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1772 - acc: 0.9072 - val_loss: 0.6178 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1658 - acc: 0.9227 - val_loss: 0.6360 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.3955 - acc: 0.6649 - val_loss: 1.4178 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7145 - acc: 0.7887 - val_loss: 0.4431 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5204 - acc: 0.7990 - val_loss: 0.6070 - val_acc: 0.9180\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4218 - acc: 0.8299 - val_loss: 0.7277 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3130 - acc: 0.8608 - val_loss: 0.6936 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3145 - acc: 0.8557 - val_loss: 0.7817 - val_acc: 0.8033\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3071 - acc: 0.8711 - val_loss: 0.8134 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 4.3866 - acc: 0.6062 - val_loss: 5.1512 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.4814 - acc: 0.6839 - val_loss: 4.2690 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.1003 - acc: 0.7927 - val_loss: 1.9748 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8572 - acc: 0.7979 - val_loss: 2.7989 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4949 - acc: 0.7202 - val_loss: 0.6743 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7009 - acc: 0.8187 - val_loss: 0.6676 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4526 - acc: 0.8601 - val_loss: 0.6813 - val_acc: 0.8033\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3486 - acc: 0.8394 - val_loss: 0.5247 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2840 - acc: 0.9067 - val_loss: 0.5223 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4290 - acc: 0.8808 - val_loss: 0.6740 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3191 - acc: 0.8601 - val_loss: 0.9208 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3168 - acc: 0.8290 - val_loss: 0.7847 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2281 - acc: 0.9067 - val_loss: 0.7063 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2101 - acc: 0.9119 - val_loss: 0.7803 - val_acc: 0.8852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.9694 - acc: 0.6891 - val_loss: 1.1533 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7384 - acc: 0.8135 - val_loss: 0.6532 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4513 - acc: 0.8446 - val_loss: 0.3971 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3049 - acc: 0.8705 - val_loss: 0.5123 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2962 - acc: 0.8756 - val_loss: 0.6303 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2458 - acc: 0.8964 - val_loss: 0.5721 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1816 - acc: 0.9119 - val_loss: 0.6727 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1412 - acc: 0.9637 - val_loss: 0.6937 - val_acc: 0.8689\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.6931 - acc: 0.5876 - val_loss: 9.6168 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.1846 - acc: 0.6856 - val_loss: 1.8620 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0636 - acc: 0.8351 - val_loss: 1.9469 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5604 - acc: 0.8660 - val_loss: 1.6334 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3610 - acc: 0.8660 - val_loss: 1.2645 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3407 - acc: 0.8505 - val_loss: 1.0958 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2643 - acc: 0.8918 - val_loss: 1.0689 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3174 - acc: 0.8918 - val_loss: 1.1287 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4687 - acc: 0.7835 - val_loss: 1.0950 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2784 - acc: 0.9021 - val_loss: 1.2015 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3143 - acc: 0.9124 - val_loss: 1.2183 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2237 - acc: 0.9124 - val_loss: 1.2371 - val_acc: 0.8525\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9335 - acc: 0.7423 - val_loss: 20.8028 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.6116 - acc: 0.6340 - val_loss: 2.7864 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.7571 - acc: 0.7320 - val_loss: 1.5973 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8383 - acc: 0.8454 - val_loss: 0.8209 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4543 - acc: 0.8505 - val_loss: 0.6286 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3808 - acc: 0.8247 - val_loss: 0.4389 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2891 - acc: 0.8814 - val_loss: 0.5446 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2573 - acc: 0.8969 - val_loss: 0.6812 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2523 - acc: 0.9021 - val_loss: 0.6975 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2201 - acc: 0.8969 - val_loss: 0.6758 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1717 - acc: 0.9278 - val_loss: 0.6859 - val_acc: 0.8361\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.2876 - acc: 0.6392 - val_loss: 0.9855 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3471 - acc: 0.8299 - val_loss: 1.4192 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.7991 - acc: 0.7371 - val_loss: 0.6855 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6932 - acc: 0.7371 - val_loss: 0.6365 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3554 - acc: 0.8351 - val_loss: 0.3468 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4232 - acc: 0.8041 - val_loss: 0.3633 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3618 - acc: 0.8505 - val_loss: 0.5647 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3542 - acc: 0.8660 - val_loss: 0.6269 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2592 - acc: 0.8969 - val_loss: 0.6645 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2760 - acc: 0.8711 - val_loss: 0.6456 - val_acc: 0.8197\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7799 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7799 - val_acc: 0.3770\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7799 - val_acc: 0.3770\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7799 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7799 - val_acc: 0.3770\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7799 - val_acc: 0.3770\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7799 - val_acc: 0.3770\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7799 - val_acc: 0.3770\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7799 - val_acc: 0.3770\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7799 - val_acc: 0.3770\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7799 - val_acc: 0.3770\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7799 - val_acc: 0.3770\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7798 - val_acc: 0.3770\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7798 - val_acc: 0.3770\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7798 - val_acc: 0.3770\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7798 - val_acc: 0.3770\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7798 - val_acc: 0.3770\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7500 - acc: 0.3938 - val_loss: 0.7798 - val_acc: 0.3770\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7499 - acc: 0.3938 - val_loss: 0.7798 - val_acc: 0.3770\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7499 - acc: 0.3938 - val_loss: 0.7798 - val_acc: 0.3770\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.7040 - acc: 0.5181 - val_loss: 0.7146 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7040 - acc: 0.5181 - val_loss: 0.7145 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7040 - acc: 0.5181 - val_loss: 0.7145 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7040 - acc: 0.5181 - val_loss: 0.7145 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7040 - acc: 0.5181 - val_loss: 0.7145 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7040 - acc: 0.5181 - val_loss: 0.7145 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7039 - acc: 0.5181 - val_loss: 0.7145 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7039 - acc: 0.5181 - val_loss: 0.7145 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7039 - acc: 0.5181 - val_loss: 0.7145 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7039 - acc: 0.5181 - val_loss: 0.7145 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7039 - acc: 0.5181 - val_loss: 0.7145 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7039 - acc: 0.5181 - val_loss: 0.7145 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7039 - acc: 0.5181 - val_loss: 0.7145 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7039 - acc: 0.5181 - val_loss: 0.7145 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7039 - acc: 0.5181 - val_loss: 0.7144 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7039 - acc: 0.5181 - val_loss: 0.7144 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7039 - acc: 0.5181 - val_loss: 0.7144 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7039 - acc: 0.5181 - val_loss: 0.7144 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7039 - acc: 0.5181 - val_loss: 0.7144 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7039 - acc: 0.5181 - val_loss: 0.7144 - val_acc: 0.5410\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.9335 - acc: 0.4072 - val_loss: 0.8908 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.9335 - acc: 0.4124 - val_loss: 0.8908 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.9335 - acc: 0.4124 - val_loss: 0.8908 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.9335 - acc: 0.4124 - val_loss: 0.8908 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.9335 - acc: 0.4124 - val_loss: 0.8908 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.9335 - acc: 0.4124 - val_loss: 0.8908 - val_acc: 0.4262\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.9335 - acc: 0.4124 - val_loss: 0.8908 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.9334 - acc: 0.4124 - val_loss: 0.8907 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.9334 - acc: 0.4124 - val_loss: 0.8907 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.9334 - acc: 0.4124 - val_loss: 0.8907 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.9334 - acc: 0.4124 - val_loss: 0.8907 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.9334 - acc: 0.4124 - val_loss: 0.8907 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.9334 - acc: 0.4124 - val_loss: 0.8907 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.9334 - acc: 0.4124 - val_loss: 0.8907 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.9334 - acc: 0.4124 - val_loss: 0.8907 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.9333 - acc: 0.4124 - val_loss: 0.8906 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.9333 - acc: 0.4124 - val_loss: 0.8906 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.9333 - acc: 0.4124 - val_loss: 0.8906 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.9333 - acc: 0.4124 - val_loss: 0.8906 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.9333 - acc: 0.4124 - val_loss: 0.8906 - val_acc: 0.4426\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.0218 - acc: 0.3299 - val_loss: 1.2107 - val_acc: 0.3443\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.0218 - acc: 0.3299 - val_loss: 1.2107 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0218 - acc: 0.3299 - val_loss: 1.2107 - val_acc: 0.3443\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0218 - acc: 0.3299 - val_loss: 1.2107 - val_acc: 0.3443\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0218 - acc: 0.3299 - val_loss: 1.2106 - val_acc: 0.3443\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0217 - acc: 0.3299 - val_loss: 1.2106 - val_acc: 0.3443\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0217 - acc: 0.3299 - val_loss: 1.2106 - val_acc: 0.3443\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0217 - acc: 0.3299 - val_loss: 1.2106 - val_acc: 0.3443\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.0217 - acc: 0.3299 - val_loss: 1.2106 - val_acc: 0.3443\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0216 - acc: 0.3299 - val_loss: 1.2105 - val_acc: 0.3443\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0216 - acc: 0.3299 - val_loss: 1.2105 - val_acc: 0.3443\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0216 - acc: 0.3299 - val_loss: 1.2105 - val_acc: 0.3443\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0216 - acc: 0.3299 - val_loss: 1.2105 - val_acc: 0.3443\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0216 - acc: 0.3299 - val_loss: 1.2105 - val_acc: 0.3443\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0215 - acc: 0.3299 - val_loss: 1.2104 - val_acc: 0.3443\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0215 - acc: 0.3299 - val_loss: 1.2104 - val_acc: 0.3443\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0215 - acc: 0.3299 - val_loss: 1.2104 - val_acc: 0.3443\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.0215 - acc: 0.3299 - val_loss: 1.2104 - val_acc: 0.3443\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0215 - acc: 0.3299 - val_loss: 1.2104 - val_acc: 0.3443\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0214 - acc: 0.3299 - val_loss: 1.2103 - val_acc: 0.3443\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b4867e3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7079 - acc: 0.5206 - val_loss: 0.6868 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7079 - acc: 0.5155 - val_loss: 0.6868 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6868 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6868 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6868 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6868 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6867 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6867 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6867 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6867 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6867 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6867 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6867 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6867 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6867 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6867 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6867 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6867 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6867 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7078 - acc: 0.5155 - val_loss: 0.6867 - val_acc: 0.4918\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b240d55e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7969 - acc: 0.4352 - val_loss: 0.8229 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7969 - acc: 0.4352 - val_loss: 0.8229 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7969 - acc: 0.4352 - val_loss: 0.8229 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7969 - acc: 0.4352 - val_loss: 0.8229 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7969 - acc: 0.4352 - val_loss: 0.8229 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7969 - acc: 0.4352 - val_loss: 0.8229 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7968 - acc: 0.4352 - val_loss: 0.8229 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7968 - acc: 0.4352 - val_loss: 0.8228 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7968 - acc: 0.4352 - val_loss: 0.8228 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7968 - acc: 0.4352 - val_loss: 0.8228 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7968 - acc: 0.4352 - val_loss: 0.8228 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7968 - acc: 0.4352 - val_loss: 0.8228 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7968 - acc: 0.4352 - val_loss: 0.8228 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7968 - acc: 0.4352 - val_loss: 0.8228 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7968 - acc: 0.4352 - val_loss: 0.8228 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7968 - acc: 0.4352 - val_loss: 0.8228 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7967 - acc: 0.4352 - val_loss: 0.8227 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7967 - acc: 0.4352 - val_loss: 0.8227 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7967 - acc: 0.4352 - val_loss: 0.8227 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7967 - acc: 0.4352 - val_loss: 0.8227 - val_acc: 0.4262\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c5d0dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.0028 - acc: 0.4249 - val_loss: 0.9367 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.0028 - acc: 0.4249 - val_loss: 0.9367 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0028 - acc: 0.4249 - val_loss: 0.9367 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0028 - acc: 0.4249 - val_loss: 0.9367 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0028 - acc: 0.4249 - val_loss: 0.9366 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0027 - acc: 0.4249 - val_loss: 0.9366 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0027 - acc: 0.4249 - val_loss: 0.9366 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0027 - acc: 0.4249 - val_loss: 0.9366 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0027 - acc: 0.4249 - val_loss: 0.9366 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0027 - acc: 0.4249 - val_loss: 0.9366 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0027 - acc: 0.4249 - val_loss: 0.9365 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0026 - acc: 0.4249 - val_loss: 0.9365 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0026 - acc: 0.4249 - val_loss: 0.9365 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0026 - acc: 0.4249 - val_loss: 0.9365 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0026 - acc: 0.4249 - val_loss: 0.9365 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0026 - acc: 0.4249 - val_loss: 0.9365 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0025 - acc: 0.4249 - val_loss: 0.9364 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0025 - acc: 0.4249 - val_loss: 0.9364 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.0025 - acc: 0.4249 - val_loss: 0.9364 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0025 - acc: 0.4249 - val_loss: 0.9364 - val_acc: 0.4754\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c7a8b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.8393 - acc: 0.2680 - val_loss: 0.9253 - val_acc: 0.0820\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8393 - acc: 0.2680 - val_loss: 0.9252 - val_acc: 0.0820\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8393 - acc: 0.2680 - val_loss: 0.9252 - val_acc: 0.0820\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8392 - acc: 0.2680 - val_loss: 0.9252 - val_acc: 0.0820\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8392 - acc: 0.2680 - val_loss: 0.9252 - val_acc: 0.0820\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8392 - acc: 0.2680 - val_loss: 0.9252 - val_acc: 0.0820\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8392 - acc: 0.2680 - val_loss: 0.9252 - val_acc: 0.0820\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8392 - acc: 0.2680 - val_loss: 0.9252 - val_acc: 0.0820\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8392 - acc: 0.2680 - val_loss: 0.9251 - val_acc: 0.0820\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8392 - acc: 0.2680 - val_loss: 0.9251 - val_acc: 0.0820\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8392 - acc: 0.2680 - val_loss: 0.9251 - val_acc: 0.0820\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8392 - acc: 0.2680 - val_loss: 0.9251 - val_acc: 0.0820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8391 - acc: 0.2680 - val_loss: 0.9251 - val_acc: 0.0820\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8391 - acc: 0.2680 - val_loss: 0.9251 - val_acc: 0.0820\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8391 - acc: 0.2680 - val_loss: 0.9251 - val_acc: 0.0820\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8391 - acc: 0.2680 - val_loss: 0.9251 - val_acc: 0.0820\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8391 - acc: 0.2680 - val_loss: 0.9250 - val_acc: 0.0820\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8391 - acc: 0.2680 - val_loss: 0.9250 - val_acc: 0.0820\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8391 - acc: 0.2680 - val_loss: 0.9250 - val_acc: 0.0820\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8391 - acc: 0.2680 - val_loss: 0.9250 - val_acc: 0.0820\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb0058670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7549 - acc: 0.4175 - val_loss: 0.7545 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7549 - acc: 0.4175 - val_loss: 0.7545 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7549 - acc: 0.4175 - val_loss: 0.7545 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7549 - acc: 0.4175 - val_loss: 0.7545 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7549 - acc: 0.4175 - val_loss: 0.7545 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7549 - acc: 0.4175 - val_loss: 0.7545 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7548 - acc: 0.4175 - val_loss: 0.7545 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7548 - acc: 0.4175 - val_loss: 0.7544 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7548 - acc: 0.4175 - val_loss: 0.7544 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7548 - acc: 0.4175 - val_loss: 0.7544 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7548 - acc: 0.4175 - val_loss: 0.7544 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7548 - acc: 0.4175 - val_loss: 0.7544 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7548 - acc: 0.4175 - val_loss: 0.7544 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7548 - acc: 0.4175 - val_loss: 0.7544 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7548 - acc: 0.4175 - val_loss: 0.7544 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7548 - acc: 0.4175 - val_loss: 0.7543 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7547 - acc: 0.4175 - val_loss: 0.7543 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7547 - acc: 0.4175 - val_loss: 0.7543 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7547 - acc: 0.4175 - val_loss: 0.7543 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7547 - acc: 0.4175 - val_loss: 0.7543 - val_acc: 0.4590\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb697a4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7204 - acc: 0.5515 - val_loss: 0.7531 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7204 - acc: 0.5515 - val_loss: 0.7531 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7204 - acc: 0.5515 - val_loss: 0.7531 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7204 - acc: 0.5515 - val_loss: 0.7531 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7204 - acc: 0.5515 - val_loss: 0.7531 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7203 - acc: 0.5515 - val_loss: 0.7530 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7203 - acc: 0.5515 - val_loss: 0.7530 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7203 - acc: 0.5515 - val_loss: 0.7530 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7203 - acc: 0.5515 - val_loss: 0.7530 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7203 - acc: 0.5515 - val_loss: 0.7530 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7203 - acc: 0.5515 - val_loss: 0.7530 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7203 - acc: 0.5515 - val_loss: 0.7529 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7203 - acc: 0.5515 - val_loss: 0.7529 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7203 - acc: 0.5515 - val_loss: 0.7529 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7202 - acc: 0.5515 - val_loss: 0.7529 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7202 - acc: 0.5515 - val_loss: 0.7529 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7202 - acc: 0.5515 - val_loss: 0.7529 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7202 - acc: 0.5515 - val_loss: 0.7529 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7202 - acc: 0.5515 - val_loss: 0.7528 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7202 - acc: 0.5515 - val_loss: 0.7528 - val_acc: 0.5246\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b4852ec10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7195 - acc: 0.4870 - val_loss: 0.7731 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7194 - acc: 0.4870 - val_loss: 0.7731 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7194 - acc: 0.4870 - val_loss: 0.7731 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7194 - acc: 0.4870 - val_loss: 0.7731 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7194 - acc: 0.4870 - val_loss: 0.7731 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7194 - acc: 0.4870 - val_loss: 0.7730 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7194 - acc: 0.4870 - val_loss: 0.7730 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7193 - acc: 0.4870 - val_loss: 0.7730 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7193 - acc: 0.4870 - val_loss: 0.7730 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7193 - acc: 0.4870 - val_loss: 0.7730 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7193 - acc: 0.4870 - val_loss: 0.7729 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7193 - acc: 0.4870 - val_loss: 0.7729 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7192 - acc: 0.4870 - val_loss: 0.7729 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7192 - acc: 0.4870 - val_loss: 0.7729 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7192 - acc: 0.4870 - val_loss: 0.7729 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7192 - acc: 0.4870 - val_loss: 0.7728 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7192 - acc: 0.4870 - val_loss: 0.7728 - val_acc: 0.4590\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7192 - acc: 0.4870 - val_loss: 0.7728 - val_acc: 0.4590\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7191 - acc: 0.4870 - val_loss: 0.7728 - val_acc: 0.4590\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7191 - acc: 0.4870 - val_loss: 0.7728 - val_acc: 0.4590\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3af8157550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.8822 - acc: 0.2850 - val_loss: 0.9844 - val_acc: 0.2131\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8822 - acc: 0.2850 - val_loss: 0.9844 - val_acc: 0.2131\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8822 - acc: 0.2850 - val_loss: 0.9844 - val_acc: 0.2131\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8821 - acc: 0.2850 - val_loss: 0.9844 - val_acc: 0.2131\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8821 - acc: 0.2850 - val_loss: 0.9843 - val_acc: 0.2131\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8821 - acc: 0.2850 - val_loss: 0.9843 - val_acc: 0.2131\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8821 - acc: 0.2850 - val_loss: 0.9843 - val_acc: 0.2131\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8821 - acc: 0.2850 - val_loss: 0.9843 - val_acc: 0.2131\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.8821 - acc: 0.2850 - val_loss: 0.9842 - val_acc: 0.2131\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8820 - acc: 0.2850 - val_loss: 0.9842 - val_acc: 0.2131\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8820 - acc: 0.2850 - val_loss: 0.9842 - val_acc: 0.2131\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8820 - acc: 0.2850 - val_loss: 0.9842 - val_acc: 0.2131\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8820 - acc: 0.2850 - val_loss: 0.9842 - val_acc: 0.2131\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8820 - acc: 0.2850 - val_loss: 0.9841 - val_acc: 0.2131\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8819 - acc: 0.2850 - val_loss: 0.9841 - val_acc: 0.2131\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8819 - acc: 0.2850 - val_loss: 0.9841 - val_acc: 0.2131\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8819 - acc: 0.2850 - val_loss: 0.9841 - val_acc: 0.2131\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8819 - acc: 0.2850 - val_loss: 0.9840 - val_acc: 0.2131\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8819 - acc: 0.2850 - val_loss: 0.9840 - val_acc: 0.2131\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8818 - acc: 0.2850 - val_loss: 0.9840 - val_acc: 0.2131\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac0794dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.8149 - acc: 0.4433 - val_loss: 0.7487 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8149 - acc: 0.4433 - val_loss: 0.7487 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8148 - acc: 0.4433 - val_loss: 0.7487 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8148 - acc: 0.4433 - val_loss: 0.7486 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8148 - acc: 0.4433 - val_loss: 0.7486 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8148 - acc: 0.4433 - val_loss: 0.7486 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.8147 - acc: 0.4433 - val_loss: 0.7486 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8147 - acc: 0.4433 - val_loss: 0.7486 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8147 - acc: 0.4433 - val_loss: 0.7485 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8147 - acc: 0.4433 - val_loss: 0.7485 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8147 - acc: 0.4433 - val_loss: 0.7485 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8146 - acc: 0.4433 - val_loss: 0.7485 - val_acc: 0.4754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8146 - acc: 0.4433 - val_loss: 0.7485 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8146 - acc: 0.4433 - val_loss: 0.7484 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8146 - acc: 0.4433 - val_loss: 0.7484 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8146 - acc: 0.4433 - val_loss: 0.7484 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8145 - acc: 0.4433 - val_loss: 0.7484 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8145 - acc: 0.4433 - val_loss: 0.7484 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8145 - acc: 0.4433 - val_loss: 0.7483 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8145 - acc: 0.4433 - val_loss: 0.7483 - val_acc: 0.4754\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac03e9940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6700 - acc: 0.6237 - val_loss: 0.6325 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6700 - acc: 0.6237 - val_loss: 0.6325 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6700 - acc: 0.6237 - val_loss: 0.6325 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6700 - acc: 0.6237 - val_loss: 0.6324 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6700 - acc: 0.6237 - val_loss: 0.6324 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6699 - acc: 0.6237 - val_loss: 0.6324 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6699 - acc: 0.6237 - val_loss: 0.6324 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6699 - acc: 0.6237 - val_loss: 0.6324 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6699 - acc: 0.6237 - val_loss: 0.6323 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6699 - acc: 0.6237 - val_loss: 0.6323 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6699 - acc: 0.6237 - val_loss: 0.6323 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6699 - acc: 0.6237 - val_loss: 0.6323 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6698 - acc: 0.6237 - val_loss: 0.6323 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6698 - acc: 0.6237 - val_loss: 0.6323 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6698 - acc: 0.6237 - val_loss: 0.6322 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6698 - acc: 0.6237 - val_loss: 0.6322 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6698 - acc: 0.6237 - val_loss: 0.6322 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6698 - acc: 0.6237 - val_loss: 0.6322 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6697 - acc: 0.6237 - val_loss: 0.6322 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6697 - acc: 0.6237 - val_loss: 0.6321 - val_acc: 0.6230\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac01c9b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6480 - acc: 0.6546 - val_loss: 0.6328 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6480 - acc: 0.6546 - val_loss: 0.6328 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6480 - acc: 0.6546 - val_loss: 0.6328 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6480 - acc: 0.6546 - val_loss: 0.6328 - val_acc: 0.6721\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6480 - acc: 0.6546 - val_loss: 0.6328 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6479 - acc: 0.6546 - val_loss: 0.6327 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6479 - acc: 0.6546 - val_loss: 0.6327 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6479 - acc: 0.6546 - val_loss: 0.6327 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6479 - acc: 0.6546 - val_loss: 0.6327 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6479 - acc: 0.6546 - val_loss: 0.6327 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6479 - acc: 0.6546 - val_loss: 0.6327 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6479 - acc: 0.6546 - val_loss: 0.6327 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6478 - acc: 0.6546 - val_loss: 0.6326 - val_acc: 0.6721\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6478 - acc: 0.6546 - val_loss: 0.6326 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6478 - acc: 0.6546 - val_loss: 0.6326 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6478 - acc: 0.6546 - val_loss: 0.6326 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6478 - acc: 0.6546 - val_loss: 0.6326 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6478 - acc: 0.6546 - val_loss: 0.6326 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6478 - acc: 0.6546 - val_loss: 0.6326 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6618 - acc: 0.640 - 0s 9ms/step - loss: 0.6478 - acc: 0.6546 - val_loss: 0.6326 - val_acc: 0.6721\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3c346e4700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.8018 - acc: 0.5181 - val_loss: 0.8121 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8018 - acc: 0.5181 - val_loss: 0.8120 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8017 - acc: 0.5181 - val_loss: 0.8120 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8017 - acc: 0.5181 - val_loss: 0.8120 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8017 - acc: 0.5181 - val_loss: 0.8119 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8016 - acc: 0.5181 - val_loss: 0.8119 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8016 - acc: 0.5181 - val_loss: 0.8118 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8016 - acc: 0.5181 - val_loss: 0.8118 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8015 - acc: 0.5181 - val_loss: 0.8118 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8015 - acc: 0.5181 - val_loss: 0.8117 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8015 - acc: 0.5181 - val_loss: 0.8117 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8014 - acc: 0.5181 - val_loss: 0.8117 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8014 - acc: 0.5181 - val_loss: 0.8116 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8014 - acc: 0.5181 - val_loss: 0.8116 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8013 - acc: 0.5181 - val_loss: 0.8115 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8013 - acc: 0.5181 - val_loss: 0.8115 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8013 - acc: 0.5181 - val_loss: 0.8115 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8012 - acc: 0.5181 - val_loss: 0.8114 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8012 - acc: 0.5181 - val_loss: 0.8114 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8012 - acc: 0.5181 - val_loss: 0.8114 - val_acc: 0.5246\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb489b1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7876 - acc: 0.4145 - val_loss: 0.7459 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7875 - acc: 0.4145 - val_loss: 0.7458 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7875 - acc: 0.4145 - val_loss: 0.7458 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7875 - acc: 0.4145 - val_loss: 0.7458 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7874 - acc: 0.4145 - val_loss: 0.7457 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7874 - acc: 0.4145 - val_loss: 0.7457 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7874 - acc: 0.4145 - val_loss: 0.7457 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7873 - acc: 0.4145 - val_loss: 0.7457 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7873 - acc: 0.4145 - val_loss: 0.7456 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7873 - acc: 0.4145 - val_loss: 0.7456 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7873 - acc: 0.4145 - val_loss: 0.7456 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7872 - acc: 0.4145 - val_loss: 0.7455 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7872 - acc: 0.4145 - val_loss: 0.7455 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7872 - acc: 0.4145 - val_loss: 0.7455 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7871 - acc: 0.4145 - val_loss: 0.7455 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7871 - acc: 0.4145 - val_loss: 0.7454 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7871 - acc: 0.4145 - val_loss: 0.7454 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7870 - acc: 0.4145 - val_loss: 0.7454 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7870 - acc: 0.4145 - val_loss: 0.7453 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7870 - acc: 0.4145 - val_loss: 0.7453 - val_acc: 0.3934\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3af8157040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7110 - acc: 0.4948 - val_loss: 0.6746 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7110 - acc: 0.4948 - val_loss: 0.6745 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7109 - acc: 0.4948 - val_loss: 0.6745 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7109 - acc: 0.4948 - val_loss: 0.6745 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7109 - acc: 0.4948 - val_loss: 0.6745 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7108 - acc: 0.4948 - val_loss: 0.6744 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7108 - acc: 0.4948 - val_loss: 0.6744 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7108 - acc: 0.4948 - val_loss: 0.6744 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7107 - acc: 0.4948 - val_loss: 0.6744 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7107 - acc: 0.4948 - val_loss: 0.6743 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7107 - acc: 0.4948 - val_loss: 0.6743 - val_acc: 0.5738\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7107 - acc: 0.4948 - val_loss: 0.6743 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7106 - acc: 0.4948 - val_loss: 0.6742 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7106 - acc: 0.4948 - val_loss: 0.6742 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7106 - acc: 0.4897 - val_loss: 0.6742 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7105 - acc: 0.4897 - val_loss: 0.6742 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7105 - acc: 0.4897 - val_loss: 0.6741 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7105 - acc: 0.4897 - val_loss: 0.6741 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7105 - acc: 0.4897 - val_loss: 0.6741 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7104 - acc: 0.4897 - val_loss: 0.6740 - val_acc: 0.5738\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb697a670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7228 - acc: 0.4433 - val_loss: 0.7480 - val_acc: 0.2951\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7228 - acc: 0.4433 - val_loss: 0.7479 - val_acc: 0.2951\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7228 - acc: 0.4433 - val_loss: 0.7479 - val_acc: 0.2951\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7228 - acc: 0.4433 - val_loss: 0.7479 - val_acc: 0.2951\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7227 - acc: 0.4433 - val_loss: 0.7479 - val_acc: 0.2951\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7227 - acc: 0.4433 - val_loss: 0.7478 - val_acc: 0.2951\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7227 - acc: 0.4433 - val_loss: 0.7478 - val_acc: 0.2951\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7227 - acc: 0.4433 - val_loss: 0.7478 - val_acc: 0.2951\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7226 - acc: 0.4433 - val_loss: 0.7478 - val_acc: 0.2951\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7226 - acc: 0.4433 - val_loss: 0.7477 - val_acc: 0.2951\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7226 - acc: 0.4433 - val_loss: 0.7477 - val_acc: 0.2951\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7226 - acc: 0.4433 - val_loss: 0.7477 - val_acc: 0.2951\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7226 - acc: 0.4433 - val_loss: 0.7477 - val_acc: 0.2951\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7225 - acc: 0.4433 - val_loss: 0.7476 - val_acc: 0.2951\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7225 - acc: 0.4433 - val_loss: 0.7476 - val_acc: 0.2951\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7225 - acc: 0.4433 - val_loss: 0.7476 - val_acc: 0.2951\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7225 - acc: 0.4433 - val_loss: 0.7476 - val_acc: 0.2951\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7225 - acc: 0.4433 - val_loss: 0.7475 - val_acc: 0.2951\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7224 - acc: 0.4433 - val_loss: 0.7475 - val_acc: 0.2951\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7224 - acc: 0.4433 - val_loss: 0.7475 - val_acc: 0.2951\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb0058e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7010 - acc: 0.5928 - val_loss: 0.7362 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7010 - acc: 0.5928 - val_loss: 0.7362 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7010 - acc: 0.5928 - val_loss: 0.7362 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7009 - acc: 0.5928 - val_loss: 0.7362 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7009 - acc: 0.5928 - val_loss: 0.7361 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7009 - acc: 0.5928 - val_loss: 0.7361 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7009 - acc: 0.5928 - val_loss: 0.7361 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7008 - acc: 0.5928 - val_loss: 0.7360 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7008 - acc: 0.5928 - val_loss: 0.7360 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7008 - acc: 0.5928 - val_loss: 0.7360 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7008 - acc: 0.5928 - val_loss: 0.7359 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7008 - acc: 0.5928 - val_loss: 0.7359 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7007 - acc: 0.5928 - val_loss: 0.7359 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7007 - acc: 0.5928 - val_loss: 0.7359 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7007 - acc: 0.5928 - val_loss: 0.7358 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7007 - acc: 0.5928 - val_loss: 0.7358 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7006 - acc: 0.5928 - val_loss: 0.7358 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7006 - acc: 0.5928 - val_loss: 0.7357 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7006 - acc: 0.5928 - val_loss: 0.7357 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7006 - acc: 0.5928 - val_loss: 0.7357 - val_acc: 0.5574\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b48555550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6377 - acc: 0.6114 - val_loss: 0.6522 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6376 - acc: 0.6114 - val_loss: 0.6522 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6376 - acc: 0.6114 - val_loss: 0.6521 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6375 - acc: 0.6114 - val_loss: 0.6521 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6375 - acc: 0.6114 - val_loss: 0.6520 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6375 - acc: 0.6114 - val_loss: 0.6520 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6374 - acc: 0.6114 - val_loss: 0.6520 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6374 - acc: 0.6114 - val_loss: 0.6519 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6374 - acc: 0.6114 - val_loss: 0.6519 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6373 - acc: 0.6114 - val_loss: 0.6519 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6373 - acc: 0.6114 - val_loss: 0.6518 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6373 - acc: 0.6114 - val_loss: 0.6518 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6372 - acc: 0.6114 - val_loss: 0.6517 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6372 - acc: 0.6114 - val_loss: 0.6517 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6372 - acc: 0.6114 - val_loss: 0.6517 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6371 - acc: 0.6114 - val_loss: 0.6516 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6371 - acc: 0.6114 - val_loss: 0.6516 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6371 - acc: 0.6114 - val_loss: 0.6515 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6370 - acc: 0.6114 - val_loss: 0.6515 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6370 - acc: 0.6114 - val_loss: 0.6515 - val_acc: 0.5738\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b482c5790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6528 - acc: 0.6010 - val_loss: 0.6652 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6527 - acc: 0.6010 - val_loss: 0.6651 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6527 - acc: 0.6010 - val_loss: 0.6651 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6527 - acc: 0.6010 - val_loss: 0.6651 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6526 - acc: 0.6010 - val_loss: 0.6650 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6526 - acc: 0.6010 - val_loss: 0.6650 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6526 - acc: 0.6010 - val_loss: 0.6650 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6526 - acc: 0.6010 - val_loss: 0.6649 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6525 - acc: 0.6010 - val_loss: 0.6649 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6525 - acc: 0.6010 - val_loss: 0.6649 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6525 - acc: 0.6010 - val_loss: 0.6648 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6525 - acc: 0.6010 - val_loss: 0.6648 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6524 - acc: 0.6010 - val_loss: 0.6648 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6524 - acc: 0.6010 - val_loss: 0.6647 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6524 - acc: 0.6010 - val_loss: 0.6647 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6524 - acc: 0.6010 - val_loss: 0.6647 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6523 - acc: 0.6010 - val_loss: 0.6647 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6523 - acc: 0.6010 - val_loss: 0.6646 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6523 - acc: 0.6010 - val_loss: 0.6646 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6522 - acc: 0.6010 - val_loss: 0.6646 - val_acc: 0.5738\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b48555940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6650 - acc: 0.5979 - val_loss: 0.6774 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6649 - acc: 0.5979 - val_loss: 0.6774 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6649 - acc: 0.5979 - val_loss: 0.6773 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6649 - acc: 0.5979 - val_loss: 0.6773 - val_acc: 0.5410\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6649 - acc: 0.5979 - val_loss: 0.6772 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6648 - acc: 0.5979 - val_loss: 0.6772 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6648 - acc: 0.5979 - val_loss: 0.6772 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6648 - acc: 0.5979 - val_loss: 0.6771 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6647 - acc: 0.5979 - val_loss: 0.6771 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6647 - acc: 0.5979 - val_loss: 0.6771 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6647 - acc: 0.5979 - val_loss: 0.6770 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6646 - acc: 0.5979 - val_loss: 0.6770 - val_acc: 0.5410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6646 - acc: 0.5979 - val_loss: 0.6770 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6646 - acc: 0.5979 - val_loss: 0.6769 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6645 - acc: 0.5979 - val_loss: 0.6769 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6645 - acc: 0.5979 - val_loss: 0.6769 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6645 - acc: 0.5979 - val_loss: 0.6768 - val_acc: 0.5410\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6645 - acc: 0.5979 - val_loss: 0.6768 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6644 - acc: 0.5979 - val_loss: 0.6767 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6644 - acc: 0.5979 - val_loss: 0.6767 - val_acc: 0.5410\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb693fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7669 - acc: 0.3505 - val_loss: 0.8114 - val_acc: 0.2623\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7669 - acc: 0.3505 - val_loss: 0.8113 - val_acc: 0.2623\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7668 - acc: 0.3505 - val_loss: 0.8113 - val_acc: 0.2623\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7668 - acc: 0.3505 - val_loss: 0.8113 - val_acc: 0.2623\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7667 - acc: 0.3505 - val_loss: 0.8112 - val_acc: 0.2623\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7667 - acc: 0.3505 - val_loss: 0.8112 - val_acc: 0.2623\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7667 - acc: 0.3505 - val_loss: 0.8111 - val_acc: 0.2623\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7666 - acc: 0.3505 - val_loss: 0.8111 - val_acc: 0.2623\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7666 - acc: 0.3505 - val_loss: 0.8110 - val_acc: 0.2623\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7665 - acc: 0.3505 - val_loss: 0.8110 - val_acc: 0.2623\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7665 - acc: 0.3505 - val_loss: 0.8109 - val_acc: 0.2623\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7665 - acc: 0.3505 - val_loss: 0.8109 - val_acc: 0.2623\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7664 - acc: 0.3505 - val_loss: 0.8108 - val_acc: 0.2623\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7664 - acc: 0.3505 - val_loss: 0.8108 - val_acc: 0.2623\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7663 - acc: 0.3505 - val_loss: 0.8107 - val_acc: 0.2623\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7663 - acc: 0.3505 - val_loss: 0.8107 - val_acc: 0.2623\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7662 - acc: 0.3505 - val_loss: 0.8106 - val_acc: 0.2623\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7662 - acc: 0.3505 - val_loss: 0.8106 - val_acc: 0.2623\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7662 - acc: 0.3505 - val_loss: 0.8105 - val_acc: 0.2623\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7661 - acc: 0.3505 - val_loss: 0.8105 - val_acc: 0.2623\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c6224c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7185 - acc: 0.4536 - val_loss: 0.7256 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7184 - acc: 0.4536 - val_loss: 0.7255 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7184 - acc: 0.4536 - val_loss: 0.7255 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7184 - acc: 0.4536 - val_loss: 0.7255 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7183 - acc: 0.4536 - val_loss: 0.7254 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7183 - acc: 0.4536 - val_loss: 0.7254 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7183 - acc: 0.4536 - val_loss: 0.7253 - val_acc: 0.4262\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7182 - acc: 0.4536 - val_loss: 0.7253 - val_acc: 0.4262\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7182 - acc: 0.4536 - val_loss: 0.7253 - val_acc: 0.4262\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7181 - acc: 0.4536 - val_loss: 0.7252 - val_acc: 0.4262\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7181 - acc: 0.4536 - val_loss: 0.7252 - val_acc: 0.4262\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7181 - acc: 0.4536 - val_loss: 0.7251 - val_acc: 0.4262\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7180 - acc: 0.4536 - val_loss: 0.7251 - val_acc: 0.4262\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7180 - acc: 0.4536 - val_loss: 0.7251 - val_acc: 0.4262\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7180 - acc: 0.4536 - val_loss: 0.7250 - val_acc: 0.4262\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7179 - acc: 0.4536 - val_loss: 0.7250 - val_acc: 0.4262\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7179 - acc: 0.4536 - val_loss: 0.7249 - val_acc: 0.4262\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7179 - acc: 0.4536 - val_loss: 0.7249 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7178 - acc: 0.4588 - val_loss: 0.7249 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7178 - acc: 0.4588 - val_loss: 0.7248 - val_acc: 0.4262\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac00599d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6936 - acc: 0.5078 - val_loss: 0.7207 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6935 - acc: 0.5078 - val_loss: 0.7206 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6935 - acc: 0.5078 - val_loss: 0.7206 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6934 - acc: 0.5078 - val_loss: 0.7205 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6934 - acc: 0.5078 - val_loss: 0.7205 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6933 - acc: 0.5078 - val_loss: 0.7204 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6933 - acc: 0.5078 - val_loss: 0.7203 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6932 - acc: 0.5078 - val_loss: 0.7203 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6932 - acc: 0.5078 - val_loss: 0.7202 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6931 - acc: 0.5078 - val_loss: 0.7202 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6931 - acc: 0.5078 - val_loss: 0.7201 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6930 - acc: 0.5078 - val_loss: 0.7201 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6930 - acc: 0.5078 - val_loss: 0.7200 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6929 - acc: 0.5078 - val_loss: 0.7199 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6929 - acc: 0.5078 - val_loss: 0.7199 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6928 - acc: 0.5078 - val_loss: 0.7198 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6928 - acc: 0.5078 - val_loss: 0.7198 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6927 - acc: 0.5078 - val_loss: 0.7197 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6927 - acc: 0.5078 - val_loss: 0.7197 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6926 - acc: 0.5078 - val_loss: 0.7196 - val_acc: 0.4918\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab271a310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7013 - acc: 0.5544 - val_loss: 0.7366 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7013 - acc: 0.5544 - val_loss: 0.7366 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7012 - acc: 0.5544 - val_loss: 0.7365 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7012 - acc: 0.5544 - val_loss: 0.7364 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7011 - acc: 0.5544 - val_loss: 0.7364 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7011 - acc: 0.5544 - val_loss: 0.7363 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7010 - acc: 0.5544 - val_loss: 0.7363 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7010 - acc: 0.5544 - val_loss: 0.7362 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7009 - acc: 0.5544 - val_loss: 0.7361 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7009 - acc: 0.5544 - val_loss: 0.7361 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7008 - acc: 0.5544 - val_loss: 0.7360 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7008 - acc: 0.5544 - val_loss: 0.7359 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7007 - acc: 0.5544 - val_loss: 0.7359 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7007 - acc: 0.5544 - val_loss: 0.7358 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7006 - acc: 0.5544 - val_loss: 0.7358 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7006 - acc: 0.5544 - val_loss: 0.7357 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7005 - acc: 0.5544 - val_loss: 0.7356 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7005 - acc: 0.5544 - val_loss: 0.7356 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7004 - acc: 0.5544 - val_loss: 0.7355 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7004 - acc: 0.5544 - val_loss: 0.7355 - val_acc: 0.4754\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c57c820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6480 - acc: 0.6546 - val_loss: 0.6629 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6479 - acc: 0.6546 - val_loss: 0.6628 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6479 - acc: 0.6546 - val_loss: 0.6628 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6479 - acc: 0.6546 - val_loss: 0.6627 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6478 - acc: 0.6546 - val_loss: 0.6627 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6478 - acc: 0.6546 - val_loss: 0.6626 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6477 - acc: 0.6546 - val_loss: 0.6626 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6477 - acc: 0.6546 - val_loss: 0.6625 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6476 - acc: 0.6546 - val_loss: 0.6625 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6476 - acc: 0.6546 - val_loss: 0.6624 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6475 - acc: 0.6546 - val_loss: 0.6623 - val_acc: 0.5738\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6475 - acc: 0.6546 - val_loss: 0.6623 - val_acc: 0.5738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6474 - acc: 0.6546 - val_loss: 0.6622 - val_acc: 0.5738\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6474 - acc: 0.6546 - val_loss: 0.6622 - val_acc: 0.5738\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6473 - acc: 0.6546 - val_loss: 0.6621 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6473 - acc: 0.6546 - val_loss: 0.6621 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6472 - acc: 0.6546 - val_loss: 0.6620 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6472 - acc: 0.6546 - val_loss: 0.6620 - val_acc: 0.5738\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6471 - acc: 0.6546 - val_loss: 0.6619 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6471 - acc: 0.6546 - val_loss: 0.6619 - val_acc: 0.5738\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb4886700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6950 - acc: 0.5515 - val_loss: 0.6995 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6950 - acc: 0.5515 - val_loss: 0.6994 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6949 - acc: 0.5515 - val_loss: 0.6993 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6949 - acc: 0.5515 - val_loss: 0.6993 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6948 - acc: 0.5515 - val_loss: 0.6992 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6948 - acc: 0.5515 - val_loss: 0.6991 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6947 - acc: 0.5515 - val_loss: 0.6991 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6947 - acc: 0.5515 - val_loss: 0.6990 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6946 - acc: 0.5515 - val_loss: 0.6989 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6946 - acc: 0.5515 - val_loss: 0.6989 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6945 - acc: 0.5515 - val_loss: 0.6988 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6945 - acc: 0.5515 - val_loss: 0.6987 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6944 - acc: 0.5515 - val_loss: 0.6987 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6944 - acc: 0.5515 - val_loss: 0.6986 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6943 - acc: 0.5515 - val_loss: 0.6986 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6943 - acc: 0.5515 - val_loss: 0.6985 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6942 - acc: 0.5515 - val_loss: 0.6984 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6942 - acc: 0.5515 - val_loss: 0.6984 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6941 - acc: 0.5515 - val_loss: 0.6983 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6941 - acc: 0.5515 - val_loss: 0.6982 - val_acc: 0.5082\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b240d5280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7004 - acc: 0.4588 - val_loss: 0.6736 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7003 - acc: 0.4588 - val_loss: 0.6735 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7003 - acc: 0.4588 - val_loss: 0.6735 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7002 - acc: 0.4588 - val_loss: 0.6734 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7002 - acc: 0.4588 - val_loss: 0.6734 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7001 - acc: 0.4588 - val_loss: 0.6733 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7000 - acc: 0.4588 - val_loss: 0.6733 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7000 - acc: 0.4588 - val_loss: 0.6732 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6999 - acc: 0.4588 - val_loss: 0.6732 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6999 - acc: 0.4588 - val_loss: 0.6731 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6998 - acc: 0.4588 - val_loss: 0.6731 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6998 - acc: 0.4588 - val_loss: 0.6730 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6997 - acc: 0.4588 - val_loss: 0.6730 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6997 - acc: 0.4588 - val_loss: 0.6729 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6996 - acc: 0.4588 - val_loss: 0.6729 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6996 - acc: 0.4588 - val_loss: 0.6728 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6995 - acc: 0.4588 - val_loss: 0.6728 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6995 - acc: 0.4588 - val_loss: 0.6727 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6994 - acc: 0.4588 - val_loss: 0.6727 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6994 - acc: 0.4588 - val_loss: 0.6726 - val_acc: 0.5574\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb4886310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6901 - acc: 0.5337 - val_loss: 0.6802 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6900 - acc: 0.5337 - val_loss: 0.6801 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6900 - acc: 0.5337 - val_loss: 0.6800 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6899 - acc: 0.5389 - val_loss: 0.6799 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6898 - acc: 0.5389 - val_loss: 0.6799 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6898 - acc: 0.5389 - val_loss: 0.6798 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6897 - acc: 0.5389 - val_loss: 0.6797 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6896 - acc: 0.5389 - val_loss: 0.6797 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6896 - acc: 0.5389 - val_loss: 0.6796 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6895 - acc: 0.5389 - val_loss: 0.6795 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6894 - acc: 0.5389 - val_loss: 0.6794 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6894 - acc: 0.5389 - val_loss: 0.6794 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6893 - acc: 0.5389 - val_loss: 0.6793 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6892 - acc: 0.5389 - val_loss: 0.6792 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6892 - acc: 0.5389 - val_loss: 0.6791 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6891 - acc: 0.5389 - val_loss: 0.6791 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6891 - acc: 0.5389 - val_loss: 0.6790 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6890 - acc: 0.5440 - val_loss: 0.6789 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6889 - acc: 0.5440 - val_loss: 0.6789 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6889 - acc: 0.5440 - val_loss: 0.6788 - val_acc: 0.5574\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b48555af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6770 - acc: 0.6321 - val_loss: 0.7006 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6769 - acc: 0.6321 - val_loss: 0.7005 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6769 - acc: 0.6321 - val_loss: 0.7004 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6768 - acc: 0.6321 - val_loss: 0.7003 - val_acc: 0.4918\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6767 - acc: 0.6321 - val_loss: 0.7002 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6767 - acc: 0.6321 - val_loss: 0.7002 - val_acc: 0.4918\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6766 - acc: 0.6321 - val_loss: 0.7001 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6765 - acc: 0.6321 - val_loss: 0.7000 - val_acc: 0.4918\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6765 - acc: 0.6321 - val_loss: 0.6999 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6764 - acc: 0.6321 - val_loss: 0.6998 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6763 - acc: 0.6321 - val_loss: 0.6998 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6762 - acc: 0.6321 - val_loss: 0.6997 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6762 - acc: 0.6321 - val_loss: 0.6996 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6761 - acc: 0.6321 - val_loss: 0.6995 - val_acc: 0.4918\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6839 - acc: 0.593 - 0s 10ms/step - loss: 0.6760 - acc: 0.6321 - val_loss: 0.6994 - val_acc: 0.4918\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6760 - acc: 0.6321 - val_loss: 0.6994 - val_acc: 0.4918\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6759 - acc: 0.6321 - val_loss: 0.6993 - val_acc: 0.4918\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6758 - acc: 0.6321 - val_loss: 0.6992 - val_acc: 0.4918\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6758 - acc: 0.6321 - val_loss: 0.6991 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6757 - acc: 0.6373 - val_loss: 0.6990 - val_acc: 0.4918\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c7a8670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6946 - acc: 0.5309 - val_loss: 0.7047 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6945 - acc: 0.5309 - val_loss: 0.7046 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6944 - acc: 0.5309 - val_loss: 0.7046 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6944 - acc: 0.5309 - val_loss: 0.7045 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6943 - acc: 0.5309 - val_loss: 0.7044 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6942 - acc: 0.5309 - val_loss: 0.7043 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6941 - acc: 0.5309 - val_loss: 0.7042 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6941 - acc: 0.5309 - val_loss: 0.7041 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6940 - acc: 0.5309 - val_loss: 0.7040 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6939 - acc: 0.5309 - val_loss: 0.7040 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6939 - acc: 0.5309 - val_loss: 0.7039 - val_acc: 0.5082\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6938 - acc: 0.5309 - val_loss: 0.7038 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6937 - acc: 0.5309 - val_loss: 0.7037 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6936 - acc: 0.5309 - val_loss: 0.7036 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6936 - acc: 0.5309 - val_loss: 0.7035 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6935 - acc: 0.5309 - val_loss: 0.7035 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6934 - acc: 0.5309 - val_loss: 0.7034 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6934 - acc: 0.5309 - val_loss: 0.7033 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6933 - acc: 0.5309 - val_loss: 0.7032 - val_acc: 0.5246\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6932 - acc: 0.5309 - val_loss: 0.7031 - val_acc: 0.5246\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb69f31f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7114 - acc: 0.4175 - val_loss: 0.7132 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7113 - acc: 0.4175 - val_loss: 0.7131 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7112 - acc: 0.4175 - val_loss: 0.7130 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7111 - acc: 0.4175 - val_loss: 0.7130 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7111 - acc: 0.4175 - val_loss: 0.7129 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7110 - acc: 0.4175 - val_loss: 0.7128 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7109 - acc: 0.4175 - val_loss: 0.7127 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7108 - acc: 0.4175 - val_loss: 0.7126 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7108 - acc: 0.4175 - val_loss: 0.7125 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7107 - acc: 0.4175 - val_loss: 0.7124 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7106 - acc: 0.4175 - val_loss: 0.7124 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7106 - acc: 0.4175 - val_loss: 0.7123 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7105 - acc: 0.4175 - val_loss: 0.7122 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7104 - acc: 0.4175 - val_loss: 0.7121 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7103 - acc: 0.4175 - val_loss: 0.7120 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7103 - acc: 0.4175 - val_loss: 0.7119 - val_acc: 0.4426\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7102 - acc: 0.4227 - val_loss: 0.7119 - val_acc: 0.4426\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7101 - acc: 0.4227 - val_loss: 0.7118 - val_acc: 0.4426\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7101 - acc: 0.4227 - val_loss: 0.7117 - val_acc: 0.4426\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7100 - acc: 0.4227 - val_loss: 0.7116 - val_acc: 0.4426\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb0058f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7055 - acc: 0.5206 - val_loss: 0.7290 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7054 - acc: 0.5206 - val_loss: 0.7289 - val_acc: 0.4098\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7054 - acc: 0.5206 - val_loss: 0.7288 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7053 - acc: 0.5206 - val_loss: 0.7288 - val_acc: 0.4098\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7052 - acc: 0.5206 - val_loss: 0.7287 - val_acc: 0.4098\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7052 - acc: 0.5206 - val_loss: 0.7286 - val_acc: 0.4098\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7051 - acc: 0.5206 - val_loss: 0.7285 - val_acc: 0.4098\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7050 - acc: 0.5206 - val_loss: 0.7284 - val_acc: 0.4098\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7050 - acc: 0.5206 - val_loss: 0.7284 - val_acc: 0.4098\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7049 - acc: 0.5206 - val_loss: 0.7283 - val_acc: 0.4098\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7048 - acc: 0.5206 - val_loss: 0.7282 - val_acc: 0.4098\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7048 - acc: 0.5206 - val_loss: 0.7281 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7047 - acc: 0.5206 - val_loss: 0.7280 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7046 - acc: 0.5206 - val_loss: 0.7279 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7046 - acc: 0.5206 - val_loss: 0.7279 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7045 - acc: 0.5206 - val_loss: 0.7278 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7044 - acc: 0.5206 - val_loss: 0.7277 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7043 - acc: 0.5206 - val_loss: 0.7276 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7043 - acc: 0.5206 - val_loss: 0.7275 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7042 - acc: 0.5206 - val_loss: 0.7275 - val_acc: 0.4098\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b480ae790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.8001 - acc: 0.4611 - val_loss: 0.8646 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7992 - acc: 0.4611 - val_loss: 0.8637 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7983 - acc: 0.4611 - val_loss: 0.8627 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7975 - acc: 0.4611 - val_loss: 0.8617 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7966 - acc: 0.4663 - val_loss: 0.8607 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7958 - acc: 0.4663 - val_loss: 0.8598 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7950 - acc: 0.4663 - val_loss: 0.8588 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7941 - acc: 0.4663 - val_loss: 0.8579 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7934 - acc: 0.4663 - val_loss: 0.8570 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7926 - acc: 0.4663 - val_loss: 0.8561 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7917 - acc: 0.4663 - val_loss: 0.8551 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7909 - acc: 0.4663 - val_loss: 0.8542 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7901 - acc: 0.4663 - val_loss: 0.8533 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7893 - acc: 0.4663 - val_loss: 0.8524 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7885 - acc: 0.4715 - val_loss: 0.8515 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7877 - acc: 0.4715 - val_loss: 0.8505 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7869 - acc: 0.4819 - val_loss: 0.8496 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7861 - acc: 0.4819 - val_loss: 0.8487 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7853 - acc: 0.4819 - val_loss: 0.8478 - val_acc: 0.4098\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7845 - acc: 0.4870 - val_loss: 0.8469 - val_acc: 0.4098\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3af824de50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7746 - acc: 0.3782 - val_loss: 0.7883 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7737 - acc: 0.3782 - val_loss: 0.7875 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7728 - acc: 0.3782 - val_loss: 0.7866 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7720 - acc: 0.3782 - val_loss: 0.7857 - val_acc: 0.3934\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7711 - acc: 0.3782 - val_loss: 0.7849 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7702 - acc: 0.3782 - val_loss: 0.7840 - val_acc: 0.3934\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7694 - acc: 0.3834 - val_loss: 0.7831 - val_acc: 0.3934\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7685 - acc: 0.3834 - val_loss: 0.7823 - val_acc: 0.3934\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7676 - acc: 0.3834 - val_loss: 0.7814 - val_acc: 0.3934\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7668 - acc: 0.3782 - val_loss: 0.7806 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7660 - acc: 0.3782 - val_loss: 0.7797 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7651 - acc: 0.3782 - val_loss: 0.7789 - val_acc: 0.3934\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7643 - acc: 0.3782 - val_loss: 0.7780 - val_acc: 0.3934\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7634 - acc: 0.3782 - val_loss: 0.7772 - val_acc: 0.3934\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7626 - acc: 0.3782 - val_loss: 0.7764 - val_acc: 0.3934\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7619 - acc: 0.3782 - val_loss: 0.7755 - val_acc: 0.3934\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7610 - acc: 0.3782 - val_loss: 0.7747 - val_acc: 0.3934\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7602 - acc: 0.3834 - val_loss: 0.7739 - val_acc: 0.3934\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7594 - acc: 0.3834 - val_loss: 0.7731 - val_acc: 0.3934\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7586 - acc: 0.3834 - val_loss: 0.7723 - val_acc: 0.3934\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac047c280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6697 - acc: 0.6082 - val_loss: 0.6926 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6690 - acc: 0.6082 - val_loss: 0.6917 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6683 - acc: 0.6134 - val_loss: 0.6907 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6676 - acc: 0.6186 - val_loss: 0.6898 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6669 - acc: 0.6186 - val_loss: 0.6888 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6662 - acc: 0.6186 - val_loss: 0.6879 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6656 - acc: 0.6186 - val_loss: 0.6870 - val_acc: 0.5574\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6649 - acc: 0.6186 - val_loss: 0.6860 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6642 - acc: 0.6186 - val_loss: 0.6851 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6636 - acc: 0.6186 - val_loss: 0.6842 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6629 - acc: 0.6186 - val_loss: 0.6833 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6622 - acc: 0.6186 - val_loss: 0.6824 - val_acc: 0.5574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6616 - acc: 0.6186 - val_loss: 0.6814 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6609 - acc: 0.6186 - val_loss: 0.6805 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6603 - acc: 0.6186 - val_loss: 0.6796 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6596 - acc: 0.6186 - val_loss: 0.6787 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6590 - acc: 0.6186 - val_loss: 0.6778 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6583 - acc: 0.6186 - val_loss: 0.6769 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6576 - acc: 0.6186 - val_loss: 0.6760 - val_acc: 0.5574\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6570 - acc: 0.6237 - val_loss: 0.6751 - val_acc: 0.5574\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac04f0430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 231ms/step - loss: 0.6953 - acc: 0.5670 - val_loss: 0.6228 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6945 - acc: 0.5670 - val_loss: 0.6219 - val_acc: 0.6393\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6937 - acc: 0.5670 - val_loss: 0.6211 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6928 - acc: 0.5670 - val_loss: 0.6203 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6920 - acc: 0.5670 - val_loss: 0.6194 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6912 - acc: 0.5722 - val_loss: 0.6186 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6904 - acc: 0.5722 - val_loss: 0.6177 - val_acc: 0.6393\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6896 - acc: 0.5773 - val_loss: 0.6169 - val_acc: 0.6393\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6888 - acc: 0.5773 - val_loss: 0.6161 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6880 - acc: 0.5773 - val_loss: 0.6153 - val_acc: 0.6393\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6872 - acc: 0.5773 - val_loss: 0.6144 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6864 - acc: 0.5773 - val_loss: 0.6136 - val_acc: 0.6393\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6856 - acc: 0.5773 - val_loss: 0.6128 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6848 - acc: 0.5773 - val_loss: 0.6120 - val_acc: 0.6393\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6840 - acc: 0.5773 - val_loss: 0.6112 - val_acc: 0.6393\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6832 - acc: 0.5825 - val_loss: 0.6104 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6825 - acc: 0.5825 - val_loss: 0.6096 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6817 - acc: 0.5825 - val_loss: 0.6088 - val_acc: 0.6393\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6809 - acc: 0.5876 - val_loss: 0.6080 - val_acc: 0.6393\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6801 - acc: 0.5928 - val_loss: 0.6072 - val_acc: 0.6393\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c7a8ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6940 - acc: 0.5773 - val_loss: 0.6519 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6933 - acc: 0.5773 - val_loss: 0.6511 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6927 - acc: 0.5773 - val_loss: 0.6503 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6920 - acc: 0.5773 - val_loss: 0.6495 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6914 - acc: 0.5773 - val_loss: 0.6488 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6907 - acc: 0.5773 - val_loss: 0.6480 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6900 - acc: 0.5773 - val_loss: 0.6473 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6894 - acc: 0.5773 - val_loss: 0.6465 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6888 - acc: 0.5773 - val_loss: 0.6457 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6882 - acc: 0.5773 - val_loss: 0.6450 - val_acc: 0.6230\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6875 - acc: 0.5773 - val_loss: 0.6442 - val_acc: 0.6230\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6869 - acc: 0.5773 - val_loss: 0.6435 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6862 - acc: 0.5773 - val_loss: 0.6427 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6856 - acc: 0.5825 - val_loss: 0.6420 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6850 - acc: 0.5825 - val_loss: 0.6412 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6843 - acc: 0.5825 - val_loss: 0.6405 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6837 - acc: 0.5825 - val_loss: 0.6397 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6831 - acc: 0.5876 - val_loss: 0.6390 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6825 - acc: 0.5928 - val_loss: 0.6383 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6818 - acc: 0.5979 - val_loss: 0.6375 - val_acc: 0.6230\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb6b279d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6799 - acc: 0.5596 - val_loss: 0.6375 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6788 - acc: 0.5596 - val_loss: 0.6365 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6778 - acc: 0.5596 - val_loss: 0.6355 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6769 - acc: 0.5596 - val_loss: 0.6346 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6759 - acc: 0.5596 - val_loss: 0.6336 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6749 - acc: 0.5596 - val_loss: 0.6327 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6740 - acc: 0.5596 - val_loss: 0.6317 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6730 - acc: 0.5648 - val_loss: 0.6308 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6721 - acc: 0.5648 - val_loss: 0.6299 - val_acc: 0.5738\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.5699 - val_loss: 0.6290 - val_acc: 0.5738\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6702 - acc: 0.5699 - val_loss: 0.6281 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6693 - acc: 0.5751 - val_loss: 0.6272 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6684 - acc: 0.5751 - val_loss: 0.6263 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6675 - acc: 0.5751 - val_loss: 0.6254 - val_acc: 0.5902\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6665 - acc: 0.5751 - val_loss: 0.6245 - val_acc: 0.5902\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6657 - acc: 0.5751 - val_loss: 0.6236 - val_acc: 0.5902\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6647 - acc: 0.5751 - val_loss: 0.6228 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6639 - acc: 0.5751 - val_loss: 0.6219 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6630 - acc: 0.5751 - val_loss: 0.6211 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6621 - acc: 0.5751 - val_loss: 0.6202 - val_acc: 0.5902\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b4852e160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6976 - acc: 0.5492 - val_loss: 0.6919 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6965 - acc: 0.5492 - val_loss: 0.6908 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6953 - acc: 0.5596 - val_loss: 0.6897 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6942 - acc: 0.5596 - val_loss: 0.6886 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6931 - acc: 0.5596 - val_loss: 0.6875 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6921 - acc: 0.5596 - val_loss: 0.6864 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6910 - acc: 0.5596 - val_loss: 0.6853 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6899 - acc: 0.5596 - val_loss: 0.6842 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6889 - acc: 0.5596 - val_loss: 0.6831 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6878 - acc: 0.5596 - val_loss: 0.6820 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6867 - acc: 0.5596 - val_loss: 0.6810 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6857 - acc: 0.5596 - val_loss: 0.6799 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6846 - acc: 0.5596 - val_loss: 0.6788 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6835 - acc: 0.5596 - val_loss: 0.6778 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6825 - acc: 0.5544 - val_loss: 0.6767 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6815 - acc: 0.5699 - val_loss: 0.6756 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6805 - acc: 0.5699 - val_loss: 0.6746 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6795 - acc: 0.5751 - val_loss: 0.6736 - val_acc: 0.5246\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6784 - acc: 0.5751 - val_loss: 0.6725 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6774 - acc: 0.5803 - val_loss: 0.6715 - val_acc: 0.5410\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb69f3670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6448 - acc: 0.5619 - val_loss: 0.6072 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6441 - acc: 0.5619 - val_loss: 0.6066 - val_acc: 0.6066\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6435 - acc: 0.5619 - val_loss: 0.6060 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6429 - acc: 0.5619 - val_loss: 0.6055 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6422 - acc: 0.5670 - val_loss: 0.6049 - val_acc: 0.6066\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6416 - acc: 0.5670 - val_loss: 0.6044 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6410 - acc: 0.5670 - val_loss: 0.6038 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6403 - acc: 0.5722 - val_loss: 0.6032 - val_acc: 0.6066\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6397 - acc: 0.5722 - val_loss: 0.6027 - val_acc: 0.6066\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6390 - acc: 0.5773 - val_loss: 0.6021 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6384 - acc: 0.5773 - val_loss: 0.6015 - val_acc: 0.6066\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6378 - acc: 0.5825 - val_loss: 0.6010 - val_acc: 0.6230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6372 - acc: 0.5825 - val_loss: 0.6004 - val_acc: 0.6230\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6366 - acc: 0.5825 - val_loss: 0.5999 - val_acc: 0.6230\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6359 - acc: 0.5876 - val_loss: 0.5993 - val_acc: 0.6230\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6353 - acc: 0.5876 - val_loss: 0.5987 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6347 - acc: 0.5876 - val_loss: 0.5982 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6341 - acc: 0.5876 - val_loss: 0.5976 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6335 - acc: 0.5928 - val_loss: 0.5970 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6329 - acc: 0.5979 - val_loss: 0.5965 - val_acc: 0.6230\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b480ae3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.8544 - acc: 0.3196 - val_loss: 0.9147 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8529 - acc: 0.3196 - val_loss: 0.9130 - val_acc: 0.3115\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8516 - acc: 0.3196 - val_loss: 0.9113 - val_acc: 0.3115\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8503 - acc: 0.3196 - val_loss: 0.9096 - val_acc: 0.3115\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8490 - acc: 0.3247 - val_loss: 0.9079 - val_acc: 0.3115\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8477 - acc: 0.3299 - val_loss: 0.9063 - val_acc: 0.3115\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8463 - acc: 0.3351 - val_loss: 0.9046 - val_acc: 0.3115\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8450 - acc: 0.3351 - val_loss: 0.9029 - val_acc: 0.3115\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8437 - acc: 0.3402 - val_loss: 0.9013 - val_acc: 0.3115\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8424 - acc: 0.3402 - val_loss: 0.8996 - val_acc: 0.3115\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8411 - acc: 0.3402 - val_loss: 0.8980 - val_acc: 0.3115\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8398 - acc: 0.3454 - val_loss: 0.8963 - val_acc: 0.3115\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8385 - acc: 0.3505 - val_loss: 0.8946 - val_acc: 0.3279\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8372 - acc: 0.3505 - val_loss: 0.8930 - val_acc: 0.3279\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8359 - acc: 0.3557 - val_loss: 0.8914 - val_acc: 0.3279\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8347 - acc: 0.3557 - val_loss: 0.8898 - val_acc: 0.3279\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8333 - acc: 0.3557 - val_loss: 0.8882 - val_acc: 0.3279\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8321 - acc: 0.3557 - val_loss: 0.8866 - val_acc: 0.3279\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8308 - acc: 0.3557 - val_loss: 0.8850 - val_acc: 0.3443\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8296 - acc: 0.3557 - val_loss: 0.8834 - val_acc: 0.3443\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b4871bf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6944 - acc: 0.5206 - val_loss: 0.7129 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6931 - acc: 0.5206 - val_loss: 0.7114 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6918 - acc: 0.5206 - val_loss: 0.7099 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6906 - acc: 0.5206 - val_loss: 0.7084 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6894 - acc: 0.5206 - val_loss: 0.7069 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6882 - acc: 0.5206 - val_loss: 0.7054 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6869 - acc: 0.5206 - val_loss: 0.7039 - val_acc: 0.4590\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6857 - acc: 0.5258 - val_loss: 0.7024 - val_acc: 0.4590\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6844 - acc: 0.5258 - val_loss: 0.7009 - val_acc: 0.4590\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6833 - acc: 0.5206 - val_loss: 0.6994 - val_acc: 0.4590\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6820 - acc: 0.5258 - val_loss: 0.6979 - val_acc: 0.4590\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6808 - acc: 0.5258 - val_loss: 0.6965 - val_acc: 0.4590\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6797 - acc: 0.5258 - val_loss: 0.6950 - val_acc: 0.4590\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6785 - acc: 0.5309 - val_loss: 0.6935 - val_acc: 0.4590\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6773 - acc: 0.5309 - val_loss: 0.6920 - val_acc: 0.4590\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6761 - acc: 0.5309 - val_loss: 0.6906 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6749 - acc: 0.5361 - val_loss: 0.6892 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6738 - acc: 0.5464 - val_loss: 0.6877 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6726 - acc: 0.5515 - val_loss: 0.6863 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6715 - acc: 0.5515 - val_loss: 0.6849 - val_acc: 0.4754\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c6229d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7186 - acc: 0.5181 - val_loss: 0.7429 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7168 - acc: 0.5181 - val_loss: 0.7406 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7151 - acc: 0.5181 - val_loss: 0.7384 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7132 - acc: 0.5233 - val_loss: 0.7362 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7116 - acc: 0.5337 - val_loss: 0.7340 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7098 - acc: 0.5337 - val_loss: 0.7318 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7082 - acc: 0.5440 - val_loss: 0.7297 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7064 - acc: 0.5492 - val_loss: 0.7276 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7048 - acc: 0.5596 - val_loss: 0.7255 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7030 - acc: 0.5596 - val_loss: 0.7234 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7013 - acc: 0.5596 - val_loss: 0.7213 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6997 - acc: 0.5596 - val_loss: 0.7192 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6980 - acc: 0.5699 - val_loss: 0.7172 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6964 - acc: 0.5751 - val_loss: 0.7151 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6948 - acc: 0.5751 - val_loss: 0.7131 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6931 - acc: 0.5751 - val_loss: 0.7110 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6915 - acc: 0.5751 - val_loss: 0.7090 - val_acc: 0.5902\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6899 - acc: 0.5803 - val_loss: 0.7070 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6883 - acc: 0.5855 - val_loss: 0.7051 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6867 - acc: 0.5855 - val_loss: 0.7031 - val_acc: 0.5902\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b48555280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8088 - acc: 0.4041 - val_loss: 0.8444 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8069 - acc: 0.4041 - val_loss: 0.8419 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8050 - acc: 0.4041 - val_loss: 0.8394 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8030 - acc: 0.4041 - val_loss: 0.8370 - val_acc: 0.3607\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8012 - acc: 0.4093 - val_loss: 0.8346 - val_acc: 0.3607\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7993 - acc: 0.4093 - val_loss: 0.8322 - val_acc: 0.3607\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7975 - acc: 0.4197 - val_loss: 0.8298 - val_acc: 0.3607\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7956 - acc: 0.4197 - val_loss: 0.8275 - val_acc: 0.3770\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7937 - acc: 0.4249 - val_loss: 0.8251 - val_acc: 0.3770\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7920 - acc: 0.4301 - val_loss: 0.8227 - val_acc: 0.3770\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7901 - acc: 0.4301 - val_loss: 0.8204 - val_acc: 0.3770\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7883 - acc: 0.4301 - val_loss: 0.8181 - val_acc: 0.4098\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7865 - acc: 0.4352 - val_loss: 0.8157 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7847 - acc: 0.4352 - val_loss: 0.8134 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7830 - acc: 0.4352 - val_loss: 0.8110 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7812 - acc: 0.4404 - val_loss: 0.8087 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7794 - acc: 0.4404 - val_loss: 0.8064 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7776 - acc: 0.4404 - val_loss: 0.8042 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7759 - acc: 0.4404 - val_loss: 0.8019 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7742 - acc: 0.4404 - val_loss: 0.7996 - val_acc: 0.4262\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac022c430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.8000 - acc: 0.3918 - val_loss: 0.8401 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7979 - acc: 0.3918 - val_loss: 0.8376 - val_acc: 0.3115\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7959 - acc: 0.3918 - val_loss: 0.8350 - val_acc: 0.3115\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7938 - acc: 0.3969 - val_loss: 0.8325 - val_acc: 0.3115\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7917 - acc: 0.3969 - val_loss: 0.8301 - val_acc: 0.3115\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7898 - acc: 0.4021 - val_loss: 0.8276 - val_acc: 0.3115\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7878 - acc: 0.4021 - val_loss: 0.8251 - val_acc: 0.3115\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7857 - acc: 0.4072 - val_loss: 0.8227 - val_acc: 0.3443\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7838 - acc: 0.4124 - val_loss: 0.8202 - val_acc: 0.3443\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7818 - acc: 0.4124 - val_loss: 0.8177 - val_acc: 0.3443\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7797 - acc: 0.4124 - val_loss: 0.8152 - val_acc: 0.3443\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7777 - acc: 0.4175 - val_loss: 0.8128 - val_acc: 0.3607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7758 - acc: 0.4227 - val_loss: 0.8103 - val_acc: 0.3770\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7738 - acc: 0.4278 - val_loss: 0.8079 - val_acc: 0.3770\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7717 - acc: 0.4278 - val_loss: 0.8054 - val_acc: 0.3770\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7697 - acc: 0.4330 - val_loss: 0.8029 - val_acc: 0.3770\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7678 - acc: 0.4330 - val_loss: 0.8005 - val_acc: 0.3770\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7658 - acc: 0.4433 - val_loss: 0.7980 - val_acc: 0.3770\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7639 - acc: 0.4381 - val_loss: 0.7955 - val_acc: 0.3770\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7618 - acc: 0.4381 - val_loss: 0.7931 - val_acc: 0.3770\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c342e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7891 - acc: 0.3969 - val_loss: 0.7862 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7871 - acc: 0.4021 - val_loss: 0.7838 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7853 - acc: 0.4021 - val_loss: 0.7814 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7833 - acc: 0.4124 - val_loss: 0.7790 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7815 - acc: 0.4124 - val_loss: 0.7766 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7797 - acc: 0.4175 - val_loss: 0.7742 - val_acc: 0.4590\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7778 - acc: 0.4227 - val_loss: 0.7718 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7759 - acc: 0.4227 - val_loss: 0.7695 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7740 - acc: 0.4278 - val_loss: 0.7672 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7722 - acc: 0.4278 - val_loss: 0.7648 - val_acc: 0.4754\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7705 - acc: 0.4278 - val_loss: 0.7625 - val_acc: 0.4754\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7685 - acc: 0.4330 - val_loss: 0.7602 - val_acc: 0.4754\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7667 - acc: 0.4330 - val_loss: 0.7579 - val_acc: 0.4754\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7649 - acc: 0.4330 - val_loss: 0.7556 - val_acc: 0.4754\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7632 - acc: 0.4330 - val_loss: 0.7534 - val_acc: 0.4754\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7613 - acc: 0.4330 - val_loss: 0.7511 - val_acc: 0.4754\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7595 - acc: 0.4278 - val_loss: 0.7489 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7577 - acc: 0.4278 - val_loss: 0.7467 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7560 - acc: 0.4278 - val_loss: 0.7445 - val_acc: 0.4754\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7541 - acc: 0.4381 - val_loss: 0.7422 - val_acc: 0.4754\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac04a74c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.8377 - acc: 0.4278 - val_loss: 0.9285 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8356 - acc: 0.4381 - val_loss: 0.9257 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8335 - acc: 0.4381 - val_loss: 0.9229 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8315 - acc: 0.4381 - val_loss: 0.9202 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8295 - acc: 0.4381 - val_loss: 0.9175 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8275 - acc: 0.4381 - val_loss: 0.9148 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8254 - acc: 0.4433 - val_loss: 0.9122 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8235 - acc: 0.4433 - val_loss: 0.9095 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8215 - acc: 0.4433 - val_loss: 0.9069 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8196 - acc: 0.4485 - val_loss: 0.9043 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8176 - acc: 0.4485 - val_loss: 0.9016 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8156 - acc: 0.4536 - val_loss: 0.8990 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8138 - acc: 0.4536 - val_loss: 0.8964 - val_acc: 0.5082\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8118 - acc: 0.4536 - val_loss: 0.8937 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8099 - acc: 0.4536 - val_loss: 0.8911 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8080 - acc: 0.4536 - val_loss: 0.8886 - val_acc: 0.5082\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8061 - acc: 0.4588 - val_loss: 0.8861 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8043 - acc: 0.4588 - val_loss: 0.8835 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8024 - acc: 0.4639 - val_loss: 0.8810 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8005 - acc: 0.4639 - val_loss: 0.8786 - val_acc: 0.5082\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac06b9820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7620 - acc: 0.5181 - val_loss: 0.7306 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7585 - acc: 0.5181 - val_loss: 0.7271 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7553 - acc: 0.5181 - val_loss: 0.7236 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7519 - acc: 0.5181 - val_loss: 0.7202 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7487 - acc: 0.5181 - val_loss: 0.7168 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7455 - acc: 0.5233 - val_loss: 0.7134 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7423 - acc: 0.5233 - val_loss: 0.7101 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7393 - acc: 0.5285 - val_loss: 0.7067 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7360 - acc: 0.5337 - val_loss: 0.7035 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7330 - acc: 0.5337 - val_loss: 0.7002 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7299 - acc: 0.5337 - val_loss: 0.6970 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7270 - acc: 0.5337 - val_loss: 0.6938 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7239 - acc: 0.5337 - val_loss: 0.6906 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7209 - acc: 0.5337 - val_loss: 0.6874 - val_acc: 0.5410\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7182 - acc: 0.5337 - val_loss: 0.6843 - val_acc: 0.5410\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7152 - acc: 0.5337 - val_loss: 0.6813 - val_acc: 0.5410\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7123 - acc: 0.5389 - val_loss: 0.6782 - val_acc: 0.5574\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7095 - acc: 0.5389 - val_loss: 0.6753 - val_acc: 0.5574\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7068 - acc: 0.5389 - val_loss: 0.6723 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7041 - acc: 0.5389 - val_loss: 0.6694 - val_acc: 0.5738\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac0742e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6989 - acc: 0.5389 - val_loss: 0.7211 - val_acc: 0.4918\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6965 - acc: 0.5440 - val_loss: 0.7185 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6943 - acc: 0.5492 - val_loss: 0.7160 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6921 - acc: 0.5492 - val_loss: 0.7135 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6900 - acc: 0.5544 - val_loss: 0.7110 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - acc: 0.5596 - val_loss: 0.7086 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6856 - acc: 0.5596 - val_loss: 0.7062 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6834 - acc: 0.5596 - val_loss: 0.7038 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6813 - acc: 0.5648 - val_loss: 0.7014 - val_acc: 0.5246\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6792 - acc: 0.5855 - val_loss: 0.6990 - val_acc: 0.5246\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6771 - acc: 0.5959 - val_loss: 0.6966 - val_acc: 0.5246\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6750 - acc: 0.5959 - val_loss: 0.6943 - val_acc: 0.5246\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6728 - acc: 0.6062 - val_loss: 0.6919 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6062 - val_loss: 0.6895 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6687 - acc: 0.6062 - val_loss: 0.6872 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6667 - acc: 0.6062 - val_loss: 0.6849 - val_acc: 0.5738\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6646 - acc: 0.6062 - val_loss: 0.6826 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6626 - acc: 0.6166 - val_loss: 0.6803 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6605 - acc: 0.6218 - val_loss: 0.6780 - val_acc: 0.6066\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6586 - acc: 0.6373 - val_loss: 0.6757 - val_acc: 0.6066\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb6b27a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.8343 - acc: 0.3454 - val_loss: 0.8661 - val_acc: 0.3607\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8305 - acc: 0.3557 - val_loss: 0.8620 - val_acc: 0.3607\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8265 - acc: 0.3608 - val_loss: 0.8580 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8228 - acc: 0.3711 - val_loss: 0.8540 - val_acc: 0.3607\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8190 - acc: 0.3763 - val_loss: 0.8501 - val_acc: 0.3443\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8152 - acc: 0.3763 - val_loss: 0.8462 - val_acc: 0.3770\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8114 - acc: 0.3866 - val_loss: 0.8423 - val_acc: 0.3770\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8076 - acc: 0.3866 - val_loss: 0.8384 - val_acc: 0.3770\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8041 - acc: 0.3866 - val_loss: 0.8346 - val_acc: 0.3770\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8006 - acc: 0.3918 - val_loss: 0.8308 - val_acc: 0.3934\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7968 - acc: 0.3918 - val_loss: 0.8270 - val_acc: 0.3934\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7933 - acc: 0.3918 - val_loss: 0.8232 - val_acc: 0.3934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7898 - acc: 0.3918 - val_loss: 0.8195 - val_acc: 0.4098\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7863 - acc: 0.3969 - val_loss: 0.8158 - val_acc: 0.4098\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7827 - acc: 0.3969 - val_loss: 0.8121 - val_acc: 0.4098\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7793 - acc: 0.4021 - val_loss: 0.8084 - val_acc: 0.4098\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7759 - acc: 0.4021 - val_loss: 0.8047 - val_acc: 0.4098\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7727 - acc: 0.4227 - val_loss: 0.8011 - val_acc: 0.4262\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7691 - acc: 0.4330 - val_loss: 0.7975 - val_acc: 0.4262\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7659 - acc: 0.4381 - val_loss: 0.7939 - val_acc: 0.4426\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac04a7ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7205 - acc: 0.4845 - val_loss: 0.6732 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7182 - acc: 0.4948 - val_loss: 0.6709 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7161 - acc: 0.5000 - val_loss: 0.6687 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7138 - acc: 0.5000 - val_loss: 0.6665 - val_acc: 0.5902\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7118 - acc: 0.5000 - val_loss: 0.6643 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7096 - acc: 0.4948 - val_loss: 0.6622 - val_acc: 0.5902\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7074 - acc: 0.5103 - val_loss: 0.6600 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7054 - acc: 0.5206 - val_loss: 0.6579 - val_acc: 0.6393\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7033 - acc: 0.5258 - val_loss: 0.6557 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7012 - acc: 0.5258 - val_loss: 0.6536 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6991 - acc: 0.5309 - val_loss: 0.6515 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6970 - acc: 0.5361 - val_loss: 0.6494 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6950 - acc: 0.5412 - val_loss: 0.6473 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6930 - acc: 0.5412 - val_loss: 0.6452 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6909 - acc: 0.5515 - val_loss: 0.6432 - val_acc: 0.6721\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6889 - acc: 0.5619 - val_loss: 0.6411 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6869 - acc: 0.5670 - val_loss: 0.6390 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6849 - acc: 0.5773 - val_loss: 0.6370 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6829 - acc: 0.5722 - val_loss: 0.6349 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6809 - acc: 0.5670 - val_loss: 0.6329 - val_acc: 0.6885\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3af84654c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7464 - acc: 0.5619 - val_loss: 0.7296 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7440 - acc: 0.5567 - val_loss: 0.7266 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7413 - acc: 0.5619 - val_loss: 0.7237 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7390 - acc: 0.5619 - val_loss: 0.7208 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7365 - acc: 0.5670 - val_loss: 0.7179 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7343 - acc: 0.5670 - val_loss: 0.7151 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7318 - acc: 0.5670 - val_loss: 0.7124 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7295 - acc: 0.5670 - val_loss: 0.7096 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7271 - acc: 0.5670 - val_loss: 0.7069 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7248 - acc: 0.5722 - val_loss: 0.7042 - val_acc: 0.6393\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7224 - acc: 0.5722 - val_loss: 0.7015 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7201 - acc: 0.5722 - val_loss: 0.6988 - val_acc: 0.6393\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7179 - acc: 0.5722 - val_loss: 0.6961 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7155 - acc: 0.5722 - val_loss: 0.6934 - val_acc: 0.6393\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7133 - acc: 0.5825 - val_loss: 0.6907 - val_acc: 0.6393\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7110 - acc: 0.5876 - val_loss: 0.6880 - val_acc: 0.6393\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7087 - acc: 0.5876 - val_loss: 0.6854 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7064 - acc: 0.5876 - val_loss: 0.6828 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7043 - acc: 0.5928 - val_loss: 0.6802 - val_acc: 0.6557\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7020 - acc: 0.5928 - val_loss: 0.6776 - val_acc: 0.6557\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c57c700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6770 - acc: 0.5440 - val_loss: 0.6694 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6731 - acc: 0.5492 - val_loss: 0.6657 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6697 - acc: 0.5492 - val_loss: 0.6621 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6660 - acc: 0.5492 - val_loss: 0.6585 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6625 - acc: 0.5596 - val_loss: 0.6549 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6590 - acc: 0.5648 - val_loss: 0.6514 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6555 - acc: 0.5648 - val_loss: 0.6478 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6521 - acc: 0.5803 - val_loss: 0.6443 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6488 - acc: 0.5751 - val_loss: 0.6408 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6455 - acc: 0.5803 - val_loss: 0.6374 - val_acc: 0.6066\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6420 - acc: 0.5855 - val_loss: 0.6340 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6388 - acc: 0.5907 - val_loss: 0.6307 - val_acc: 0.6557\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6356 - acc: 0.6010 - val_loss: 0.6274 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6324 - acc: 0.6114 - val_loss: 0.6241 - val_acc: 0.6721\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6292 - acc: 0.6114 - val_loss: 0.6208 - val_acc: 0.6885\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6261 - acc: 0.6166 - val_loss: 0.6176 - val_acc: 0.6721\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6230 - acc: 0.6425 - val_loss: 0.6143 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6199 - acc: 0.6528 - val_loss: 0.6112 - val_acc: 0.6885\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6171 - acc: 0.6580 - val_loss: 0.6080 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6140 - acc: 0.6736 - val_loss: 0.6050 - val_acc: 0.7049\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c6220d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6678 - acc: 0.6528 - val_loss: 0.6683 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6647 - acc: 0.6580 - val_loss: 0.6649 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6617 - acc: 0.6580 - val_loss: 0.6616 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6588 - acc: 0.6580 - val_loss: 0.6583 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6560 - acc: 0.6788 - val_loss: 0.6550 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6531 - acc: 0.6839 - val_loss: 0.6518 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6504 - acc: 0.6891 - val_loss: 0.6487 - val_acc: 0.6885\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6476 - acc: 0.6891 - val_loss: 0.6455 - val_acc: 0.6885\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6448 - acc: 0.6943 - val_loss: 0.6424 - val_acc: 0.7049\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6421 - acc: 0.7150 - val_loss: 0.6394 - val_acc: 0.7049\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6395 - acc: 0.7150 - val_loss: 0.6363 - val_acc: 0.7049\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6369 - acc: 0.7254 - val_loss: 0.6333 - val_acc: 0.7049\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6343 - acc: 0.7306 - val_loss: 0.6303 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6317 - acc: 0.7306 - val_loss: 0.6274 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6291 - acc: 0.7306 - val_loss: 0.6244 - val_acc: 0.7049\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6265 - acc: 0.7254 - val_loss: 0.6215 - val_acc: 0.7049\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6241 - acc: 0.7254 - val_loss: 0.6186 - val_acc: 0.7049\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6215 - acc: 0.7254 - val_loss: 0.6157 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6191 - acc: 0.7254 - val_loss: 0.6129 - val_acc: 0.7049\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6166 - acc: 0.7202 - val_loss: 0.6101 - val_acc: 0.7049\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb693f790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7135 - acc: 0.4639 - val_loss: 0.7220 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7101 - acc: 0.4639 - val_loss: 0.7182 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7070 - acc: 0.4691 - val_loss: 0.7145 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7039 - acc: 0.4742 - val_loss: 0.7109 - val_acc: 0.5082\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7009 - acc: 0.4691 - val_loss: 0.7073 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6976 - acc: 0.4742 - val_loss: 0.7038 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6946 - acc: 0.4845 - val_loss: 0.7003 - val_acc: 0.4918\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6916 - acc: 0.4845 - val_loss: 0.6969 - val_acc: 0.5082\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6887 - acc: 0.4845 - val_loss: 0.6934 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6856 - acc: 0.4845 - val_loss: 0.6900 - val_acc: 0.5082\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6827 - acc: 0.4845 - val_loss: 0.6866 - val_acc: 0.5082\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6797 - acc: 0.4845 - val_loss: 0.6832 - val_acc: 0.5082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6769 - acc: 0.4948 - val_loss: 0.6798 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6739 - acc: 0.5000 - val_loss: 0.6765 - val_acc: 0.5246\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.5052 - val_loss: 0.6732 - val_acc: 0.5246\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6683 - acc: 0.5155 - val_loss: 0.6699 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6654 - acc: 0.5258 - val_loss: 0.6667 - val_acc: 0.5246\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6627 - acc: 0.5309 - val_loss: 0.6635 - val_acc: 0.5410\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6599 - acc: 0.5412 - val_loss: 0.6603 - val_acc: 0.5410\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6572 - acc: 0.5464 - val_loss: 0.6571 - val_acc: 0.5574\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b480aef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7012 - acc: 0.5670 - val_loss: 0.7427 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6978 - acc: 0.5722 - val_loss: 0.7378 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6945 - acc: 0.5722 - val_loss: 0.7330 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6910 - acc: 0.5722 - val_loss: 0.7283 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6879 - acc: 0.5722 - val_loss: 0.7236 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6845 - acc: 0.5722 - val_loss: 0.7190 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6814 - acc: 0.5722 - val_loss: 0.7144 - val_acc: 0.5246\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6780 - acc: 0.5722 - val_loss: 0.7099 - val_acc: 0.5246\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6749 - acc: 0.5722 - val_loss: 0.7054 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6718 - acc: 0.5670 - val_loss: 0.7009 - val_acc: 0.5410\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6688 - acc: 0.5670 - val_loss: 0.6965 - val_acc: 0.5410\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6655 - acc: 0.5670 - val_loss: 0.6921 - val_acc: 0.5410\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6625 - acc: 0.5722 - val_loss: 0.6878 - val_acc: 0.5410\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6595 - acc: 0.5670 - val_loss: 0.6836 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6564 - acc: 0.5670 - val_loss: 0.6794 - val_acc: 0.5574\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6536 - acc: 0.5670 - val_loss: 0.6753 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6504 - acc: 0.5670 - val_loss: 0.6712 - val_acc: 0.5738\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6477 - acc: 0.5722 - val_loss: 0.6671 - val_acc: 0.5902\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6448 - acc: 0.5773 - val_loss: 0.6630 - val_acc: 0.5902\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6419 - acc: 0.5825 - val_loss: 0.6591 - val_acc: 0.5902\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b480ae430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7423 - acc: 0.3660 - val_loss: 0.7189 - val_acc: 0.3934\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7386 - acc: 0.3711 - val_loss: 0.7149 - val_acc: 0.3934\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7349 - acc: 0.3814 - val_loss: 0.7110 - val_acc: 0.4098\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7312 - acc: 0.3918 - val_loss: 0.7071 - val_acc: 0.4262\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7277 - acc: 0.4072 - val_loss: 0.7033 - val_acc: 0.4426\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7241 - acc: 0.4227 - val_loss: 0.6995 - val_acc: 0.4426\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7205 - acc: 0.4278 - val_loss: 0.6958 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7171 - acc: 0.4536 - val_loss: 0.6921 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7136 - acc: 0.4588 - val_loss: 0.6885 - val_acc: 0.4754\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7102 - acc: 0.4742 - val_loss: 0.6848 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7069 - acc: 0.4845 - val_loss: 0.6813 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7036 - acc: 0.4845 - val_loss: 0.6777 - val_acc: 0.5082\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7002 - acc: 0.5052 - val_loss: 0.6742 - val_acc: 0.5574\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6970 - acc: 0.5258 - val_loss: 0.6707 - val_acc: 0.5574\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6938 - acc: 0.5361 - val_loss: 0.6673 - val_acc: 0.5738\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6906 - acc: 0.5464 - val_loss: 0.6639 - val_acc: 0.6066\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6874 - acc: 0.5412 - val_loss: 0.6606 - val_acc: 0.6066\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6843 - acc: 0.5515 - val_loss: 0.6573 - val_acc: 0.6230\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6812 - acc: 0.5773 - val_loss: 0.6541 - val_acc: 0.6230\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6781 - acc: 0.5876 - val_loss: 0.6508 - val_acc: 0.6230\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3af80bac10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7144 - acc: 0.4819 - val_loss: 0.7035 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7089 - acc: 0.5130 - val_loss: 0.6974 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7035 - acc: 0.5440 - val_loss: 0.6913 - val_acc: 0.5246\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6984 - acc: 0.5544 - val_loss: 0.6852 - val_acc: 0.5574\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6931 - acc: 0.5907 - val_loss: 0.6792 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6879 - acc: 0.6166 - val_loss: 0.6733 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6828 - acc: 0.6425 - val_loss: 0.6675 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6779 - acc: 0.6580 - val_loss: 0.6618 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6730 - acc: 0.6736 - val_loss: 0.6562 - val_acc: 0.6230\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6681 - acc: 0.6632 - val_loss: 0.6508 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6633 - acc: 0.6736 - val_loss: 0.6454 - val_acc: 0.6721\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6588 - acc: 0.6788 - val_loss: 0.6401 - val_acc: 0.6885\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6540 - acc: 0.6891 - val_loss: 0.6349 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6494 - acc: 0.6995 - val_loss: 0.6298 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6448 - acc: 0.7098 - val_loss: 0.6247 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6405 - acc: 0.7254 - val_loss: 0.6197 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6360 - acc: 0.7358 - val_loss: 0.6148 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6317 - acc: 0.7409 - val_loss: 0.6100 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6274 - acc: 0.7513 - val_loss: 0.6052 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6231 - acc: 0.7617 - val_loss: 0.6005 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3af80ba280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7008 - acc: 0.4456 - val_loss: 0.7052 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6957 - acc: 0.4974 - val_loss: 0.6999 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6907 - acc: 0.5078 - val_loss: 0.6945 - val_acc: 0.4918\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6860 - acc: 0.5285 - val_loss: 0.6891 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6811 - acc: 0.5751 - val_loss: 0.6838 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6765 - acc: 0.5907 - val_loss: 0.6785 - val_acc: 0.5574\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6717 - acc: 0.6062 - val_loss: 0.6733 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6670 - acc: 0.6218 - val_loss: 0.6682 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6625 - acc: 0.6218 - val_loss: 0.6631 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6580 - acc: 0.6528 - val_loss: 0.6580 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6536 - acc: 0.6736 - val_loss: 0.6530 - val_acc: 0.6557\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6491 - acc: 0.6736 - val_loss: 0.6480 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6448 - acc: 0.6788 - val_loss: 0.6431 - val_acc: 0.7213\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6404 - acc: 0.6839 - val_loss: 0.6383 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6362 - acc: 0.6839 - val_loss: 0.6336 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6321 - acc: 0.6995 - val_loss: 0.6290 - val_acc: 0.7377\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6279 - acc: 0.6995 - val_loss: 0.6244 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6238 - acc: 0.7098 - val_loss: 0.6199 - val_acc: 0.7541\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6198 - acc: 0.7254 - val_loss: 0.6154 - val_acc: 0.7541\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6159 - acc: 0.7254 - val_loss: 0.6110 - val_acc: 0.7541\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb48dd700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7296 - acc: 0.3557 - val_loss: 0.7372 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7246 - acc: 0.3763 - val_loss: 0.7316 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7196 - acc: 0.4021 - val_loss: 0.7262 - val_acc: 0.4262\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7145 - acc: 0.4330 - val_loss: 0.7208 - val_acc: 0.4426\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7099 - acc: 0.4639 - val_loss: 0.7155 - val_acc: 0.4754\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7051 - acc: 0.5000 - val_loss: 0.7102 - val_acc: 0.5082\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7003 - acc: 0.5309 - val_loss: 0.7050 - val_acc: 0.5082\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6957 - acc: 0.5515 - val_loss: 0.6998 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6912 - acc: 0.5825 - val_loss: 0.6946 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6866 - acc: 0.6031 - val_loss: 0.6895 - val_acc: 0.6393\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6821 - acc: 0.6186 - val_loss: 0.6845 - val_acc: 0.6393\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6778 - acc: 0.6237 - val_loss: 0.6796 - val_acc: 0.6557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6733 - acc: 0.6392 - val_loss: 0.6747 - val_acc: 0.6557\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6689 - acc: 0.6598 - val_loss: 0.6699 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6648 - acc: 0.6649 - val_loss: 0.6651 - val_acc: 0.6885\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6606 - acc: 0.6701 - val_loss: 0.6605 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6564 - acc: 0.6856 - val_loss: 0.6558 - val_acc: 0.6885\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6523 - acc: 0.6907 - val_loss: 0.6512 - val_acc: 0.7049\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6483 - acc: 0.6907 - val_loss: 0.6466 - val_acc: 0.7213\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6442 - acc: 0.7010 - val_loss: 0.6421 - val_acc: 0.7377\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c7a81f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6557 - acc: 0.7165 - val_loss: 0.6526 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6515 - acc: 0.7216 - val_loss: 0.6480 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6476 - acc: 0.7423 - val_loss: 0.6434 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6437 - acc: 0.7371 - val_loss: 0.6389 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6401 - acc: 0.7371 - val_loss: 0.6345 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6362 - acc: 0.7526 - val_loss: 0.6301 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6325 - acc: 0.7629 - val_loss: 0.6257 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6288 - acc: 0.7629 - val_loss: 0.6214 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6252 - acc: 0.7680 - val_loss: 0.6171 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6218 - acc: 0.7732 - val_loss: 0.6129 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6182 - acc: 0.7732 - val_loss: 0.6087 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6147 - acc: 0.7784 - val_loss: 0.6046 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6113 - acc: 0.7835 - val_loss: 0.6006 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6080 - acc: 0.7938 - val_loss: 0.5967 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6046 - acc: 0.7990 - val_loss: 0.5928 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6015 - acc: 0.7938 - val_loss: 0.5890 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5983 - acc: 0.7887 - val_loss: 0.5853 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5951 - acc: 0.7887 - val_loss: 0.5816 - val_acc: 0.7869\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5920 - acc: 0.7990 - val_loss: 0.5780 - val_acc: 0.7869\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5890 - acc: 0.7990 - val_loss: 0.5744 - val_acc: 0.7869\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c5d0c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6925 - acc: 0.5206 - val_loss: 0.6876 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6877 - acc: 0.5464 - val_loss: 0.6821 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6830 - acc: 0.5567 - val_loss: 0.6768 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6782 - acc: 0.5876 - val_loss: 0.6715 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6737 - acc: 0.6237 - val_loss: 0.6661 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6693 - acc: 0.6443 - val_loss: 0.6609 - val_acc: 0.6393\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6648 - acc: 0.6546 - val_loss: 0.6556 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6603 - acc: 0.6649 - val_loss: 0.6505 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6560 - acc: 0.6701 - val_loss: 0.6454 - val_acc: 0.6885\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6517 - acc: 0.6701 - val_loss: 0.6404 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6474 - acc: 0.6753 - val_loss: 0.6355 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6431 - acc: 0.6856 - val_loss: 0.6306 - val_acc: 0.7541\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6390 - acc: 0.6959 - val_loss: 0.6258 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6349 - acc: 0.7010 - val_loss: 0.6211 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6308 - acc: 0.7062 - val_loss: 0.6165 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6269 - acc: 0.7113 - val_loss: 0.6120 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6231 - acc: 0.7268 - val_loss: 0.6075 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6191 - acc: 0.7268 - val_loss: 0.6031 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6154 - acc: 0.7320 - val_loss: 0.5987 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6116 - acc: 0.7371 - val_loss: 0.5944 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb48bc040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6967 - acc: 0.4767 - val_loss: 0.6835 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6894 - acc: 0.5130 - val_loss: 0.6754 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6820 - acc: 0.5751 - val_loss: 0.6674 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6748 - acc: 0.6166 - val_loss: 0.6596 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6679 - acc: 0.6580 - val_loss: 0.6519 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6611 - acc: 0.6839 - val_loss: 0.6445 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6544 - acc: 0.6943 - val_loss: 0.6371 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6479 - acc: 0.7150 - val_loss: 0.6299 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6415 - acc: 0.7150 - val_loss: 0.6228 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6353 - acc: 0.7358 - val_loss: 0.6159 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6292 - acc: 0.7668 - val_loss: 0.6092 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6232 - acc: 0.7720 - val_loss: 0.6026 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6174 - acc: 0.7772 - val_loss: 0.5962 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6116 - acc: 0.7772 - val_loss: 0.5899 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6061 - acc: 0.7824 - val_loss: 0.5838 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6005 - acc: 0.7876 - val_loss: 0.5779 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5952 - acc: 0.7927 - val_loss: 0.5720 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5901 - acc: 0.7927 - val_loss: 0.5663 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5847 - acc: 0.8031 - val_loss: 0.5608 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5799 - acc: 0.8083 - val_loss: 0.5554 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb69f35e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6914 - acc: 0.4974 - val_loss: 0.6957 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6839 - acc: 0.5440 - val_loss: 0.6876 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6769 - acc: 0.5803 - val_loss: 0.6796 - val_acc: 0.5574\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6697 - acc: 0.6166 - val_loss: 0.6720 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6628 - acc: 0.6528 - val_loss: 0.6644 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6561 - acc: 0.6736 - val_loss: 0.6569 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6495 - acc: 0.7150 - val_loss: 0.6496 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6429 - acc: 0.7306 - val_loss: 0.6424 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6367 - acc: 0.7461 - val_loss: 0.6353 - val_acc: 0.8361\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6304 - acc: 0.7461 - val_loss: 0.6284 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6242 - acc: 0.7617 - val_loss: 0.6216 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6183 - acc: 0.7668 - val_loss: 0.6150 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6124 - acc: 0.7668 - val_loss: 0.6084 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6069 - acc: 0.7772 - val_loss: 0.6020 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6011 - acc: 0.8083 - val_loss: 0.5957 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5957 - acc: 0.7979 - val_loss: 0.5895 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5903 - acc: 0.7979 - val_loss: 0.5834 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5850 - acc: 0.7979 - val_loss: 0.5775 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5799 - acc: 0.8031 - val_loss: 0.5717 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5749 - acc: 0.8135 - val_loss: 0.5660 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b480ae280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7012 - acc: 0.4175 - val_loss: 0.7040 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6939 - acc: 0.4948 - val_loss: 0.6959 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6870 - acc: 0.5309 - val_loss: 0.6879 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6802 - acc: 0.5979 - val_loss: 0.6801 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6735 - acc: 0.6495 - val_loss: 0.6723 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6670 - acc: 0.6804 - val_loss: 0.6647 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6607 - acc: 0.7010 - val_loss: 0.6573 - val_acc: 0.6230\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6542 - acc: 0.7371 - val_loss: 0.6500 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6480 - acc: 0.7474 - val_loss: 0.6429 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6421 - acc: 0.7526 - val_loss: 0.6359 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6361 - acc: 0.7732 - val_loss: 0.6290 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6302 - acc: 0.7835 - val_loss: 0.6223 - val_acc: 0.8033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6244 - acc: 0.7887 - val_loss: 0.6157 - val_acc: 0.8033\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6189 - acc: 0.7990 - val_loss: 0.6093 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6135 - acc: 0.8041 - val_loss: 0.6029 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6080 - acc: 0.8093 - val_loss: 0.5967 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6028 - acc: 0.8144 - val_loss: 0.5907 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5977 - acc: 0.8144 - val_loss: 0.5847 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5924 - acc: 0.8247 - val_loss: 0.5790 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5875 - acc: 0.8247 - val_loss: 0.5733 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b485550d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7032 - acc: 0.4433 - val_loss: 0.6945 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6961 - acc: 0.4948 - val_loss: 0.6867 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6893 - acc: 0.5258 - val_loss: 0.6790 - val_acc: 0.6393\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6829 - acc: 0.5876 - val_loss: 0.6715 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6765 - acc: 0.6598 - val_loss: 0.6640 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6701 - acc: 0.6649 - val_loss: 0.6567 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6638 - acc: 0.6907 - val_loss: 0.6495 - val_acc: 0.7541\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6578 - acc: 0.7113 - val_loss: 0.6424 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6516 - acc: 0.7371 - val_loss: 0.6354 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6460 - acc: 0.7268 - val_loss: 0.6286 - val_acc: 0.8033\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6400 - acc: 0.7320 - val_loss: 0.6219 - val_acc: 0.8033\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6345 - acc: 0.7320 - val_loss: 0.6153 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6290 - acc: 0.7371 - val_loss: 0.6088 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6236 - acc: 0.7577 - val_loss: 0.6024 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6183 - acc: 0.7474 - val_loss: 0.5963 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6132 - acc: 0.7526 - val_loss: 0.5902 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6082 - acc: 0.7629 - val_loss: 0.5843 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6031 - acc: 0.7680 - val_loss: 0.5785 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5984 - acc: 0.7680 - val_loss: 0.5728 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5936 - acc: 0.7732 - val_loss: 0.5672 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb489baf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7042 - acc: 0.4536 - val_loss: 0.6925 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6971 - acc: 0.4897 - val_loss: 0.6847 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6902 - acc: 0.5309 - val_loss: 0.6771 - val_acc: 0.5902\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6833 - acc: 0.5515 - val_loss: 0.6695 - val_acc: 0.6066\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6766 - acc: 0.5876 - val_loss: 0.6620 - val_acc: 0.6721\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6701 - acc: 0.6186 - val_loss: 0.6545 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6637 - acc: 0.6392 - val_loss: 0.6472 - val_acc: 0.7377\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6573 - acc: 0.6856 - val_loss: 0.6401 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6509 - acc: 0.7113 - val_loss: 0.6331 - val_acc: 0.8033\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6448 - acc: 0.7216 - val_loss: 0.6263 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6390 - acc: 0.7320 - val_loss: 0.6196 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6332 - acc: 0.7320 - val_loss: 0.6131 - val_acc: 0.8361\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6274 - acc: 0.7474 - val_loss: 0.6068 - val_acc: 0.8361\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6218 - acc: 0.7629 - val_loss: 0.6006 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6164 - acc: 0.7835 - val_loss: 0.5945 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6112 - acc: 0.7938 - val_loss: 0.5886 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6059 - acc: 0.7990 - val_loss: 0.5828 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6007 - acc: 0.7990 - val_loss: 0.5772 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5958 - acc: 0.8041 - val_loss: 0.5717 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5908 - acc: 0.8144 - val_loss: 0.5663 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b48555040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8661 - acc: 0.4870 - val_loss: 0.7604 - val_acc: 0.5410\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8560 - acc: 0.4922 - val_loss: 0.7526 - val_acc: 0.5410\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8466 - acc: 0.4974 - val_loss: 0.7450 - val_acc: 0.5410\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8381 - acc: 0.4974 - val_loss: 0.7377 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8289 - acc: 0.4974 - val_loss: 0.7305 - val_acc: 0.5574\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8204 - acc: 0.4974 - val_loss: 0.7234 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8118 - acc: 0.4974 - val_loss: 0.7163 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8036 - acc: 0.5130 - val_loss: 0.7096 - val_acc: 0.5738\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7955 - acc: 0.5233 - val_loss: 0.7029 - val_acc: 0.5902\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7877 - acc: 0.5285 - val_loss: 0.6965 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7799 - acc: 0.5337 - val_loss: 0.6901 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7724 - acc: 0.5389 - val_loss: 0.6837 - val_acc: 0.5902\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7648 - acc: 0.5440 - val_loss: 0.6774 - val_acc: 0.5902\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7572 - acc: 0.5440 - val_loss: 0.6712 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7504 - acc: 0.5389 - val_loss: 0.6653 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7432 - acc: 0.5389 - val_loss: 0.6594 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7361 - acc: 0.5389 - val_loss: 0.6536 - val_acc: 0.6230\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7298 - acc: 0.5389 - val_loss: 0.6477 - val_acc: 0.6393\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7228 - acc: 0.5544 - val_loss: 0.6419 - val_acc: 0.6721\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7161 - acc: 0.5596 - val_loss: 0.6362 - val_acc: 0.6721\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb693fee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7763 - acc: 0.4249 - val_loss: 0.8816 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7661 - acc: 0.4352 - val_loss: 0.8706 - val_acc: 0.3115\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7556 - acc: 0.4404 - val_loss: 0.8596 - val_acc: 0.3607\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7465 - acc: 0.4611 - val_loss: 0.8489 - val_acc: 0.3770\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7365 - acc: 0.4819 - val_loss: 0.8384 - val_acc: 0.3934\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7273 - acc: 0.4870 - val_loss: 0.8281 - val_acc: 0.4262\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7187 - acc: 0.5026 - val_loss: 0.8180 - val_acc: 0.4426\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7095 - acc: 0.5078 - val_loss: 0.8081 - val_acc: 0.4426\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7007 - acc: 0.5233 - val_loss: 0.7983 - val_acc: 0.4426\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6918 - acc: 0.5544 - val_loss: 0.7887 - val_acc: 0.4426\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6839 - acc: 0.5596 - val_loss: 0.7792 - val_acc: 0.4426\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6755 - acc: 0.5648 - val_loss: 0.7699 - val_acc: 0.4426\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6677 - acc: 0.5699 - val_loss: 0.7609 - val_acc: 0.4426\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6602 - acc: 0.5907 - val_loss: 0.7521 - val_acc: 0.4426\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6528 - acc: 0.5959 - val_loss: 0.7435 - val_acc: 0.4426\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6463 - acc: 0.6010 - val_loss: 0.7350 - val_acc: 0.4590\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6392 - acc: 0.6062 - val_loss: 0.7267 - val_acc: 0.4754\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6323 - acc: 0.6218 - val_loss: 0.7187 - val_acc: 0.4754\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6269 - acc: 0.6477 - val_loss: 0.7109 - val_acc: 0.4918\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6204 - acc: 0.6528 - val_loss: 0.7033 - val_acc: 0.5082\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb48ddaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6874 - acc: 0.5670 - val_loss: 0.6650 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6804 - acc: 0.5670 - val_loss: 0.6578 - val_acc: 0.5738\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6737 - acc: 0.5825 - val_loss: 0.6507 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6677 - acc: 0.5876 - val_loss: 0.6437 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6613 - acc: 0.5979 - val_loss: 0.6370 - val_acc: 0.6393\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6552 - acc: 0.5979 - val_loss: 0.6304 - val_acc: 0.6557\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6493 - acc: 0.6082 - val_loss: 0.6238 - val_acc: 0.6557\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6436 - acc: 0.6289 - val_loss: 0.6174 - val_acc: 0.6557\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6381 - acc: 0.6237 - val_loss: 0.6110 - val_acc: 0.6557\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6326 - acc: 0.6186 - val_loss: 0.6047 - val_acc: 0.6885\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6270 - acc: 0.6237 - val_loss: 0.5987 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6219 - acc: 0.6392 - val_loss: 0.5927 - val_acc: 0.6885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6171 - acc: 0.6495 - val_loss: 0.5869 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6121 - acc: 0.6598 - val_loss: 0.5814 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6072 - acc: 0.6649 - val_loss: 0.5760 - val_acc: 0.7541\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6026 - acc: 0.6649 - val_loss: 0.5707 - val_acc: 0.7541\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5983 - acc: 0.6804 - val_loss: 0.5654 - val_acc: 0.7541\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5938 - acc: 0.6856 - val_loss: 0.5603 - val_acc: 0.7541\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5895 - acc: 0.7062 - val_loss: 0.5554 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5852 - acc: 0.7216 - val_loss: 0.5505 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3af8157670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6110 - acc: 0.6701 - val_loss: 0.5340 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6068 - acc: 0.6856 - val_loss: 0.5303 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6028 - acc: 0.6856 - val_loss: 0.5265 - val_acc: 0.7541\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5991 - acc: 0.6856 - val_loss: 0.5228 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5951 - acc: 0.6856 - val_loss: 0.5191 - val_acc: 0.7541\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5915 - acc: 0.6907 - val_loss: 0.5154 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5879 - acc: 0.6959 - val_loss: 0.5118 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5839 - acc: 0.7113 - val_loss: 0.5082 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5804 - acc: 0.7113 - val_loss: 0.5046 - val_acc: 0.7705\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5769 - acc: 0.7165 - val_loss: 0.5010 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5730 - acc: 0.7320 - val_loss: 0.4975 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5695 - acc: 0.7371 - val_loss: 0.4939 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5660 - acc: 0.7474 - val_loss: 0.4904 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5625 - acc: 0.7474 - val_loss: 0.4870 - val_acc: 0.7705\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5590 - acc: 0.7526 - val_loss: 0.4837 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5555 - acc: 0.7577 - val_loss: 0.4804 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5521 - acc: 0.7629 - val_loss: 0.4772 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5485 - acc: 0.7680 - val_loss: 0.4740 - val_acc: 0.7869\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5452 - acc: 0.7680 - val_loss: 0.4707 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5419 - acc: 0.7680 - val_loss: 0.4674 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3af8157430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.7192 - acc: 0.4536 - val_loss: 0.7272 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7130 - acc: 0.4536 - val_loss: 0.7209 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7074 - acc: 0.4536 - val_loss: 0.7147 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7017 - acc: 0.4536 - val_loss: 0.7086 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6964 - acc: 0.4536 - val_loss: 0.7028 - val_acc: 0.4590\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6910 - acc: 0.4536 - val_loss: 0.6972 - val_acc: 0.4754\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6862 - acc: 0.4588 - val_loss: 0.6916 - val_acc: 0.4754\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6811 - acc: 0.4588 - val_loss: 0.6863 - val_acc: 0.4754\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6767 - acc: 0.4639 - val_loss: 0.6811 - val_acc: 0.4918\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6721 - acc: 0.4639 - val_loss: 0.6760 - val_acc: 0.4918\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6680 - acc: 0.4639 - val_loss: 0.6709 - val_acc: 0.4918\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6639 - acc: 0.4691 - val_loss: 0.6660 - val_acc: 0.4918\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6598 - acc: 0.4794 - val_loss: 0.6612 - val_acc: 0.4918\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6558 - acc: 0.4897 - val_loss: 0.6565 - val_acc: 0.5082\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6519 - acc: 0.5052 - val_loss: 0.6519 - val_acc: 0.5082\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6484 - acc: 0.5206 - val_loss: 0.6473 - val_acc: 0.5246\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6447 - acc: 0.5206 - val_loss: 0.6429 - val_acc: 0.5082\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6410 - acc: 0.5309 - val_loss: 0.6386 - val_acc: 0.5082\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6378 - acc: 0.5361 - val_loss: 0.6344 - val_acc: 0.5082\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6345 - acc: 0.5464 - val_loss: 0.6303 - val_acc: 0.5082\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab2609160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.6231 - acc: 0.6373 - val_loss: 0.5701 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6156 - acc: 0.6321 - val_loss: 0.5621 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6089 - acc: 0.6477 - val_loss: 0.5547 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6022 - acc: 0.6580 - val_loss: 0.5476 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5953 - acc: 0.6580 - val_loss: 0.5406 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5892 - acc: 0.6632 - val_loss: 0.5338 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5833 - acc: 0.6684 - val_loss: 0.5273 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5772 - acc: 0.6736 - val_loss: 0.5212 - val_acc: 0.7213\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5712 - acc: 0.6736 - val_loss: 0.5152 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5659 - acc: 0.6736 - val_loss: 0.5092 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5602 - acc: 0.6736 - val_loss: 0.5033 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5545 - acc: 0.6943 - val_loss: 0.4976 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5494 - acc: 0.6943 - val_loss: 0.4920 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5441 - acc: 0.6995 - val_loss: 0.4865 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5390 - acc: 0.7098 - val_loss: 0.4812 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5340 - acc: 0.7098 - val_loss: 0.4759 - val_acc: 0.7869\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5289 - acc: 0.7150 - val_loss: 0.4709 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5243 - acc: 0.7254 - val_loss: 0.4661 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5195 - acc: 0.7358 - val_loss: 0.4614 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5148 - acc: 0.7409 - val_loss: 0.4569 - val_acc: 0.8033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb4802ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.8168 - acc: 0.3575 - val_loss: 0.7775 - val_acc: 0.4098\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8024 - acc: 0.3731 - val_loss: 0.7630 - val_acc: 0.4262\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7876 - acc: 0.3990 - val_loss: 0.7491 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7746 - acc: 0.4197 - val_loss: 0.7355 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7611 - acc: 0.4508 - val_loss: 0.7222 - val_acc: 0.5082\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7487 - acc: 0.4560 - val_loss: 0.7095 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7364 - acc: 0.4560 - val_loss: 0.6971 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7252 - acc: 0.4663 - val_loss: 0.6851 - val_acc: 0.5410\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7140 - acc: 0.4922 - val_loss: 0.6735 - val_acc: 0.5410\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7030 - acc: 0.5130 - val_loss: 0.6623 - val_acc: 0.5902\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6924 - acc: 0.5389 - val_loss: 0.6516 - val_acc: 0.5902\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6827 - acc: 0.5544 - val_loss: 0.6411 - val_acc: 0.6230\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6731 - acc: 0.5648 - val_loss: 0.6309 - val_acc: 0.6393\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6642 - acc: 0.5803 - val_loss: 0.6211 - val_acc: 0.6557\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6553 - acc: 0.6010 - val_loss: 0.6116 - val_acc: 0.6885\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6469 - acc: 0.6010 - val_loss: 0.6024 - val_acc: 0.6885\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6384 - acc: 0.6218 - val_loss: 0.5936 - val_acc: 0.6721\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6305 - acc: 0.6218 - val_loss: 0.5849 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6227 - acc: 0.6269 - val_loss: 0.5764 - val_acc: 0.6885\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6152 - acc: 0.6373 - val_loss: 0.5680 - val_acc: 0.7213\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac0787ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6994 - acc: 0.5361 - val_loss: 0.6982 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6870 - acc: 0.5619 - val_loss: 0.6850 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6753 - acc: 0.5773 - val_loss: 0.6722 - val_acc: 0.6066\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6644 - acc: 0.5876 - val_loss: 0.6598 - val_acc: 0.6230\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6537 - acc: 0.5979 - val_loss: 0.6477 - val_acc: 0.6230\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6432 - acc: 0.6031 - val_loss: 0.6362 - val_acc: 0.6230\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6331 - acc: 0.6392 - val_loss: 0.6251 - val_acc: 0.6393\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6238 - acc: 0.6443 - val_loss: 0.6145 - val_acc: 0.6721\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6148 - acc: 0.6443 - val_loss: 0.6042 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6058 - acc: 0.6598 - val_loss: 0.5943 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5975 - acc: 0.6701 - val_loss: 0.5850 - val_acc: 0.6721\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5893 - acc: 0.6804 - val_loss: 0.5761 - val_acc: 0.7049\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5813 - acc: 0.6856 - val_loss: 0.5675 - val_acc: 0.7049\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5737 - acc: 0.6907 - val_loss: 0.5594 - val_acc: 0.7049\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5667 - acc: 0.7062 - val_loss: 0.5514 - val_acc: 0.7213\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5596 - acc: 0.7165 - val_loss: 0.5435 - val_acc: 0.7213\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5528 - acc: 0.7165 - val_loss: 0.5360 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5466 - acc: 0.7371 - val_loss: 0.5287 - val_acc: 0.7705\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5403 - acc: 0.7423 - val_loss: 0.5217 - val_acc: 0.7705\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5342 - acc: 0.7526 - val_loss: 0.5150 - val_acc: 0.7705\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb492e430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6807 - acc: 0.5052 - val_loss: 0.6629 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6714 - acc: 0.5619 - val_loss: 0.6530 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6626 - acc: 0.5722 - val_loss: 0.6433 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6542 - acc: 0.5979 - val_loss: 0.6337 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6456 - acc: 0.6237 - val_loss: 0.6242 - val_acc: 0.6557\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6377 - acc: 0.6443 - val_loss: 0.6149 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6301 - acc: 0.6546 - val_loss: 0.6055 - val_acc: 0.7049\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6223 - acc: 0.6701 - val_loss: 0.5962 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6145 - acc: 0.6907 - val_loss: 0.5872 - val_acc: 0.7213\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6071 - acc: 0.7423 - val_loss: 0.5784 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5997 - acc: 0.7629 - val_loss: 0.5699 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5928 - acc: 0.7784 - val_loss: 0.5614 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5854 - acc: 0.7938 - val_loss: 0.5531 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5787 - acc: 0.7938 - val_loss: 0.5450 - val_acc: 0.8033\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5719 - acc: 0.8093 - val_loss: 0.5370 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5650 - acc: 0.8093 - val_loss: 0.5293 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5587 - acc: 0.8247 - val_loss: 0.5216 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5522 - acc: 0.8247 - val_loss: 0.5141 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5458 - acc: 0.8196 - val_loss: 0.5067 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5397 - acc: 0.8247 - val_loss: 0.4995 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb693fee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6326 - acc: 0.6495 - val_loss: 0.5890 - val_acc: 0.6557\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6174 - acc: 0.6495 - val_loss: 0.5763 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6042 - acc: 0.6546 - val_loss: 0.5643 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5912 - acc: 0.6701 - val_loss: 0.5531 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5791 - acc: 0.6856 - val_loss: 0.5426 - val_acc: 0.6885\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5684 - acc: 0.6856 - val_loss: 0.5326 - val_acc: 0.6885\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5582 - acc: 0.6907 - val_loss: 0.5232 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5486 - acc: 0.6907 - val_loss: 0.5144 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5394 - acc: 0.6907 - val_loss: 0.5061 - val_acc: 0.7541\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5303 - acc: 0.7010 - val_loss: 0.4983 - val_acc: 0.7705\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5230 - acc: 0.6959 - val_loss: 0.4909 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5152 - acc: 0.7113 - val_loss: 0.4841 - val_acc: 0.7869\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5088 - acc: 0.7423 - val_loss: 0.4775 - val_acc: 0.7869\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5012 - acc: 0.7629 - val_loss: 0.4713 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4957 - acc: 0.7732 - val_loss: 0.4654 - val_acc: 0.8033\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4893 - acc: 0.7784 - val_loss: 0.4598 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4838 - acc: 0.7887 - val_loss: 0.4546 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4786 - acc: 0.7887 - val_loss: 0.4496 - val_acc: 0.8033\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4734 - acc: 0.7938 - val_loss: 0.4450 - val_acc: 0.8197\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4686 - acc: 0.7938 - val_loss: 0.4405 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb0058af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.8243 - acc: 0.4093 - val_loss: 0.7614 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8021 - acc: 0.4145 - val_loss: 0.7399 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7812 - acc: 0.4352 - val_loss: 0.7193 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7618 - acc: 0.4560 - val_loss: 0.6997 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7439 - acc: 0.4715 - val_loss: 0.6811 - val_acc: 0.5410\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7256 - acc: 0.4819 - val_loss: 0.6636 - val_acc: 0.5738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7095 - acc: 0.5026 - val_loss: 0.6470 - val_acc: 0.6066\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6931 - acc: 0.5233 - val_loss: 0.6315 - val_acc: 0.6230\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6778 - acc: 0.5699 - val_loss: 0.6169 - val_acc: 0.6393\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6635 - acc: 0.5907 - val_loss: 0.6029 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6502 - acc: 0.5855 - val_loss: 0.5896 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6367 - acc: 0.6425 - val_loss: 0.5772 - val_acc: 0.7213\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6249 - acc: 0.6736 - val_loss: 0.5653 - val_acc: 0.7705\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6123 - acc: 0.7047 - val_loss: 0.5541 - val_acc: 0.7869\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6012 - acc: 0.7098 - val_loss: 0.5433 - val_acc: 0.7869\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5906 - acc: 0.7358 - val_loss: 0.5329 - val_acc: 0.8033\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5802 - acc: 0.7461 - val_loss: 0.5229 - val_acc: 0.8033\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5700 - acc: 0.7617 - val_loss: 0.5134 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5606 - acc: 0.7617 - val_loss: 0.5042 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5516 - acc: 0.7772 - val_loss: 0.4954 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c622ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6714 - acc: 0.5959 - val_loss: 0.6393 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6571 - acc: 0.6166 - val_loss: 0.6233 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6435 - acc: 0.6373 - val_loss: 0.6080 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6305 - acc: 0.6632 - val_loss: 0.5932 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6189 - acc: 0.6684 - val_loss: 0.5790 - val_acc: 0.7705\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6068 - acc: 0.6839 - val_loss: 0.5654 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5959 - acc: 0.6891 - val_loss: 0.5523 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5852 - acc: 0.6943 - val_loss: 0.5396 - val_acc: 0.8033\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5744 - acc: 0.7098 - val_loss: 0.5274 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5649 - acc: 0.7150 - val_loss: 0.5154 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5552 - acc: 0.7150 - val_loss: 0.5041 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5462 - acc: 0.7202 - val_loss: 0.4932 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5372 - acc: 0.7254 - val_loss: 0.4828 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5288 - acc: 0.7254 - val_loss: 0.4726 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5206 - acc: 0.7306 - val_loss: 0.4630 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5126 - acc: 0.7409 - val_loss: 0.4537 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5051 - acc: 0.7461 - val_loss: 0.4448 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4975 - acc: 0.7513 - val_loss: 0.4364 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4909 - acc: 0.7513 - val_loss: 0.4284 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4836 - acc: 0.7513 - val_loss: 0.4207 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b4871b3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.8239 - acc: 0.3557 - val_loss: 0.8030 - val_acc: 0.3115\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8009 - acc: 0.3711 - val_loss: 0.7794 - val_acc: 0.3443\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7788 - acc: 0.3969 - val_loss: 0.7570 - val_acc: 0.4426\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7581 - acc: 0.4381 - val_loss: 0.7356 - val_acc: 0.4590\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7393 - acc: 0.4742 - val_loss: 0.7149 - val_acc: 0.5246\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7208 - acc: 0.5155 - val_loss: 0.6950 - val_acc: 0.5410\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7031 - acc: 0.5567 - val_loss: 0.6763 - val_acc: 0.5738\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6868 - acc: 0.5825 - val_loss: 0.6585 - val_acc: 0.5902\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6711 - acc: 0.6031 - val_loss: 0.6416 - val_acc: 0.6721\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6559 - acc: 0.6134 - val_loss: 0.6256 - val_acc: 0.6721\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6419 - acc: 0.6237 - val_loss: 0.6105 - val_acc: 0.6885\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6284 - acc: 0.6340 - val_loss: 0.5962 - val_acc: 0.6885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6156 - acc: 0.6598 - val_loss: 0.5826 - val_acc: 0.6885\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6037 - acc: 0.6753 - val_loss: 0.5697 - val_acc: 0.7213\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5920 - acc: 0.6907 - val_loss: 0.5575 - val_acc: 0.7377\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5805 - acc: 0.7010 - val_loss: 0.5460 - val_acc: 0.7705\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5705 - acc: 0.7113 - val_loss: 0.5350 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5603 - acc: 0.7216 - val_loss: 0.5247 - val_acc: 0.7869\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5509 - acc: 0.7165 - val_loss: 0.5147 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5415 - acc: 0.7268 - val_loss: 0.5052 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b482c5f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.8856 - acc: 0.4433 - val_loss: 0.8379 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8542 - acc: 0.4433 - val_loss: 0.8105 - val_acc: 0.4754\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8263 - acc: 0.4433 - val_loss: 0.7847 - val_acc: 0.4590\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7999 - acc: 0.4536 - val_loss: 0.7606 - val_acc: 0.4754\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7740 - acc: 0.4691 - val_loss: 0.7382 - val_acc: 0.4918\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7511 - acc: 0.4794 - val_loss: 0.7173 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7306 - acc: 0.4794 - val_loss: 0.6977 - val_acc: 0.5410\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7091 - acc: 0.5103 - val_loss: 0.6795 - val_acc: 0.5574\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6918 - acc: 0.5515 - val_loss: 0.6623 - val_acc: 0.5574\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6743 - acc: 0.5773 - val_loss: 0.6463 - val_acc: 0.5574\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6595 - acc: 0.6082 - val_loss: 0.6311 - val_acc: 0.5574\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6452 - acc: 0.6289 - val_loss: 0.6168 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6310 - acc: 0.6495 - val_loss: 0.6036 - val_acc: 0.6066\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6189 - acc: 0.6598 - val_loss: 0.5910 - val_acc: 0.6066\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6070 - acc: 0.6649 - val_loss: 0.5792 - val_acc: 0.6066\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5972 - acc: 0.6753 - val_loss: 0.5679 - val_acc: 0.6230\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5868 - acc: 0.6959 - val_loss: 0.5573 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5775 - acc: 0.7062 - val_loss: 0.5471 - val_acc: 0.6557\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5691 - acc: 0.7113 - val_loss: 0.5373 - val_acc: 0.6557\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5605 - acc: 0.7216 - val_loss: 0.5280 - val_acc: 0.6721\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3af80bab80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7032 - acc: 0.4691 - val_loss: 0.6556 - val_acc: 0.5902\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6874 - acc: 0.5206 - val_loss: 0.6408 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6729 - acc: 0.5722 - val_loss: 0.6266 - val_acc: 0.6721\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6586 - acc: 0.6237 - val_loss: 0.6133 - val_acc: 0.6885\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6454 - acc: 0.6649 - val_loss: 0.6006 - val_acc: 0.7377\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6322 - acc: 0.6804 - val_loss: 0.5885 - val_acc: 0.7541\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6211 - acc: 0.6856 - val_loss: 0.5767 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6095 - acc: 0.6959 - val_loss: 0.5656 - val_acc: 0.7705\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5984 - acc: 0.7216 - val_loss: 0.5551 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5879 - acc: 0.7268 - val_loss: 0.5449 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5783 - acc: 0.7320 - val_loss: 0.5351 - val_acc: 0.7869\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5682 - acc: 0.7423 - val_loss: 0.5259 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5595 - acc: 0.7577 - val_loss: 0.5170 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5505 - acc: 0.7680 - val_loss: 0.5086 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5418 - acc: 0.7887 - val_loss: 0.5004 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5339 - acc: 0.7938 - val_loss: 0.4925 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5265 - acc: 0.7990 - val_loss: 0.4849 - val_acc: 0.8197\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5186 - acc: 0.8041 - val_loss: 0.4777 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5115 - acc: 0.7990 - val_loss: 0.4709 - val_acc: 0.8033\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5048 - acc: 0.8041 - val_loss: 0.4643 - val_acc: 0.7869\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb46b7af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7091 - acc: 0.5026 - val_loss: 0.6909 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6900 - acc: 0.5492 - val_loss: 0.6703 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6718 - acc: 0.6114 - val_loss: 0.6506 - val_acc: 0.6885\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6540 - acc: 0.6632 - val_loss: 0.6316 - val_acc: 0.7049\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6384 - acc: 0.6632 - val_loss: 0.6133 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6224 - acc: 0.6839 - val_loss: 0.5960 - val_acc: 0.7377\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6071 - acc: 0.6943 - val_loss: 0.5792 - val_acc: 0.7705\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5930 - acc: 0.6995 - val_loss: 0.5632 - val_acc: 0.7869\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5791 - acc: 0.7202 - val_loss: 0.5482 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5661 - acc: 0.7254 - val_loss: 0.5339 - val_acc: 0.8361\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5533 - acc: 0.7254 - val_loss: 0.5204 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5414 - acc: 0.7461 - val_loss: 0.5074 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5307 - acc: 0.7461 - val_loss: 0.4947 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5189 - acc: 0.7461 - val_loss: 0.4828 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5089 - acc: 0.7513 - val_loss: 0.4713 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4989 - acc: 0.7513 - val_loss: 0.4605 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4895 - acc: 0.7617 - val_loss: 0.4503 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4806 - acc: 0.7668 - val_loss: 0.4409 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4716 - acc: 0.7720 - val_loss: 0.4320 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4633 - acc: 0.7720 - val_loss: 0.4236 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3af80ba430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7242 - acc: 0.4611 - val_loss: 0.7171 - val_acc: 0.4590\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6957 - acc: 0.5492 - val_loss: 0.6910 - val_acc: 0.5082\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6694 - acc: 0.5803 - val_loss: 0.6662 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6458 - acc: 0.6321 - val_loss: 0.6427 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6241 - acc: 0.7098 - val_loss: 0.6206 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6020 - acc: 0.7409 - val_loss: 0.5998 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5838 - acc: 0.8031 - val_loss: 0.5804 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5665 - acc: 0.8031 - val_loss: 0.5621 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5502 - acc: 0.7979 - val_loss: 0.5450 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5346 - acc: 0.7979 - val_loss: 0.5289 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5208 - acc: 0.7927 - val_loss: 0.5138 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5081 - acc: 0.7927 - val_loss: 0.4997 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4960 - acc: 0.7979 - val_loss: 0.4866 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4850 - acc: 0.7979 - val_loss: 0.4742 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4746 - acc: 0.8031 - val_loss: 0.4627 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4648 - acc: 0.8031 - val_loss: 0.4520 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4558 - acc: 0.8031 - val_loss: 0.4422 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4471 - acc: 0.8083 - val_loss: 0.4330 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4395 - acc: 0.8135 - val_loss: 0.4247 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4317 - acc: 0.8135 - val_loss: 0.4172 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab27278b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6211 - acc: 0.6598 - val_loss: 0.5745 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5989 - acc: 0.7010 - val_loss: 0.5510 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5812 - acc: 0.7216 - val_loss: 0.5292 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5616 - acc: 0.7320 - val_loss: 0.5092 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5455 - acc: 0.7577 - val_loss: 0.4905 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5296 - acc: 0.7680 - val_loss: 0.4733 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5147 - acc: 0.7784 - val_loss: 0.4573 - val_acc: 0.9180\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5012 - acc: 0.7887 - val_loss: 0.4424 - val_acc: 0.9180\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4887 - acc: 0.8041 - val_loss: 0.4287 - val_acc: 0.9180\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4761 - acc: 0.8093 - val_loss: 0.4159 - val_acc: 0.9180\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4653 - acc: 0.8144 - val_loss: 0.4039 - val_acc: 0.9180\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4557 - acc: 0.8144 - val_loss: 0.3929 - val_acc: 0.9180\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4455 - acc: 0.8299 - val_loss: 0.3830 - val_acc: 0.9180\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4363 - acc: 0.8351 - val_loss: 0.3735 - val_acc: 0.9180\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4281 - acc: 0.8505 - val_loss: 0.3647 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4209 - acc: 0.8505 - val_loss: 0.3566 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4133 - acc: 0.8505 - val_loss: 0.3493 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4064 - acc: 0.8557 - val_loss: 0.3425 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4003 - acc: 0.8557 - val_loss: 0.3363 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3945 - acc: 0.8660 - val_loss: 0.3307 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab2507af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 241ms/step - loss: 0.8042 - acc: 0.4381 - val_loss: 0.8003 - val_acc: 0.4426\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7741 - acc: 0.4536 - val_loss: 0.7671 - val_acc: 0.4590\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7475 - acc: 0.4794 - val_loss: 0.7354 - val_acc: 0.4754\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7233 - acc: 0.5103 - val_loss: 0.7056 - val_acc: 0.5246\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6996 - acc: 0.5464 - val_loss: 0.6777 - val_acc: 0.5738\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6779 - acc: 0.5567 - val_loss: 0.6519 - val_acc: 0.6066\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6572 - acc: 0.5979 - val_loss: 0.6280 - val_acc: 0.6721\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6374 - acc: 0.6495 - val_loss: 0.6058 - val_acc: 0.7049\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6192 - acc: 0.6804 - val_loss: 0.5853 - val_acc: 0.7377\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6032 - acc: 0.6959 - val_loss: 0.5664 - val_acc: 0.7541\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5871 - acc: 0.7165 - val_loss: 0.5490 - val_acc: 0.7705\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5723 - acc: 0.7526 - val_loss: 0.5329 - val_acc: 0.8197\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5585 - acc: 0.7784 - val_loss: 0.5180 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5454 - acc: 0.7835 - val_loss: 0.5041 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5330 - acc: 0.7887 - val_loss: 0.4911 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5217 - acc: 0.8041 - val_loss: 0.4790 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5102 - acc: 0.8093 - val_loss: 0.4678 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5000 - acc: 0.8196 - val_loss: 0.4570 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4904 - acc: 0.8196 - val_loss: 0.4469 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4817 - acc: 0.8247 - val_loss: 0.4376 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb471d700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.8174 - acc: 0.4227 - val_loss: 0.7630 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7850 - acc: 0.4227 - val_loss: 0.7345 - val_acc: 0.4918\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7551 - acc: 0.4330 - val_loss: 0.7073 - val_acc: 0.5082\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7280 - acc: 0.4227 - val_loss: 0.6818 - val_acc: 0.5738\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7021 - acc: 0.4588 - val_loss: 0.6577 - val_acc: 0.5902\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6788 - acc: 0.5052 - val_loss: 0.6351 - val_acc: 0.6721\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6558 - acc: 0.5670 - val_loss: 0.6140 - val_acc: 0.7213\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6374 - acc: 0.6186 - val_loss: 0.5944 - val_acc: 0.7541\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6170 - acc: 0.6701 - val_loss: 0.5764 - val_acc: 0.7869\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6010 - acc: 0.6856 - val_loss: 0.5595 - val_acc: 0.7869\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5839 - acc: 0.7010 - val_loss: 0.5438 - val_acc: 0.8197\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5695 - acc: 0.7268 - val_loss: 0.5292 - val_acc: 0.8033\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5553 - acc: 0.7371 - val_loss: 0.5154 - val_acc: 0.8197\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5426 - acc: 0.7577 - val_loss: 0.5025 - val_acc: 0.8197\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5303 - acc: 0.7680 - val_loss: 0.4904 - val_acc: 0.8197\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5193 - acc: 0.7732 - val_loss: 0.4793 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5082 - acc: 0.7784 - val_loss: 0.4689 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4984 - acc: 0.7887 - val_loss: 0.4593 - val_acc: 0.8197\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4889 - acc: 0.8041 - val_loss: 0.4503 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4804 - acc: 0.8041 - val_loss: 0.4418 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab2507ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6123 - acc: 0.7202 - val_loss: 0.5750 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5857 - acc: 0.7565 - val_loss: 0.5483 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5617 - acc: 0.7668 - val_loss: 0.5241 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5400 - acc: 0.8135 - val_loss: 0.5023 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5199 - acc: 0.8083 - val_loss: 0.4824 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5016 - acc: 0.8187 - val_loss: 0.4645 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4853 - acc: 0.8342 - val_loss: 0.4487 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4694 - acc: 0.8446 - val_loss: 0.4349 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4552 - acc: 0.8497 - val_loss: 0.4222 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4425 - acc: 0.8446 - val_loss: 0.4111 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4308 - acc: 0.8394 - val_loss: 0.4015 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4206 - acc: 0.8446 - val_loss: 0.3926 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4106 - acc: 0.8497 - val_loss: 0.3850 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4017 - acc: 0.8446 - val_loss: 0.3786 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3932 - acc: 0.8446 - val_loss: 0.3727 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3860 - acc: 0.8446 - val_loss: 0.3676 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3788 - acc: 0.8549 - val_loss: 0.3632 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3725 - acc: 0.8549 - val_loss: 0.3593 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3667 - acc: 0.8549 - val_loss: 0.3558 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3608 - acc: 0.8549 - val_loss: 0.3536 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb46b7e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6617 - acc: 0.6166 - val_loss: 0.6501 - val_acc: 0.6230\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6294 - acc: 0.6839 - val_loss: 0.6135 - val_acc: 0.6721\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6013 - acc: 0.7098 - val_loss: 0.5803 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5763 - acc: 0.7254 - val_loss: 0.5503 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5531 - acc: 0.7409 - val_loss: 0.5232 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5314 - acc: 0.7617 - val_loss: 0.4989 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5135 - acc: 0.7617 - val_loss: 0.4767 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4966 - acc: 0.7720 - val_loss: 0.4570 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4812 - acc: 0.7772 - val_loss: 0.4398 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4677 - acc: 0.7979 - val_loss: 0.4247 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4554 - acc: 0.7979 - val_loss: 0.4115 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4439 - acc: 0.7927 - val_loss: 0.4000 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4344 - acc: 0.8031 - val_loss: 0.3898 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4248 - acc: 0.8083 - val_loss: 0.3812 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4164 - acc: 0.8135 - val_loss: 0.3737 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4089 - acc: 0.8342 - val_loss: 0.3672 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4016 - acc: 0.8394 - val_loss: 0.3616 - val_acc: 0.8361\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3951 - acc: 0.8497 - val_loss: 0.3567 - val_acc: 0.8361\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3892 - acc: 0.8549 - val_loss: 0.3524 - val_acc: 0.8361\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3831 - acc: 0.8549 - val_loss: 0.3488 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3af80ba3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7262 - acc: 0.4639 - val_loss: 0.6938 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6884 - acc: 0.5412 - val_loss: 0.6548 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6528 - acc: 0.6289 - val_loss: 0.6196 - val_acc: 0.7049\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6220 - acc: 0.6753 - val_loss: 0.5875 - val_acc: 0.7541\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5932 - acc: 0.7268 - val_loss: 0.5583 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5683 - acc: 0.7474 - val_loss: 0.5316 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5456 - acc: 0.7629 - val_loss: 0.5076 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5240 - acc: 0.7887 - val_loss: 0.4859 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5056 - acc: 0.7887 - val_loss: 0.4664 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4884 - acc: 0.8093 - val_loss: 0.4489 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4723 - acc: 0.8093 - val_loss: 0.4334 - val_acc: 0.9016\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4586 - acc: 0.8144 - val_loss: 0.4195 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4459 - acc: 0.8196 - val_loss: 0.4074 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4334 - acc: 0.8247 - val_loss: 0.3967 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4227 - acc: 0.8299 - val_loss: 0.3871 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4131 - acc: 0.8299 - val_loss: 0.3786 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4041 - acc: 0.8351 - val_loss: 0.3713 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3956 - acc: 0.8299 - val_loss: 0.3649 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3880 - acc: 0.8402 - val_loss: 0.3593 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3808 - acc: 0.8505 - val_loss: 0.3542 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b482c59d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7720 - acc: 0.3196 - val_loss: 0.7809 - val_acc: 0.3770\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7371 - acc: 0.4072 - val_loss: 0.7389 - val_acc: 0.5246\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7053 - acc: 0.5000 - val_loss: 0.7003 - val_acc: 0.6230\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6749 - acc: 0.5876 - val_loss: 0.6649 - val_acc: 0.6557\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6474 - acc: 0.6392 - val_loss: 0.6319 - val_acc: 0.7213\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6222 - acc: 0.6959 - val_loss: 0.6018 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5992 - acc: 0.7320 - val_loss: 0.5743 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5770 - acc: 0.7474 - val_loss: 0.5495 - val_acc: 0.8197\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5579 - acc: 0.7732 - val_loss: 0.5266 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5402 - acc: 0.7835 - val_loss: 0.5059 - val_acc: 0.8197\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5228 - acc: 0.7835 - val_loss: 0.4871 - val_acc: 0.8361\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5081 - acc: 0.7835 - val_loss: 0.4700 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4942 - acc: 0.7784 - val_loss: 0.4546 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4815 - acc: 0.7938 - val_loss: 0.4405 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4702 - acc: 0.8041 - val_loss: 0.4275 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4594 - acc: 0.8093 - val_loss: 0.4157 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4496 - acc: 0.8247 - val_loss: 0.4049 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4407 - acc: 0.8247 - val_loss: 0.3951 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4321 - acc: 0.8247 - val_loss: 0.3864 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4245 - acc: 0.8247 - val_loss: 0.3786 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b480ae4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.7139 - acc: 0.5052 - val_loss: 0.6756 - val_acc: 0.5738\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6809 - acc: 0.5722 - val_loss: 0.6424 - val_acc: 0.6557\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6498 - acc: 0.6649 - val_loss: 0.6117 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6234 - acc: 0.7216 - val_loss: 0.5834 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5981 - acc: 0.7577 - val_loss: 0.5573 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5747 - acc: 0.7732 - val_loss: 0.5337 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5538 - acc: 0.7887 - val_loss: 0.5121 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5344 - acc: 0.8041 - val_loss: 0.4926 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5162 - acc: 0.8041 - val_loss: 0.4752 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5001 - acc: 0.7990 - val_loss: 0.4596 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4851 - acc: 0.8196 - val_loss: 0.4455 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4718 - acc: 0.8299 - val_loss: 0.4329 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4593 - acc: 0.8299 - val_loss: 0.4215 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4483 - acc: 0.8299 - val_loss: 0.4116 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4378 - acc: 0.8351 - val_loss: 0.4027 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4282 - acc: 0.8351 - val_loss: 0.3945 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4198 - acc: 0.8351 - val_loss: 0.3872 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4114 - acc: 0.8351 - val_loss: 0.3810 - val_acc: 0.8525\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4045 - acc: 0.8351 - val_loss: 0.3754 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3975 - acc: 0.8402 - val_loss: 0.3702 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb45fac10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6951 - acc: 0.4974 - val_loss: 0.6427 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6481 - acc: 0.6528 - val_loss: 0.5976 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6107 - acc: 0.7409 - val_loss: 0.5581 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5733 - acc: 0.7876 - val_loss: 0.5241 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5428 - acc: 0.8187 - val_loss: 0.4941 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5171 - acc: 0.8238 - val_loss: 0.4677 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4912 - acc: 0.8238 - val_loss: 0.4450 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4706 - acc: 0.8290 - val_loss: 0.4251 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4518 - acc: 0.8290 - val_loss: 0.4080 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4366 - acc: 0.8290 - val_loss: 0.3938 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4218 - acc: 0.8290 - val_loss: 0.3828 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4090 - acc: 0.8394 - val_loss: 0.3731 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3975 - acc: 0.8342 - val_loss: 0.3651 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3875 - acc: 0.8394 - val_loss: 0.3583 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3789 - acc: 0.8446 - val_loss: 0.3522 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3704 - acc: 0.8497 - val_loss: 0.3474 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3628 - acc: 0.8497 - val_loss: 0.3445 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3560 - acc: 0.8394 - val_loss: 0.3421 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3494 - acc: 0.8394 - val_loss: 0.3402 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3433 - acc: 0.8394 - val_loss: 0.3390 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb4886700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7739 - acc: 0.2953 - val_loss: 0.7311 - val_acc: 0.4262\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7193 - acc: 0.3627 - val_loss: 0.6768 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6700 - acc: 0.6269 - val_loss: 0.6286 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6290 - acc: 0.6995 - val_loss: 0.5856 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5929 - acc: 0.7409 - val_loss: 0.5467 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5602 - acc: 0.7772 - val_loss: 0.5117 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5331 - acc: 0.7927 - val_loss: 0.4810 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5078 - acc: 0.8083 - val_loss: 0.4546 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4856 - acc: 0.8083 - val_loss: 0.4319 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4667 - acc: 0.8135 - val_loss: 0.4126 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4497 - acc: 0.8135 - val_loss: 0.3965 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4354 - acc: 0.8187 - val_loss: 0.3833 - val_acc: 0.8525\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4220 - acc: 0.8238 - val_loss: 0.3724 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4119 - acc: 0.8238 - val_loss: 0.3631 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4014 - acc: 0.8238 - val_loss: 0.3550 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3929 - acc: 0.8342 - val_loss: 0.3481 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3844 - acc: 0.8342 - val_loss: 0.3420 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3777 - acc: 0.8394 - val_loss: 0.3370 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3712 - acc: 0.8446 - val_loss: 0.3328 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3651 - acc: 0.8446 - val_loss: 0.3290 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb693fca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6717 - acc: 0.5825 - val_loss: 0.6262 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6297 - acc: 0.6959 - val_loss: 0.5834 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5919 - acc: 0.7268 - val_loss: 0.5461 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5572 - acc: 0.7680 - val_loss: 0.5134 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5282 - acc: 0.7887 - val_loss: 0.4841 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5042 - acc: 0.8144 - val_loss: 0.4585 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4814 - acc: 0.8247 - val_loss: 0.4361 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4611 - acc: 0.8351 - val_loss: 0.4169 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4436 - acc: 0.8402 - val_loss: 0.4004 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4282 - acc: 0.8402 - val_loss: 0.3863 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4140 - acc: 0.8454 - val_loss: 0.3746 - val_acc: 0.8689\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4015 - acc: 0.8351 - val_loss: 0.3652 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3909 - acc: 0.8351 - val_loss: 0.3575 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3804 - acc: 0.8454 - val_loss: 0.3512 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3720 - acc: 0.8454 - val_loss: 0.3459 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3644 - acc: 0.8505 - val_loss: 0.3412 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3566 - acc: 0.8505 - val_loss: 0.3367 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3499 - acc: 0.8505 - val_loss: 0.3335 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3439 - acc: 0.8557 - val_loss: 0.3302 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3382 - acc: 0.8557 - val_loss: 0.3270 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb693f160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7321 - acc: 0.4227 - val_loss: 0.6863 - val_acc: 0.5574\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6824 - acc: 0.5722 - val_loss: 0.6344 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6373 - acc: 0.7165 - val_loss: 0.5891 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6008 - acc: 0.7732 - val_loss: 0.5496 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5662 - acc: 0.7887 - val_loss: 0.5148 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5404 - acc: 0.8093 - val_loss: 0.4838 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5142 - acc: 0.8144 - val_loss: 0.4566 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4941 - acc: 0.8144 - val_loss: 0.4326 - val_acc: 0.9180\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4766 - acc: 0.8196 - val_loss: 0.4117 - val_acc: 0.9180\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4603 - acc: 0.8144 - val_loss: 0.3941 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4452 - acc: 0.8093 - val_loss: 0.3793 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4337 - acc: 0.8144 - val_loss: 0.3667 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4219 - acc: 0.8093 - val_loss: 0.3561 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4137 - acc: 0.8093 - val_loss: 0.3472 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4042 - acc: 0.8196 - val_loss: 0.3403 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3966 - acc: 0.8247 - val_loss: 0.3348 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3896 - acc: 0.8247 - val_loss: 0.3306 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3829 - acc: 0.8196 - val_loss: 0.3272 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3772 - acc: 0.8196 - val_loss: 0.3244 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3717 - acc: 0.8247 - val_loss: 0.3219 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab275eee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6863 - acc: 0.5464 - val_loss: 0.6201 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6376 - acc: 0.6546 - val_loss: 0.5697 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5951 - acc: 0.7526 - val_loss: 0.5261 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5586 - acc: 0.8093 - val_loss: 0.4890 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5273 - acc: 0.8247 - val_loss: 0.4580 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5004 - acc: 0.8247 - val_loss: 0.4319 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4768 - acc: 0.8299 - val_loss: 0.4101 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4563 - acc: 0.8299 - val_loss: 0.3917 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4395 - acc: 0.8247 - val_loss: 0.3768 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4250 - acc: 0.8299 - val_loss: 0.3640 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4126 - acc: 0.8299 - val_loss: 0.3533 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4017 - acc: 0.8299 - val_loss: 0.3446 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3929 - acc: 0.8247 - val_loss: 0.3374 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3844 - acc: 0.8299 - val_loss: 0.3316 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3770 - acc: 0.8351 - val_loss: 0.3267 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3710 - acc: 0.8402 - val_loss: 0.3232 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3654 - acc: 0.8454 - val_loss: 0.3213 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3603 - acc: 0.8454 - val_loss: 0.3205 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3553 - acc: 0.8557 - val_loss: 0.3200 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3509 - acc: 0.8660 - val_loss: 0.3204 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab27398b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7204 - acc: 0.3990 - val_loss: 0.6586 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6510 - acc: 0.6788 - val_loss: 0.5886 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5938 - acc: 0.7358 - val_loss: 0.5307 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5479 - acc: 0.7772 - val_loss: 0.4843 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5081 - acc: 0.7927 - val_loss: 0.4468 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4765 - acc: 0.8031 - val_loss: 0.4178 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4494 - acc: 0.8135 - val_loss: 0.3946 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4279 - acc: 0.8135 - val_loss: 0.3774 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4106 - acc: 0.8187 - val_loss: 0.3647 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3946 - acc: 0.8187 - val_loss: 0.3555 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3818 - acc: 0.8342 - val_loss: 0.3480 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3697 - acc: 0.8446 - val_loss: 0.3420 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3597 - acc: 0.8342 - val_loss: 0.3361 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3498 - acc: 0.8394 - val_loss: 0.3324 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3412 - acc: 0.8446 - val_loss: 0.3301 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3336 - acc: 0.8497 - val_loss: 0.3288 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3268 - acc: 0.8497 - val_loss: 0.3282 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3204 - acc: 0.8497 - val_loss: 0.3278 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3143 - acc: 0.8601 - val_loss: 0.3265 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3088 - acc: 0.8601 - val_loss: 0.3266 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab266f1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6806 - acc: 0.5959 - val_loss: 0.6207 - val_acc: 0.6885\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6137 - acc: 0.7202 - val_loss: 0.5520 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5593 - acc: 0.7979 - val_loss: 0.4962 - val_acc: 0.9180\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5151 - acc: 0.7979 - val_loss: 0.4519 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4793 - acc: 0.8083 - val_loss: 0.4169 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4505 - acc: 0.8031 - val_loss: 0.3895 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4270 - acc: 0.8031 - val_loss: 0.3690 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4101 - acc: 0.8135 - val_loss: 0.3538 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3946 - acc: 0.8290 - val_loss: 0.3426 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3817 - acc: 0.8290 - val_loss: 0.3351 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3709 - acc: 0.8394 - val_loss: 0.3314 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3626 - acc: 0.8394 - val_loss: 0.3292 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3558 - acc: 0.8446 - val_loss: 0.3294 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3488 - acc: 0.8497 - val_loss: 0.3289 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3425 - acc: 0.8549 - val_loss: 0.3274 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3365 - acc: 0.8549 - val_loss: 0.3253 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3319 - acc: 0.8653 - val_loss: 0.3229 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3263 - acc: 0.8653 - val_loss: 0.3203 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3217 - acc: 0.8705 - val_loss: 0.3163 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3177 - acc: 0.8756 - val_loss: 0.3128 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab24e93a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6782 - acc: 0.5464 - val_loss: 0.6012 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6114 - acc: 0.7938 - val_loss: 0.5398 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5573 - acc: 0.8351 - val_loss: 0.4882 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5134 - acc: 0.8351 - val_loss: 0.4463 - val_acc: 0.9180\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4769 - acc: 0.8402 - val_loss: 0.4122 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4472 - acc: 0.8402 - val_loss: 0.3846 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4231 - acc: 0.8402 - val_loss: 0.3630 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4033 - acc: 0.8454 - val_loss: 0.3467 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3864 - acc: 0.8454 - val_loss: 0.3354 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3712 - acc: 0.8557 - val_loss: 0.3277 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3603 - acc: 0.8814 - val_loss: 0.3222 - val_acc: 0.9016\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3496 - acc: 0.8763 - val_loss: 0.3184 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3420 - acc: 0.8763 - val_loss: 0.3153 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3339 - acc: 0.8763 - val_loss: 0.3135 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3273 - acc: 0.8763 - val_loss: 0.3119 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3210 - acc: 0.8763 - val_loss: 0.3116 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3159 - acc: 0.8763 - val_loss: 0.3117 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3109 - acc: 0.8866 - val_loss: 0.3131 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3064 - acc: 0.8866 - val_loss: 0.3139 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3018 - acc: 0.8866 - val_loss: 0.3150 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb47b01f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6853 - acc: 0.5825 - val_loss: 0.6167 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6178 - acc: 0.7938 - val_loss: 0.5501 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5630 - acc: 0.8041 - val_loss: 0.4951 - val_acc: 0.9180\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5195 - acc: 0.8144 - val_loss: 0.4498 - val_acc: 0.9180\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4865 - acc: 0.8247 - val_loss: 0.4131 - val_acc: 0.9180\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4584 - acc: 0.8247 - val_loss: 0.3841 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4373 - acc: 0.8196 - val_loss: 0.3621 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4191 - acc: 0.8247 - val_loss: 0.3464 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4037 - acc: 0.8351 - val_loss: 0.3363 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3914 - acc: 0.8299 - val_loss: 0.3301 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3818 - acc: 0.8351 - val_loss: 0.3260 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3736 - acc: 0.8351 - val_loss: 0.3225 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3658 - acc: 0.8351 - val_loss: 0.3188 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3591 - acc: 0.8402 - val_loss: 0.3149 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3528 - acc: 0.8402 - val_loss: 0.3097 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3469 - acc: 0.8402 - val_loss: 0.3057 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3414 - acc: 0.8557 - val_loss: 0.3025 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3369 - acc: 0.8557 - val_loss: 0.3002 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3326 - acc: 0.8608 - val_loss: 0.2991 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3282 - acc: 0.8608 - val_loss: 0.2991 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac026a3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6494 - acc: 0.7113 - val_loss: 0.5805 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5928 - acc: 0.7938 - val_loss: 0.5263 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5450 - acc: 0.8196 - val_loss: 0.4820 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5067 - acc: 0.8144 - val_loss: 0.4452 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4743 - acc: 0.8196 - val_loss: 0.4161 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4490 - acc: 0.8299 - val_loss: 0.3923 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4264 - acc: 0.8299 - val_loss: 0.3742 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4097 - acc: 0.8351 - val_loss: 0.3598 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3933 - acc: 0.8505 - val_loss: 0.3499 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3822 - acc: 0.8557 - val_loss: 0.3435 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3709 - acc: 0.8608 - val_loss: 0.3392 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3629 - acc: 0.8557 - val_loss: 0.3371 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3546 - acc: 0.8608 - val_loss: 0.3367 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3487 - acc: 0.8608 - val_loss: 0.3367 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3437 - acc: 0.8608 - val_loss: 0.3362 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3383 - acc: 0.8608 - val_loss: 0.3365 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3341 - acc: 0.8660 - val_loss: 0.3365 - val_acc: 0.9016\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3295 - acc: 0.8660 - val_loss: 0.3369 - val_acc: 0.9016\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3253 - acc: 0.8660 - val_loss: 0.3362 - val_acc: 0.9016\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3213 - acc: 0.8711 - val_loss: 0.3352 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c5d0ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7420 - acc: 0.5803 - val_loss: 0.6979 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6289 - acc: 0.6321 - val_loss: 0.5903 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5604 - acc: 0.6943 - val_loss: 0.5207 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5075 - acc: 0.7513 - val_loss: 0.4734 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4667 - acc: 0.7720 - val_loss: 0.4372 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4334 - acc: 0.8290 - val_loss: 0.4056 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4072 - acc: 0.8342 - val_loss: 0.3820 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3865 - acc: 0.8394 - val_loss: 0.3643 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3707 - acc: 0.8446 - val_loss: 0.3530 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3600 - acc: 0.8446 - val_loss: 0.3458 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3475 - acc: 0.8549 - val_loss: 0.3458 - val_acc: 0.8525\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3382 - acc: 0.8653 - val_loss: 0.3501 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3296 - acc: 0.8549 - val_loss: 0.3571 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3221 - acc: 0.8549 - val_loss: 0.3629 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3177 - acc: 0.8705 - val_loss: 0.3680 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb00585e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.7230 - acc: 0.5440 - val_loss: 0.6194 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6570 - acc: 0.6321 - val_loss: 0.5577 - val_acc: 0.7541\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5978 - acc: 0.7098 - val_loss: 0.5110 - val_acc: 0.7869\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5556 - acc: 0.7565 - val_loss: 0.4750 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5184 - acc: 0.7824 - val_loss: 0.4454 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4872 - acc: 0.8083 - val_loss: 0.4201 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4616 - acc: 0.7979 - val_loss: 0.3974 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4383 - acc: 0.8031 - val_loss: 0.3784 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4185 - acc: 0.8135 - val_loss: 0.3627 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4021 - acc: 0.8083 - val_loss: 0.3511 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3879 - acc: 0.8187 - val_loss: 0.3438 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3761 - acc: 0.8187 - val_loss: 0.3404 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3653 - acc: 0.8394 - val_loss: 0.3403 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3567 - acc: 0.8342 - val_loss: 0.3436 - val_acc: 0.8361\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3495 - acc: 0.8446 - val_loss: 0.3473 - val_acc: 0.8361\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3436 - acc: 0.8446 - val_loss: 0.3509 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3390 - acc: 0.8497 - val_loss: 0.3525 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3338 - acc: 0.8497 - val_loss: 0.3518 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb6960a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8883 - acc: 0.3814 - val_loss: 0.7636 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7843 - acc: 0.4588 - val_loss: 0.6811 - val_acc: 0.5902\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6993 - acc: 0.5412 - val_loss: 0.6161 - val_acc: 0.6557\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6358 - acc: 0.6649 - val_loss: 0.5660 - val_acc: 0.7377\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5841 - acc: 0.7268 - val_loss: 0.5249 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5426 - acc: 0.7526 - val_loss: 0.4883 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5056 - acc: 0.8041 - val_loss: 0.4557 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4731 - acc: 0.8093 - val_loss: 0.4265 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4428 - acc: 0.8299 - val_loss: 0.3991 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4147 - acc: 0.8454 - val_loss: 0.3742 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3912 - acc: 0.8505 - val_loss: 0.3541 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3704 - acc: 0.8557 - val_loss: 0.3388 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3540 - acc: 0.8608 - val_loss: 0.3283 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3432 - acc: 0.8608 - val_loss: 0.3219 - val_acc: 0.9016\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3330 - acc: 0.8711 - val_loss: 0.3190 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3259 - acc: 0.8660 - val_loss: 0.3190 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3208 - acc: 0.8557 - val_loss: 0.3213 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3164 - acc: 0.8557 - val_loss: 0.3240 - val_acc: 0.8852\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3146 - acc: 0.8557 - val_loss: 0.3280 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3109 - acc: 0.8608 - val_loss: 0.3301 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c622550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6798 - acc: 0.6237 - val_loss: 0.6136 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6082 - acc: 0.7320 - val_loss: 0.5281 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5510 - acc: 0.7680 - val_loss: 0.4608 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5098 - acc: 0.7680 - val_loss: 0.4103 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4780 - acc: 0.7835 - val_loss: 0.3750 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4506 - acc: 0.7887 - val_loss: 0.3512 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4280 - acc: 0.8041 - val_loss: 0.3359 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4141 - acc: 0.8196 - val_loss: 0.3282 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4026 - acc: 0.8144 - val_loss: 0.3247 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3934 - acc: 0.8144 - val_loss: 0.3251 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3876 - acc: 0.8299 - val_loss: 0.3261 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3790 - acc: 0.8196 - val_loss: 0.3230 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3733 - acc: 0.8299 - val_loss: 0.3181 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3674 - acc: 0.8351 - val_loss: 0.3143 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3623 - acc: 0.8402 - val_loss: 0.3127 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3585 - acc: 0.8402 - val_loss: 0.3113 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3545 - acc: 0.8454 - val_loss: 0.3115 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3514 - acc: 0.8454 - val_loss: 0.3131 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3490 - acc: 0.8454 - val_loss: 0.3126 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3459 - acc: 0.8505 - val_loss: 0.3159 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b480aef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7331 - acc: 0.5206 - val_loss: 0.7176 - val_acc: 0.5082\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6696 - acc: 0.5309 - val_loss: 0.6684 - val_acc: 0.5574\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6306 - acc: 0.5670 - val_loss: 0.6338 - val_acc: 0.5738\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5979 - acc: 0.5979 - val_loss: 0.6080 - val_acc: 0.6393\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5739 - acc: 0.6753 - val_loss: 0.5848 - val_acc: 0.7049\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5519 - acc: 0.7577 - val_loss: 0.5621 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5329 - acc: 0.7990 - val_loss: 0.5399 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5144 - acc: 0.8299 - val_loss: 0.5163 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4973 - acc: 0.8351 - val_loss: 0.4915 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4793 - acc: 0.8402 - val_loss: 0.4674 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4611 - acc: 0.8454 - val_loss: 0.4441 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4419 - acc: 0.8402 - val_loss: 0.4224 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4239 - acc: 0.8402 - val_loss: 0.4040 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4043 - acc: 0.8351 - val_loss: 0.3895 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3919 - acc: 0.8402 - val_loss: 0.3801 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3787 - acc: 0.8608 - val_loss: 0.3737 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3715 - acc: 0.8557 - val_loss: 0.3699 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3627 - acc: 0.8505 - val_loss: 0.3646 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3543 - acc: 0.8505 - val_loss: 0.3611 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3483 - acc: 0.8505 - val_loss: 0.3574 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c622f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6417 - acc: 0.6218 - val_loss: 0.4866 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5244 - acc: 0.7565 - val_loss: 0.4225 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4549 - acc: 0.8083 - val_loss: 0.3892 - val_acc: 0.8197\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4137 - acc: 0.8238 - val_loss: 0.3737 - val_acc: 0.8525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3898 - acc: 0.8290 - val_loss: 0.3657 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3733 - acc: 0.8290 - val_loss: 0.3589 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3603 - acc: 0.8394 - val_loss: 0.3529 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3486 - acc: 0.8342 - val_loss: 0.3467 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3371 - acc: 0.8549 - val_loss: 0.3469 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3276 - acc: 0.8601 - val_loss: 0.3424 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3175 - acc: 0.8601 - val_loss: 0.3395 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3100 - acc: 0.8705 - val_loss: 0.3398 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3033 - acc: 0.8653 - val_loss: 0.3392 - val_acc: 0.8525\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2968 - acc: 0.8705 - val_loss: 0.3377 - val_acc: 0.8525\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2919 - acc: 0.8808 - val_loss: 0.3351 - val_acc: 0.8689\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2882 - acc: 0.8756 - val_loss: 0.3328 - val_acc: 0.8689\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2823 - acc: 0.8756 - val_loss: 0.3312 - val_acc: 0.8689\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2776 - acc: 0.8756 - val_loss: 0.3310 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2726 - acc: 0.8756 - val_loss: 0.3297 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2679 - acc: 0.8860 - val_loss: 0.3272 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b240d5af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7569 - acc: 0.4145 - val_loss: 0.6852 - val_acc: 0.6066\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6593 - acc: 0.6062 - val_loss: 0.5795 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5909 - acc: 0.6995 - val_loss: 0.5078 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5368 - acc: 0.7461 - val_loss: 0.4554 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4962 - acc: 0.7772 - val_loss: 0.4175 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4610 - acc: 0.8135 - val_loss: 0.3895 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4317 - acc: 0.8290 - val_loss: 0.3729 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4087 - acc: 0.8290 - val_loss: 0.3654 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3902 - acc: 0.8394 - val_loss: 0.3628 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3746 - acc: 0.8394 - val_loss: 0.3613 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3655 - acc: 0.8394 - val_loss: 0.3616 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3584 - acc: 0.8446 - val_loss: 0.3589 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3511 - acc: 0.8497 - val_loss: 0.3536 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3454 - acc: 0.8549 - val_loss: 0.3486 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3400 - acc: 0.8549 - val_loss: 0.3480 - val_acc: 0.9016\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3326 - acc: 0.8756 - val_loss: 0.3467 - val_acc: 0.9016\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3271 - acc: 0.8705 - val_loss: 0.3452 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3221 - acc: 0.8756 - val_loss: 0.3438 - val_acc: 0.8689\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3174 - acc: 0.8808 - val_loss: 0.3425 - val_acc: 0.8689\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3134 - acc: 0.8860 - val_loss: 0.3400 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab2739dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7155 - acc: 0.4691 - val_loss: 0.6107 - val_acc: 0.7541\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6197 - acc: 0.6392 - val_loss: 0.5349 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5558 - acc: 0.7320 - val_loss: 0.4694 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4991 - acc: 0.7577 - val_loss: 0.4152 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4545 - acc: 0.8144 - val_loss: 0.3726 - val_acc: 0.9180\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4161 - acc: 0.8196 - val_loss: 0.3436 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3824 - acc: 0.8351 - val_loss: 0.3277 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3585 - acc: 0.8557 - val_loss: 0.3204 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3418 - acc: 0.8454 - val_loss: 0.3201 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3315 - acc: 0.8505 - val_loss: 0.3214 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3221 - acc: 0.8505 - val_loss: 0.3239 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3172 - acc: 0.8557 - val_loss: 0.3254 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3118 - acc: 0.8660 - val_loss: 0.3244 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3055 - acc: 0.8763 - val_loss: 0.3226 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac0188af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.7924 - acc: 0.4897 - val_loss: 0.6369 - val_acc: 0.6393\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6364 - acc: 0.6495 - val_loss: 0.5271 - val_acc: 0.7869\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5449 - acc: 0.7423 - val_loss: 0.4629 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5090 - acc: 0.7680 - val_loss: 0.4202 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4857 - acc: 0.7835 - val_loss: 0.3880 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4641 - acc: 0.7990 - val_loss: 0.3647 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4415 - acc: 0.8196 - val_loss: 0.3519 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4200 - acc: 0.8144 - val_loss: 0.3465 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4023 - acc: 0.8196 - val_loss: 0.3483 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3922 - acc: 0.8351 - val_loss: 0.3531 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3816 - acc: 0.8402 - val_loss: 0.3544 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3742 - acc: 0.8351 - val_loss: 0.3539 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3665 - acc: 0.8454 - val_loss: 0.3500 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac00a9280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5704 - acc: 0.7062 - val_loss: 0.4215 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4950 - acc: 0.7732 - val_loss: 0.3865 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4398 - acc: 0.8299 - val_loss: 0.3645 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4061 - acc: 0.8402 - val_loss: 0.3477 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3831 - acc: 0.8454 - val_loss: 0.3323 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3628 - acc: 0.8454 - val_loss: 0.3243 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3511 - acc: 0.8505 - val_loss: 0.3224 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3419 - acc: 0.8557 - val_loss: 0.3253 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3358 - acc: 0.8557 - val_loss: 0.3246 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3292 - acc: 0.8660 - val_loss: 0.3257 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3235 - acc: 0.8660 - val_loss: 0.3275 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3185 - acc: 0.8711 - val_loss: 0.3309 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab21ea430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.7079 - acc: 0.5026 - val_loss: 0.6001 - val_acc: 0.7705\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5960 - acc: 0.7461 - val_loss: 0.5044 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5141 - acc: 0.8083 - val_loss: 0.4342 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4574 - acc: 0.8031 - val_loss: 0.3820 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4134 - acc: 0.8187 - val_loss: 0.3453 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3859 - acc: 0.8238 - val_loss: 0.3247 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3666 - acc: 0.8187 - val_loss: 0.3139 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3511 - acc: 0.8342 - val_loss: 0.3140 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3400 - acc: 0.8497 - val_loss: 0.3188 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3298 - acc: 0.8446 - val_loss: 0.3232 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3201 - acc: 0.8497 - val_loss: 0.3287 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3124 - acc: 0.8497 - val_loss: 0.3321 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3c3472fd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6075 - acc: 0.6839 - val_loss: 0.5105 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4973 - acc: 0.7565 - val_loss: 0.4268 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4430 - acc: 0.7876 - val_loss: 0.3847 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4091 - acc: 0.8135 - val_loss: 0.3637 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3860 - acc: 0.8238 - val_loss: 0.3539 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3696 - acc: 0.8238 - val_loss: 0.3466 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3561 - acc: 0.8290 - val_loss: 0.3439 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3442 - acc: 0.8497 - val_loss: 0.3499 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3338 - acc: 0.8653 - val_loss: 0.3567 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3242 - acc: 0.8705 - val_loss: 0.3627 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3172 - acc: 0.8705 - val_loss: 0.3646 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3096 - acc: 0.8756 - val_loss: 0.3582 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb69f3af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6942 - acc: 0.5619 - val_loss: 0.5932 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5519 - acc: 0.7474 - val_loss: 0.4653 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4634 - acc: 0.7938 - val_loss: 0.3842 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4114 - acc: 0.8247 - val_loss: 0.3358 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3716 - acc: 0.8557 - val_loss: 0.3135 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3484 - acc: 0.8608 - val_loss: 0.3079 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3304 - acc: 0.8711 - val_loss: 0.3148 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3195 - acc: 0.8763 - val_loss: 0.3212 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3101 - acc: 0.8866 - val_loss: 0.3261 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3030 - acc: 0.8918 - val_loss: 0.3290 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2992 - acc: 0.8814 - val_loss: 0.3314 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3c346e4af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6329 - acc: 0.6443 - val_loss: 0.5208 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5363 - acc: 0.7835 - val_loss: 0.4431 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4708 - acc: 0.8196 - val_loss: 0.3900 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4299 - acc: 0.8299 - val_loss: 0.3580 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3995 - acc: 0.8196 - val_loss: 0.3422 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3833 - acc: 0.8351 - val_loss: 0.3342 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3704 - acc: 0.8351 - val_loss: 0.3262 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3576 - acc: 0.8454 - val_loss: 0.3180 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3495 - acc: 0.8454 - val_loss: 0.3166 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3401 - acc: 0.8660 - val_loss: 0.3167 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3338 - acc: 0.8711 - val_loss: 0.3225 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3275 - acc: 0.8763 - val_loss: 0.3282 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3224 - acc: 0.8763 - val_loss: 0.3349 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3180 - acc: 0.8660 - val_loss: 0.3420 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b4852e430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6342 - acc: 0.6443 - val_loss: 0.5397 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5208 - acc: 0.7887 - val_loss: 0.4425 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4555 - acc: 0.8093 - val_loss: 0.3784 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4147 - acc: 0.8299 - val_loss: 0.3432 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3864 - acc: 0.8351 - val_loss: 0.3304 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3657 - acc: 0.8454 - val_loss: 0.3300 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3545 - acc: 0.8557 - val_loss: 0.3387 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3449 - acc: 0.8608 - val_loss: 0.3466 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3383 - acc: 0.8660 - val_loss: 0.3517 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3303 - acc: 0.8660 - val_loss: 0.3552 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3254 - acc: 0.8711 - val_loss: 0.3516 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b480ae9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6002 - acc: 0.6943 - val_loss: 0.4423 - val_acc: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4687 - acc: 0.8135 - val_loss: 0.3635 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3988 - acc: 0.8083 - val_loss: 0.3426 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3569 - acc: 0.8394 - val_loss: 0.3448 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3304 - acc: 0.8497 - val_loss: 0.3511 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3166 - acc: 0.8601 - val_loss: 0.3628 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3017 - acc: 0.8653 - val_loss: 0.3664 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2923 - acc: 0.8705 - val_loss: 0.3778 - val_acc: 0.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb45faaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7301 - acc: 0.4870 - val_loss: 0.5185 - val_acc: 0.9180\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5389 - acc: 0.7927 - val_loss: 0.4010 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4485 - acc: 0.8031 - val_loss: 0.3362 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3985 - acc: 0.8135 - val_loss: 0.3127 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3717 - acc: 0.8394 - val_loss: 0.3227 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3546 - acc: 0.8549 - val_loss: 0.3456 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3479 - acc: 0.8705 - val_loss: 0.3621 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3441 - acc: 0.8653 - val_loss: 0.3589 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3342 - acc: 0.8653 - val_loss: 0.3425 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb45fab80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7944 - acc: 0.3557 - val_loss: 0.5579 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5689 - acc: 0.7526 - val_loss: 0.4185 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4532 - acc: 0.8093 - val_loss: 0.3475 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3922 - acc: 0.8351 - val_loss: 0.3195 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3608 - acc: 0.8557 - val_loss: 0.3137 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3436 - acc: 0.8557 - val_loss: 0.3230 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3308 - acc: 0.8763 - val_loss: 0.3317 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3173 - acc: 0.8866 - val_loss: 0.3419 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3070 - acc: 0.8969 - val_loss: 0.3470 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2963 - acc: 0.8866 - val_loss: 0.3443 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb693f040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6235 - acc: 0.6186 - val_loss: 0.4606 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4945 - acc: 0.8144 - val_loss: 0.3722 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4241 - acc: 0.8351 - val_loss: 0.3319 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3869 - acc: 0.8196 - val_loss: 0.3219 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3659 - acc: 0.8351 - val_loss: 0.3207 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3529 - acc: 0.8351 - val_loss: 0.3180 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3417 - acc: 0.8505 - val_loss: 0.3179 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3336 - acc: 0.8557 - val_loss: 0.3155 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3253 - acc: 0.8763 - val_loss: 0.3167 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3177 - acc: 0.8763 - val_loss: 0.3232 - val_acc: 0.8852\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3059 - acc: 0.8763 - val_loss: 0.3196 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2960 - acc: 0.8814 - val_loss: 0.3152 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2897 - acc: 0.8814 - val_loss: 0.3170 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2822 - acc: 0.8763 - val_loss: 0.3284 - val_acc: 0.8852\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2731 - acc: 0.8866 - val_loss: 0.3418 - val_acc: 0.8525\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2683 - acc: 0.8969 - val_loss: 0.3528 - val_acc: 0.8361\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2628 - acc: 0.8969 - val_loss: 0.3467 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b486f20d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7978 - acc: 0.4588 - val_loss: 0.5714 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5578 - acc: 0.8041 - val_loss: 0.4230 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4507 - acc: 0.8351 - val_loss: 0.3556 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4050 - acc: 0.8505 - val_loss: 0.3354 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3776 - acc: 0.8557 - val_loss: 0.3421 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3605 - acc: 0.8402 - val_loss: 0.3576 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3464 - acc: 0.8557 - val_loss: 0.3707 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3335 - acc: 0.8711 - val_loss: 0.3760 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3232 - acc: 0.8763 - val_loss: 0.3815 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab21eaee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6273 - acc: 0.6321 - val_loss: 0.4157 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4389 - acc: 0.8342 - val_loss: 0.3349 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3666 - acc: 0.8446 - val_loss: 0.3334 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3418 - acc: 0.8705 - val_loss: 0.3515 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3233 - acc: 0.8705 - val_loss: 0.3748 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3080 - acc: 0.8756 - val_loss: 0.3673 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2940 - acc: 0.8860 - val_loss: 0.3606 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2790 - acc: 0.8756 - val_loss: 0.3681 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb46b7af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6751 - acc: 0.5907 - val_loss: 0.4636 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4662 - acc: 0.8187 - val_loss: 0.3573 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3821 - acc: 0.8290 - val_loss: 0.3368 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3538 - acc: 0.8342 - val_loss: 0.3437 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3367 - acc: 0.8653 - val_loss: 0.3454 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3275 - acc: 0.8653 - val_loss: 0.3482 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3162 - acc: 0.8756 - val_loss: 0.3523 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3026 - acc: 0.8860 - val_loss: 0.3544 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab21b7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6552 - acc: 0.6237 - val_loss: 0.4236 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4407 - acc: 0.8454 - val_loss: 0.3314 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3707 - acc: 0.8608 - val_loss: 0.3192 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3354 - acc: 0.8557 - val_loss: 0.3208 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3212 - acc: 0.8814 - val_loss: 0.3336 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3115 - acc: 0.8866 - val_loss: 0.3502 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3004 - acc: 0.8814 - val_loss: 0.3534 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2863 - acc: 0.8763 - val_loss: 0.3453 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab22d5dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7346 - acc: 0.4742 - val_loss: 0.4624 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5037 - acc: 0.8299 - val_loss: 0.3538 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4122 - acc: 0.8299 - val_loss: 0.3147 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3810 - acc: 0.8247 - val_loss: 0.3067 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3621 - acc: 0.8351 - val_loss: 0.3152 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3449 - acc: 0.8557 - val_loss: 0.3213 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3279 - acc: 0.8608 - val_loss: 0.3207 - val_acc: 0.8852\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3109 - acc: 0.8660 - val_loss: 0.3229 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2982 - acc: 0.8866 - val_loss: 0.3307 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c57cee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6466 - acc: 0.6186 - val_loss: 0.4192 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4452 - acc: 0.8196 - val_loss: 0.3375 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3804 - acc: 0.8247 - val_loss: 0.3380 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3674 - acc: 0.8557 - val_loss: 0.3628 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3481 - acc: 0.8660 - val_loss: 0.3615 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3359 - acc: 0.8763 - val_loss: 0.3590 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3181 - acc: 0.8763 - val_loss: 0.3497 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b4867e0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6453 - acc: 0.5855 - val_loss: 0.3761 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4074 - acc: 0.8187 - val_loss: 0.3235 - val_acc: 0.9016\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3620 - acc: 0.8446 - val_loss: 0.3406 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3211 - acc: 0.8549 - val_loss: 0.3557 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3046 - acc: 0.8549 - val_loss: 0.3804 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2801 - acc: 0.8705 - val_loss: 0.3707 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2711 - acc: 0.8756 - val_loss: 0.3701 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac06ce790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6288 - acc: 0.5907 - val_loss: 0.3759 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4120 - acc: 0.8083 - val_loss: 0.3284 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3652 - acc: 0.8446 - val_loss: 0.3395 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3437 - acc: 0.8549 - val_loss: 0.3467 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3233 - acc: 0.8808 - val_loss: 0.3338 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3127 - acc: 0.8756 - val_loss: 0.3320 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2966 - acc: 0.8808 - val_loss: 0.3468 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c5d0820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6453 - acc: 0.5722 - val_loss: 0.3621 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4011 - acc: 0.8299 - val_loss: 0.3120 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3367 - acc: 0.8763 - val_loss: 0.3209 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3185 - acc: 0.8814 - val_loss: 0.3192 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3116 - acc: 0.8814 - val_loss: 0.3197 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2966 - acc: 0.8969 - val_loss: 0.3465 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2791 - acc: 0.8918 - val_loss: 0.3669 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb0058280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6796 - acc: 0.4742 - val_loss: 0.3960 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4442 - acc: 0.8299 - val_loss: 0.3219 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3794 - acc: 0.8196 - val_loss: 0.3514 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3600 - acc: 0.8402 - val_loss: 0.3658 - val_acc: 0.8852\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3439 - acc: 0.8454 - val_loss: 0.3572 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3232 - acc: 0.8711 - val_loss: 0.3391 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3081 - acc: 0.8660 - val_loss: 0.3382 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac06ce820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6205 - acc: 0.6804 - val_loss: 0.3766 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4093 - acc: 0.8144 - val_loss: 0.3318 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3545 - acc: 0.8454 - val_loss: 0.3481 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3366 - acc: 0.8608 - val_loss: 0.3646 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3268 - acc: 0.8763 - val_loss: 0.3894 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3137 - acc: 0.8866 - val_loss: 0.3782 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2982 - acc: 0.8918 - val_loss: 0.3635 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b480ae5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5747 - acc: 0.7358 - val_loss: 0.3118 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3706 - acc: 0.8549 - val_loss: 0.3585 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3335 - acc: 0.8497 - val_loss: 0.3802 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3108 - acc: 0.8601 - val_loss: 0.3604 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2888 - acc: 0.8705 - val_loss: 0.3901 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2755 - acc: 0.8964 - val_loss: 0.3849 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b240d55e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6184 - acc: 0.5959 - val_loss: 0.3389 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3782 - acc: 0.8238 - val_loss: 0.3775 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3687 - acc: 0.8549 - val_loss: 0.3743 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3435 - acc: 0.8705 - val_loss: 0.3384 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3114 - acc: 0.8756 - val_loss: 0.3420 - val_acc: 0.9180\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2920 - acc: 0.8808 - val_loss: 0.3538 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2759 - acc: 0.8860 - val_loss: 0.3436 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2584 - acc: 0.8912 - val_loss: 0.3480 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2403 - acc: 0.9119 - val_loss: 0.3559 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb69f3c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5713 - acc: 0.6959 - val_loss: 0.3224 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3583 - acc: 0.8454 - val_loss: 0.3430 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3248 - acc: 0.8711 - val_loss: 0.3447 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3159 - acc: 0.8660 - val_loss: 0.3668 - val_acc: 0.8361\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2916 - acc: 0.8711 - val_loss: 0.4063 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2802 - acc: 0.8608 - val_loss: 0.3823 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab21b7b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6207 - acc: 0.5464 - val_loss: 0.3144 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4014 - acc: 0.8196 - val_loss: 0.3356 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3794 - acc: 0.8351 - val_loss: 0.3728 - val_acc: 0.8689\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3416 - acc: 0.8557 - val_loss: 0.3299 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3140 - acc: 0.8608 - val_loss: 0.3090 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3064 - acc: 0.8557 - val_loss: 0.3362 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2843 - acc: 0.8918 - val_loss: 0.3455 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2645 - acc: 0.9021 - val_loss: 0.3578 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2453 - acc: 0.9021 - val_loss: 0.3796 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2244 - acc: 0.9072 - val_loss: 0.3953 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac0146310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6103 - acc: 0.6701 - val_loss: 0.3338 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3819 - acc: 0.8351 - val_loss: 0.3570 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3493 - acc: 0.8608 - val_loss: 0.3761 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3388 - acc: 0.8763 - val_loss: 0.3826 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3195 - acc: 0.8918 - val_loss: 0.3847 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3007 - acc: 0.8918 - val_loss: 0.3928 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab262b430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7334 - acc: 0.5959 - val_loss: 0.4374 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4722 - acc: 0.7979 - val_loss: 0.4075 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4195 - acc: 0.8031 - val_loss: 0.4274 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3793 - acc: 0.8394 - val_loss: 0.3792 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3568 - acc: 0.8394 - val_loss: 0.3570 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3174 - acc: 0.8497 - val_loss: 0.4166 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3172 - acc: 0.8705 - val_loss: 0.4213 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3069 - acc: 0.8705 - val_loss: 0.3684 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2952 - acc: 0.8808 - val_loss: 0.3469 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2822 - acc: 0.8860 - val_loss: 0.3867 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2710 - acc: 0.8860 - val_loss: 0.4473 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2724 - acc: 0.8912 - val_loss: 0.4566 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2670 - acc: 0.9067 - val_loss: 0.4121 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2568 - acc: 0.8964 - val_loss: 0.3735 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab2219700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6109 - acc: 0.6632 - val_loss: 0.3481 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3978 - acc: 0.8290 - val_loss: 0.3802 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3814 - acc: 0.8497 - val_loss: 0.3652 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3437 - acc: 0.8497 - val_loss: 0.3092 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3397 - acc: 0.8394 - val_loss: 0.3329 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3231 - acc: 0.8808 - val_loss: 0.3999 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3186 - acc: 0.8860 - val_loss: 0.3633 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2921 - acc: 0.8756 - val_loss: 0.3547 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2883 - acc: 0.8601 - val_loss: 0.3947 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab2219670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6710 - acc: 0.6649 - val_loss: 0.3899 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3814 - acc: 0.8351 - val_loss: 0.3032 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3667 - acc: 0.8814 - val_loss: 0.3646 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3457 - acc: 0.8969 - val_loss: 0.3940 - val_acc: 0.8689\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3114 - acc: 0.8866 - val_loss: 0.3292 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2882 - acc: 0.8763 - val_loss: 0.3235 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2794 - acc: 0.8711 - val_loss: 0.3309 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3af80ba820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7609 - acc: 0.4433 - val_loss: 0.4528 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4810 - acc: 0.8093 - val_loss: 0.3728 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4290 - acc: 0.7990 - val_loss: 0.4085 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4187 - acc: 0.8299 - val_loss: 0.3521 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3808 - acc: 0.8351 - val_loss: 0.3506 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3583 - acc: 0.8505 - val_loss: 0.3573 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3453 - acc: 0.8505 - val_loss: 0.3590 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3466 - acc: 0.8557 - val_loss: 0.3623 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3392 - acc: 0.8505 - val_loss: 0.3797 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3276 - acc: 0.8505 - val_loss: 0.3969 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b4852ef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8080 - acc: 0.5464 - val_loss: 0.4368 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5302 - acc: 0.7474 - val_loss: 0.3516 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3976 - acc: 0.8299 - val_loss: 0.3919 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3682 - acc: 0.8402 - val_loss: 0.4182 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3460 - acc: 0.8402 - val_loss: 0.3944 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3315 - acc: 0.8660 - val_loss: 0.3777 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3230 - acc: 0.8660 - val_loss: 0.3782 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b482c5670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6618 - acc: 0.6062 - val_loss: 0.3968 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3959 - acc: 0.8290 - val_loss: 0.3490 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3509 - acc: 0.8446 - val_loss: 0.3774 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3145 - acc: 0.8653 - val_loss: 0.3602 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3085 - acc: 0.8549 - val_loss: 0.3526 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2921 - acc: 0.8549 - val_loss: 0.4204 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2919 - acc: 0.8756 - val_loss: 0.3988 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb6960670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5796 - acc: 0.6891 - val_loss: 0.3602 - val_acc: 0.8361\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4194 - acc: 0.8187 - val_loss: 0.3457 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3547 - acc: 0.8549 - val_loss: 0.3960 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3369 - acc: 0.8653 - val_loss: 0.3991 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3112 - acc: 0.8653 - val_loss: 0.3439 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2957 - acc: 0.8705 - val_loss: 0.3848 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2703 - acc: 0.8860 - val_loss: 0.5110 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2499 - acc: 0.8912 - val_loss: 0.5008 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2208 - acc: 0.9016 - val_loss: 0.4499 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2046 - acc: 0.9016 - val_loss: 0.4596 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c7a8ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6523 - acc: 0.5773 - val_loss: 0.3504 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4029 - acc: 0.8505 - val_loss: 0.4313 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3405 - acc: 0.8505 - val_loss: 0.3582 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3293 - acc: 0.8660 - val_loss: 0.3471 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3056 - acc: 0.8608 - val_loss: 0.4417 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3141 - acc: 0.8557 - val_loss: 0.4193 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2706 - acc: 0.8608 - val_loss: 0.3663 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2715 - acc: 0.8711 - val_loss: 0.4133 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2620 - acc: 0.8866 - val_loss: 0.5068 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb48ddb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6481 - acc: 0.6134 - val_loss: 0.3502 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4439 - acc: 0.7938 - val_loss: 0.4462 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3631 - acc: 0.8351 - val_loss: 0.4935 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3406 - acc: 0.8454 - val_loss: 0.4434 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3032 - acc: 0.8608 - val_loss: 0.4199 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2885 - acc: 0.8557 - val_loss: 0.4118 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb48861f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6499 - acc: 0.5825 - val_loss: 0.3284 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4083 - acc: 0.8144 - val_loss: 0.4366 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4155 - acc: 0.8196 - val_loss: 0.3948 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3522 - acc: 0.8660 - val_loss: 0.3227 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3412 - acc: 0.8454 - val_loss: 0.3403 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3344 - acc: 0.8505 - val_loss: 0.3669 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3285 - acc: 0.8402 - val_loss: 0.3652 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2945 - acc: 0.8711 - val_loss: 0.3523 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2805 - acc: 0.8866 - val_loss: 0.3549 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb47b03a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6847 - acc: 0.5337 - val_loss: 0.3333 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3871 - acc: 0.8290 - val_loss: 0.4267 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3310 - acc: 0.8860 - val_loss: 0.3695 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3052 - acc: 0.8705 - val_loss: 0.3286 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2906 - acc: 0.8860 - val_loss: 0.3976 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2814 - acc: 0.8601 - val_loss: 0.4518 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2525 - acc: 0.8808 - val_loss: 0.3819 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2595 - acc: 0.9067 - val_loss: 0.3783 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2349 - acc: 0.9067 - val_loss: 0.4643 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac036e550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6970 - acc: 0.5648 - val_loss: 0.3361 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3969 - acc: 0.8031 - val_loss: 0.4829 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3551 - acc: 0.8705 - val_loss: 0.3385 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3422 - acc: 0.8446 - val_loss: 0.3327 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2968 - acc: 0.8705 - val_loss: 0.3980 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2878 - acc: 0.8808 - val_loss: 0.4075 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2606 - acc: 0.9016 - val_loss: 0.4023 - val_acc: 0.9016\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2523 - acc: 0.8964 - val_loss: 0.4023 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2519 - acc: 0.8860 - val_loss: 0.4173 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab273fee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6085 - acc: 0.6134 - val_loss: 0.3425 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3967 - acc: 0.8247 - val_loss: 0.3927 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3557 - acc: 0.8608 - val_loss: 0.3253 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3255 - acc: 0.8763 - val_loss: 0.3955 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3016 - acc: 0.8763 - val_loss: 0.4437 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2842 - acc: 0.8866 - val_loss: 0.3828 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2635 - acc: 0.8969 - val_loss: 0.3839 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2496 - acc: 0.9021 - val_loss: 0.4092 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac036eb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7666 - acc: 0.4536 - val_loss: 0.3630 - val_acc: 0.9016\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3835 - acc: 0.8299 - val_loss: 0.5229 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3890 - acc: 0.8351 - val_loss: 0.3769 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3385 - acc: 0.8608 - val_loss: 0.3258 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3245 - acc: 0.8402 - val_loss: 0.3500 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3189 - acc: 0.8763 - val_loss: 0.3817 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2996 - acc: 0.8918 - val_loss: 0.3821 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2795 - acc: 0.9072 - val_loss: 0.3961 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2658 - acc: 0.8918 - val_loss: 0.4450 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab2359c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6408 - acc: 0.6804 - val_loss: 0.5287 - val_acc: 0.8033\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4713 - acc: 0.8093 - val_loss: 0.3950 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3279 - acc: 0.8608 - val_loss: 0.3255 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3571 - acc: 0.8299 - val_loss: 0.3326 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3103 - acc: 0.8660 - val_loss: 0.3960 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2942 - acc: 0.8866 - val_loss: 0.4779 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2915 - acc: 0.8711 - val_loss: 0.4853 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2627 - acc: 0.8918 - val_loss: 0.4800 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b240d5dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6274 - acc: 0.6114 - val_loss: 0.4927 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7888 - acc: 0.7668 - val_loss: 0.8299 - val_acc: 0.7213\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5554 - acc: 0.7927 - val_loss: 0.3814 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3239 - acc: 0.8653 - val_loss: 0.3041 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3801 - acc: 0.8601 - val_loss: 0.3103 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2878 - acc: 0.8756 - val_loss: 0.4439 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2866 - acc: 0.8808 - val_loss: 0.5041 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2959 - acc: 0.8860 - val_loss: 0.4644 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2674 - acc: 0.8912 - val_loss: 0.4081 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb693f940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6708 - acc: 0.7306 - val_loss: 0.7116 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5174 - acc: 0.8238 - val_loss: 0.3387 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3744 - acc: 0.8446 - val_loss: 0.3141 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3560 - acc: 0.8549 - val_loss: 0.3514 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3070 - acc: 0.8653 - val_loss: 0.3933 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2870 - acc: 0.8705 - val_loss: 0.3603 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2435 - acc: 0.9119 - val_loss: 0.3522 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2341 - acc: 0.9016 - val_loss: 0.3622 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb471d790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6347 - acc: 0.6134 - val_loss: 0.3845 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4821 - acc: 0.8454 - val_loss: 0.5948 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4339 - acc: 0.8454 - val_loss: 0.3268 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3126 - acc: 0.8660 - val_loss: 0.3751 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2808 - acc: 0.8814 - val_loss: 0.4210 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2612 - acc: 0.8918 - val_loss: 0.4085 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2390 - acc: 0.8866 - val_loss: 0.4223 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2230 - acc: 0.9175 - val_loss: 0.4951 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb48dd310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7890 - acc: 0.5464 - val_loss: 0.4672 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5153 - acc: 0.7784 - val_loss: 0.5688 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4289 - acc: 0.8196 - val_loss: 0.3046 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3500 - acc: 0.8299 - val_loss: 0.2767 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3621 - acc: 0.8196 - val_loss: 0.3339 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3038 - acc: 0.8505 - val_loss: 0.4412 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2831 - acc: 0.8660 - val_loss: 0.4691 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2736 - acc: 0.8660 - val_loss: 0.4791 - val_acc: 0.9016\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2451 - acc: 0.8711 - val_loss: 0.5084 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b0c5d00d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6431 - acc: 0.6856 - val_loss: 0.5277 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7113 - acc: 0.8196 - val_loss: 0.4762 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4435 - acc: 0.8196 - val_loss: 0.4742 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3641 - acc: 0.8454 - val_loss: 0.3404 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3384 - acc: 0.8608 - val_loss: 0.3342 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3156 - acc: 0.8505 - val_loss: 0.4009 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2854 - acc: 0.8763 - val_loss: 0.5133 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2743 - acc: 0.8763 - val_loss: 0.5390 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2502 - acc: 0.8866 - val_loss: 0.5276 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2193 - acc: 0.9021 - val_loss: 0.5328 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb69609d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6280 - acc: 0.5959 - val_loss: 1.0735 - val_acc: 0.6721\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7364 - acc: 0.7824 - val_loss: 0.4831 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4403 - acc: 0.8601 - val_loss: 0.4649 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2755 - acc: 0.8912 - val_loss: 0.5099 - val_acc: 0.7869\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2781 - acc: 0.8964 - val_loss: 0.4280 - val_acc: 0.8361\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2565 - acc: 0.9016 - val_loss: 0.3941 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2418 - acc: 0.8964 - val_loss: 0.4347 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2089 - acc: 0.9223 - val_loss: 0.4994 - val_acc: 0.8361\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1754 - acc: 0.9326 - val_loss: 0.5260 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1479 - acc: 0.9430 - val_loss: 0.5720 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1221 - acc: 0.9430 - val_loss: 0.6714 - val_acc: 0.8361\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b482c5ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7096 - acc: 0.4870 - val_loss: 0.5772 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5481 - acc: 0.8238 - val_loss: 0.2918 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3778 - acc: 0.8705 - val_loss: 0.3833 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3289 - acc: 0.8705 - val_loss: 0.3420 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3066 - acc: 0.8549 - val_loss: 0.3375 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2738 - acc: 0.8808 - val_loss: 0.3640 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2379 - acc: 0.9119 - val_loss: 0.3535 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb69f30d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.8624 - acc: 0.5258 - val_loss: 0.6361 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5632 - acc: 0.7990 - val_loss: 0.5164 - val_acc: 0.8361\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3973 - acc: 0.8247 - val_loss: 0.3435 - val_acc: 0.9016\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3216 - acc: 0.8660 - val_loss: 0.4379 - val_acc: 0.8525\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2942 - acc: 0.8711 - val_loss: 0.5213 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2840 - acc: 0.8660 - val_loss: 0.4938 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2595 - acc: 0.9021 - val_loss: 0.4938 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2372 - acc: 0.9021 - val_loss: 0.5433 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab273f550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1465 - acc: 0.4845 - val_loss: 0.5372 - val_acc: 0.8689\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7081 - acc: 0.7577 - val_loss: 0.7941 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5680 - acc: 0.7526 - val_loss: 0.3389 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3969 - acc: 0.7990 - val_loss: 0.3377 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3936 - acc: 0.8041 - val_loss: 0.3780 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3356 - acc: 0.8247 - val_loss: 0.4683 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3237 - acc: 0.8505 - val_loss: 0.5298 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3185 - acc: 0.8505 - val_loss: 0.4855 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2798 - acc: 0.8763 - val_loss: 0.4663 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab270e940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6385 - acc: 0.5722 - val_loss: 0.4762 - val_acc: 0.8852\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7165 - acc: 0.7680 - val_loss: 0.4985 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6991 - acc: 0.8351 - val_loss: 0.5339 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6127 - acc: 0.8196 - val_loss: 0.6714 - val_acc: 0.8033\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4258 - acc: 0.8402 - val_loss: 0.5713 - val_acc: 0.8033\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3186 - acc: 0.8402 - val_loss: 0.4257 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3215 - acc: 0.8608 - val_loss: 0.4702 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2676 - acc: 0.9021 - val_loss: 0.6012 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2471 - acc: 0.9072 - val_loss: 0.6086 - val_acc: 0.9016\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2232 - acc: 0.9072 - val_loss: 0.6079 - val_acc: 0.8852\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2097 - acc: 0.9227 - val_loss: 0.6672 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ac03013a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.8321 - acc: 0.5181 - val_loss: 0.7332 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.2390 - acc: 0.6839 - val_loss: 0.6989 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5042 - acc: 0.8653 - val_loss: 0.7456 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6150 - acc: 0.8756 - val_loss: 0.6295 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4405 - acc: 0.8860 - val_loss: 0.4754 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2855 - acc: 0.8912 - val_loss: 0.5211 - val_acc: 0.7705\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2850 - acc: 0.8446 - val_loss: 0.4912 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2458 - acc: 0.9067 - val_loss: 0.4340 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2417 - acc: 0.9016 - val_loss: 0.5222 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2010 - acc: 0.9275 - val_loss: 0.7075 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1899 - acc: 0.9275 - val_loss: 0.7166 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1589 - acc: 0.9482 - val_loss: 0.7170 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1383 - acc: 0.9482 - val_loss: 0.7616 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab24895e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6822 - acc: 0.5389 - val_loss: 0.8763 - val_acc: 0.8197\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0798 - acc: 0.7461 - val_loss: 1.1348 - val_acc: 0.6885\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8923 - acc: 0.7409 - val_loss: 0.9127 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6907 - acc: 0.8601 - val_loss: 0.8691 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5724 - acc: 0.8497 - val_loss: 0.6976 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3790 - acc: 0.8497 - val_loss: 0.4825 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2710 - acc: 0.8705 - val_loss: 0.3934 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2836 - acc: 0.9016 - val_loss: 0.3625 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2570 - acc: 0.9067 - val_loss: 0.3705 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2276 - acc: 0.8964 - val_loss: 0.4539 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2016 - acc: 0.9067 - val_loss: 0.5858 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1757 - acc: 0.9275 - val_loss: 0.6432 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1448 - acc: 0.9482 - val_loss: 0.5912 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab2651e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.0179 - acc: 0.5000 - val_loss: 1.3493 - val_acc: 0.7213\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.9514 - acc: 0.7835 - val_loss: 0.5308 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4617 - acc: 0.8247 - val_loss: 0.4565 - val_acc: 0.8525\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3283 - acc: 0.8711 - val_loss: 0.4899 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3161 - acc: 0.8866 - val_loss: 0.5228 - val_acc: 0.9016\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2956 - acc: 0.8866 - val_loss: 0.5665 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2570 - acc: 0.8866 - val_loss: 0.6179 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2191 - acc: 0.9021 - val_loss: 0.6333 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3a9c747820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.9607 - acc: 0.5619 - val_loss: 1.0447 - val_acc: 0.7869\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0233 - acc: 0.7062 - val_loss: 0.4447 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4888 - acc: 0.8402 - val_loss: 0.3380 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4358 - acc: 0.8196 - val_loss: 0.3603 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3537 - acc: 0.8351 - val_loss: 0.5024 - val_acc: 0.8525\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3498 - acc: 0.8557 - val_loss: 0.4703 - val_acc: 0.8852\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2980 - acc: 0.8711 - val_loss: 0.4156 - val_acc: 0.8852\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2831 - acc: 0.8557 - val_loss: 0.4346 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b482c5f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.3921 - acc: 0.4794 - val_loss: 0.7086 - val_acc: 0.8525\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0936 - acc: 0.7320 - val_loss: 0.9409 - val_acc: 0.7705\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7024 - acc: 0.7577 - val_loss: 0.4102 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4640 - acc: 0.8247 - val_loss: 0.3533 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3775 - acc: 0.8196 - val_loss: 0.4353 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3376 - acc: 0.8454 - val_loss: 0.5487 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3229 - acc: 0.8814 - val_loss: 0.5425 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2792 - acc: 0.8763 - val_loss: 0.5793 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2647 - acc: 0.8918 - val_loss: 0.6265 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b486f2310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.0344 - acc: 0.5544 - val_loss: 7.0145 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 5.6879 - acc: 0.5233 - val_loss: 0.7521 - val_acc: 0.8689\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.2955 - acc: 0.8238 - val_loss: 1.5583 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.2024 - acc: 0.8601 - val_loss: 1.6777 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8687 - acc: 0.8601 - val_loss: 1.3064 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5583 - acc: 0.8808 - val_loss: 0.9834 - val_acc: 0.8689\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4190 - acc: 0.8808 - val_loss: 0.7405 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3257 - acc: 0.8860 - val_loss: 0.5860 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3240 - acc: 0.8808 - val_loss: 0.4578 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2844 - acc: 0.8808 - val_loss: 0.4051 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2520 - acc: 0.8860 - val_loss: 0.4469 - val_acc: 0.8689\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2272 - acc: 0.8912 - val_loss: 0.5166 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2185 - acc: 0.9016 - val_loss: 0.5247 - val_acc: 0.8689\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1974 - acc: 0.9067 - val_loss: 0.4995 - val_acc: 0.8689\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1764 - acc: 0.9223 - val_loss: 0.5237 - val_acc: 0.8525\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3ab21f3160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.8520 - acc: 0.6943 - val_loss: 5.6952 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 4.5607 - acc: 0.5026 - val_loss: 1.4547 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.9595 - acc: 0.7979 - val_loss: 2.0809 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.3813 - acc: 0.8238 - val_loss: 1.8898 - val_acc: 0.8689\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7855 - acc: 0.8549 - val_loss: 1.4121 - val_acc: 0.8689\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4346 - acc: 0.8653 - val_loss: 0.9597 - val_acc: 0.9016\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3190 - acc: 0.8705 - val_loss: 0.6902 - val_acc: 0.9180\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3193 - acc: 0.8497 - val_loss: 0.5837 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2990 - acc: 0.8705 - val_loss: 0.5135 - val_acc: 0.8852\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2580 - acc: 0.8860 - val_loss: 0.5229 - val_acc: 0.9016\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2422 - acc: 0.8964 - val_loss: 0.5855 - val_acc: 0.9016\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2168 - acc: 0.9016 - val_loss: 0.6150 - val_acc: 0.9016\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1797 - acc: 0.9326 - val_loss: 0.6645 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1487 - acc: 0.9689 - val_loss: 0.7422 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b4871b670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.4853 - acc: 0.5000 - val_loss: 5.2903 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 3.3698 - acc: 0.5825 - val_loss: 2.1569 - val_acc: 0.7049\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.9922 - acc: 0.7216 - val_loss: 0.9378 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.9919 - acc: 0.8402 - val_loss: 1.0977 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5762 - acc: 0.8969 - val_loss: 1.1304 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3974 - acc: 0.8557 - val_loss: 1.0865 - val_acc: 0.8361\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3039 - acc: 0.8918 - val_loss: 1.0191 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2664 - acc: 0.8763 - val_loss: 0.9551 - val_acc: 0.8689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b480aec10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.1199 - acc: 0.6959 - val_loss: 5.7702 - val_acc: 0.4754\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 5.1953 - acc: 0.5361 - val_loss: 1.1988 - val_acc: 0.8525\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 2.2320 - acc: 0.7835 - val_loss: 1.7394 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.5933 - acc: 0.8299 - val_loss: 1.4560 - val_acc: 0.9016\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8502 - acc: 0.8608 - val_loss: 1.1580 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5347 - acc: 0.8557 - val_loss: 0.9210 - val_acc: 0.8197\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4397 - acc: 0.8299 - val_loss: 0.6689 - val_acc: 0.8361\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4064 - acc: 0.8505 - val_loss: 0.4960 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3732 - acc: 0.8144 - val_loss: 0.4337 - val_acc: 0.8525\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3444 - acc: 0.8041 - val_loss: 0.4323 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2974 - acc: 0.8454 - val_loss: 0.4839 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2773 - acc: 0.8711 - val_loss: 0.5090 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2482 - acc: 0.8660 - val_loss: 0.5038 - val_acc: 0.9016\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2221 - acc: 0.8866 - val_loss: 0.4938 - val_acc: 0.9180\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1977 - acc: 0.8918 - val_loss: 0.5196 - val_acc: 0.9016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3b4852eca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.4090 - acc: 0.5515 - val_loss: 5.1567 - val_acc: 0.5246\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.3079 - acc: 0.6031 - val_loss: 1.0170 - val_acc: 0.8197\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.4592 - acc: 0.8093 - val_loss: 0.5442 - val_acc: 0.8689\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.9987 - acc: 0.7938 - val_loss: 0.4500 - val_acc: 0.8852\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4255 - acc: 0.8351 - val_loss: 0.6190 - val_acc: 0.8852\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3589 - acc: 0.8299 - val_loss: 0.7366 - val_acc: 0.7049\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4373 - acc: 0.8196 - val_loss: 0.5892 - val_acc: 0.8689\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3240 - acc: 0.8763 - val_loss: 0.5581 - val_acc: 0.8852\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2685 - acc: 0.8763 - val_loss: 0.6062 - val_acc: 0.8852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb00589d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6734 - acc: 0.5702 - val_loss: 0.6283 - val_acc: 0.7377\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6217 - acc: 0.6901 - val_loss: 0.5736 - val_acc: 0.8033\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5771 - acc: 0.7603 - val_loss: 0.5283 - val_acc: 0.8361\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5407 - acc: 0.7851 - val_loss: 0.4892 - val_acc: 0.8197\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5089 - acc: 0.8017 - val_loss: 0.4581 - val_acc: 0.8197\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4818 - acc: 0.8099 - val_loss: 0.4319 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4581 - acc: 0.8182 - val_loss: 0.4102 - val_acc: 0.8525\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4404 - acc: 0.8264 - val_loss: 0.3927 - val_acc: 0.8689\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4242 - acc: 0.8264 - val_loss: 0.3784 - val_acc: 0.8689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4099 - acc: 0.8182 - val_loss: 0.3678 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3983 - acc: 0.8306 - val_loss: 0.3583 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3880 - acc: 0.8347 - val_loss: 0.3513 - val_acc: 0.8852\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3796 - acc: 0.8306 - val_loss: 0.3445 - val_acc: 0.8852\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3714 - acc: 0.8430 - val_loss: 0.3388 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3647 - acc: 0.8471 - val_loss: 0.3334 - val_acc: 0.8852\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3583 - acc: 0.8471 - val_loss: 0.3303 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3526 - acc: 0.8512 - val_loss: 0.3277 - val_acc: 0.8852\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3475 - acc: 0.8554 - val_loss: 0.3244 - val_acc: 0.8852\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3432 - acc: 0.8512 - val_loss: 0.3221 - val_acc: 0.8852\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3390 - acc: 0.8512 - val_loss: 0.3204 - val_acc: 0.8852\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100000)\n",
    "params = dict(batch_size=[32, 64, 128], lr= [0.000001, 0.0001, 0.001, 0.01, 0.1,],\n",
    "             neurons=[8, 16, 32, 64, 128, 256, 512])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "grid = GridSearchCV(model, params, return_train_score=True, scoring=make_scorer(roc_auc_score))\n",
    "grid.fit(x_train_scaled, y_train, callbacks=[es], validation_data=(x_test_scaled, y_test))\n",
    "grid_result = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "53       1.042360      0.034008         0.057428        0.003441   \n",
      "88       1.090786      0.059419         0.062460        0.001893   \n",
      "90       1.052872      0.056681         0.147113        0.167978   \n",
      "\n",
      "   param_batch_size param_lr param_neurons  \\\n",
      "53               64    0.001           128   \n",
      "88              128    0.001           128   \n",
      "90              128    0.001           512   \n",
      "\n",
      "                                              params  split0_test_score  \\\n",
      "53   {'batch_size': 64, 'lr': 0.001, 'neurons': 128}           0.861742   \n",
      "88  {'batch_size': 128, 'lr': 0.001, 'neurons': 128}           0.845644   \n",
      "90  {'batch_size': 128, 'lr': 0.001, 'neurons': 512}           0.845644   \n",
      "\n",
      "    split1_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
      "53           0.847643  ...         0.832559        0.035592                1   \n",
      "88           0.847643  ...         0.831768        0.031681                2   \n",
      "90           0.861953  ...         0.827872        0.047176                3   \n",
      "\n",
      "    split0_train_score  split1_train_score  split2_train_score  \\\n",
      "53            0.854731            0.843606            0.869213   \n",
      "88            0.843978            0.845199            0.845150   \n",
      "90            0.858978            0.874094            0.887904   \n",
      "\n",
      "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
      "53            0.835056            0.847770          0.850075         0.011495  \n",
      "88            0.823536            0.846805          0.840934         0.008745  \n",
      "90            0.853682            0.868568          0.868645         0.011983  \n",
      "\n",
      "[3 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(grid_result.sort_values('mean_test_score', ascending=False)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7576 - acc: 0.4421\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6831 - acc: 0.5248\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6219 - acc: 0.6983\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5714 - acc: 0.7603\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5329 - acc: 0.8099\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5017 - acc: 0.8264\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4766 - acc: 0.8264\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4567 - acc: 0.8430\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4369 - acc: 0.8471\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4224 - acc: 0.8430\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4094 - acc: 0.8388\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3985 - acc: 0.8430\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 926us/step - loss: 0.3897 - acc: 0.8471\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3807 - acc: 0.8554\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3734 - acc: 0.8595\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3668 - acc: 0.8595\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3613 - acc: 0.8595\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3559 - acc: 0.8636\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3513 - acc: 0.8636\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3464 - acc: 0.8636\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3423 - acc: 0.8595\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3386 - acc: 0.8595\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3350 - acc: 0.8595\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3316 - acc: 0.8636\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3284 - acc: 0.8719\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3256 - acc: 0.8760\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3226 - acc: 0.8760\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3196 - acc: 0.8760\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3167 - acc: 0.8760\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3142 - acc: 0.8760\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3117 - acc: 0.8760\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3088 - acc: 0.8802\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 938us/step - loss: 0.3066 - acc: 0.8802\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3040 - acc: 0.8802\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 934us/step - loss: 0.3016 - acc: 0.8802\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3417 - acc: 0.843 - 0s 2ms/step - loss: 0.2995 - acc: 0.8843\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2970 - acc: 0.8843\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2948 - acc: 0.8843\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2928 - acc: 0.8802\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 972us/step - loss: 0.2903 - acc: 0.8802\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2883 - acc: 0.8802\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2861 - acc: 0.8802\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2839 - acc: 0.8843\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2819 - acc: 0.8843\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2798 - acc: 0.8843\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2776 - acc: 0.8843\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2756 - acc: 0.8843\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2733 - acc: 0.8843\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2715 - acc: 0.8843\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2696 - acc: 0.8843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3ab22c5be0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=keras_model, epochs=50, lr=0.001, batch_size=64, neurons=128)\n",
    "model.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3bb45fad30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "pred = model.predict(x_test_scaled)\n",
    "conf_df = pd.DataFrame(data=confusion_matrix(pred, y_test),\n",
    "                   columns = [['Predicted Non Diseased', 'Predicted Diseased']],\n",
    "                   index = [['Actual Non Diseased', 'Actual Diseased']]\n",
    "                   )\n",
    "sns.heatmap(conf_df, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2677 - acc: 0.8843\n",
      "Train Score: 0.8842975497245789\n",
      "1/1 [==============================] - 0s 867us/step - loss: 0.3064 - acc: 0.9016\n",
      "Test Score: 0.9016393423080444\n",
      "Recall Score: 0.875\n",
      "Precision Score: 0.9333333333333333\n",
      "AUC Score: 0.9030172413793103\n",
      "F1 Score: 0.9032258064516129 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Train Score:', model.score(x_train_scaled, y_train))\n",
    "print('Test Score:', model.score(x_test_scaled, y_test))\n",
    "print('Recall Score:', recall_score(y_test, model.predict(x_test_scaled)))\n",
    "print('Precision Score:', precision_score(y_test, model.predict(x_test_scaled)))\n",
    "print('AUC Score:', roc_auc_score(y_test, model.predict(x_test_scaled)))\n",
    "print('F1 Score:', f1_score(y_test, model.predict(x_test_scaled)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7679 - acc: 0.2607\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7209 - acc: 0.4356\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6817 - acc: 0.6073\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6462 - acc: 0.6865\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6134 - acc: 0.7756\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5854 - acc: 0.7855\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5603 - acc: 0.7855\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5398 - acc: 0.7954\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5217 - acc: 0.7987\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5055 - acc: 0.7987\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4915 - acc: 0.7987\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4813 - acc: 0.7987\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4713 - acc: 0.7987\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 975us/step - loss: 0.4643 - acc: 0.7987\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4573 - acc: 0.7987\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4517 - acc: 0.7987\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4482 - acc: 0.8020\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4446 - acc: 0.8020\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4427 - acc: 0.8020\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4399 - acc: 0.7987\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4386 - acc: 0.7987\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4370 - acc: 0.7987\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4363 - acc: 0.7954\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4354 - acc: 0.7954\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4348 - acc: 0.7954\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4343 - acc: 0.7954\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4340 - acc: 0.7954\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4337 - acc: 0.7954\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4333 - acc: 0.7954\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4332 - acc: 0.7954\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4330 - acc: 0.7954\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4328 - acc: 0.7954\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4328 - acc: 0.7954\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4327 - acc: 0.7954\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 975us/step - loss: 0.4325 - acc: 0.7954\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4325 - acc: 0.8020\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4324 - acc: 0.8020\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4322 - acc: 0.8020\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4321 - acc: 0.8020\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4320 - acc: 0.8020\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4319 - acc: 0.8020\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4319 - acc: 0.7987\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4319 - acc: 0.8020\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4318 - acc: 0.8020\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4318 - acc: 0.8020\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4316 - acc: 0.8020\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4315 - acc: 0.8020\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4315 - acc: 0.8020\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4314 - acc: 0.8020\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4314 - acc: 0.8020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3ab259e940>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_for_decision_boundary(lr, neurons):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model\n",
    "model_pca = KerasClassifier(build_fn=model_for_decision_boundary, epochs=50, lr=0.001, batch_size=64, neurons=128)\n",
    "model_pca.fit(x_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "resolution = 200# 100x100 background pixels\n",
    "X2d_xmin, X2d_xmax = np.min(x_pca[:,0]), np.max(x_pca[:,0])\n",
    "X2d_ymin, X2d_ymax = np.min(x_pca[:,1]), np.max(x_pca[:,1])\n",
    "xx, yy = np.meshgrid(np.linspace(X2d_xmin, X2d_xmax, resolution), np.linspace(X2d_ymin, X2d_ymax, resolution))\n",
    "zz = model_pca.predict(np.c_[xx.ravel(), yy.ravel()]).reshape((resolution, resolution))\n",
    "plt.scatter(df_pca_no_heart_problem.iloc[:, 0], df_pca_no_heart_problem.iloc[:, 1], label='No heart problem')\n",
    "plt.scatter(df_pca_heart_problem.iloc[:, 0], df_pca_heart_problem.iloc[:, 1], label='Heart problem')\n",
    "plt.legend()\n",
    "plt.contourf(xx, yy, zz, alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
